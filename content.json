{"meta":{"title":"Kuro's Blog","subtitle":"Kuro","description":"坚持 是一种品格","author":"Kuro","url":"https://midkuro.github.io","root":"/"},"pages":[{"title":"about","date":"2020-05-20T09:29:27.000Z","updated":"2020-05-20T09:30:17.111Z","comments":true,"path":"about/index.html","permalink":"https://midkuro.github.io/about/index.html","excerpt":"","text":"关于我从事 JAVA 后台开发，主要开发语言 PHP，熟悉使用 Spring Boot、Spring Cloud 等主流框架；熟悉JVM内存运行区域、类加载机制，熟悉多线程编程，线程安全设计。 对DevOps有一定的了解。编写代码遵循SonarLint检测。 热爱开源项目、热爱新技术、热爱新事物。 关于工作城市：深圳南山区 关于学习正在往终身学习者前进…近期学习方向：NIO 关于座右铭 坚持 是一种品格 关于爱好热爱运动，喜爱羽毛球、看小说。 联系我 Blog: midkuro.io GitHub: midkuro Email: 276302007@qq.com"}],"posts":[{"title":"'Java 垃圾收集器'","slug":"garbage-collector","date":"2020-05-21T14:40:00.000Z","updated":"2020-05-21T15:08:18.149Z","comments":true,"path":"2020/05/21/garbage-collector/","link":"","permalink":"https://midkuro.github.io/2020/05/21/garbage-collector/","excerpt":"","text":"垃圾收集器与内存分配策略GC回收的区间 清理Eden区和Survivor区叫Minor GC； 清理Old区叫Major GC； 清理整个堆空间————包括年轻代和老年代叫Full GC； GC回收的定位保守式 GC在进行 GC 的时候，会从一些已知的位置（也就是GC Roots）开始扫描内存，扫描到一个数字就判断他是不是可能是指向GC堆中的一个指针,然后一直递归的扫描下去，最后完成可达性分析。 这里扫描会涉及上下边界检查，GC堆的上下界是已知的、对齐检查，通常分配空间的时候会有对齐要求，假如说是4字节对齐，那么不能被4整除的数字就肯定不是指针。 这种模糊的判断方法因为无法准确判断一个位置上是否是真的指向 GC ，GC 采取一种保守的态度，把所有可疑的引用均当作指针，所以被命名为保守式 GC。 优点：不需要准确的判断出一个指针，所以效率快。 缺点：不能识别指针和非指针，对于一些已经死掉的对象，很可能会被误认为仍有地方引用他们，引起无用的内存占用，造成资源浪费。 准确式 GC与保守式 GC 相对的就是准确式 GC，何为 准确式 GC？就是我们准确的知道，某个位置上面是否是指针。 也就是说给定某个位置上的某块数据，要能知道它的准确类型是什么，这样才可以合理地解读数据的含义； GC 所关心的含义就是 这块数据是不是指针。要实现这样的 GC，JVM就要能够判断出所有位置上的数据是不是指向 GC 堆里的引用，包括活动记录（栈、寄存器）里的数据。 在java中实现的方式是：从外部记录下类型信息，存成映射表，在HotSpot虚拟机中把这种映射表称之为OopMap，不同的虚拟机名称可能不一样。 GC开始的时候，就通过OopMap这样的一个映射表知道，在对象内的什么偏移量上是什么类型的数据，而且特定的位置记录下栈和寄存器中哪些位置是引用。 生成映射表的两种方式： 每次都遍历原始的映射表，循环的一个个偏移量扫描过去；这种用法也叫 “ 解释式 ”。 为每个映射表生成一块定制的扫描代码（想像扫描映射表的循环被展开的样子），以后每次要用映射表就直接执行生成的扫描代码；这种用法也叫 “ 编译式 ”。 半保守式 GCJVM可以选择在栈上不记录类型信息，而是通过让数据自身带上标记，也就是对象上记录类型信息。这样的话，扫描栈的时候仍然会跟保守式 GC的过程一样，但扫描到 GC 堆内的对象时因为对象带有足够类型信息了，JVM就能够判断出在该对象内什么位置的数据是引用类型了，这种是半保守式 GC。 垃圾收集器如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。这里讨论的收集器基于JDK 1.7 Update 14之后的 HotSpot 虚拟机，这个虚拟机包含的所有收集器如下图所示 上图展示了 7 种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。接下来将逐一介绍这些收集器的特性、基本原理和使用场景，并重点分析 CMS 和 G1 这两款相对复杂的收集器，了解它们的部分运作细节。 先明确一点：下文是各个收集器的比较，但不是为了挑出最好的收集器，而是挑选最合适的收集器。 Serial收集器 (串行收集器)Serial收集器是最基本、发展历史最悠久的收集器，曾经是虚拟机新生代收集的唯一选择。这是一个单线程的收集器，但它的 “ 单线程 ” 的意义并不仅仅说明它只会使用一个 CPU 或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。 “Stop The World“ 这个名字也许听起来很酷，但这项工作实际上是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难以接受的。下图示意了 Serial/Serial Old 收集器的运行过程。 实际上到现在为止，它依然是虚拟机运行在 Client 模式下的默认新生代收集器。它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 在用户的桌面应用场景中，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本上不会再大了），停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，只要不是频繁发生，这点停顿是可以接受的。所以，Serial 收集器对于运行在 Client 模式下的虚拟机来说是一个很好的选择。 ParNew收集器ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括 Serial 收集器可用的所有控制参数（例如：-XX:SurvivorRatio、-XX:PretenureSizeThreshold、-XX:HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与 Serial 收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。ParNew 收集器的工作过程如下图所示。 ParNew 收集器除了多线程收集之外，其他与 Serial 收集器相比并没有太多创新之处，但它却是许多运行在 Server 模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了 Serial 收集器外，目前只有它能与 CMS 收集器（并发收集器，后面有介绍）配合工作。 ParNew 收集器在单 CPU 的环境中不会有比 Serial 收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证可以超越 Serial 收集器。 当然，随着可以使用的 CPU 的数量的增加，它对于 GC 时系统资源的有效利用还是很有好处的。它默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多（如 32 个)的环境下，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。 注意，从 ParNew 收集器开始，后面还会接触到几款并发和并行的收集器。这里有必要先解释两个名词：并发和并行。这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，它们可以解释如下。 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个 CPU 上。 Parallel Scavenge收集器Parallel Scavenge 收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器……看上去和 ParNew 都一样，那它有什么特别之处呢？ Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS 等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标则是达到一个可控制的吞吐量（Throughput）。 所谓吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了 100 分钟，其中垃圾收集花掉1分钟，那吞吐量就是99% 。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。 MaxGCPauseMillis参数允许的值是一个大于 0 的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值。 不过大家不要认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些，收集 300MB 新生代肯定比收集 500MB 快吧，这也直接导致垃圾收集发生得更频繁一些，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每次停顿70毫秒。停顿时间的确在下降，但吞吐量也降下来了。 GCTimeRatio 参数的值应当是一个 0 到 100 的整数，也就是垃圾收集时间占总时间的比率，相当于是吞吐量的倒数。如果把此参数设置为 19，那允许的最大 GC 时间就占总时间的 5%（即 1/（1+19）），默认值为 99 ，就是允许最大 1%（即 1/（1+99））的垃圾收集时间。 由于与吞吐量关系密切，Parallel Scavenge 收集器也经常称为“吞吐量优先”收集器。除上述两个参数之外，Parallel Scavenge 收集器还有一个参数-XX:+UseAdaptiveSizePolicy值得关注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden 与 Survivor 区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为 GC 自适应的调节策略（GC Ergonomics）。 Serial Old 收集器Serial Old 是 Serial 收集器的老年代版本，它同样是一个单线程收集器，使用“标记-整理”算法。这个收集器的主要意义也是在于给 Client 模式下的虚拟机使用。如果在 Server 模式下，那么它主要还有两大用途：一种用途是在 JDK 1.5 以及之前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途就是作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。这两点都将在后面的内容中详细讲解。Serial Old 收集器的工作过程如下图所示。 Parallel Old收集器Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和“标记-整理”算法。这个收集器是在 JDK 1.6 中才开始提供的，在此之前，新生代的 Parallel Scavenge 收集器一直处于比较尴尬的状态。 原因是，如果新生代选择了 Parallel Scavenge 收集器，老年代除了 Serial Old（PS MarkSweep）收集器外别无选择（Parallel Scavenge 收集器无法与 CMS 收集器配合工作）。 由于老年代 Serial Old 收集器在服务端应用性能上的 “ 拖累 ”，使用了 Parallel Scavenge 收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集中无法充分利用服务器多 CPU 的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有 ParNew 加 CMS 的组合 “ 给力 ”。 直到 Parallel Old 收集器出现后，“ 吞吐量优先 ” 收集器终于有了比较名副其实的应用组合，在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。Parallel Old 收集器的工作过程如下图所示。 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。 目前很大一部分的 Java 应用集中在互联网站或者 B/S 系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS 收集器就非常符合这类应用的需求。 从名字（包含”Mark Sweep”）上就可以看出，CMS 收集器是基于“标记—清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤，包括： 初始标记（CMS initial mark） 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） 其中，初始标记、重新标记这两个步骤仍然需要 “Stop The World“。初始标记仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，并发标记阶段就是进行 GC RootsTracing 的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 CMS 是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、低停顿，但是 CMS 还远达不到完美的程度，它有以下 3 个明显的缺点： 第一、导致吞吐量降低。CMS 收集器对 CPU 资源非常敏感。其实，面向并发设计的程序都对 CPU 资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。 CMS 默认启动的回收线程数是（CPU数量+3）/4，也就是当 CPU 在4个以上时，并发回收时垃圾收集线程不少于 25% 的 CPU 资源，并且随着 CPU 数量的增加而下降。但是当 CPU 不足 4 个（譬如2个）时，CMS 对用户程序的影响就可能变得很大，如果本来 CPU 负载就比较大，还分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了 50%，其实也让人无法接受。 第二、CMS 收集器无法处理浮动垃圾（Floating Garbage），可能出现”Concurrent Mode Failure”失败而导致另一次 Full GC（新生代和老年代同时回收） 的产生。由于 CMS 并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留待下一次 GC 时再清理掉。这一部分垃圾就称为 “ 浮动垃圾 ” 。 也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS 收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。 在 JDK 1.5 的默认设置下，CMS收集器当老年代使用了 68% 的空间后就会被激活，这是一个偏保守的设置，如果在应用中老年代增长不是太快，可以适当调高参数-XX:CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数从而获取更好的性能，在 JDK 1.6 中，CMS 收集器的启动阈值已经提升至 92% 。 要是 CMS 运行期间预留的内存无法满足程序需要，就会出现一次 “Concurrent Mode Failure” 失败，这时虚拟机将启动后备预案：临时启用 Serial Old 收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX:CM SInitiatingOccupancyFraction设置得太高很容易导致大量 “Concurrent Mode Failure” 失败，性能反而降低。 第三、产生空间碎片。 CMS 是一款基于“标记—清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次 Full GC 。 为了解决这个问题，CMS 收集器提供了一个-XX:+UseCMSCompactAtFullCollection开关参数（默认就是开启的），用于在CMS收集器顶不住要进行 Full GC 时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。虚拟机设计者还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction，这个参数是用于设置执行多少次不压缩的 Full GC 后，跟着来一次带压缩的（默认值为0，表示每次进入Full GC时都进行碎片整理）。 G1收集器G1（Garbage-First）收集器是当今收集器技术发展的最前沿成果之一，G1 是一款面向服务端应用的垃圾收集器。HotSpot 开发团队赋予它的使命是（在比较长期的）未来可以替换掉 JDK 1.5 中发布的 CMS 收集器。与其他 GC 收集器相比，G1 具备如下特点。 并行与并发： G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短 Stop-The-World 停顿的时间，部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 Java 程序继续执行。 分代收集： 与其他收集器一样，分代概念在 G1 中依然得以保留。虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次 GC 的旧对象以获取更好的收集效果。 空间整合： 与 CMS 的 “ 标记—清理 ” 算法不同，G1 从整体来看是基于 “ 标记—整理 ” 算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着 G1 运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 GC 。 可预测的停顿： 这是 G1 相对于 CMS 的另一大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时 Java（RTSJ）的垃圾收集器的特征了。 在 G1 之前的其他收集器进行收集的范围都是整个新生代或者老年代，而 G1 不再是这样。使用 G1 收集器时，Java 堆的内存布局就与其他收集器有很大差别，它将整个 Java 堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分 Region （不需要连续）的集合。 G1 收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1 在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region（这也就是Garbage-First名称的来由），保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。 在 G1 收集器中，Region 之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使用 Remembered Set 来避免全堆扫描的。 G1 中每个Region 都有一个与之对应的 Remembered Set，虚拟机发现程序在对 Reference 类型的数据进行写操作时，会产生一个 Write Barrier暂时中断写操作，检查 Reference 引用的对象是否处于不同的 Region 之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过 CardTabl 把相关引用信息记录到被引用对象所属的 Region 的 Remembered Set 之中。当进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描也不会有遗漏。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤： 初始标记（Initial Marking） 并发标记（Concurrent Marking） 最终标记（Final Marking） 筛选回收（Live Data Counting and Evacuation） G1 的前几个步骤的运作过程和 CMS 有很多相似之处。 初始标记阶段仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改 TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的 Region 中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记阶段是从 GC Root 开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 而最终标记阶段则是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中，这阶段需要停顿线程，但是可并行执行。 最后在筛选回收阶段首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划，从Sun公司透露出来的信息来看，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。通过下图可以比较清楚地看到G1收集器的运作步骤中并发和需要停顿的阶段。 GC日志阅读 GC 日志是处理 Java 虚拟机内存问题的基础技能，它只是一些人为确定的规则，没有太多技术含量。 每一种收集器的日志形式都是由它们自身的实现所决定的，换而言之，每个收集器的日志格式都可以不一样。但虚拟机设计者为了方便用户阅读，将各个收集器的日志都维持一定的共性，例如以下两段典型的 GC 日志： 1233.125 : [GC [DefNew : 3324K-＞152K（3712K），0.0025925 secs] 3324K-＞152K（11904K），0.0031680 secs]100.667 : [Full GC [Tenured : 0 K-＞210K（10240K），0.0149142secs] 4603K-＞210K（19456K），[Perm:2999K-＞2999K（21248K）]，0.0150007 secs] [Times:user&#x3D;0.01 sys&#x3D;0.00，real&#x3D;0.02 secs] 最前面的数字33.125： 和 100.667： 代表了 GC 发生的时间，这个数字的含义是从 Java 虚拟机启动以来经过的秒数。 GC 日志开头的 [GC 和 [Full GC 说明了这次垃圾收集的停顿类型，而不是用来区分新生代 GC 还是老年代 GC 的。 如果有 Full ，说明这次 GC 是发生了 Stop-The-World的，例如下面这段新生代收集器 ParNew 的日志也会出现 [Full GC（这一般是因为出现了分配担保失败之类的问题，所以才导致 STW）。如果是调用 System.gc() 方法所触发的收集，那么在这里将显示 [Full GC（System）。 1[Full GC 283.736 : [ParNew : 261599K-＞261599K（261952K），0.0000288 secs] 接下来的 [DefNew、[Tenured、[Perm 表示 GC 发生的区域，这里显示的区域名称与使用的 GC 收集器是密切相关的，例如上面样例所使用的 Serial 收集器中的新生代名为 “Default New Generation“，所以显示的是 [DefNew。 如果是 ParNew 收集器，新生代名称就会变为 [ParNew，意为 “Parallel New Generation“。如果采用 Parallel Scavenge 收集器，那它配套的新生代称为 PSYoungGen，老年代和永久代同理，名称也是由收集器决定的。 后面方括号内部的 3324K-＞152K（3712K含义是 GC 前该内存区域已使用容量 -＞ GC 后该内存区域已使用容量 （该内存区域总容量）。而在方括号之外的 3324K-＞152K（11904K） 表示 GC 前 Java 堆已使用容量 -＞ GC 后 Java 堆已使用容量 （Java 堆总容量）。 再往后，0.0025925 secs 表示该内存区域 GC 所占用的时间，单位是秒。有的收集器会给出更具体的时间数据，如 [Times:user=0.01 sys=0.00，real=0.02 secs] ，这里面的 user、sys 和 real 与 Linux 的 time 命令所输出的时间含义一致，分别代表用户态消耗的 CPU 时间、内核态消耗的 CPU 事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time）。 CPU 时间与墙钟时间的区别是，墙钟时间包括各种非运算的等待耗时，例如等待磁盘 I/O、等待线程阻塞，而 CPU 时间不包括这些耗时，但当系统有多 CPU 或者多核的话，多线程操作会叠加这些 CPU 时间，所以读者看到 user 或 sys 时间超过 real 时间是完全正常的。 垃圾收集器参数总结JDK 1.7 中的各种垃圾收集器到此已全部介绍完毕，在描述过程中提到了很多虚拟机非稳定的运行参数，在下图中整理了这些参数供读者实践时参考。 内存分配与回收策略对象的内存分配，往大方向讲，就是在堆上分配，对象主要分配在新生代的Eden区上。少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。 对象优先在Eden分配大多数情况下，对象在新生代 Eden 区中分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。 虚拟机提供了-XX:+PrintGCDetails这个收集器日志参数，告诉虚拟机在发生垃圾收集行为时打印内存回收日志，并且在进程退出的时候输出当前的内存各区域分配情况。 123456789101112private static final int_1MB=1024 * 1024; /** *VM参数：-verbose:gc-Xms20M-Xmx20M-Xmn10M-XX:+PrintGCDetails -XX:SurvivorRatio=8 */ public static void testAllocation () &#123; byte[] allocation1,allocation2,allocation3,allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; allocation4 = new byte[4 * _1MB];//出现一次Minor GC &#125; 运行结果： 123456789101112[GC [DefNew : 6651K-＞148K（9216K），0.0070106 secs]6651K-＞6292K（19456K），0.0070426 secs][Times:user&#x3D;0.00 sys&#x3D;0.00，real&#x3D;0.00 secs]Heapdef new generation total 9216K,used 4326K[0x029d0000，0x033d0000，0x033d0000）eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）from space 1024K，14%used[0x032d0000，0x032f5370，0x033d0000）to space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）tenured generation total 10240K,used 6144K[0x033d0000，0x03dd0000，0x03dd0000）the space 10240K，60%used[0x033d0000，0x039d0030，0x039d0200，0x03dd0000）compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）the space 12288K，17%used[0x03dd0000，0x03fe0998，0x03fe0a00，0x049d0000）No shared spaces configured. 上方代码的 testAllocation() 方法中，尝试分配 3 个 2MB 大小和 1 个 4MB 大小的对象，在运行时通过-Xms20M、-Xmx20M、-Xmn10M这 3 个参数限制了 Java 堆大小为 20MB ，不可扩展，其中 10MB 分配给新生代，剩下的 10MB 分配给老年代。 -XX:SurvivorRatio=8决定了新生代中 Eden 区与一个 Survivor 区的空间比例是 8:1，从输出的结果也可以清晰地看到 eden space 8192K、from space 1024K、to space 1024K 的信息，新生代总可用空间为 9216KB（Eden区+1个Survivor区的总容量）。 执行 testAllocation() 中分配 allocation4 对象的语句时会发生一次 Minor GC，这次 GC 的结果是新生代 6651KB 变为 148KB ，而总内存占用量则几乎没有减少（因为 allocation1、allocation2、allocation3 三个对象都是存活的，虚拟机几乎没有找到可回收的对象）。 这次 GC 发生的原因是给 allocation4 分配内存的时候，发现 Eden 已经被占用了 6MB，剩余空间已不足以分配 allocation4 所需的 4MB 内存，因此发生 Minor GC。 GC 期间虚拟机又发现已有的 3 个 2MB 大小的对象全部无法放入 Survivor 空间（Survivor 空间只有 1MB 大小），所以只好通过分配担保机制提前转移到老年代去。 这次 GC 结束后，4MB 的 allocation4 对象顺利分配在 Eden 中，因此程序执行完的结果是 Eden 占用 4MB（被allocation4占用），Survivor 空闲，老年代被占用 6MB（被allocation1、allocation2、allocation3占用）。通过 GC 日志可以证实这一点。 Minor GC 和 Full GC 有什么不一样吗？ 新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。 老年代 GC（Major GC/Full GC）：指发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 Parallel Scavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程）。Major GC 的速度一般会比 Minor GC 慢 10 倍以上。 大对象直接进入老年代所谓的大对象是指，需要大量连续内存空间的 Java 对象，最典型的大对象就是那种很长的字符串以及数组（ byte[] 数组就是典型的大对象）。大对象对虚拟机的内存分配来说就是一个坏消息（特别是短命大对象，写程序的时候应当避免），经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。 虚拟机提供了一个 -XX:PretenureSizeThreshold 参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在 Eden 区及两个 Survivor 区之间发生大量的内存复制。 123456789private static final int_1MB=1024 * 1024; /** *VM参数：-verbose:gc-Xms20M-Xmx20M-Xmn10M-XX:+PrintGCDetails-XX:SurvivorRatio=8 *-XX:PretenureSizeThreshold=3145728 */ public static void testPretenureSizeThreshold () &#123; byte[] allocation; allocation = new byte[4 * _1MB];//直接分配在老年代中 &#125; 运行结果： 12345678910Heapdef new generation total 9216K,used 671K[0x029d0000，0x033d0000，0x033d0000）eden space 8192K，8%used[0x029d0000，0x02a77e98，0x031d0000）from space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）tenured generation total 10240K,used 4096K[0x033d0000，0x03dd0000，0x03dd0000）the space 10240K，40%used[0x033d0000，0x037d0010，0x037d0200，0x03dd0000）compacting perm gen total 12288K,used 2107K[0x03dd0000，0x049d0000，0x07dd0000）the space 12288K，17%used[0x03dd0000，0x03fdefd0，0x03fdf000，0x049d0000）No shared spaces configured. 执行以上代码中的 testPretenureSizeThreshold() 方法后，我们看到 Eden 空间几乎没有被使用，而老年代的 10MB 空间被使用了 40%，也就是 4MB 的 allocation 对象直接就分配在老年代中，这是因为 PretenureSizeThreshold 参数被设置为 3MB（就是 3145728，这个参数不能像 -Xmx 之类的参数一样直接写 3MB），因此超过 3MB 的对象都会直接在老年代进行分配。 注意 PretenureSizeThreshold 参数只对 Serial 和 ParNew 两款收集器有效，Parallel Scavenge 收集器不认识这个参数，Parallel Scavenge 收集器一般并不需要设置。如果遇到必须使用此参数的场合，可以考虑 ParNew 加 CMS 的收集器组合。 长期存活的对象将进入老年代虚拟机给每个对象定义了一个对象年龄（Age）计数器。 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并且对象年龄设为 1 。对象在 Survivor 区中每“熬过”一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就将会被晋升到老年代中。 对象晋升老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold设置。 动态对象年龄判定为了能更好地适应不同程序的内存状况，无须等到 MaxTenuringThreshold 中要求的年龄，同年对象达到 Survivor 空间的一半后，他们以及年龄大于他们的对象都将直接进入老年代。 空间分配担保在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。 如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败，如果允许，将继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次Minor GC，如果小于或者HandlePromotionFailure设置不允许，那么将进行Full GC。 “本篇文章主要摘自《深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》”","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/tags/JVM/"}]},{"title":"'Java 垃圾回收机制'","slug":"garbage-collection","date":"2020-05-21T14:30:00.000Z","updated":"2020-05-21T14:57:55.623Z","comments":true,"path":"2020/05/21/garbage-collection/","link":"","permalink":"https://midkuro.github.io/2020/05/21/garbage-collection/","excerpt":"","text":"垃圾回收机制想要了解垃圾收集策略，需要先了解 Java内存区域 说起垃圾收集（Garbage Collection，GC），经过半个多世纪的发展，目前的内存的动态分配与内存回收技术已经相当成熟，一切看起来都进入了 “ 自动化 ” 时代，那为什么还要去了解GC和内存分配呢？ 答案很简单：需要排查各种内存溢出、内存泄漏问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，就需要对这些 “ 自动化 ” 的技术实施必要的监控和调节。 上篇文章介绍了在内存运行时区域的各个部分，其中程序计数器、虚拟机栈、本地方法区随线程而生，随线程而灭，不需要过多考虑回收问题，因为方法结束或者线程结束时，内存自然就回收了，这里主要讨论的是 Java 堆和方法区，本章后续讨论中的 “ 内存 ”分配和回收也仅指着一部分内存。 GC完成需要思考的三件事： 哪些内存需要回收？ 什么时候回收？ 如何回收？ 对象判断机制引用计数法引用计数法（Reference Counting）：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；计数器为 0 时，对象就是不可能再被使用的。简单高效，缺点是无法解决对象之间相互循环引用的问题。 举个简单的例子： 12345678910111213141516public class ReferenceTest &#123; public Object instance = null; public static void test() &#123; ReferenceTest objA = new ReferenceTest(); ReferenceTest objB = new ReferenceTest(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; System.gc(); &#125;&#125; 很显然，在这种情况下，引用计数法是无法解决的，而虚拟机并没有因为这两个对象互相引用就不回收它们，这也从说明虚拟机并不是通过引用计数法来判断对象是否存活的。 可达性分析算法可达性分析（Reachability Analysis），通过一系列的称为 “GC Roots”，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是不可用的。 在 Java 语言中，可作为 GC Roots 的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中 JNI（Native方法）引用的对象 作为 GC Roots 的节点主要在全局性的引用与执行上下文中。要明确的是，Tracing GC必须以当前存活的对象集为 Roots，因此必须选取确定存活的引用类型对象。 GC 管理的区域是 Java 堆，虚拟机栈、方法区和本地方法栈不被 GC 所管理，因此选用这些区域内引用的对象作为 GC Roots，是不会被 GC 所回收的。 其中虚拟机栈和本地方法栈都是线程私有的内存区域，只要线程没有终止，就能确保它们中引用的对象的存活。而方法区中类静态属性引用的对象是显然存活的。常量引用的对象在当前可能存活，因此，也可能是 GC roots 的一部分。 再谈引用JDK1.2 以前，一个对象只有被引用和没有被引用两种状态。 后来，Java 对引用的概念进行了扩充，将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4 种，这 4 种引用强度依次逐渐减弱。 强引用：指在程序代码之中普遍存在的，类似 “ Object obj=new Object() ” 这类的引用，垃圾收集器永远不会回收存活的强引用对象。 软引用：还有用但并非必需的对象。在系统将要发生内存溢出异常之前 ，将会把这些对象列进回收范围之中进行第二次回收。 弱引用：也是用来描述非必需对象的，被弱引用关联的对象 只能生存到下一次垃圾收集发生之前 。当垃圾收集器工作时，无论内存是否足够，都会回收掉只被弱引用关联的对象。 虚引用：是最弱的一种引用关系。 无法通过虚引用来取得一个对象实例 。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 生存与死亡不可达的对象将暂时处于“ 缓刑 ”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程： 如果对象在进行可达性分析后发现没有与 GC Roots 相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize() 方法。 当对象没有覆盖 finalize() 方法，或者 finalize() 方法已经被虚拟机调用过，虚拟机将这两种情况都视为 “没有必要执行”，直接进行第二次标记。 如果这个对象被判定为有必要执行 finalize() 方法，那么这个对象将会放置在一个叫做 F-Queue 的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的 Finalizer 线程去执行它。 这里所谓的 “ 执行 ” 是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，因为如果一个对象在 finalize() 方法中执行缓慢，将很可能会一直阻塞 F-Queue队列，甚至导致整个内存回收系统崩溃。 来看一段代码： 12345678910111213141516171819202122232425262728293031323334353637public class FinalizerTest &#123; public static FinalizerTest object = null; public void isAlive() &#123; System.out.println(\"I'm alive\"); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println(\"method finalize is executed\"); object = this; &#125; public static void main(String[] args) throws Exception &#123; object = new FinalizerTest(); // 第一次执行，finalize方法会自救 object = null; System.gc(); // 因为Finalizer方法优先级低，所以暂停0.5秒等待它 Thread.sleep(500); if (object != null) &#123; object.isAlive(); &#125; else &#123; System.out.println(\"I'm dead\"); &#125; // 下面代码和上面的完全一样，但是这次自救失败了 object = null; System.gc(); Thread.sleep(500); if (object != null) &#123; object.isAlive(); &#125; else &#123; System.out.println(\"I'm dead\"); &#125; &#125;&#125; 输出结果： 123method finalize is executedI&#39;m aliveI&#39;m dead 如果不重写finalize()方法，输出将会是： 12I&#39;m deadI&#39;m dead 值得注意的地方是，代码中有两段完全一样的代码片段，执行结果却是一次逃脱成功，一次失败，这是因为任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。 应该尽量避免使用finalize()方法拯救对象，它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序，finalize()能做的所有工作，使用try-finally或者其他方法能都可以做的更好、更及时。 回收方法区永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类 回收废弃常量与回收 Java 堆中的对象非常类似。以常量池中字面量的回收为例，假如一个字符串 “abc” 已经进入了常量池中，但是当前系统没有任何一个 String 对象引用它，也没有其他地方引用了这个字面量，如果这时发生内存回收，而且必要的话，这个 “abc” 常量就会被系统清理出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。 类需要满足下面3个条件才能算是无用的类： 该类所有实例都已经被回收，也就是说 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader已经被回收。 该类对应的 java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是 “ 可以 ” ，而并不是和对象一样，不使用了就必然会回收。 在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 垃圾收集算法标记-清除算法最基础的收集算法是 标记-清除（Mark-Sweep）算法，算法分为 “ 标记 ” 和 “ 清除 ”两个阶段：首先标记处所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 它主要不足有两个： 效率问题 ： 标记和清除两个过程都不高 空间问题 ： 标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 标记清除算法的执行过程如图所示： 复制算法为了解决效率问题，一种称为 “ 复制 ”(Copying)的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只是用其中的一块。当这块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次性清理掉。 这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要一动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。 复制算法的执行过程如图所示： 现在的商业虚拟机都采用这种算法来回收新生代，IBM 研究指出新生代中的对象 98% 是 “朝生夕死” 的，所以并不需要按照 1:1 的比例来划分内存空间，而是将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor 。 当回收时，将 Eden 和 Survivor 中还存活着的对象一次性地复制到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才用过的 Survivor 空间。HotSpot 虚拟机默认Eden:Survivor = 8:1，也就是每次新生代中可用内存空间为整个新生代容量的 90%（其中一块Survivor不可用），只有 10% 的内存会被“浪费”。 当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于 10% 的对象存活，当 Survivor 空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。 内存的分配担保就好比我们去银行借款，如果我们信誉很好，在 98% 的情况下都能按时偿还，于是银行可能会默认我们下一次也能按时按量地偿还贷款，只需要有一个担保人能保证如果我不能还款时，可以从他的账户扣钱，那银行就认为没有风险了。 内存的分配担保也一样，如果另外一块 Survivor 空间没有足够空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。关于对新生代进行分配担保的内容，在本章稍后在讲解垃圾收集器执行规则时还会再详细讲解。 标记-整理算法复制算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费 50% 的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都 100% 存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，有人提出了另外一种 “ 标记-整理 ”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 标记-整理算法的执行过程如图所示： 第一个过程和标记清除算法的第一个过程一样。然后是整理，最后在清除。 标记整理算法的优缺点： 优点：解决内存碎片问题。 缺点：不仅要标记所有存活对象，还要移动所有存活对象的地址并更新被移动的对象相关的引用。从效率上来说，要低于复制算法。 分代收集策略当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，根据对象存活周期的不同将内存划分为几块并采用不用的垃圾收集算法。 一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。 而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。 HotSpot的算法实现枚举根节点以可达性分析中从 GC Roots 节点找引用链这个操作为例，可作为 GC Roots 的节点主要在全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表）中，现在很多应用仅仅方法区就有数百兆，如果要逐个检查这里面的引用，那么必然会消耗很多时间。 另外，可达性分析对执行时间的敏感还体现在 GC 停顿上，因为这项分析工作必须在一个能确保 一致性 的快照中进行。这里的 一致性 指的是整个分析期间整个执行系统看起来就像被冻结在某个时间点上，不可以出现分析过程中对象引用关系还在不断变化的情况，否则分析结果准确性就无法得到保证。 这点是导致 GC 进行时必须停顿所有 Java 执行线程（Sun将这件事情称为”Stop The World,STW“）的其中一个重要原因，即使是在号称（几乎）不会发生停顿的 CMS 收集器中，枚举根节点时也是必须要停顿的。 因此，目前的主流 Java 虚拟机使用的都是准确式 GC（即虚拟机可以知道内存中某个位置的数据具体是什么类型。），所以当执行系统停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。 在 HotSpot 的实现中，是使用一组称为 OopMap 的数据结构来达到枚举 GC Roots的目的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在 JIT 编译过程中，也会在特定的位置记录栈和寄存器中哪些位置是引用。这样， GC 在扫描时就可以直接得知这些信息了。 OopMap垃圾收集时，收集线程会对栈上的内存进行扫描，看看哪些位置存储了 Reference 类型。如果发现某个位置确实存的是 Reference 类型，就意味着它所引用的对象这一次不能被回收。 但问题是，栈上的本地变量表里面只有一部分数据是 Reference 类型的（它们是 GC 所需要的），那些非 Reference 类型的数据对 GC 而言毫无用处，但 GC 还是不得不对整个栈全部扫描一遍，这是对时间和资源的一种浪费。 一个很自然的想法是，能不能用空间换时间，在某个时候把栈上代表引用的位置全部记录下来，这样到真正 GC 的时候就可以直接读取，而不用再一点一点的扫描了。事实上，大部分主流的虚拟机也正是这么做的，比如 HotSpot ，它使用一种叫做 OopMap 的数据结构来记录这类信息。 OopMap 记录了栈上本地变量到堆上对象的引用关系。枚举根节点时，递归遍历每个栈帧的 OopMap ，通过栈中记录的被引用对象的内存地址，即可找到这些对象（ GC Roots ）。 RememberedSetRememberedSet 主要用来处理频繁的新生代 GC。 目的：执行新生代 GC而不执行老年代 GC 背景：一般来说，GC 的过程是先枚举根节点。根节点有可能在新生代中，也有可能在老年代中。这里由于我们只想回收新生代（换句话说，不想回收老年代），所以没有必要对位于老年代的 GC Roots 做全面的可达性分析。 问题：可能存在位于老年代的某个 GC Root，它引用了新生代的某个对象，这个对象你是不能清除的。那怎么办呢？ 通过空间换时间的办法。事实上，对于位于不同年代对象之间的引用关系，虚拟机会在程序运行过程中给记录下来。对应上面所举的例子，“ 老年代对象引用新生代对象 ” 这种关系，会在引用关系发生时，在新生代边上专门开辟一块空间记录下来，这就是 RememberedSet 。 所以新生代的 GC Roots + RememberedSet 存储的内容，才是新生代收集时真正的 GC Roots 。然后就可以以此为据，在新生代上做可达性分析，进行垃圾回收。 安全点在 OopMap 的协助下，HotSpot 可以快速且准确地完成 GC Roots 枚举，但一个很现实的问题随之而来：可能导致引用关系变化，或者说 OopMap 内容变化的指令非常多，如果为每一条指令都生成对应的 OopMap，那将会需要大量的额外空间，这样 GC 的空间成本将会变得很高。 实际上，HotSpot 也的确没有为每条指令都生成 OopMap，前面已经提到，只是在 “ 特定的位置 ” 记录了这些信息，这些位置称为安全点(SafePoint)，即程序执行时并非在所有地方都能停顿下来开始 GC ，只有在到达安全点时才能暂停。 Safepoint 的选定既不能太少以致于 GC 过少，也不能过于频繁以致于过分增大运行时的负荷。 对于 Safepoint，另一个需要考虑的问题是如何在 GC 发生时让所有线程都 “跑” 到最近的安全点上再停顿下来。这里有两种方案可供选择： 抢先式中断（Preemptive Suspension） 主动式中断（Voluntary Suspension）。 其中抢先式中断不需要线程的执行代码主动去配合，在 GC 发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它 “跑” 到安全点上。现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而响应 GC 事件。 而主动式中断的思想是当 GC 需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地方。 一个线程意味着一个栈，一个栈由多个栈帧组成，一个栈帧对应着一个方法，一个方法里面可能有多个安全点。 GC 发生时，程序首先运行到最近的一个安全点停下来，然后更新自己的 OopMap ，记下栈上哪些位置代表着引用。 安全区域使用 Safepoint 似乎已经完美地解决了如何进入 GC 的问题，但实际情况却并不一定。Safepoint 机制保证了程序执行时，在不太长的时间内就会遇到可进入 GC 的Safepoint。但是，程序“不执行”的时候呢？ 所谓的程序不执行就是没有分配 CPU 时间，典型的例子就是线程处于 Sleep 状态或者 Blocked 状态，这时候线程无法响应 JVM 的中断请求，“走”到安全的地方去中断挂起，JVM 也显然不太可能等待线程重新被分配 CPU 时间。对于这种情况，就需要安全区域（Safe Region）来解决。 安全区域是指在一段代码片段之中，引用关系不会发生变化。 在这个区域中的任意地方开始 GC 都是安全的。我们也可以把 Safe Region 看做是被扩展了的 Safepoint。在线程执行到 Safe Region 中的代码时，首先标识自己已经进入了 Safe Region，那样，当在这段时间里 JVM 要发起 GC 时，就不用管标识自己为 Safe Region状态的线程了。 在线程要离开 Safe Region 时，它要检查系统是否已经完成了根节点枚举（或者是整个 GC 过程），如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开 Safe Region 的信号为止。 “本篇文章主要摘自《深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》”","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/tags/JVM/"}]},{"title":"'Java 运行时数据区域'","slug":"jvm-memory","date":"2020-05-21T14:20:00.000Z","updated":"2020-05-21T14:58:17.614Z","comments":true,"path":"2020/05/21/jvm-memory/","link":"","permalink":"https://midkuro.github.io/2020/05/21/jvm-memory/","excerpt":"","text":"运行时数据区域Java 虚拟机在执行 Java 程序过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随虚拟机进程的启动而存在，有的区域则依赖用户线程的启动和结束而建立和销毁。 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。 由于 Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器内核都只会执行一条线程中的指令。 因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是 Native 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何OutOfMemoryError 情况的区域。 Java虚拟机栈与程序计数器一样，Java 虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。 虚拟机栈描述的是Java方法执行的内存模型：每个方法执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。 经常有人把Java内存区分为堆内存（Heap）和栈内存（Stack），这种划分方式的流行只能说明大多数程序员最关注的、域对象内存分配关系最密切的内存区是这两块。Java 内存区域的划分实际上远比这复杂。 其中所指的“栈”就是虚拟机栈，或者说是虚拟机栈中的局部变量表。 局部变量表局部变量表存放了编译期可知的各种基本数据类型、对象引用和returnAddress类型。 基本数据类型：boolean、byte、char、short、int、float、long、double 对象引用：reference类型，它不等同于对象本身，可能是个对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他于此对象相关的位置 returnAddress类型：指向了一条字节码指令的地址 其中64位长度的 long 和 double 类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。Slot是栈帧中的局部变量表的最小单位。 局部变量表所需的内存空间在编译期完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 虚拟机栈规定了两种异常情况： 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。 如果虚拟机栈可以动态扩展，在扩展时无法申请到足够的内存，将抛出OutOfMemoryError(OOM)异常。 操作数栈Java 虚拟机的解释执行引擎被称为“ 基于栈的执行引擎 ”，其中所指的栈就是指－操作数栈。 操作数栈也常被称为操作栈，它是一个后入先出栈。 和局部变量表一样，操作数栈也是被组织成一个以字长为单位的数组。但是和前者不同的是，它不是通过索引来访问，而是通过标准的栈操作 压栈和出栈 来访问的。 比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用。 虚拟机在操作数栈中存储数据的方式和在局部变量表中是一样的。 虚拟机把操作数栈作为它的工作区，大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。 举例来说，在JVM中执行 a = b + c的字节码执行过程中操作数栈以及局部变量表的变化如下图所示。 局部变量表中存储着 a、b、c 三个局部变量，首先将 b 和 c 分别压入栈中将栈顶的两个数出栈执行求和操作，并将结果再次压入栈顶中，之后将栈顶的数出栈赋值给 a 看一个比较经典的例子 1234567891011public class IncrementTest &#123; public static void main(String[] args) &#123; int i = 1; i = i++; int j = i++; int k = i + ++i * i++; System.out.println(\"i = \" + i); System.out.println(\"j = \" + j); System.out.println(\"k = \" + k); &#125;&#125; 答案： 123i = 4j = 1k = 11 代码分析： 代码 i = i++，自增操作是在局部变量中的，而不是在操作数栈中。 把局部变量表中的 i 的值 1 压入操作数栈中 把局部变量表中的 i 变量自增 1，此时 i 的值为 2 把操作数栈中的值 1 赋值给局部变量表中的 i 变量，此时 i 的值又变为了 1 代码 int j = i++，赋值操作发生在自增前。 把局部变量表中的 i 的值 1 压入操作数栈中 把操作数栈中的值 1 赋值给局部变量表中的 j 变量，此时 j 的值为 1 把局部变量表中的 i 变量自增 1，此时 i 的值为 2 代码 int k = i + ++i * i++ 把局部变量表中的 i 的值 2 压入操作数栈中 把局部变量表中的 i 变量自增 1，此时 i 的值为 3 把局部变量表中的 i 的值 3 压入操作数栈中（++i），此时 i 的值为 3 再把局部变量表中的 i 的值 3 压入操作数栈中（i++），此时 i 的值为 3 把局部变量表中的 i 变量自增 1，此时 i的值为 4 把操作数栈中前两个弹出求乘积（3 * 3 = 9），将结果再次压入操作数栈中 把操作数栈中前两个弹出求和（9 + 2 = 11），将结果再次压入操作数栈中 将操作数栈中的值 11 赋值给局部变量表中的 k 变量，此时 k 的值为 11 总结： 赋值 =，最后计算 = 右边的从左到右加载值依次压入操作数栈 根据运算符的优先级判断先算哪个 自增和自减操作都是直接修改变量的值，不经过操作数栈 最后赋值之前，临时结果都是保存在操作数栈中的 值得提醒的是，i++和++i都不是原子操作，因为它并不会作为一个不可分割的操作来执行，实际上它包含三个独立的操作： 读取i的值 将值加1 然后将计算结果写入i这是一个读取-修改-写入的操作序列，并且其结果状态依赖于之前的状态。 即使使用 volatile 修饰，保证了多个线程多i的可见性，每次从局部变量表读取的都是最新的值，也不是线程安全的。 如果假设 i=9，在某些情况下，多个线程读到的值都为 9，接着执行递增操作，并且都将i设置成 10 ，显然不是线程安全的。 动态链接每个栈帧中包含一个在常量池中对当前方法的引用， 目的是支持方法调用过程的动态连接。 Class 文件中存放了大量的符号引用，这些符号引用一部分会在类加载阶段或第一次使用时转化为直接引用，这种转化称为静态解析，如静态方法、私有方法等等，另一部分将在每一次运行期间转化为直接引用，这部分称为动态连接。栈帧中保存了一个引用，指向该方法在运行时常量池中的位置，通过运行时常量池的符号引用（指向堆），完成将符号引用转化为直接引用。 方法返回地址方法执行时有两种退出情况： 正常退出，即正常执行到任何方法的返回字节码指令，如 return等 异常退出，即某些指令导致了 Java 虚拟机抛出异常并且没有处理 无论何种退出情况，都将返回至方法当前被调用的位置。方法退出的过程相当于弹出当前栈帧，退出可能有三种方式： 返回值压入上层调用栈帧。 异常信息抛给能够处理的栈帧。 PC计数器指向方法调用后的下一条指令。 当方法执行正常退出时，当前栈帧承担着恢复调用者状态的责任，包括恢复调用者的局部变量表和操作数栈，以及正确递增程序计数器、跳过刚才执行的方法调用指令等。调用者的代码在被调用方法的返回值压入调用者栈帧的操作数栈后，会继续正常执行。 本地方法栈本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。Sun HotSpot虚拟机直接就把本地方法栈和虚拟机栈合二为一。 与虚拟机栈一样，本地方法栈区域也会抛出 StackOverflowError 和 OutOfMemoryError 异常。 Java堆对于大多数应用来说，Java 堆（Java Heap）是 Java 虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做 “ GC堆 ”（Garbage Collected Heap）。从内存回收的角度来看，由于现在收集器基本都采用分代收集算法，所以 Java 堆中还可以细分为：新生代和老年代；再细致一点的有 Eden 空间、From Survivor 空间、To Survivor 空间等。 从内存分配的角度来看，线程共享的 Java 堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer,TLAB）。不过无论如何划分，都与存放的内容无关，无论哪个区域，存储的都是对象实例，进一步划分的目的是为了更好的回收内存，或者更快的分配内存。 Java 堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，当前主流的虚拟机都是按照可扩展来实现的（通过 -Xmx 和 -Xms 控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出 OutOfMemoryError异常。 方法区方法区（Method Area）与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 Java 虚拟机规范对方法区的限制非常宽松，除了和 Java 堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。垃圾收集行为在这个区域是比较少出现的，其内存回收目标主要是针对常量池的回收和对类型的卸载。当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError 异常。 HotSpot 虚拟机它是Sun JDK和OpenJDK中所带的虚拟机，也是目前使用范围最广的 Java 虚拟机。在2008年和2009年，Oracle公司分别收购了BEA公司和Sun公司，Oracle同时拥有了两款优秀的Java虚拟机：JRockit VM和HotSpot VM。 永久代对于习惯在HotSpot 虚拟机上开发、部署程序的开发者来说,很多人更愿意把方法区称为“永久代”(Permanent Generation)，本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队把 GC 分代收集扩展至方法区，或者说，使用永久代来实现方法区而已。 目的是为了方法区也可以用堆内存的 GC 垃圾回收器，而不用重新针对方法区做 GC 操作，所以称永久代是方法区的一个存储实现。 方法区只是 JVM 的一种规范，不同的虚拟机实现的原理不一样，只有HotSpot虚拟机才有永久代的概念。 常量池class常量池我们写的每一个 Java 类被编译后，就会形成一份class 文件。class 文件中除了包含类的版本、字段、方法、接口等描述信息外，还有一项信息就是常量池(constant pool table)，用于存放编译器生成的各种字面量(Literal)和符号引用(Symbolic References)。 每个class文件都有一个class常量池。 字面量包括： 文本字符串 八大基本类型的值 被申明为final的常量 符号引用包括： 类和方法的全限定名 字段的名称和描述符 方法的名称和描述符 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。class文件常量池将在类加载后进入方法区的运行时常量池中存放。 一般来说，除了保存 Class 文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。 运行时常量池相对于 Class 文件常量池的另外一个重要特征是具备动态性，Java 语言并不要求常量一定只有编译期才能产生，也就是并非预置入 Class 文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是 String 类的 intern() 方法。 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。 字符串常量池 在HotSpot虚拟机里实现的字符串常量池(string pool)功能的是一个StringTable类，它是一个Hash表，这个StringTable在每个HotSpot虚拟机的实例只有一份，被所有的类共享。字符串常量由一个一个字符组成，放在了StringTable上。 JDK版本变化JDK1.6及以前的版本，字符串常量池是存放在永久代中。 在JDK1.7的版本中，字符串常量池从永久代移出到正常的Java 堆(Java Heap)中，原因是因为永久代空间太小，容易造成OOM。 在JDK1.8的版本中，Hotspot虚拟机废除了永久代，开始使用元空间（Metaspace）实现方法区，字符串常量池依旧保留在堆内存中，其他内容移至元空间，元空间直接在本地内存分配，而不需要占用堆内存，所以不会造成OOM现象。 值得注意的是，方法区只是Jvm的一种规范，Hotspot通过废除永久代，使用元空间实现方法区，并不存在废除方法区、方法区被元空间代替这种说法。 为什么要使用元空间取代永久代的实现？ 字符串存在永久代中，容易出现性能问题和内存溢出 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低 将 HotSpot 与 JRockit 合二为一 1234567public static void main(String[] args) &#123; String str = \"String\"; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; str.intern(); str = str + str; &#125;&#125; 使用JDK1.7 或者 1.8 能够看到，往字符串常量池中无限增加，最终 OOM 的位置是在Java 堆（Java heap）中。 String.intern()用来返回常量池中的某字符串，如果常量池中已经存在该字符串，则直接返回常量池中该对象的引用。否则，在常量池中加入该对象，然后返回引用。 看一道比较常见的面试题，在不考虑 GC 的情况下，下面的代码创建了多少个 String 对象，输出结果是什么？ 123String str1 = new String(\"he\") + new String(\"llo\");String str2 = str1.intern();System.out.println(str1 == str2); 答案： 在 JDK 1.6 下输出是 false，创建了 6 个对象 在 JDK 1.7 之后的版本输出是 true，创建了 5 个对象 代码分析： 为什么输出会有这些变化呢？主要还是字符串池从永久代中脱离、移入堆区的原因， intern() 方法也相应发生了变化： 在 JDK 1.6 中，调用 intern() 首先会在字符串池中寻找equal() 相等的字符串，假如字符串存在就返回该字符串在字符串池中的引用；假如字符串不存在，虚拟机会重新在永久代上创建一个实例，将 StringTable 的一个表项指向这个新创建的实例。 在 JDK 1.7 中，由于字符串池不在永久代了，intern() 做了一些修改，更方便地利用堆中的对象。字符串存在时和 JDK 1.6一样，但是字符串不存在时不再需要重新创建实例，可以直接指向堆上的实例。 我们基于JDK1.7版本，来看个例子： 123String str1 = new String(\"abc\");String str2 = str1.intern();System.out.println(str1 == str2); //false 由于字符串常量池中已存在abc，所以返回了字符串常量池中的引用，如下图所示 再来看个例子： 1234String str1 = new String(\"he\") + new String(\"llo\");str1.intern();String str2 = \"hello\";System.out.println(str1 == str2); //true 该结果等于true应该是能够理解的，不理解的可以查看上文针对该代码的实例分析图 这里扩展一点，若是把str1.intern();代码注释掉，则产生的结果为false。 其原因在于str1对象是通过new对象拼接产生的，字符串常量池中并不存在字符串hello，当调用String str2=&quot;hello&quot;;代码时字符串常量池中产生才该字符串，所以他们并不是同一个地址引用。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域。 在 JDK 1.4 中新加入了 NIO，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。 显然，本机直接内存的分配不会受到 Java 堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括 RAM 以及 SWAP 区或者分页文件）大小以及处理器寻址空间的限制。服务器管理员在配置虚拟机参数时，会根据实际内存设置 -Xmx 等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现 OutOfMemoryError 异常。 “本篇文章主要摘自《深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》”","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/tags/JVM/"}]},{"title":"'kubernetes 环境搭建'","slug":"kubernetes-install","date":"2020-05-21T14:00:00.000Z","updated":"2020-05-21T12:40:08.500Z","comments":true,"path":"2020/05/21/kubernetes-install/","link":"","permalink":"https://midkuro.github.io/2020/05/21/kubernetes-install/","excerpt":"","text":"K8S的安装方式最简单的方法是使用yum install kubernetes命令安装Kubernetes集群，但仍需修改各组件的启动参数，才能完成对Kubernetes集群的配置，整个过程比较复杂，也容易出错。但是对于新手来说是一个熟悉k8s的一个过程，可以适当借鉴学习。 Kubernetes从1.4版本开始引入了命令行工具kubeadm，致力于简化集群的安装过程，并解决Kubernetes集群的高可用问题。在Kubernetes 1.13版本中，kubeadm工具进入GA阶段，宣称已经为生产环境应用准备就绪。比较推荐使用这种方式，安装便捷并且容错率高 本节先讲解基于 yum install kubernetes命令安装 Master节点：192.168.1.132 Node节点：192.168.1.134 K8S基于yum的安装安装前先关闭防火墙 1systemctl stop firewalld 修改系统文件/etc/sysconfig/selinux，将SELINUX=enforcing修改成SELINUX=disabled，然后重启Linux。或者执行以下命令 1setenforce 0 编辑/etc/sysctl.conf添加以下内容 123456net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward=1vm.swappiness = 0fs.inotify.maxuserwatches = 24576vm.max_map_count=655360 然后执行命令 sysctl -p,如果报错，执行命令modprobe br_netfilter 安装Master节点1、安装Docker 安装docker教程 2、Master节点安装etcd 1yum install etcd -y etcd用于K8S的数据存储，原生支持做集群，修改/etc/etcd/etcd.conf配置,指向Master节点 123[root@localhost /]# vim /etc/etcd/etcd.conf6 行：ETCD_LISTEN_CLIENT_URLS=\"http://0.0.0.0:2379\"22行：ETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.1.132:2379\" 启动etcd服务并且设置开机自启 12[root@localhost /]# systemctl start etcd.service[root@localhost /]# systemctl enable etcd.service 检查 12345678[root@localhost /]# netstat -lntup|grep 2379tcp6 0 0 :::2379 :::* LISTEN 117472/etcd#检查健康状态[root@localhost /]# etcdctl -C http://192.168.1.132:2379 cluster-healthmember 8e9e05c52164694d is healthy: got healthy result from http://192.168.1.132:2379cluster is healthy 测试 1234567891011# 插入数据 键（目录）值（123456）[root@localhost /]# etcdctl set /test/word 123456 123456[root@localhost /]# etcdctl ls //test[root@localhost /]# etcdctl ls /test/test/word[root@localhost /]# etcdctl get /test/word # 查看值123456[root@localhost /]#etcdctl rm /test/word # 删除键值对[root@localhost /]#etcdctl rmdir /test # 删除目录 3、Master节点192.168.1.132安装K8S 以下命令根据需求二选一即可 12345#安装Master节点和Node节点的服务，适用于服务器数量不够时共用同一台服务器yum install kubernetes -y#安装Master节点需要的服务，适用于服务器数量充足分离Master和Node节点yum install kubernetes-master.x86_64 -y 本人Master节点[192.168.1.132]也安装了Node节点服务,可以用于测试两个不同宿主机上Node节点通信。 kubelet默认把数据存放在/var/lib/kubelet下面，如果根目录下空间太小，可能会把磁盘撑爆。可以将数据挂载在充足空间的盘上 1234mkdir -p /home/kubeletcp -r /var/lib/kubelet /home/rm -rf /var/lib/kubeletln -sf /home/kubelet /var/lib/kubelet 4、修改apiserver配置文件 安装好了后进入/etc/kubernetes/配置目录修改相关配置 12345678910111213[root@localhost /]# vim /etc/kubernetes/apiserver#服务的监听地址8 行: KUBE_API_ADDRESS=\"--insecure-bind-address=0.0.0.0\"#服务监听的端口11行：KUBE_API_PORT=\"--port=8080\"#通过10250端口控制kubelet14行：KUBELET_PORT=\"--kubelet-port=10250\" #APIserver是通过那个地址和端口连接etcd数据17行：KUBE_ETCD_SERVERS=\"--etcd-servers=http://192.168.1.132:2379\"#K8S创建service服务的网段配置 20行：KUBE_SERVICE_ADDRESSES=\"--service-cluster-ip-range=10.254.0.0/16\"#默认的管理控制插件---将后面的ServiceAccount去掉23行：KUBE_ADMISSION_CONTROL=\"--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota\" 5、修改通用的配置文件config 123[root@localhost kubernetes]# vim /etc/kubernetes/config#通过那个地址端口找到API服务22行：KUBE_MASTER=\"--master=[http://192.168.1.132:8080] 6、启动服务并设置开启自启 123456systemctl enable kube-apiserver.servicesystemctl start kube-apiserver.servicesystemctl enable kube-controller-manager.servicesystemctl start kube-controller-manager.servicesystemctl enable kube-scheduler.servicesystemctl start kube-scheduler.service 7、测试集群是否正常 12345[root@localhost /]# kubectl get componentstatusNAME STATUS MESSAGE ERRORetcd-0 Healthy &#123;\"health\":\"true\"&#125; controller-manager Healthy ok scheduler Healthy ok 安装Node节点1、Node节点192.168.1.134安装K8S 如果没有第二台服务器，Master节点和Node节点同一台服务器时跳过安装步骤 1yum install kubernetes-node.x86_64 -y (自动会安装docker) 值得一提的是，如果Master节点也安装了Node节点的服务，Master节点机器也需要修改以下的所有相关配置 2、修改kube-proxy服务配置文件 12[root@localhost ~]# vim /etc/kubernetes/config22行：KUBE_MASTER=\"--master=[http://192.168.1.132:8080] 3、修改kubelet服务配置文件 1234567891011[root@localhost ~]# vim /etc/kubernetes/kubelet# 监听的地址5行：KUBELET_ADDRESS=\"--address=0.0.0.0\"#kubelet端口 8行：KUBELET_PORT=\"--port=10250\"# 给自己定义唯一的名字 不能冲突 IP地址或者主机名（各自节点改各自节点的IP）11行：KUBELET_HOSTNAME=\"--hostname-override=192.168.1.134\"# Master节点的连接api的地址14行：KUBELET_API_SERVER=\"--api-servers=[http://192.168.1.132:8080]# 节点的DNS配置KUBELET_ARGS=\"--cluster-dns=192.168.1.1 --cluster-domain=cluster.local\" 如果不知道DNS配置，可以执行下列命令 12345[root@localhost kubernetes]# cat /etc/resolv.conf# Generated by NetworkManagernameserver 192.168.1.1nameserver 114.114.114.114search localdomain 如果没有任何信息显示，vim /etc/resolv.conf并增加以下内容nameserver 114.114.114.114然后把该DNS增加到kubelet文件配置中 4、修改服务通用的配置文件config 123[root@localhost kubernetes]# vim /etc/kubernetes/config#通过那个地址端口找到API服务22行：KUBE_MASTER=\"--master=[http://192.168.1.132:8080] 5、启动服务并设置开机自启 12345systemctl start kubelet.service systemctl enable kubelet.service systemctl start kube-proxy.servicesystemctl enable kube-proxy.service 6、在Master节点测试是否有节点加入集群 1234[root@localhost /]# kubectl get nodeNAME STATUS AGE192.168.1.132 Ready 8d192.168.1.134 Ready 9d 安装flanneld网络通讯由于K8S创建的Service、Pod服务均是生成的虚拟IP，两台Node节点之间的Pod通信需要通过第三方插件实现.Master节点和Node节点都需要安装和配置 1、安装flanneld 1yum install flannel -y 2、修改flanneld配置文件 1sed -i 's#http://127.0.0.1:2379#http://192.168.1.132:2379#g' /etc/sysconfig/flanneld 多网卡的话需要在LANNEL_ETCD_ENDPOINTS项中增加--iface=网卡名 这里/etc/sysconfig/flanneld可以设置密钥验证，详情请自行百度! 3、Master节点配置etcd中关于flanneld的Key 12etcdctl mk /atomic.io/network/config '&#123; \"Network\": \"172.16.0.0/16\" &#125;'etcdctl get /atomic.io/network/config 这里的/atomic.io/network需要和/etc/sysconfig/flanneld里的FLANNEL_ETCD_PREFIX配置对应。 4、设置flanneld启动配置 1234567891011121314151617181920[root@localhost /]# vim /usr/lib/systemd/system/flanneld.service[Unit]Description=Flanneld overlay address etcd agentAfter=network.targetAfter=network-online.targetWants=network-online.targetAfter=etcd.serviceBefore=docker.service[Service]Type=notifyEnvironmentFile=/etc/sysconfig/flanneldEnvironmentFile=-/etc/sysconfig/docker-networkExecStart=/usr/bin/flanneld-start $FLANNEL_OPTIONSExecStartPost=/usr/libexec/flannel/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/dockerRestart=on-failure[Install]WantedBy=multi-user.targetWantedBy=docker.service 5、设置Docker启动配置 1234567891011121314151617181920212223242526272829303132[root@localhost /]# vim /usr/lib/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=http://docs.docker.comAfter=network.targetWants=docker-storage-setup.serviceRequires=docker-cleanup.timer[Service]Type=notifyNotifyAccess=mainEnvironmentFile=/run/flannel/subnet.env #增加该行配置EnvironmentFile=-/etc/sysconfig/dockerEnvironmentFile=-/etc/sysconfig/docker-storageEnvironmentFile=-/etc/sysconfig/docker-networkEnvironment=GOTRACEBACK=crashEnvironment=DOCKER_HTTP_HOST_COMPAT=1Environment=PATH=/usr/libexec/docker:/usr/bin:/usr/sbin#更改启动方式 如果没有更改过docker存储路径，不需要配置 --graph /home/dockerExecStart=/usr/bin/dockerd --graph /home/docker $DOCKER_NETWORK_OPTIONS#增加docker启动的防火墙拦截允许配置ExecStartPost=/sbin/iptables -I FORWARD -s 0.0.0.0/0 -j ACCEPTExecReload=/bin/kill -s HUP $MAINPIDLimitNOFILE=1048576LimitNPROC=1048576LimitCORE=infinityTimeoutStartSec=0Restart=on-abnormalKillMode=process[Install]WantedBy=multi-user.target 6、启动flanneld 12345678910111213141516systemctl daemon-reloadsystemctl start flanneld.servicesystemctl enable flanneld.service#重启Master节点服务systemctl restart dockersystemctl restart kube-apiserversystemctl restart kube-controller-managersystemctl restart kube-schedulersystemctl restart kubeletsystemctl restart kube-proxy#重启Node节点服务systemctl restart dockersystemctl restart kubeletsystemctl restart kube-proxy 7、测试网段 以上的一系列操作，主要是为了让flanneld和docker创建的网络处于同一个网段，先通过设置etcd设置flanneld的网段范围，再配置docker启动前加载flanneld的配置从图中能够看到docker0和flannel0都处于同一个网段172.16.0.0中,可以用一个轻巧的容器测试一下 1234#docker拉取网络镜像[root@localhost /]# docker pull docker.io/busybox#分别在Master节点及Node节点执行命令[root@localhost /]# docker run -it docker.io/busybox:latest 从图中可以看到，创建了两个容器，IP分别是172.16.43.6和172.16.43.4互相能够Ping通。 如果不能Ping通，则在每个Node节点上都配置相应的静态路由项 1234#Master节点 #172.16.9.0 为Node节点的flannel0的IP[root@localhost ~]# route add -net 172.16.9.0 netmask 255.255.255.0 gw 192.168.1.134 #Node节点 #172.16.43.0 为Master节点的flannel0的IP[root@localhost ~]# route add -net 172.16.43.0 netmask 255.255.255.0 gw 192.168.1.132 这意味着，每一个新部署的容器都将使用这个Node（docker0的网桥IP）作为它的默认网关。而这些Node（类似路由器）都有其他docker0的路由信息，这样它们就能够相互连通了。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/categories/Kubernetes/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/tags/Kubernetes/"}]},{"title":"'kubernetes 基础概念'","slug":"kubernetes-introduction","date":"2020-05-21T13:50:00.000Z","updated":"2020-05-21T12:40:15.426Z","comments":true,"path":"2020/05/21/kubernetes-introduction/","link":"","permalink":"https://midkuro.github.io/2020/05/21/kubernetes-introduction/","excerpt":"","text":"Docker基本概念什么是DockerDocker是使用 Google公司推出的Go 语言进行开发实现，基于Linux 内核的cgroup、namespace、以及AUFS类的Union FS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术，由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 Docker在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得Docker技术比虚拟机技术更为轻便、快捷。下面的图片比较了Docker和传统虚拟化方式的不同之处。 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程。 而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比 传统虚拟机更为轻便。 为什么要使用Docker作为一种新兴的虚拟化方式，Docker跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源：由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker对系统资源的利用率更高。 更快速的启动时间： Docker容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间 一致的运行环境： Docker的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现这段代码在我机器上没问题啊这类问题。 持续交付和部署： Docker可以通过定制应用镜像来实现持续集成、持续交付、部署。可以通过Dockerfile来进行镜像构建，结合持续集成系统进行集成测试、自动部署。 更轻松的迁移： 由于Docker确保了执行环境的一致性，使得应用的迁移更加容易，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展： Docker使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker团队提供了一大批高质量的官方镜像，既可以直接使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 基本概念镜像Image 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含任何动态数据，其内容在构建之后也不会被改变。 Docker设计时，将其设计为分层存储的架构。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除 前一层的文件，而是仅在当前层标记为该文件已删除。分层存储的特征使得镜像的复用、定制变的更为容易。 容器Container 镜像和容器的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。因此容器可以拥有自己的root文件系统、自己的网络配置、自己的进程空间，甚至自己的用户ID空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。容器也具备分层存储的特征。 Kubernetes什么是KubernetesKubernetes是一个完备的分布式系统支撑平台。Kubernetes具有完备的集群管理能力，包括多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和服务发现机制、内建的智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制，以及多粒度的资源配额管理能力。同时，Kubernetes提供了完善的管理工具，这些工具涵盖了包括开发、部署测试、运维监控在内的各个环节。因此，Kubernetes是一个全新的基于容器技术的分布式架构解决方案，并且是一个一站式的完备的分布式系统开发和支撑平台。 Kubernetes英文中字母K和S中间有8个英文，所以也简称为K8S。 为什么要使用Kubernetes 轻装上阵地开发复杂系统 可以全面拥抱微服务架构 可以随时随地迁移系统 拥有横向弹性扩容机制 Kubernetes基本概念Kubernetes中的大部分概念如Node、Pod、Replication Controller、Service等都可以被看作一种资源对象，几乎所有资源对象都可以通过Kubernetes提供的kubectl工具（或者API编程调用）执行增、删、改、查等操作并将其保存在etcd中持久化存储。从这个角度来看，Kubernetes其实是一个高度自动化的资源控制系统，它通过跟踪对比etcd库里保存的“资源期望状态”与当前环境中的“实际资源状态”的差异来实现自动控制和自动纠错的高级功能。 MasterKubernetes里的Master指的是集群控制节点，在每个Kubernetes集群里都需要有一个Master来负责整个集群的管理和控制，基本上Kubernetes的所有控制命令都发给它，它负责具体的执行过程，我们后面执行的所有命令基本都是在Master上运行的。Master通常会占据一个独立的服务器（高可用部署建议用3台服务器），主要原因是它太重要了，是整个集群的“首脑”，如果它宕机或者不可用，那么对集群内容器应用的管理都将失效。 在Master上运行着以下关键进程: Kubernetes API Server（kube-apiserver） 提供了HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程。 Kubernetes Controller Manager（kube-controller-manager） Kubernetes里所有资源对象的自动化控制中心，可以将其理解为资源对象的大总管。 Kubernetes Scheduler（kube-scheduler） 负责资源调度（Pod调度）的进程，相当于公交公司的调度室，在Master上通常还需要部署etcd服务，因为Kubernetes里的所有资源对象的数据都被保存在etcd中。 Node除了Master，Kubernetes集群中的其他机器被称为Node，在较早的版本中也被称为Minion。与Master一样，Node可以是一台物理主机，也可以是一台虚拟机。Node是Kubernetes集群中的工作负载节点，每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，其上的工作负载会被Master自动转移到其他节点上。 在每个Node上都运行着以下关键进程: kubelet 负责Pod对应的容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能。 kube-proxy 实现Kubernetes Service的通信与负载均衡机制的重要组件。 Docker Engine（docker） Docker引擎，负责本机的容器创建和管理工作。 Node可以在运行期间动态增加到Kubernetes集群中，前提是在这个节点上已经正确安装、配置和启动了上述关键进程，在默认情况下kubelet会向Master注册自己，这也是Kubernetes推荐的Node管理方式。 一旦Node被纳入集群管理范围，kubelet进程就会定时向Master汇报自身的情报，例如操作系统、Docker版本、机器的CPU和内存情况，以及当前有哪些Pod在运行等，这样Master就可以获知每个Node的资源使用情况，并实现高效均衡的资源调度策略。 而某个Node在超过指定时间不上报信息时，会被Master判定为“失联”，Node的状态被标记为不可用（Not Ready），随后Master会触发“工作负载大转移”的自动流程。 我们可以执行下述命令查看在集群中有多少个Node： 然后可以通过kubectl describe node &lt;node_name&gt;查看某个Node的详细信息: PodPod是Kubernetes最重要的基本概念，下图所示是Pod的组成示意图，我们看到每个Pod都有一个特殊的被称为根容器的Pause容器。Pause容器对应的镜像属于Kubernetes平台的一部分，除了Pause容器，每个Pod还包含一个或多个紧密相关的用户业务容器。 为什么Kubernetes会设计出一个全新的Pod的概念并且Pod有这样特殊的组成结构？ 原因之一：在一组容器作为一个单元的情况下，我们难以简单地对“整体”进行判断及有效地行动。比如，一个容器死亡了，此时算是整体死亡么？是N/M的死亡率么？引入业务无关并且不易死亡的Pause容器作为Pod的根容器，以它的状态代表整个容器组的状态，就简单、巧妙地解决了这个难题。 原因之二：Pod里的多个业务容器共享Pause容器的IP，共享Pause容器挂接的Volume，这样既简化了密切关联的业务容器之间的通信问题，也很好地解决了它们之间的文件共享问题。 Kubernetes为每个Pod都分配了唯一的IP地址，称之为Pod IP，一个Pod里的多个容器共享Pod IP地址。Kubernetes要求底层网络支持集群内任意两个Pod之间的TCP/IP直接通信，这通常采用虚拟二层网络技术来实现，例如Flannel、Open vSwitch等 因此我们需要牢记一点：在Kubernetes里，一个Pod里的容器与另外主机上的Pod容器能够直接通信，同一个Pod里的容器之间仅需通过localhost就能互相通信。 Pod、容器与Node的关系: 一个Pod中的应用容器共享同一组资源： PID命名空间：Pod中的不同应用程序可以看到其他应用程序的进程ID 网络命名空间：Pod中的多个容器能够访问同一个IP和端口范围 IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信 UTS命名空间：Pod中的多个容器共享一个主机名 Volumes（共享存储卷）：Pod中的各个容器可以访问在Pod级别定义的Volumes Pod的生命周期通过Replication Controller来管理；通过模板进行定义，然后分配到一个Node上运行，在Pod所包含容器运行结束后，Pod结束。 Kubernetes为Pod设计了一套独特的网络配置，包括：为每个Pod分配一个IP地址，使用Pod名作为容器间通信的主机名等。 LabelLabel（标签）是Kubernetes系统中另外一个核心概念。一个Label是一个key=value的键值对，其中key与value由用户自己指定。Label可以被附加到各种资源对象上，例如Node、Pod、Service、RC等，一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上。Label通常在资源对象定义时确定，也可以在对象创建后动态添加或者删除。 我们可以通过给指定的资源对象捆绑一个或多个不同的Label来实现多维度的资源分组管理功能，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。 Label相当于我们熟悉的“标签”。给某个资源对象定义一个Label，就相当于给它打了一个标签，随后可以通过Label Selector（标签选择器）查询和筛选拥有某些Label的资源对象，Kubernetes通过这种方式实现了类似SQL的简单又通用的对象查询机制。 Service在Kubernetes的世界里，虽然每个Pod都会被分配一个单独的IP地址，但这个IP地址会随着Pod的销毁而消失，这就引出一个问题：如果有一组Pod组成一个集群来提供服务，那么如何来访问它呢？Service！ 一个Service可以看作一组提供相同服务的Pod的对外访问接口，Service作用于哪些Pod是通过Label Selector来定义的。 拥有一个指定的名字（比如my-mysql-server） 拥有一个虚拟IP（Cluster IP、Service IP或VIP）和端口号，销毁之前不会改变，只能内网访问 能够提供某种远程服务能力 被映射到了提供这种服务能力的一组容器应用上 如果Service要提供外网服务，需指定公共IP和NodePort，或外部负载均衡器 Service可以通过配置NodePort，在Node上打开一个主机的真实端口，这样，能够访问Node的客户端就能通过这个端口访问到内部的Service了 Replication ControllerReplication Controller（简称RC）是Kubernetes系统中的核心概念之一，简单来说，它其实定义了一个期望的场景，即声明某种Pod的副本数量在任意时刻都符合某个预期值 目标Pod的定义 目标Pod需要运行的副本数量 要监控的目标Pod标签（Label） Kubernetes通过RC中定义的Label筛选出对应的Pod实例，并实时监控其状态和数量，如果实例数量少于定义的副本数量（Replicas），则会根据RC中定义的Pod模板来创建一个新的Pod，然后将此Pod调度到合适的Node上启动运行，直到Pod实例数量达到预定目标。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/categories/Kubernetes/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/tags/Kubernetes/"}]},{"title":"'docker 安装私服仓库'","slug":"docker-registry","date":"2020-05-21T13:00:00.000Z","updated":"2020-05-21T12:15:54.606Z","comments":true,"path":"2020/05/21/docker-registry/","link":"","permalink":"https://midkuro.github.io/2020/05/21/docker-registry/","excerpt":"","text":"docker私服仓库docker的私服仓库存储不像maven私服有完整独立的应用，它是通过docker获取私服仓库镜像，并根据镜像创建私服仓库容器 说白了，docker的私服仓库的搭建就是拉取镜像、创建容器、上传镜像的过程 宿主机环境IP：192.168.1.131 私服仓库的搭建1、拉取私服镜像 1docker pull registry:2 2、启动私服 1docker run --name registry -tid --privileged=true --restart=always --net=host -v /home/docker/repository:/var/lib/registry registry 这里使用的是V2版本的私服仓库,/var/lib/registry是私服仓库存储上传镜像的路径，把它挂载到宿主机上避免因为容器坏损丢失私服仓库的镜像存储 3、标记镜像 12命令：docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]例子：docker tag mtex-admin 192.168.1.131:5000/mtex-admin 这里以镜像名：mtex-admin为例，标记镜像将其归入某一仓库,再次查看镜像列表 1docker images 能够看见出现了192.168.1.131:5000/mtex-admin镜像名称，细心点会发现它的镜像ID和mtex-admin是一样的也就是说，两个镜像名称都映射到同一个镜像ID上，如何避免这种情况呢？ 可以执行tag命令之后，删除原来的旧镜像名称，只保留一个名称映射 也可以在创建镜像时，镜像名称以[私服IP:端口/名称]命名,不必在执行tag命令 4、上传私服 1docker push 192.168.1.131:5000/mtex-admin 可以看到上传成功了，使用192.168.1.134试一下拉取镜像 1docker pull 192.168.1.131:5000/mtex-admin 5、配置解析 考虑到记住IP比较麻烦，可以在/etc/hosts中增加本地仓库的域名解析 1echo \"192.168.1.131 docker-registry\" &gt;&gt; /etc/hosts 这时候再执行cat /etc/hosts能够看到，已经增加进去了 6、查看私服镜像 可以通过浏览器打开http://192.168.1.131:5000/v2/_catalog查看 7、删除私服镜像 上面已经将私服的镜像内容挂载到宿主机/home/docker/repository路径中，只需要进入对应路径删除镜像即可路径目录是/home/docker/repository/docker/registry/v2/repositories 常见问题Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交互时可能会出现以下错误 1Get https://192.168.1.131:5000/v2/: http: server gave HTTP response to HTTPS client docker版本1.2以上的，在/etc/docker/daemon.json文件中增加以下内容 12#必须要增加在第一行&#123; \"insecure-registries\":[\"192.168.1.131:5000\"] 然后重启docker，重启registry 1systemctl restart docker.service 查看docker版本的命令docker -v，低于1.2的版本可以升级版本，也可以上网寻找解决方法.","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"}]},{"title":"'docker 执行DockerFile创建镜像'","slug":"docker-dockfile","date":"2020-05-21T12:30:00.000Z","updated":"2020-05-21T14:46:01.278Z","comments":true,"path":"2020/05/21/docker-dockfile/","link":"","permalink":"https://midkuro.github.io/2020/05/21/docker-dockfile/","excerpt":"","text":"DockerFile 文件常用详解 FROM：指定基础镜像，必须为第一个命令 12345678格式： FROM &lt;image&gt; FROM &lt;image&gt;:&lt;tag&gt; FROM &lt;image&gt;@&lt;digest&gt;示例： FROM centos:7.2.1511注： tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像 MAINTAINER：维护者信息 123456格式： MAINTAINER &lt;name&gt;示例： MAINTAINER caijinkun MAINTAINER caijinkun &lt;caijinkun@mastercom.cn&gt; MAINTAINER caijinkun \"caijinkun@mastercom.cn\" RUN：构建镜像时执行的命令 123456789101112131415RUN用于在镜像容器中执行命令，其有以下两种命令执行方式：shell执行格式： RUN &lt;command&gt;exec执行格式： RUN [\"executable\", \"param1\", \"param2\"]示例： RUN [\"executable\", \"param1\", \"param2\"] RUN apk update RUN [\"/etc/execfile\", \"arg1\", \"arg1\"]注： RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像， 可以在构建时指定--no-cache参数,如：docker build --no-cache 每执行Run命令，都会创建一个中间镜像层，使得最终创建的镜像文件变大，建议把命令都在一个Run中执行，用&amp;&amp;分隔. ADD：将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget 12345678910格式： ADD &lt;src&gt;... &lt;dest&gt; ADD [\"&lt;src&gt;\",... \"&lt;dest&gt;\"] 用于支持包含空格的路径示例： ADD hom* /mydir/ # 添加所有以\"hom\"开头的文件 ADD hom?.txt /mydir/ # ? 替代一个单字符,例如：\"home.txt\" ADD test relativeDir/ # 添加 \"test\" 到 `WORKDIR`/relativeDir/ ADD test /absoluteDir/ # 添加 \"test\" 到 /absoluteDir/注： 该命令只能添加Dockerfile路径的下层文件，所以需要事先拷贝文件到该路径下 COPY：功能类似ADD，但是是不会自动解压文件，也不能访问网络资源，建议直接用ADD CMD：构建容器后调用，也就是在容器启动时才进行调用 12345678910格式： CMD [\"executable\",\"param1\",\"param2\"] (执行可执行文件，优先) CMD [\"param1\",\"param2\"] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数) CMD command param1 param2 (执行shell内部命令)示例： CMD echo \"This is a test.\" | wc - CMD [\"/usr/bin/wc\",\"--help\"] CMD [\"java\",\"-jar\",\"mtex-config-0.0.1-SNAPSHOT.jar\"]注： CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令 ENTRYPOINT：配置容器，使其可执行化。配合CMD可省去”application”，只使用参数。 1234567891011格式： ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (可执行文件, 优先) ENTRYPOINT command param1 param2 (shell内部命令)示例： FROM ubuntu ENTRYPOINT [\"top\", \"-b\"] CMD [\"-c\"]注： ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT 而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令。 ENV：设置环境变量 1234567格式： ENV &lt;key&gt; &lt;value&gt; #&lt;key&gt;之后的所有内容均会被视为其&lt;value&gt;的组成部分，因此，一次只能设置一个变量 ENV &lt;key&gt;=&lt;value&gt; ... #可以设置多个变量，每个变量为一个\"&lt;key&gt;=&lt;value&gt;\"的键值对，如果&lt;key&gt;中包含空格，可以使用\\来进行转义，也可以通过\"\"来进行标示；另外，反斜线也可以用于续行示例： ENV myName John Doe ENV myDog Rex The Dog ENV myCat=fluffy EXPOSE：指定于外界交互的端口 12345678910格式： EXPOSE &lt;port&gt; [&lt;port&gt;...]示例： EXPOSE 80 443 EXPOSE 8080 EXPOSE 11211/tcp 11211/udp注： EXPOSE并不会让容器的端口访问到主机。要使其可访问 需要在docker run 运行容器时通过 -p 来发布这些端口 或通过 -P 参数来发布EXPOSE导出的所有端口 VOLUME：用于指定持久化目录 123456789101112格式： VOLUME [\"path\"]示例： VOLUME [\"/data\",\"/home\"]注： 和docker run -v 的区别是无法挂载指定的目录. 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能： 1.卷可以容器间共享和重用 2.容器并不一定要和其它容器共享卷 3.修改卷后会立即生效 4.对卷的修改不会对镜像产生影响 5.卷会一直存在，直到没有任何容器在使用它 WORKDIR：工作目录，类似于cd命令 12345678格式： WORKDIR path示例： WORKDIR /home (这时工作目录为/home) WORKDIR jenkins-running-jar (这时工作目录为/home/jenkins-running-jar)注： 通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY等命令都会在该目录下执行。 在使用docker run运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 docker 执行DockerFile创建镜像基础镜像 docker pull centos:7.2.1511先从仓库中拉取一个centos7.2的系统，来作为最底层的镜像 先下载 jre-8u201-linux-x64.tar.gz 下载地址 以此为基础创建一个具备java环境的基础镜像 这里使用jre而非jdk，主要是为了降低镜像大小。 这里注意需要引入镜像的文件必须与Dockerfile路径同级或下级 在jre-8u201-linux-x64.tar.gz文件路径下 vi Dockerfile 创建镜像，拷贝以下内容 123456789101112131415#使用的基础镜像FROM centos:7.2.1511#作者信息MAINTAINER caijinkun \"caijinkun@mastercom.cn\"#安装中文和zip支持RUN yum -y install kde-l10n-Chinese &amp;&amp; yum -y reinstall glibc-common &amp;&amp; yum -y install unzip zip &amp;&amp; yum clean all &amp;&amp; localedef -c -f UTF-8 -i zh_CN zh_CN.utf8#加入jreADD jre-8u201-linux-x64.tar.gz /usr/local/#设置环境变量ENV JAVA_HOME /usr/local/jre1.8.0_201ENV PATH $JAVA_HOME/bin:$PATHENV LC_ALL zh_CN.utf8ENV TZ Asia/Shanghai 执行Dockfile文件 docker build -t java:jre1.8.0.201 . 并检查镜像创建是否成功docker images java mtex-config镜像基础镜像已经完毕，准备创建程序的DockerFile和程序，这里以mtex-config为例 12345678910111213#使用的基础镜像FROM java:jre1.8.0.201#作者信息MAINTAINER caijinkun \"caijinkun@mastercom.cn\"#加入服务ADD mtex-config-0.0.1-SNAPSHOT.zip tmp.zipRUN mkdir -p /home/jenkins-running-jar/mtex-config/ &amp;&amp; unzip -o tmp.zip -d /home/jenkins-running-jar/mtex-config/ &amp;&amp; rm -f tmp.zip &amp;&amp; rm -rf /home/jenkins-running-jar/mtex-config/properties &amp;&amp;rm -rf /home/jenkins-running-jar/mtex-config/properties_*#工作目录WORKDIR /home/jenkins-running-jar/mtex-config/#启动服务CMD [\"nohup\",\"java\",\"-jar\",\"mtex-config-0.0.1-SNAPSHOT.jar\"] 这里需要引入自身的配置文件夹，所以把压缩包引入镜像后先删除原配置文件夹.待使用docker启动时将自身配置文件挂载进去，也可以使用其他方式. 使用docker启动mtex-config,这里pro-properties是我自身的配置文件夹名称，这里挂载到主机的是linux自带的日志，可自行进行log日志挂载 1docker run --name mtex-config -tid --privileged=true --restart=always --net=host -v /home/jenkins-running-jar/mtex-config/pro-properties:/home/jenkins-running-jar/mtex-config/properties/ -v /home/file/nohupLog/mtex-config.log:/home/jenkins-running-jar/mtex-config/nohup.out mtex-config 启动容器时把自身的配置文件夹挂载到容器中即可.--net=host代表和主机使用同一个网段,即同一个IP和端口. 如果打算通过-p进行端口映射，需要先在启宿主机的防火墙上开启该端口，并对外暴露. mtex-sys镜像程序镜像基本都类似，都是根据业务要求挂载不同的文件即可. 12345678910111213#使用的基础镜像FROM java:jre1.8.0.201#作者信息MAINTAINER caijinkun \"caijinkun@mastercom.cn\"#加入服务ADD mtex-sys-0.0.1-SNAPSHOT.zip tmp.zipRUN mkdir -p /home/jenkins-running-jar/mtex-sys/ &amp;&amp; unzip -o tmp.zip -d /home/jenkins-running-jar/mtex-sys/ &amp;&amp; rm -f tmp.zip#工作目录WORKDIR /home/jenkins-running-jar/mtex-sys/#启动服务CMD [\"nohup\",\"java\",\"-jar\",\"mtex-sys-0.0.1-SNAPSHOT.jar\"] docker启动mtex-sys实例: 1docker run --name mtex-sys -tid --privileged=true --restart=always --net=host -v /home/file/nohupLog/mtex-sys.log:/home/jenkins-running-jar/mtex-sys/nohup.out mtex-sys 这时要注意，sys作为框架需要访问很多个项目的文件夹配置及路径，根据需求进行挂载，或者弄一个项目的共享文件夹即可.","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"}]},{"title":"'docker 安装nginx redis'","slug":"docker-use","date":"2020-05-21T11:30:00.000Z","updated":"2020-05-21T12:16:07.838Z","comments":true,"path":"2020/05/21/docker-use/","link":"","permalink":"https://midkuro.github.io/2020/05/21/docker-use/","excerpt":"","text":"docker 安装 nginxdocker安装镜像，使用的是两个命令docker search xxx 和 docker pull xxx，xxx则为要安装的镜像名称,这里要注意的是创建容器会和主机时间相差8个小时 搜索nginx镜像 docker search nginx 安装nginx镜像 docker pull nginx 查看镜像信息 docker images nginx 建议在nginx.conf中配置使用root启动nginx避免权限不足引起问题 编辑配置文件并设置为root. 重命名镜像名称 docker tag IMAGEID REPOSITORY:TAG IMAGEID是镜像ID，REPOSITORY是镜像新名称，TAG是镜像新标签 创建并启动容器命令 docker run [OPTIONS] IMAGE [COMMAND] [ARG...] docker启动nginx实例： docker run 参数配置 作用 --name xxx 为容器指定一个名称为 xxx -t 为容器重新分配一个伪输入终端，通常与 -i 同时使用； -i 以交互模式运行容器，通常与 -t 同时使用； -d 后台运行容器，并返回容器ID； --privileged=true centos默认关闭SElinux，需要开启特权模式，以root的形式进入容器，否则是普通用户 --restart=always 容器开启自动启动 -p 端口映射，格式为：主机(宿主)端口:容器端口 -v 主机路径:容器路径 把主机的文件挂载到容器中 或 把容器文件同步到主机中 -v /etc/localtime:/etc/localtime:ro 把主机时间同步到容器中，不同步会相差8小时 123456789docker run --name nginx -tid --privileged=true --restart=always -p 8181:8181 -v /home/local/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/file/log/nginx/log:/var/log/nginx -v /home/jenkins-running-jar/static/:/home/jenkins-running-jar/static/ -v /etc/localtime:/etc/localtime:ro docker.io/nginx#分解命令#把容器的日志配置同步到主机中-v /home/file/log/nginx/log:/var/log/nginx #是把主机中的配置文件挂载到容器中-v /home/local/nginx/conf/nginx.conf:/etc/nginx/nginx.conf#挂载nginx配置中需要访问的静态文件-v /home/jenkins-running-jar/static/:/home/jenkins-running-jar/static/ docker.io/nginx为镜像名称 查看容器命令 docker ps -a 停止容器命令 docker stop 容器ID或容器名称 删除容器命令 docker rm 容器ID或者容器名称 进入容器命令 docker exec -it 容器ID /bin/bash 退出容器命令 exit 删除镜像命令 docker rmi 镜像ID docker 安装 Redis安装Redis镜像 docker pull redis:3.2 准备 redis.conf,若无此文件可自行新建同名文件并复制进去如果使用上文配置文件则可不需要执行以下操作，原版的redis.conf需修改以下几点:原文件： 1234bind 127.0.0.1protected-mode yesappendonly no//持久化# requirepass foobared 修改后： 1234#bind 127.0.0.1protected-mode noappendonly yes//持久化requirepass yourpassword //redis密码 docker启动redis实例： 1234567docker run --name redis -tid --privileged=true --restart=always -p 6379:6379 -v /home/local/redis/redis.conf:/etc/redis/redis.conf -v /home/local/redis/data:/data redis redis-server /etc/redis/redis.conf#分解命令#把主机的配置文件挂载到容器中-v /home/local/redis/redis.conf:/etc/redis/redis.conf#映射挂载的数据目录-v /home/local/redis/data:/data","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"}]},{"title":"'docker 安装及存储路径配置'","slug":"docker-install","date":"2020-05-21T11:00:00.000Z","updated":"2020-05-21T12:15:59.606Z","comments":true,"path":"2020/05/21/docker-install/","link":"","permalink":"https://midkuro.github.io/2020/05/21/docker-install/","excerpt":"","text":"docker 安装及存储路径配置docker的安装安装docker yum install docker 启动服务 systemctl start docker.service 设置开机自启 systemctl enable docker.service 查看docker版本 docker version 使用centos7系统的，建议把selinux服务关闭，它会影响docker的启动及一些容器的使用. SELinux一共有3种状态，分别是Enforcing，Permissive和Disabled状态。第一种是默认状态，表示强制启用，第二种是宽容的意思，即大部分规则都放行。第三种是禁用，即不设置任何规则。可以通过命令 getenforce 查看selinux服务的状态，默认一般都是 Enforcing。 修改selinux状态，编辑配置文件 vi /etc/selinux/config 将 SELINUX=enforcing改为SELINUX=disabled，该操作后需要重启机器。 docker存储路径配置docker每次创建一个镜像、容器都会占据大量的内存空间，所以建议在安装的时候就把docker放在大空间的路径下，默认的docker是安装在/var/lib/docker下. 如果docker已经启动，请先关闭它 systemctl stop docker.service . 我打算把它迁移到 /home/docker 路径下，所以先创建文件夹 mkdir /home/docker 然后编辑docker存储路径配置 vi /lib/systemd/system/docker.service,找到ExecStart项 ,把它改成ExecStart=/usr/bin/dockerd --graph /home/docker 保存文件后需要执行命令重新加载配置 systemctl daemon-reload. 然后将原路径文件拷贝到新的路径下 cp -r /var/lib/docker/* /home/docker/ docker中不存在容器的话，可以把原路径下的文件删除 如果docker已经存在容器，需要迁移容器的挂载点 首先输入命令 df -hl 查看挂载点，docker容器会创建名称为overlay和shm的挂载点.这时候可以执行命令cat /proc/mounts|grep docker查看挂载点哪些是属于docker的. 然后执行 umount 挂载点全路径 去掉该容器的挂载，并修改挂载点的路径，改成迁移后的docker路径,重新执行挂载命令 mount 新挂载点路径 再次查看挂载 df -hl 这时候应该看到的都是新的路径，也可以删除原路径下的文件了，如果依旧删除失败，重启机器后可删除，然后尝试运行镜像。 如果运行镜像失败提示:Error response from daemon: shim error: docker-runc not installed on system,执行命令创建软连接cd /usr/libexec/docker/和ln -s docker-runc-current docker-runc 如果运行镜像失败提示:exec: “docker-proxy”: executable file not found in $PATH，执行命令创建软连接 ln -s /usr/libexec/docker/docker-proxy-current /usr/bin/docker-proxy 再次运行镜像，应该就能启动了，个人觉得迁移存储路径，有很大可能会出现上面的运行镜像失败的错误，如果是新装的docker迁移了存储路径，也可以先执行上面创建软连接的命令避免以后发生错误. 常用的docker命令 docker run 参数配置 作用 -v /etc/localtime:/etc/localtime:ro 把主机时间同步到容器中，不同步会相差8小时 --privileged=true centos默认关闭SElinux，需要开启特权模式，以root的形式进入容器，否则是普通用户 --restart=always 容器开启自动启动 --net=host 容器和宿主机的IP同网段 -v 主机路径:容器路径 用户把主机的文件挂载到容器中 /usr/sbin/init 在容器中开启系统命令，能够使用systemctl的命令 -d: 后台运行容器，并返回容器ID； -i: 以交互模式运行容器，通常与 -t 同时使用； -p: 端口映射，格式为：主机(宿主)端口:容器端口 -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； --name=nginx-lb 为容器指定一个名称； 命令大全","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"}]},{"title":"'linux 安装Nodejs'","slug":"nodeJs-install","date":"2020-05-20T13:00:00.000Z","updated":"2020-05-20T13:22:18.317Z","comments":true,"path":"2020/05/20/nodeJs-install/","link":"","permalink":"https://midkuro.github.io/2020/05/20/nodeJs-install/","excerpt":"","text":"node.js安装第一种安装方式1.安装gcc，make，openssl 1yum install -y gcc make gcc-c++ openssl-devel 2.下载安装包下载 node-v9.3.0-linux-x64.tar.gz 下载地址 需要其他版本的请到官网中下载即可 官网地址 3.上传安装包 创建nodejs路径文件夹 1mkdir /var/local/nodejs 进入该路径,并上传安装包到该路径中 1cd /var/local/nodedjs 4.解压安装包 1tar -xf node-v9.3.0-linux-x64.tar.gz 5.编译 进入源代码所在路径 1cd node-v9.3.0-linux-x64 执行配置脚本 1./configure 编译与部署 1make &amp;&amp; make install 6.测试 12node -vnpm -v 这种方式安装，需要安装安装gcc等一些编译环境插件，而且编译比较久，部署完成后nodejs为分别放在好几个文件夹内： 123456#放置nodejs 执行程序/usr/local/bin#放置了node_modules，即nodejs的各种模块/usr/lib#放置了nodejs扩展开发用头文件/usr/include 优点是全局安装nodejs模块，直接使用，而且不受用户访问权限影响，推荐使用这种. 第二种安装方式可以不用执行上面的第一步操作，然后用以下方式替代第五步操作 确认node.js的路径，我这里是/usr/local/nodejs/node-v9.3.0-linux-x64/bin，依次执行 12ln -s /usr/local/nodejs/node-v9.3.0-linux-x64/bin/node /usr/bin/nodeln -s /usr/local/nodejs/node-v9.3.0-linux-x64/bin/npm /usr/bin/npm 注意ln指令用于创建关联（类似与Windows的快捷方式）必须给全路径，否则可能关联错误 该方式需要使用root权限去关联，并且非root用户需要做环境变量配置才能使用node.js node.js卸载1.自带工具删除 1yum remove nodejs npm -y 2.2.手动删除残留 进入 /usr/local/bin 删除 node 的可执行文件node和npm 进入 /usr/local/lib 删除所有 node 和 node_modules文件夹 进入 /usr/local/include 删除所有 node 和 node_modules 文件夹 检查 ~ 文件夹里面的”local”、”lib”、”include”、文件夹，然后删除里面的所有”node” 和”node_modules”文件夹 jenkins中使用node.js 在jenkins界面上 系统管理-全局工具配置 中配置安装的nodejs路径 先搭建一个jenkins前端构建任务，构建一次，作用是为了让jenkins检出SVN上的前端代码 到jenkins项目路径中 cd进入workspace文件夹，再进入前端任务名称的文件夹 确认检出的SVN代码文件夹中是否有package.json文件,进入文件路径中 执行以下命令安装node_modules 123npm install webpack -gnpm install webpack-cli -gnpm install --unsafe-perm=true --allow-root 然后组件安装完成后，即可在jenkins构建任务中编辑shell命令执行npm run dist-p-xxx等操作","categories":[{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.github.io/categories/Nodejs/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.github.io/tags/Nodejs/"}]},{"title":"'linux 下安装nginx redis'","slug":"software-install","date":"2020-05-20T12:35:00.000Z","updated":"2020-05-20T15:48:59.355Z","comments":true,"path":"2020/05/20/software-install/","link":"","permalink":"https://midkuro.github.io/2020/05/20/software-install/","excerpt":"","text":"安装nginx1.下载安装包nginx-1.14.1.tar.gz 其他版本请自行下载 官网地址 2.上传并解压安装包 1tar -zxvf nginx-1.14.1.tar.gz 3.设置配置信息 1./configure --prefix=/usr/local/nginx (安装后的文件存放路径） 如果出现以下异常信息 1234./configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option. 则执行命令安装pcre-devel 1yum -y install pcre-devel 安装pcre-devel完成后再次执行命令 1./configure --prefix=/usr/local/nginx 执行完后还有可能会出现这样的问题： 1234567checking for PCRE JIT support ... not foundchecking for system md library ... not foundchecking for system md5 library ... not foundchecking for OpenSSL md5 crypto library ... not foundchecking for sha1 in system md library ... not foundchecking for OpenSSL sha1 crypto library ... not foundchecking for zlib library ... found 若出现上述问题则安装openssl 1yum -y install openssl openssl-devel 安装openssl完成后再次执行命令 1./configure --prefix=/usr/local/nginx 出现下图信息则说明配置成功 4.安装 12makemake install 出现类似这样的就表示安装成功了 123456cp conf/nginx.conf '/usr/local/nginx/conf/nginx.conf.default'test -d '/usr/local/nginx/logs' || mkdir -p '/usr/local/nginx/logs'test -d '/usr/local/nginx/logs' || mkdir -p '/usr/local/nginx/logs'test -d '/usr/local/nginx/html' || cp -R html '/usr/local/nginx'test -d '/usr/local/nginx/logs' || mkdir -p '/usr/local/nginx/logs'make[1]: Leaving directory '/root/setup/nginx/nginx-1.14.1' 安装完后/usr/local/nginx 后出现几个文件夹conf、html、logs、sbin，配置nginx.conf在文件夹conf中 启动nginx 1./usr/nginx/sbin/nginx 部分nginx启动失败解决方法 关闭SELINUX 12vi /etc/selinux/config将SELINUX=enforcing改为SELINUX=disabled 这时候需要注意，开启nginx配置的防火墙端口 开启防火墙端口教程 安装redis1.安装redis 1yum install redis 2.下载fedora的epel仓库 1yum install epel-release 3.安装redis数据库 1yum install redis 4.修改redis.conf配置文件 123456789101112原文件：bind 127.0.0.1protected-mode yesappendonly no//持久化# requirepass foobared修改后：#bind 127.0.0.1protected-mode noappendonly yes//持久化requirepass yourpassword //redis密码 5.使用配置文件启动 redis 1redis-server /etc/redis.conf &amp; 6.启动redis相关命令 12345678# 启动redisservice redis start 或 systemctl start redis.service# 停止redisservice redis stop 或 systemctl stop redis.service# 查看redis运行状态service redis status 或 systemctl status redis.service# 查看redis进程ps -ef | grep redis 7.本机测试访问 12redis-cli -h 127.0.0.1 -p 6379quit 这时候需要注意，非本机访问redis需要开启防火墙端口 开启防火墙端口教程","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.github.io/categories/Nginx/"},{"name":"Redis","slug":"Nginx/Redis","permalink":"https://midkuro.github.io/categories/Nginx/Redis/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.github.io/tags/Linux/"},{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.github.io/tags/Nginx/"},{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/tags/Redis/"}]},{"title":"'centos7 设置应用程序为系统服务'","slug":"systemctl-use","date":"2020-05-20T12:30:00.000Z","updated":"2020-05-20T13:25:51.999Z","comments":true,"path":"2020/05/20/systemctl-use/","link":"","permalink":"https://midkuro.github.io/2020/05/20/systemctl-use/","excerpt":"","text":"centos7使用systemctl以下的 xxx为服务名称，需根据自身需求修改 1.进入目录 1cd /usr/lib/systemd/system/ 2.创建xxx.service文件 1vi xxx.service 3.赋予xxx.service文件权限 1chmod 754 xxx.service xxx.service文件详解[Unit] 部份 设置参数 参数意义说明 Description 服务名称 After 说明此服务 是在哪个服务启动之后才启动的意思！基本上仅是说明服务启动的顺序而已，并没有强制要求里头的服务一定要启动后此 unit 才能启动。 Before 与 After 的意义相反，是在什么服务启动前最好启动这个服务的意思。不过这仅是规范服务启动的顺序，并非强制要求的意思。 Requires 明确的定义此服务需要在哪个服务启动后才能够启动！就是设置相依服务！如果在此项设置的前导服务没有启动，那么此服务就不会被启动！ Conflicts 代表互斥的服务！亦即这个项目后面接的服务如果有启动，那么我们这个服务本身就不能启动！我们服务有启动，则此项目后的服务就不能启动！ [Service] 部份 设置参数 参数意义说明 Type 说明这个程序启动的方式，会影响到 ExecStart,一般来说，有下面几种类型 simple：默认值，这个程序主要由 ExecStart 接的指令串来启动，启动后常驻于内存中。forking：由 ExecStart 启动的程序通过 spawns 延伸出其他子程序来作为此程序 的主要服务。原生的父程序在启动结束后就会终止运行。 传统的 unit 服务大多属于这种项目.还有oneshot、dbus、idle等类型，请自行了解. EnvironmentFile 可以指定启动脚本的环境配置文件.例如 sshd.service 的配置文件写入到 /etc/sysconfig/sshd 当中！你也可以使用 Environment= 后面接多个不同的 Shell 变量来给予设置 ExecStart 启动应用程序的命令 ExecStop 停止应用程序的命令 ExecReload 重载应用程序的命令 Restart 当设置 Restart=1 时，则当此服务终止后，会再次的启动此服务 [Install] 部份 设置参数 参数意义说明 WantedBy 这个设置后面接的大部分是 *.target unit,意思是这个服务本身是附挂在哪一个target unit下面的,都是附挂在 multi-user.target下面 redis及nginx为例以redis为例，在该路径下 vi redis.service，并复制进去以下内容，进行相应修改. 123456789101112[unit]Description&#x3D;redis - high performance web serverAfter&#x3D;network.target remote-fs.target nss-lookup.target[Service]Type&#x3D;forkingExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis-5.0.2&#x2F;start.shExecReload&#x3D;ExecStop&#x3D;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis-5.0.2&#x2F;stop.sh[Install]WantedBy&#x3D;multi-user.target 以nginx为例，在该路径下 vi nginx.service，并复制进去以下内容，进行相应修改. 123456789101112[unit]Description&#x3D;nginx - high performance web serverAfter&#x3D;network.target remote-fs.target nss-lookup.target[Service]Type&#x3D;forkingExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.confExecReload&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reloadExecStop&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s stop[Install]WantedBy&#x3D;multi-user.target 比如我mtex-auth服务的启动需要依赖mtex-config服务，可以这样配置vi mtex-auth.service 123456789101112[Unit]Description&#x3D;mtex-auth - high performance web serverAfter&#x3D;network.target remote-fs.target nss-lookup.target mtex-configRequires&#x3D;mtex-config[Service]Type&#x3D;forkingExecStart&#x3D;&#x2F;home&#x2F;jenkins-running-shell&#x2F;mtex-auth&#x2F;start.shExecReload&#x3D;ExecStop&#x3D;&#x2F;home&#x2F;jenkins-running-shell&#x2F;mtex-auth&#x2F;stop.sh[Install]WantedBy&#x3D;multi-user.target 服务命令操作以nginx为例，保存nginx.service文件后赋予执行权限 1chmod 754 nginx.service nginx开机自启 1systemctl enable nginx.service 启动nginx 1systemctl start nginx.service 停止nginx 1systemctl stop nginx.service 重启nginx 1systemctl restart nginx.service centos7也可以使用旧版命令 system stop xxx 、system start xxx达到效果.","categories":[{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.github.io/categories/Systemctl/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.github.io/tags/Linux/"},{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.github.io/tags/Systemctl/"}]},{"title":"'linux 开放防火墙端口'","slug":"firewalld-use","date":"2020-05-20T12:00:00.000Z","updated":"2020-05-20T13:22:08.301Z","comments":true,"path":"2020/05/20/firewalld-use/","link":"","permalink":"https://midkuro.github.io/2020/05/20/firewalld-use/","excerpt":"","text":"centos7开放防火墙端口启动防火墙 1systemctl start firewalld 停止防火墙 1systemctl stop firewalld 查看防火墙状态 1firewall-cmd --state 查看防火墙启动状态详情 1systemctl status firewalld 开机禁用 1systemctl disable firewalld 开机启用 1systemctl enable firewalld 查看所有打开的端口 1firewall-cmd --zone=public --list-ports 开启端口 1firewall-cmd --zone=public --add-port=80/tcp --permanent –permanent永久生效，没有此参数重启后失效 重新载入 1firewall-cmd --reload 查看端口状态 1firewall-cmd --zone=public --query-port=80/tcp 删除端口 1firewall-cmd --zone= public --remove-port=80/tcp --permanent","categories":[{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.github.io/categories/Firewall/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.github.io/tags/Linux/"},{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.github.io/tags/Firewall/"}]},{"title":"'jenkins 参数化构建'","slug":"jenkins-param","date":"2020-05-20T07:50:40.000Z","updated":"2020-05-21T14:57:21.945Z","comments":true,"path":"2020/05/20/jenkins-param/","link":"","permalink":"https://midkuro.github.io/2020/05/20/jenkins-param/","excerpt":"","text":"jenkins参数化构建通过输入参数进行构建项目，需要插件build with parameters plugin，正常安装成功的jenkins应该都会自带了的，那么参数可以做什么事呢？如果我想要jenkins构建svn上指定版本号的代码并进行测试，就可以使用参数构建. 首先先了解一下怎么获取svn上指定的版本代码:通过项目路径@版本号进行获取的，版本号为head时，则取最新版本. 打开jenkins的任务配置，在General模块中找到参数化构建工程,勾选并添加自己的参数类型，本文选的是字符参数. 填写完相应的参数配置，需要修改项目svn的路径，将其改成项目路径@$参数名称 的格式.这时候的svn校验将失效，因为是配置了参数. 点击保存，就已经完成了参数化构建的配置了.这时候立即构建的按钮将变成Build with Parameters ,是不是觉得很简单？ 这时候又会发现，上下游均配置了参数化构建，但是触发了上游项目构建，并不能将参数传递到我的下游项目中，这时候会发现下游项目使用的是配置中的默认参数head,怎么做到传递一次参数即可触发构建呢？ 这时候要先安装一款插件Parameterized Trigger Plugin，安装完成后解除项目的上下游关系 然后编辑上游项目的任务配置，找到Post Steps模块,点击Add post-build step,能够看到多了一项选择，选中Trigger/call builds other projects 这里做的是正向配置上下游关系，上文解除了之前上下游关系，目的就是为了在这里通过参数传递进行配置。填入下游项目的工程名称，并点击Add Parameters添加参数，在这里我选择的是Predefined parameters,其他的暂时没有去了解.并填写传参的参数，格式为参数名=${参数名大写},这里我并有去测试小写能不能传递，亲们可以试试看… 这时候构建上游，也能够接收到同样的参数并指定的SVN版本号进行构建了,如果想要在shell命令中使用参数，也可以通过${参数名大写}进行取值. jenkins远程触发项目构建jenkins远程触发项目构建能够实现的功能有很多，本文主要讲解如何通过一个url进行触发构建. 打开任务配置并找到构建触发器模块，勾选触发远程构建并配置一个秘钥，这个秘钥相当于密码，密码错误的话不会触发构建. 如何调度已经说得很清楚了：http://IP:端口号/job/任务名称/build?token=秘钥 也可以使用参数进行远程触发：http://IP:端口号/job/任务名称/buildWithParameters?token=秘钥&amp;&amp;参数名=参数值 也就是说，这时候项目配置了参数构建及远程触发构建，就可以通过http请求的调度促使jenkins进行参数化远程构建… 这个时候会发现，如果我没有登录，它是不让我远程触发构建的，那我如何不需要登录就进行触发构建呢？ 首先先安装一个插件Build Authorization Token Root Plugin,然后登录用户-&gt;点击右上角的登录名-&gt;再点击设置 输入生成token的字符串，并生成一串token秘钥，切记拷贝生成的token秘钥，然后回到项目的构建触发器模块，将生成的token秘钥填入身份验证令牌中即可 这时候请求的url将发生变化: 无参请求:http://IP:端口号/buildByToken/build?job=任务名称&amp;token=秘钥 参数请求:http://IP:端口号/buildByToken/buildWithParameters?job=任务名称&amp;token=秘钥&amp;参数名=参数值","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]},{"title":"'jenkins 上下游与持续集成构建'","slug":"jenkins-upstream","date":"2020-05-20T05:52:40.000Z","updated":"2020-05-21T14:57:37.038Z","comments":true,"path":"2020/05/20/jenkins-upstream/","link":"","permalink":"https://midkuro.github.io/2020/05/20/jenkins-upstream/","excerpt":"","text":"spring boot项目之间的引用触发上下游构建首先上下游关系是可以通过配置实现的，可以通过正向配置或反向配置实现，建议统一使用一种。 先理解一下上游下游的概念，目前我的dao项目作为一个基础类库，然后mtex-auth引入依赖dao，那么dao就是mtex-auth的上游，mtex-auth就是dao的下游。 在这情况下，上游dao主动去建立和下游的mtex-auth的关系，则为正向配置，而下游mtex-auth主动去建立和上游dao的关系，则为反向配置。 正向配置：在dao任务中找到 构建后操作模块增加构建后操作步骤，选择构建其他工程，在该路径填写mtex-auth任务名称,则dao构建成功后会主动触发mtex-auth任务进行构建 反向配置:在mtex任务中找到 构建触发器模块，勾选其他工程构建后触发并填写dao任务名称 在我的理解中，不管正向配置还是反向配置，作用都是一样的，都是建立上下游关系，上游构建成功后触发下游构建,所以建议只使用一种配置，没必要双向关系. 配置好上下游权限后，建议每一个下游任务的配置中增加限制，打开任务进入General模块，点击高级，勾选该项目上游正在构建时阻止该项目构建选项. 设想一下，如果存在项目关系如下： A项目作为B项目的上游 A项目作为C项目的上游 B项目作为C项目的上游 那么在A项目构建成功后，逻辑来讲它是会触发两个下游之间的构建，也就是B项目和C项目同时构建，等B项目构建完会再次触发一次C项目的构建。而通过勾选上游构建时阻止构建下游，就能避免这个问题。 最理想的构建顺序是 A-B-C ,那么在A任务的正向配置中，则不需要配置下游项目C，只需要配置下游项目B，反向配置也一样。 其次，在任务模块构建触发器中，建议关闭 Build whenever a SNAPSHOT dependency is built，因为该配置会根据pom文件的快照项目依赖自动创建上下游关系，导致和正反向配置重复并可能出现多次打包的情况。 jenkins持续集成构建任务关系依赖可能出现这种情况，A、B、C项目都作为D项目的上游，而A、B、C又是单独互不影响的项目，这时候它们是可以进行并发构建的，可是这样就会触发D项目的3次构建，这明显是不合理的，那么怎么做到 A、B、C项目同时构建，然后再触发下游D项目的构建呢？ 首先安装一个串行的插件 Multijob,它支持将任务捆绑构建。我们需要先解除A、B、C项目和D项目的上下游关系，也就是取消正反向配置,并且取消A、B、C任务中General模块的 该项目上游正在构建时阻止该项目构建配置，切记必须取消，否则无法进行构建. 新建任务，选择 Multijob Project,创建一个任务E。 找到构建模块，点击增加构建步骤并选择Multijob Phase,并依次添加A、B、C任务名称 这个时候可以点击每个任务右下角的高级进行详细配置 构建方式可以选择 串行或者并行，串行的话则按照添加任务的顺序进行构建，并行则同时构建。 构建条件可以选择 构建成功触发、构建失败触发、无论结果如何都触发等操作，按需求配置。 配置完成后关联E项目和D项目之间的上下游关系,并配置该项目上游正在构建时阻止该项目构建即可，就能满足触发E项目时， 触发A、B、C项目同时构建，然后再触发下游D项目的构建的操作。 这个时候如果项目是并行的，必须设置jenkins的最大并行执行器的数量,系统管理-&gt;系统设置-&gt;填写执行器数量。","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]},{"title":"'jenkins 搭建简单的构建'","slug":"jenkins-use","date":"2020-05-20T05:51:40.000Z","updated":"2020-05-21T14:57:30.312Z","comments":true,"path":"2020/05/20/jenkins-use/","link":"","permalink":"https://midkuro.github.io/2020/05/20/jenkins-use/","excerpt":"","text":"jenkins插件安装及环境配置在使用jenkins之前，我们先学会配置jenkins的环境以及插件的安装，jenkins的环境配置均支持自动下载安装，但是不建议，也许是个人对环境路径存放位置具有强迫症吧。 首先进入jenkins页面，点击左侧 系统管理 ,然后找到 全局工具配置 然后选中 JDK及Maven的环境进行配置，点击新增将出现配置路径，将已安装的JDK及Maven路径配置上即可,对git有需要的可以自行配置. 配置完成后点击下方的save进行保存，接下来进入插件安装，点击插件管理，并进入可选插件界面 在该界面中，请不要使用右上角的 过滤 功能，由于插件过多，使用jenkins自带的过滤功能会导致浏览器卡死，所以请使用浏览器内容搜索的功能 ctrl + F在浏览器的搜索框中输入 Maven Integration 搜索maven插件，不同的插件版本命名可能略有差异，找到maven插件后在左边文本框中打钩，点击下方直接安装即可 在安装过程中，有一个安装后重启jenkins的设置，建议取消打钩，等待安装完成即可. jenkins基于maven编译简单的java项目在主界面中点击新建任务 进行创建，此时能够看到构建一个maven项目,该选项是需要安装 Maven Integration 才会出现的，选中它并输入项目名称，点击下方的确认按钮 上图的步骤2也可以通过输入一个已存在的任务名称，将任务的所有配置拷贝复制到新建任务当中. General：建议一定要勾选丢弃旧的构建，并配置构建保留天数及数量，可以配置10天、10个，感觉足以，不丢弃旧的构建容易把磁盘空间占满. 源码管理：选中SVN（Git操作也差不多）,并输入项目的svn路径，然后添加svn访问用户，输入账号密码即可，jenkins会自动帮你检测该账号能否访问svn路径并提示。 构建触发器配置： 第一个参数代表的是分钟 minute，取值 0~59； 第二个参数代表的是小时 hour，取值 0~23； 第三个参数代表的是天 day，取值 1~31； 第四个参数代表的是月 month，取值 1~12； 最后一个参数代表的是星期 week，取值 0~7，0 和 7 都是表示星期天。 常用例子: 每小时构建一次： * H/1 * * * 每隔5分钟构建一次： H/5 * * * * 每天8点30分构建一次： 30 8 * * * 每个小时的第10分钟构建一次： 10 * * * * 每周六日的1点10分构建一次： 10 1 * * 6,0 Pre Steps：构建前需要执行的一些操作，可以选择shell脚本、window命令等，这个根据需求去研究如何配置，暂时不细讲 Build： 建议使用clean install 替换 clean package 命令,clean package是把项目打包到target下，它并不会打包到maven的仓库，而clean install会打包进maven的仓库，可以避免一些不必要的问题。 比如我曾经遇见过的一个问题，A项目依赖了B项目，而B项目使用的是clean package命令，导致A项目打包的时候去maven仓库找不到B项目的jar包，所以A项目一直打包失败。 Post Steps：构建后需要执行的一些操作，同Pre Steps，其中构建不稳定指的是最近的5次构建中，曾经出现过构建失败。 构建的邮件发送通知以后再细讲，配置到这后一个简单的构建任务就已经完成了，点击保存，界面会出现新建的构建任务，点击右边的构建即可。 进入项目详情，左下角能够看到一些构建历史，点击构建历史能够查看每一次的构建详情，也能看到触发的构建原因，SVN更新的版本、信息等。","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]},{"title":"'jenkins 安装及卸载'","slug":"jenkins-install","date":"2020-05-20T05:50:40.000Z","updated":"2020-05-21T14:57:42.773Z","comments":true,"path":"2020/05/20/jenkins-install/","link":"","permalink":"https://midkuro.github.io/2020/05/20/jenkins-install/","excerpt":"","text":"安装JDK使用jenkins，需要安装jdk及maven，可以自己安装于本机，也可以通过安装完jenkins后进行自动安装。 jdk-8u201-linux-x64.tar.gz 下载地址 官网地址 apache-maven-3.6.0-bin.tar.gz 下载地址 官网地址 如需更换版本请另行到官网中下载,在linux系统中安装包请选择 linux-x64.tar.gz后缀的安装包进行下载. 下文涉及到JDK及Maven版本相关的命令请自行修改成对应的版本. 在linux终端输入命令 cd /usr/local/ ，并创建java文件夹 mkdir java 执行 cd java 进入java路径中，并将下载的安装包上传至该路径 /usr/local/java下 然后执行命令解压下载的压缩包: tar -zxvf jdk-8u201-linux-x64.tar.gz 若提示错误则请先执行 yum install -y tar 安装压缩包命令再执行解压命令(仅限centos，其他系统请自行百度). 使用vi进入文件编辑模式，配置环境变量:vi /etc/profile 敲击键盘i进入编辑模式，在文件末尾添加以下内容: 12345export JAVA_HOME=/usr/local/java/jdk1.8.0_201export JAVA_BIN=/usr/local/java/jdk1.8.0_201/binexport PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$PATH 敲击键盘:wq 表示退出vi编辑模式并保存修改 执行命令使系统环境变量配置重新加载：source /etc/profile 测试JDK安装是否成功,输入 javac 和java -version 是否安装成功.出现下图类似的信息即安装成功 安装Maven操作与JDK基本相同，Maven环境变量需要配置的内容： 12export MAVEN_HOME=/usr/local/maven/apache-maven-3.6.0export PATH=$PATH:$MAVEN_HOME/bin` 测试Maven安装是否成功，输入 mvn -v 或者 mvn -version 即可. 安装Jenkinsjenkins安装包 jenkins-2.138.3-1.1.noarch.rpm 下载地址 官网地址 不同版本的jenkins安装插件的成功率不一样，推荐使用该jenkins版本，支持中文，并且插件安装的成功率较高。 上传安装包至linux服务器任意路径下，并在该路径下执行 rpm -ivh jenkins-2.138.3-1.1.noarch.rpm 进行安装 安装成功后可查看jenkins默认安装目录： rpm -ql jenkins 可自定义修改jenkins配置文件： vi /etc/sysconfig/jenkins 123456#jenkins端口配置JENKINS_PORT=\"8080\"#启动jenkins的用户，最好使用root，否则会出现权限不够等问题JENKINS_USER=\"jenkins\"#jenkins的项目路径，建议将其改成 `/data/jenkins` 放在大空间的路径下，避免出现空间不足等问题JENKINS_HOME=\"/var/lib/jenkins\" 若修改了JENKINS_HOME 配置，则需执行 cp -r 原路径 目标路径 命令，其中 -r 参数表示若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件. 根据上文将/var/lib/jenkins/路径修改为 /data/jenkins,则执行的命令为 cp -r /var/lib/jenkins/* /data/jenkins/ 退出vi编辑模式并保存 然后设置jenkins服务开机自启动: systemctl enable jenkins.service 启动jenkins: systemtl start jenkins.service ，将start改为restart、stop分别为重启、停止jenkins 如果启动时报错 Starting Jenkins -bash: /usr/bin/java: No such file or directory，则需要编辑文件 vim /etc/init.d/jenkins，将/usr/bin/java改为自己java的地址，自己java地址的查看命令 which java 启动jenkins后，浏览器访问 http://ip:端口 第一次登录Jenkins会要求解锁，复制红色标记中的路径，执行命令 cat 红色标记的路径，将返回的密码填入浏览器页面中，点击continue继续 输入完成后会提示安装自定义插件还是推荐插件，此处我选择左边的推荐插件，安装过程可能由于网络原因导致失败，后续失败的可以在系统设置-插件管理里面卸载或者重新安装即可，也可以在插件安装完成后选择retry重新安装失败的插件，尝试多几次即可。 创建用户并登陆 看到以下界面则代表jenkins已安装成功，到这里linux下安装配置jenkins教程就结束了 卸载Jenkins依次执行以下命令彻底卸载Jenkins 123456service jenkins stopyum clean allyum -y remove jenkinsrm -rf /var/cache/jenkins#请修改为自身机器的jenkins的路径rm -rf /var/lib/jenkins/","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]}],"categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/categories/JVM/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/categories/Kubernetes/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.github.io/categories/Nodejs/"},{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.github.io/categories/Nginx/"},{"name":"Redis","slug":"Nginx/Redis","permalink":"https://midkuro.github.io/categories/Nginx/Redis/"},{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.github.io/categories/Systemctl/"},{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.github.io/categories/Firewall/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/tags/JVM/"},{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/tags/Kubernetes/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.github.io/tags/Nodejs/"},{"name":"Linux","slug":"Linux","permalink":"https://midkuro.github.io/tags/Linux/"},{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.github.io/tags/Nginx/"},{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/tags/Redis/"},{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.github.io/tags/Systemctl/"},{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.github.io/tags/Firewall/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]}