{"meta":{"title":"Kuro's Blog","subtitle":"Kuro","description":"坚持 是一种品格","author":"Kuro","url":"https://midkuro.github.io","root":"/"},"pages":[{"title":"about","date":"2020-05-20T09:29:27.000Z","updated":"2020-05-20T09:30:17.111Z","comments":true,"path":"about/index.html","permalink":"https://midkuro.github.io/about/index.html","excerpt":"","text":"关于我从事 JAVA 后台开发，主要开发语言 PHP，熟悉使用 Spring Boot、Spring Cloud 等主流框架；熟悉JVM内存运行区域、类加载机制，熟悉多线程编程，线程安全设计。 对DevOps有一定的了解。编写代码遵循SonarLint检测。 热爱开源项目、热爱新技术、热爱新事物。 关于工作城市：深圳南山区 关于学习正在往终身学习者前进…近期学习方向：NIO 关于座右铭 坚持 是一种品格 关于爱好热爱运动，喜爱羽毛球、看小说。 联系我 Blog: midkuro.io GitHub: midkuro Email: 276302007@qq.com"}],"posts":[{"title":"'字节顺序'","slug":"binary-endian","date":"2020-09-23T04:20:00.000Z","updated":"2020-09-23T08:13:49.815Z","comments":true,"path":"2020/09/23/binary-endian/","link":"","permalink":"https://midkuro.github.io/2020/09/23/binary-endian/","excerpt":"","text":"字节序了解什么是字节顺序前，先复习一下单位换算的基本概念。 位(bit)：计算机中的最小数据单位，计算机存储的都是二进制0和1这两个鬼。 字节(Byte)：字节是存储空间的基本计量单位，也是内存的基本单位，也是编址单位。例如，一个计算机的内存是4GB，就是该计算机的内存中共有4×1024×1024×1024个字节，意味着它有4G的内存寻址空间。 换算关系： 1 GB = 1024 MB 1 MB = 1024 KB 1 KB = 1024 Bytes 1 Byte = 8 bits 思考个问题，通常描述32位二进制数据，为什么是用8个十六进制数呢？如0x1A2B3C4D 4个二进制bit 表示的数值范围是从00001111，即015, 刚好等同于 一位 16进制数的数值范围0~F(15)，也就是说，4个二进制位(bit) = 1个十六进制(Hex)，8个二进制位(bit) = 一个字节(Byte) = 2个十六进制(hex)，32个二进制位(bit) = 四个字节(Byte) = 8个十六进制(hex)。 所以针对一个32位的二进制数值，通常十六进制来表示，如0x1A2B3C4D，总共四个字节，两个十六进制数表示一个字节，高位字节为0x1A，低位字节为0x4D；中间两个字节分别为0x2B和0x3C； 数值0x1A2B3C4D想要在计算机中正确使用，就必须要考虑在内存中将其对应的四个字节合理存储。假设内存的地址都是从低到高分配的，那么对于一个数值多个字节顺序存储就有两种存储方式： 方式一：数值的高位字节存放在内存的低地址端，低位字节存放在内存的高地址端： 内存低地址 ——————–&gt; 内存高地址 0x1A | 0x2B | 0x3C | 0x4D 高位字节 &lt;——————– 低位字节 方式二、数值的低位字节存放在内存的低地址端，高位字节存放在内存的高地址端： 内存低地址 ——————–&gt; 内存高地址 0x4D | 0x3C | 0x2B | 0x1A 低位字节 ——————–&gt; 高位字节 方式一 ，我们就称之为 大端（Big endian）模式；即数值高位字节放在内存的低地址端，低位字节放在内存的高地址端。 方式二 ，我们就称之为 小端（Little endian）模式；即数值低位字节放在内存的低地址端，高位字节放在内存的高地址端。 画图更直观理解一下： 总结大端小端是不同的字节顺序存储方式，统称为字节序； 大端模式，是指数据的高字节位 保存在 内存的低地址中，而数据的低字节位 保存在 内存的高地址中。这样的存储模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，而数据从高位往低位放。和我们”从左到右“阅读习惯一致。 小端模式，是指数据的高字节位 保存在 内存的高地址中，而数据的低字节位 保存在 内存的低地址中。这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低，和我们的逻辑方法一致。 优缺点Big-Endian 优点：靠首先提取高位字节，你总是可以由看看在偏移位置为0的字节来确定这个数字是正数还是负数。你不必知道这个数值有多长，或者你也不必过一些字节来看这个数值是否含有符号位。这个数值是以它们被打印出来的顺序存放的，所以从二进制到十进制的函数特别有效。因而，对于不同要求的机器，在设计存取方式时就会不同。 Little-Endian 优点：提取一个，两个，四个或者更长字节数据的汇编指令以与其他所有格式相同的方式进行：首先在偏移地址为0的地方提取最低位的字节，因为地址偏移和字节数是一对一的关系，多重精度的数学函数就相对地容易写了。 如果你增加数字的值，你可能在左边增加数字（高位非指数函数需要更多的数字）。因此，经常需要增加两位数字并移动存储器里所有Big-endian顺序的数字，把所有数向右移，这会增加计算机的工作量。不过，使用Little- Endian的存储器中不重要的字节可以存在它原来的位置，新的数可以存在它的右边的高位地址里。这就意味着计算机中的某些计算可以变得更加简单和快速。 网络字节顺序1、字节内的比特位不受这种顺序的影响比如一个字节 1000 0000 （或表示为十六进制 80H)不管是什么顺序其内存中的表示法都是这样。 2、*大于1个字节的数据类型才有字节顺序问题*比如 Byte A，这个变量只有一个字节的长度，所以根据上一条没有字节顺序问题。所以字节顺序是“字节之间的相对顺序”的意思。 3、大于1个字节的数据类型的字节顺序有两种比如 short B，这是一个两字节的数据类型，这时就有字节之间的相对顺序问题了。网络字节顺序是“所见即所得”的顺序。而Intel类型的CPU的字节顺序与此相反。比如上面的 short B=0102H(十六进制，每两位表示一个字节的宽度）。所见到的是“0102”，按一般数学常识，数轴从左到右的方向增加，即内存地址从左到右增加的话，在内存中这个 short B的字节顺序是：01 02这就是网络字节顺序。所见到的顺序和在内存中的顺序是一致的！假设通过抓包得到网络数据的两个字节流为：01 02 *而相反的字节顺序就不同了，其在内存中的顺序为：02 01*如果这表示两个 Byte类型的变量，那么自然不需要考虑字节顺序的问题。如果这表示一个 short 变量，那么就需要考虑字节顺序问题。根据网络字节顺序“所见即所得”的规则，这个变量的值就是：0102 假设本地主机是Intel类型的，那么要表示这个变量，有点麻烦：定义变量 short X，字节流地址为：pt，按顺序读取内存是为x=((short)pt);那么X的内存顺序当然是 01 02按非 “所见即所得” 的规则，这个内存顺序和看到的一样显然是不对的，所以要把这两个字节的位置调换。调换的方法可以自己定义，但用已经有的API还是更为方便。 网络字节顺序与主机字节顺序 网络字节顺序NBO（Network Byte Order）：按从高到低的顺序存储，在网络上使用统一的网络字节顺序，可以避免兼容性问题。 主机字节顺序（HBO，Host Byte Order）：不同的机器HBO不相同，与CPU设计有关计算机数据存储有两种字节优先顺序：高位字节优先和低位字节优先。Internet上数据以高位字节优先顺序在网络上传输，所以对于在内部是以低位字节优先方式存储数据的机器，在Internet上传输数据时就需要进行转换。 “本篇文章主要摘自参考资料”","categories":[{"name":"binary","slug":"binary","permalink":"https://midkuro.github.io/categories/binary/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"linux","slug":"linux","permalink":"https://midkuro.github.io/tags/linux/"}]},{"title":"'锁升级的过程'","slug":"synchronized-process","date":"2020-09-22T04:20:00.000Z","updated":"2020-09-23T10:11:30.644Z","comments":true,"path":"2020/09/22/synchronized-process/","link":"","permalink":"https://midkuro.github.io/2020/09/22/synchronized-process/","excerpt":"","text":"锁升级的过程在Java中说到锁，肯定熟悉Synchronized关键字，synchronized关键字最主要有以下3种应用方式，下面分别介绍 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 在非静态方法中加锁同步代码块，比如加锁this对象，如下： 12345public void lockTest() &#123; synchronized (this) &#123; System.out.println(\"加锁this对象\"); &#125;&#125; 也可以加锁new出来的对象，如下： 1234567891011public class LockDemo &#123; static L l = new L(); public static void lockTest() &#123; synchronized (l) &#123; System.out.println(\"锁 l 对象\"); &#125; &#125;&#125;public class L &#123;&#125; 当然在Java中，JUC并发工具包也提供了ReentrantLock锁，如下： 123456789public class LockDemo &#123; static ReentrantLock lock = new ReentrantLock(); public static void lockTest() &#123; lock.lock(); System.out.println(\"ReentrantLock加锁\"); lock.unlock(); &#125;&#125; 那么ReentrantLock锁，它是通过锁什么呢？可以跟踪ReentrantLock的源码看看： 123456789101112131415161718192021222324252627282930/** * The synchronization state. */private volatile int state;/** * Atomically sets synchronization state to the given updated * value if the current state value equals the expected value. * This operation has memory semantics of a &#123;@code volatile&#125; read * and write. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful. False return indicates that the actual * value was not equal to the expected value. */protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125;/** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 可以看到ReentrantLock主要是通过设置了一个volatile关键字的state属性，通过CAS机制去申请获得锁，修改state属性。 那么synchronized是锁的是什么呢？又是通过什么来标示锁状态呢？ 对象组成想要了解synchronized锁的原理，需要先了解在JVM虚拟机中Java对象的结构 如上图所示，java对象都是存储在堆中，一个java对象分为三个部分：对象头、实例数据、填充数据。 实例变量：指的就是对象的实例数据，数据占用的字节数不固定。如下，实例数据就在对象中占了5个字节大小。 1234public class Demo &#123; boolean flag = false; //boolean类型占1个字节 int k = 0; //int类型占4个字节&#125; 填充数据：在64位的虚拟机中，规定了java对象大小要求必须是8个字节的整数倍，所以当大小不满足8个字节的整数倍时，会自动填充。比如上图实例变量占用了5个字节，那么为了对齐数据，该对象可能需要填充3个字节数据。 对象头：对象头是对象的第一部分且是所有对象公共部分，对象头由两部分组成，分别是Mark Word和Klass Pointer（或者叫做Class Metadata Address），如果对象是数组，则由三部分组成，将会多出一部分记录数组长度。 因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中无法确定数组的大小。 案例分析 本文如无特殊说明时，对象均指普通对象，如果是数组对象，会特别指出。 先回顾一下，八大基础数据类型的内存占用情况： Primitive Type Memory Required(bytes) boolean 1 byte 1 short 2 char 2 int 4 float 4 long 8 double 8 然后通过引入jol-core依赖，输出对象的字节存储结构，用以分析对象头的组成情况 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.13&lt;/version&gt;&lt;/dependency&gt; 1234567891011public class LockDemo &#123; static L l = new L(); public static void main(String[] args) &#123; System.out.println(ClassLayout.parseInstance(l).toPrintable()); &#125;&#125;public class L &#123; boolean flag = false;&#125; 输出结果： 123456789cn.mastercom.lock.L object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 43 c0 00 20 (01000011 11000000 00000000 00100000) (536920131) 12 1 boolean L.flag false 13 3 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total 由上述案例可以看到，对象头作为一个对象的开头存储结构，在64位的虚拟机中，对象头object header占用了96bit（位）=12byte（字节）。 其中OFFSET代表字节的偏移量，并且可以看到，对象头之后存储了实例数据，从偏移量OFFSET=12开始，boolean类型占用了SIZE=1(byte)。 从OFFSET=13开始，SIZE=3(byte)属于填充数据，用于补齐对象字节大小是8的整数倍，也就是说，当对象刚好等于8的整数倍时，则不需要填充补齐。 举个例子，将L类里的boolean类型(1byte)改成int(4byte)类型，则对象大小=对象头(12byte)+实例数据Int类型(4byte)=16byte，这时候已经是8的整数倍了，则不需要填充数据对齐。 一个（非数组）java对象中，一定会具备12B大小的对象头，实例数据或填充数据均可以是0B，比如： 12B对象头+4B实例数据=16B=8的整数倍 12B对象头+4B填充数据=16B=8的整数倍 如果该对象是一个数组对象的话，那么它的对象头由三部分组成：分别是Mark Word和Klass Pointer和数组长度。 123456public class LockDemo &#123; public static void main(String[] args) &#123; System.out.println(ClassLayout.parseInstance(new int[] &#123; 15, 11 &#125;).toPrintable()); &#125;&#125; 输出结果： 123456789[Ljava.lang.Object; object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) f5 22 00 20 (11110101 00100010 00000000 00100000) (536879861) 12 4 (object header) 02 00 00 00 (00000010 00000000 00000000 00000000) (2) 16 8 java.lang.Object Object;.&lt;elements&gt; N&#x2F;AInstance size: 24 bytesSpace losses: 0 bytes internal + 0 bytes external &#x3D; 0 bytes total 可以看到，当对象是一个数组时，对象头将会多出4个字节用于存储数组的长度，也就是说，对象头占了16个byte的大小。 申明在64位的虚拟机中： 1、普通对象的对象头占用了96bit（位）= 12byte（字节） 2、对象头大小 = Mark Word(64bit) + Klass Pointer(32bit) = 96bit = 12byte 3、数组对象的对象头占用了128bit(位) = 16byte（字节） 4、数组对象头大小 = Mark Word(64bit) + Klass Pointer(32bit) + 数组长度(32bit) = 128bit = 16byte 。 5、其中Klass Pointer和数组长度实际上均是占用了64bit大小，由于虚拟机默认开启了指针压缩，在存储时，分别将64bit的Klass Pointer和64bit的数组长度均压缩成32bit，所以Klass Pointer和数组长度的实际存储空间均是32bit。 6、一个对象占用的最小内存是16byte。 7、静态属性不算在对象大小内 在32位的虚拟机中： 1、在32位的虚拟机中，普通对象的对象头占用了64bit（位）=8byte（字节）。 2、对象头大小 = Mark Word(32bit) + Klass Pointer(32bit) = 64bit = 8byte 3、数组对象的对象头占用了96bit（位） = 12byte（字节） 4、数组对象头大小=Mark Word(32bit) + Klass Pointer(32bit) + 数组长度(32bit) = 128bit = 12byte 对象头在JVM虚拟机规范中规范了对象头的定义： 每个GC管理的堆对象开头的公共结构。（每一个oop指针都指向一个对象头。）包括对象的布局、类型、GC状态、同步状态和标识哈希码的基本信息，由两个词组成（在Hotspot虚拟机中，分别是Mark Word和Klass Pointer），在数组中，他后面紧跟着一个长度字段，Java对象和VM内部对象都有一个通用的对象头格式。 Mark Word在存储格式如下： 由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间。 对象拥有五种状态：无锁、偏向锁、轻量级锁，重量级锁、GC标志。 其中不同的状态分别对应不同的锁标识位，如下： 锁状态 是否偏向锁 锁标志位 无锁 0 01 偏向锁 1 01 轻量级锁 00 重量级锁 10 GC标志 11 无锁和偏向锁的锁标识位均是01，通过是否偏向锁的信息判断锁的状态。 其中偏向锁和轻量级锁是JDK 1.6 对synchronized锁进行优化后新增的，这里面的重量级锁也通常说的是synchronized的对象锁。 在JDK 1.6以后的版本中，处理同步锁时存在锁升级的概念，JVM对同步锁的处理是从偏向锁开始的，随着竞争越来越激烈，处理方式从偏向锁升级到轻量级锁、最终升级到重量级锁。 这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 无锁状态当一个对象被创建时，它将处于无锁状态： 32位虚拟机： 锁状态 25bit 4bit 1bit是否偏向锁 2bit锁标志位 无锁 对象HashCode 对象分代年龄 0 01 64位虚拟机： 锁状态 25bit 31bit 1bit 4bit 1bit是否偏向锁 2bit锁标志位 无锁 unused 对象HashCode unsused 对象分代年龄 0 01 可以看到，在32位虚拟机中，无锁状态的对象，前25bit存储了对象的HashCode，跟着4bit存储了对象的分代年龄，接着1bit存储偏向锁信息，最后2bit存储锁标志位信息。 在64位虚拟机中，无锁状态的对象，前25bit未被使用，跟着31bit存储了对象的HashCode，接着1bit未被使用（某种场景下被用作cms_free），之后的存储同上。 对象HashCode（identitry_hashcode）：是当前对象存储在内存地址中的值 对象分代年龄（age）：在常规的策略中，一个对象创建后将存放在新生代中，度过了15次Young GC之后，将会存储到老年代中，而对象分代年龄则标记着当前对象经历过几次GC。由于对象分代年龄占了4bit，其范围是【00001111】，也就是【015】，也正是如此，新生代升级老年代的默认年龄由此得来。 是否偏向锁（biased_lock）：对象是否启用偏向锁标记，为1时表示对象启用偏向锁，为0时表示对象没有偏向锁。lock 和 biased_lock共同表示对象处于什么锁状态 锁标志位（lock）：由于希望用尽可能少的二进制位表示尽可能多的信息，所以设置了 lock标记。该标记的值不同，整个 Mark Word表示的含义不同。biased_lock 和 lock一起，表达的锁状态含义。 在上文中解释了定义好的Mark Word格式，在64位虚拟机的环境中，我们通过代码输出对象头来分析一下是否与之一致。 1234567public class LockDemo &#123; static L l = new L(); public static void main(String[] args) &#123; System.out.println(ClassLayout.parseInstance(l).toPrintable()); &#125;&#125; 123456789输出结果：cn.mastercom.lock.L object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 43 c0 00 20 (01000011 11000000 00000000 00100000) (536920131) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 可以看到，前8个字节的数据，分别占了两行，但是结果集和预想的不太一样，如果按照格式规定，应该有31位的HashCode，但是从结果上都是0，并没有发现所谓的HashCode，这是为什么呢？ 因为HashCode存储的是地址，地址需要通过计算得出，通过观察hashCode方法，发现是个public native int hashCode();本地方法，底层通过C++实现计算出来的。 我们通过调度hashCode()方法计算对象的Hashcode后，再观看一下对象头的变化 12345678public class LockDemo &#123; static L l = new L(); public static void main(String[] args) &#123; System.out.println(\"HashCode：\" + Integer.toHexString(l.hashCode())); System.out.println(ClassLayout.parseInstance(l).toPrintable()); &#125;&#125; 可以很明显得看到了数据发生了变化，但是怎么去观看这些二进制数据呢？ 这里需要引入一个字节顺序的概念，它和操作系统有关，在Linux操作系统上，它的字节顺序是是大端存储，在Windows中，它的字节顺序是小端存储，本案例处于Windows操作系统中。 如 二进制数值【10000000 00010000】，在小端存储中，低位（值）对低位（地址），高位对高位，也就是变成 【00010000 10000000】，换句话说，上文输出的对象头格式，应该倒过来看。 从偏移量OFFSET=8，SIZE=4的信息，表示的是Klass Pointer的信息，VALUE列下方的数值输出的是十六进制的数据，我们代码输出的HashCode也转成十六进制，接着倒着看OFFSET=4的信息，有25bit未被使用，接着可以看到选中区域就是存储了HashCode。如图所示。 最开始的【00000001】，也正如上图Mark Word格式所描述相同，如下： 1bit 4bit 1bit 2bit unused age biased_lock lock 也正是这样，可以看到，当前对象处于无锁状态，其对应的锁标志位是【01】 “本篇文章主要参考参考资料”","categories":[{"name":"Synchronized","slug":"Synchronized","permalink":"https://midkuro.github.io/categories/Synchronized/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"Synchronized","slug":"Synchronized","permalink":"https://midkuro.github.io/tags/Synchronized/"}]},{"title":"'SpringMVC 工作原理'","slug":"springmvc-model","date":"2020-09-11T04:20:00.000Z","updated":"2020-09-11T09:48:37.429Z","comments":true,"path":"2020/09/11/springmvc-model/","link":"","permalink":"https://midkuro.github.io/2020/09/11/springmvc-model/","excerpt":"","text":"SpringMVC工作原理SpringMVC流程 1、 用户发送请求至前端控制器DispatcherServlet。 2、 DispatcherServlet收到请求调用HandlerMapping处理器映射器。 3、 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。 4、 DispatcherServlet调用HandlerAdapter处理器适配器。 5、 HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。 6、 Controller执行完成返回ModelAndView。 7、 HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。 8、 DispatcherServlet将ModelAndView传给ViewReslover视图解析器。 9、 ViewReslover解析后返回具体View。 10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。 11、 DispatcherServlet响应用户。 组件说明：以下组件通常使用框架提供实现： DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。 HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。 ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。 组件：1、前端控制器DispatcherServlet（不需要工程师开发）,由框架提供作用：接收请求，响应结果，相当于转发器，中央处理器。有了dispatcherServlet减少了其它组件之间的耦合度。用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性。 2、处理器映射器HandlerMapping(不需要工程师开发),由框架提供作用：根据请求的url查找HandlerHandlerMapping负责根据用户请求找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 3、处理器适配器HandlerAdapter作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。 4、处理器Handler(需要工程师开发)注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行HandlerHandler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要工程师根据业务需求开发Handler。 5、视图解析器View resolver(不需要工程师开发),由框架提供作用：进行视图解析，根据逻辑视图名解析成真正的视图（view）View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 springmvc框架提供了很多的View视图类型，包括：jstlView、freemarkerView、pdfView等。一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由工程师根据业务需求开发具体的页面。 6、视图View(需要工程师开发jsp…)View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…） 核心架构的具体流程步骤如下：1、首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；2、DispatcherServlet——&gt;HandlerMapping， HandlerMapping 将会把请求映射为HandlerExecutionChain 对象（包含一个Handler 处理器（页面控制器）对象、多个HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新的映射策略；3、DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；4、HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView 对象（包含模型数据、逻辑视图名）；5、ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver 将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术；6、View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术；7、返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。 下边两个组件通常情况下需要开发： Handler：处理器，即后端控制器用controller表示。 View：视图，即展示给用户的界面，视图中通常需要标签语言展示模型数据。 在将SpringMVC之前我们先来看一下什么是MVC模式 MVC：MVC是一种设计模式 MVC的原理图： 分析： M-Model 模型（完成业务逻辑：有javaBean构成，service+dao+entity） V-View 视图（做界面的展示 jsp，html……） C-Controller 控制器（接收请求—&gt;调用模型—&gt;根据结果派发页面） springMVC是什么： springMVC是一个MVC的开源框架，springMVC=struts2+spring，springMVC就相当于是Struts2加上sring的整合，但是这里有一个疑惑就是，springMVC和spring是什么样的关系呢？这个在百度百科上有一个很好的解释：意思是说，springMVC是spring的一个后续产品，其实就是spring在原有基础上，又提供了web应用的MVC模块，可以简单的把springMVC理解为是spring的一个模块（类似AOP，IOC这样的模块），网络上经常会说springMVC和spring无缝集成，其实springMVC就是spring的一个子模块，所以根本不需要同spring进行整合。 SpringMVC的原理图： 第一步:用户发起请求到前端控制器（DispatcherServlet） 第二步：前端控制器请求处理器映射器（HandlerMappering）去查找处理器（Handle）：通过xml配置或者注解进行查找 第三步：找到以后处理器映射器（HandlerMappering）像前端控制器返回执行链（HandlerExecutionChain） 第四步：前端控制器（DispatcherServlet）调用处理器适配器（HandlerAdapter）去执行处理器（Handler） 第五步：处理器适配器去执行Handler 第六步：Handler执行完给处理器适配器返回ModelAndView 第七步：处理器适配器向前端控制器返回ModelAndView 第八步：前端控制器请求视图解析器（ViewResolver）去进行视图解析 第九步：视图解析器像前端控制器返回View 第十步：前端控制器对视图进行渲染 第十一步：前端控制器向用户响应结果 springMVC中的几个组件： 前端控制器（DispatcherServlet）：接收请求，响应结果，相当于电脑的CPU。 处理器映射器（HandlerMapping）：根据URL去查找处理器 处理器（Handler）：（需要程序员去写代码处理逻辑的） 处理器适配器（HandlerAdapter）：会把处理器包装成适配器，这样就可以支持多种类型的处理器，类比笔记本的适配器（适配器模式的应用） 视图解析器（ViewResovler）：进行视图解析，多返回的字符串，进行处理，可以解析成对应的页面 “本篇文章主要摘自参考资料”","categories":[{"name":"springMVC","slug":"springMVC","permalink":"https://midkuro.github.io/categories/springMVC/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://midkuro.github.io/tags/SpringMVC/"}]},{"title":"'MySql 核心技术 '","slug":"mysql-technology","date":"2020-09-08T04:00:00.000Z","updated":"2020-09-11T07:35:11.924Z","comments":true,"path":"2020/09/08/mysql-technology/","link":"","permalink":"https://midkuro.github.io/2020/09/08/mysql-technology/","excerpt":"","text":"MySql 核心技术基本概念启动和停止方式一：计算机——右击管理——服务 方式二：通过管理员身份运行 12net start 服务名（启动服务）net stop 服务名（停止服务） 登录和退出登录：mysql 【-h主机名 -P端口号 】-u用户名 -p密码 退出：exit或 ctrl+C 常见命令12345678910111213141516171.查看当前所有的数据库show databases;2.打开指定的库use 库名3.查看当前库的所有表show tables;4.查看其它库的所有表show tables from 库名;5.查看表结构desc 表名;6.查看服务器的版本方式一：登录到mysql服务端select version();方式二：没有登录到mysql服务端mysql --version或mysql --V 语法规范 不区分大小写,但建议关键字大写，表名、列名小写 每条命令最好用分号结尾 每条命令根据需要，可以进行缩进 或换行 注释： 单行注释：#注释文字单行注释：– 注释文字多行注释：/* 注释文字 */ 语言分类DQL（Data Query Language）：数据查询语言（select） DML (Data Manipulate Language):数据操作语言（insert 、update、delete） DDL（Data Define Languge）：数据定义语言（create、drop、alter） TCL（Transaction Control Language）：事务控制语言（commit、rollback） DQL语言基础查询语法： 1select 查询列表 from 表名; 特点： 1、查询列表可以是：表中的字段、常量值、表达式、函数2、查询的结果是一个虚拟的表格 加号+作用：做加法运算 123select 数值+数值; 直接运算select 字符+数值;先试图将字符转换成数值，如果转换成功，则继续运算；否则转换成0，再做运算select null+值;结果都为null 条件查询语法： 123select 查询列表from 表名where 筛选条件 分类： 简单条件运算符：&gt; &lt; = != &lt;&gt; &gt;= &lt;= 逻辑运算符：&amp;&amp; / and、|| / or、! / not 模糊查询：like、between and、in、is null /is not null通配符：%任意多个字符，_任意单个字符 is null 和 &lt;=&gt; 比较： 普通类型的数值 null值 可读性 is null × √ √ &lt;=&gt; √ √ × 排序查询语法： 1234select 查询列表from 表where 筛选条件order by 排序列表 【asc&#x2F;desc】 特点：1、asc ：升序，如果不写默认升序，desc：降序 2、排序列表 支持 单个字段、多个字段、函数、表达式、别名 3、order by的位置一般放在查询语句的最后（除limit语句之外） 常见函数单行函数字符函数123456789101112131415161718192021222324252627282930313233#1.length 获取参数值的字节个数SELECT LENGTH(&#39;john&#39;);#2.concat 拼接字符串SELECT CONCAT(last_name,&#39;_&#39;,first_name) 姓名 FROM employees;#3.upper 变大写 lower 变小写SELECT UPPER(&#39;john&#39;);SELECT LOWER(&#39;joHn&#39;);#4.substr、substring 截取字符串 注意：索引从1开始#截取从指定索引处后面所有字符SELECT SUBSTR(&#39;李莫愁爱上了陆展元&#39;,7) out_put;#截取从指定索引处指定字符长度的字符SELECT SUBSTR(&#39;李莫愁爱上了陆展元&#39;,1,3) out_put;#5.instr 返回子串第一次出现的索引，如果找不到返回0SELECT INSTR(&#39;杨不殷六侠悔爱上了殷六侠&#39;,&#39;殷八侠&#39;) AS out_put;#6.trim 去空格&#x2F;指定字符SELECT LENGTH(TRIM(&#39; 张翠山 &#39;)) AS out_put;#去除指定字符SELECT TRIM(&#39;aa&#39; FROM &#39;aaaaaaaaa张aaaaaaaaaaaa翠山aaaaa&#39;) AS out_put;#7.lpad 用指定的字符实现左填充指定长度SELECT LPAD(&#39;殷素素&#39;,2,&#39;*&#39;) AS out_put;#8.rpad 用指定的字符实现右填充指定长度SELECT RPAD(&#39;殷素素&#39;,12,&#39;ab&#39;) AS out_put;#9.replace 替换SELECT REPLACE(&#39;周芷若周芷若张无忌爱上了周芷若&#39;,&#39;周芷若&#39;,&#39;赵敏&#39;) AS out_put; 数学函数1234567891011121314151617181920#round 四舍五入SELECT ROUND(-1.55);SELECT ROUND(1.567,2);#ceil 向上取整,返回&gt;&#x3D;该参数的最小整数SELECT CEIL(-1.02);#floor 向下取整，返回&lt;&#x3D;该参数的最大整数SELECT FLOOR(-9.99); #truncate 截断SELECT TRUNCATE(1.69999,1); #1.6#mod取余&#x2F;*mod(a,b) ： a-a&#x2F;b*bmod(-10,-3):-10- (-10)&#x2F;(-3)*（-3）&#x3D;-1*&#x2F;SELECT MOD(10,-3);SELECT 10%3; 日期函数12345678910111213141516171819202122#now 返回当前系统日期+时间SELECT NOW();#curdate 返回当前系统日期，不包含时间SELECT CURDATE();#curtime 返回当前时间，不包含日期SELECT CURTIME();#可以获取指定的部分，年、月、日、小时、分钟、秒SELECT YEAR(NOW()) 年;SELECT YEAR(&#39;1998-1-1&#39;) 年;SELECT YEAR(hiredate) 年 FROM employees;SELECT MONTH(NOW()) 月;SELECT MONTHNAME(NOW()) 月;#str_to_date 将字符通过指定的格式转换成日期SELECT STR_TO_DATE(&#39;1998-3-2&#39;,&#39;%Y-%c-%d&#39;) AS out_put;#date_format 将日期转换成字符SELECT DATE_FORMAT(NOW(),&#39;%y年%m月%d日&#39;) AS out_put; 其他函数123SELECT VERSION();SELECT DATABASE();SELECT USER(); 流程控制函数123456789101112131415161718192021222324252627282930313233343536#1.if(条件表达式，表达式1，表达式2)：如果条件表达式成立，返回表达式1，否则返回表达式2SELECT IF(10&lt;5,&#39;大&#39;,&#39;小&#39;);#2.case情况1case 变量或表达式或字段when 常量1 then 值1when 常量2 then 值2...else 值nend#案例：SELECT salary 原始工资,department_id,CASE department_idWHEN 30 THEN salary*1.1WHEN 40 THEN salary*1.2WHEN 50 THEN salary*1.3ELSE salaryEND AS 新工资FROM employees;#case情况2case when 条件1 then 值1when 条件2 then 值2...else 值nend#案例：SELECT salary,CASE WHEN salary&gt;20000 THEN &#39;A&#39;WHEN salary&gt;15000 THEN &#39;B&#39;WHEN salary&gt;10000 THEN &#39;C&#39;ELSE &#39;D&#39;END AS 工资级别FROM employees; 分组函数功能：用作统计使用，又称为聚合函数或统计函数或组函数 分类：sum 求和、avg 平均值、max 最大值 、min 最小值 、count 计算个数 特点：1、sum、avg一般用于处理数值型、max、min、count可以处理任何类型 2、以上分组函数都忽略null值 3、可以和distinct搭配实现去重的运算 4、一般使用count(*)用作统计行数 5、和分组函数一同查询的字段要求是group by后的字段 效率上：MyISAM存储引擎，count(*)最高InnoDB存储引擎，count(*)和count(1)效率&gt;count(字段) 12345SELECT SUM(salary) FROM employees;SELECT AVG(salary) FROM employees;SELECT MIN(salary) FROM employees;SELECT MAX(salary) FROM employees;SELECT COUNT(salary) FROM employees; 分组查询语法： 12345select 查询列表from 表【where 筛选条件】group by 分组的字段【order by 排序的字段】; 特点：1、和分组函数一同查询的字段必须是group by后出现的字段 2、筛选分为两类：分组前筛选和分组后筛选 3、分组可以按单个字段也可以按多个字段 4、可以搭配着排序使用 问题：分组函数做筛选能不能放在where后面答：不能 问题：where——group by——having 一般来讲，能用分组前筛选的，尽量使用分组前筛选，提高效率 使用关键字 筛选的表 位置 分组前筛选 where 原始表 group by前 分组后筛选 having 分组后的结果 group by后 1234567#案例：每个工种有奖金的员工的最高工资&gt;6000的工种编号和最高工资,按最高工资升序SELECT job_id,MAX(salary) mFROM employeesWHERE commission_pct IS NOT NULLGROUP BY job_idHAVING m&gt;6000ORDER BY m ; 连接查询含义：又称多表查询，当查询的字段来自于多个表时，就会用到连接查询 笛卡尔乘积现象：表1 有m行，表2有n行，结果=m*n行 发生原因：没有有效的连接条件如何避免：添加有效的连接条件 分类： 按年代分类： sql92标准:仅仅支持内连接 sql99标准【推荐】：支持内连接+外连接（左外和右外）+交叉连接 按功能分类： 内连接： 等值连接 非等值连接 自连接 外连接： 左外连接 右外连接 全外连接 交叉连接SQL92语法等值连接语法： 1234567select 查询列表from 表1 别名,表2 别名where 表1.key&#x3D;表2.key【and 筛选条件】【group by 分组字段】【having 分组后的筛选】【order by 排序字段】 特点： ① 一般为表起别名 ②多表的顺序可以调换 ③n表连接至少需要n-1个连接条件 ④等值连接的结果是多表的交集部分 非等值连接语法： 1234567select 查询列表from 表1 别名,表2 别名where 非等值的连接条件【and 筛选条件】【group by 分组字段】【having 分组后的筛选】【order by 排序字段】 自连接语法： 1234567select 查询列表from 表 别名1,表 别名2where 等值的连接条件【and 筛选条件】【group by 分组字段】【having 分组后的筛选】【order by 排序字段】 SQL99语法内连接语法： 1234567891011121314select 查询列表from 表1 别名【inner】 join 表2 别名 on 连接条件where 筛选条件group by 分组列表having 分组后的筛选order by 排序列表limit 子句;#案例SELECT last_name,department_nameFROM departments dJOIN employees eON e.&#96;department_id&#96; &#x3D; d.&#96;department_id&#96;; 特点：①表的顺序可以调换②内连接的结果=多表的交集③n表连接至少需要n-1个连接条件 分类：等值连接、非等值连接、自连接 外连接语法： 123456789101112131415select 查询列表from 表1 别名left|right|full【outer】 join 表2 别名 on 连接条件where 筛选条件group by 分组列表having 分组后的筛选order by 排序列表limit 子句;#案例SELECT b.*,bo.*FROM boys boLEFT OUTER JOIN beauty bON b.&#96;boyfriend_id&#96; &#x3D; bo.&#96;id&#96;WHERE b.&#96;id&#96; IS NULL; 特点：①查询的结果=主表中所有的行，如果从表和它匹配的将显示匹配行，如果从表没有匹配的则显示null②left join 左边的就是主表，right join 右边的就是主表， full join 两边都是主表③一般用于查询除了交集部分的剩余的不匹配的行 交叉连接语法： 123select 查询列表from 表1 别名cross join 表2 别名; 子查询含义：嵌套在其他语句内部的select语句称为子查询或内查询，外面的语句可以是insert、update、delete、select等，一般select作为外面语句较多外面如果为select语句，则此语句称为外查询或主查询 分类：1、按出现位置select后面：仅仅支持标量子查询 from后面：表子查询 where或having后面：标量子查询、列子查询、行子查询 exists后面：标量子查询、列子查询、行子查询、表子查询 2、按结果集的行列标量子查询（单行子查询）：结果集为一行一列列子查询（多行子查询）：结果集为多行一列行子查询：结果集为多行多列表子查询：结果集为多行多列 分页查询语法： 12345678910111213141516171819select 查询列表from 表【join type】 join 表2on 连接条件where 筛选条件group by 分组字段having 分组后的筛选order by 排序的字段】limit 【offset,】size;offset要显示条目的起始索引（起始索引从0开始）size 要显示的条目个数#案例1：查询前五条员工信息SELECT * FROM employees LIMIT 0,5;SELECT * FROM employees LIMIT 5;#案例2：查询第11条——第25条SELECT * FROM employees LIMIT 10,15; 特点： limit语句放在查询语句的最后，假如要显示的页数为page，每一页条目数为size 123select 查询列表from 表limit (page-1)*size,size; 联合查询union 联合 合并：将多条查询语句的结果合并成一个结果 语法： 12345678910查询语句1union 【all】查询语句2union 【all】...#案例：查询部门编号&gt;90或邮箱包含a的员工信息SELECT * FROM employees WHERE email LIKE &#39;%a%&#39;UNIONSELECT * FROM employees WHERE department_id&gt;90; 应用场景：要查询的结果来自于多个表，且多个表没有直接的连接关系，但查询的信息一致时 特点：1、要求多条查询语句的查询列数是一致的！2、要求多条查询语句的查询的每一列的类型和顺序最好一致3、union关键字默认去重，如果使用union all 可以包含重复项 查询总结执行顺序： 123456789select 查询列表 7from 表1 别名 1连接类型 join 表2 2on 连接条件 3where 筛选 4group by 分组列表 5having 筛选 6order by排序列表 8limit 起始条目索引，条目数; 9 DML语言插入语句语法： 123insert into 表名(字段名,...) values(值,...);或insert into 表名 set 字段&#x3D;值,字段&#x3D;值,...; 特点：1、要求值的类型和字段的类型要一致或兼容2、字段的个数和顺序不一定与原始表中的字段个数和顺序一致但必须保证值和字段一一对应3、假如表中有可以为null的字段，注意可以通过以下两种方式插入null值①字段和值都省略②字段写上，值使用null4、字段和值的个数必须一致5、字段名可以省略，默认所有列 两种方式 的区别：1.方式一支持一次插入多行，语法如下： 1insert into 表名【(字段名,..)】 values(值，..),(值，...),...; 2.方式一支持子查询，语法如下： 1insert into 表名 查询语句; 修改语句语法： 1234567891011121314151617181920212223update 表名set 列&#x3D;新值,列&#x3D;新值,...where 筛选条件;#修改多表的记录【补充】sql92语法：update 表1 别名,表2 别名set 列&#x3D;值,...where 连接条件and 筛选条件;sql99语法：update 表1 别名inner|left|right join 表2 别名on 连接条件set 列&#x3D;值,...where 筛选条件;#案例 修改多表的记录UPDATE boys boINNER JOIN beauty b ON bo.&#96;id&#96;&#x3D;b.&#96;boyfriend_id&#96;SET b.&#96;phone&#96;&#x3D;&#39;119&#39;,bo.&#96;userCP&#96;&#x3D;1000WHERE bo.&#96;boyName&#96;&#x3D;&#39;张无忌&#39;; 删除语句语法： 123456789101112131415161718方式一：deletedelete from 表名 where 筛选条件#多表的删除【补充】sql92语法：delete 表1的别名,表2的别名from 表1 别名,表2 别名where 连接条件and 筛选条件;sql99语法：delete 表1的别名,表2的别名from 表1 别名inner|left|right join 表2 别名 on 连接条件where 筛选条件;方式二：truncatetruncate table 表名; delete和truncate的区别： 1.delete 可以加where 条件，truncate不能加 2.truncate删除，效率高一丢丢 3.假如要删除的表中有自增长列，如果用delete删除后，再插入数据，自增长列的值从断点开始，而truncate删除后，再插入数据，自增长列的值从1开始。 4.truncate删除没有返回值，delete删除有返回值 5.truncate删除不能回滚，delete删除可以回滚. DDL语言库的管理1234567891011121314#库的创建create database 【if not exists】库名 库名【 character set 字符集名】;#案例：创建库BooksCREATE DATABASE IF NOT EXISTS books ;#库的修改RENAME DATABASE books TO 新库名;#更改库的字符集ALTER DATABASE books CHARACTER SET gbk;#库的删除DROP DATABASE IF EXISTS books; 表的管理表的创建1234567891011121314151617create table 表名( 列名 列的类型【(长度) 约束】, 列名 列的类型【(长度) 约束】, 列名 列的类型【(长度) 约束】, ... 列名 列的类型【(长度) 约束】)#案例：创建表BookCREATE TABLE book( id INT,#编号 bName VARCHAR(20),#图书名 price DOUBLE,#价格 authorId INT,#作者编号 publishDate DATETIME#出版日期); 表的修改12345678910111213141516alter table 表名 add|drop|modify|change column 列名 【列类型 约束】;#添加列alter table 表名 add column 列名 类型 【first|after 字段名】;#修改列的类型或约束alter table 表名 modify column 列名 新类型 【新约束】;#修改列名alter table 表名 change column 旧列名 新列名 类型;#删除列alter table 表名 drop column 列名;#修改表名alter table 表名 rename 【to】 新表名; 表的删除1drop table【if exists】 表名; 表的复制12345#复制表的结构create table 表名 like 旧表;#复制表的结构+数据create table 表名 select 查询列表 from 旧表【where 筛选】; 数据类型数值型整型 tinyint smallint mediumint int bigint 字节 1 2 3 4 8 特点：①都可以设置无符号和有符号，默认有符号，通过unsigned设置无符号 ②如果超出了范围，会报out or range异常，插入临界值 ③长度可以不指定，默认会有一个长度，长度代表显示的最大宽度，如果不够则左边用0填充，但需要搭配zerofill，并且默认变为无符号整型 1234#如何设置无符号CREATE TABLE tab_int( t1 INT(7) ZEROFILL); 浮点型定点数：decimal(M,D)浮点数： float(M,D) double(M,D) 字节 4 8 特点：①M代表整数部位+小数部位的个数，D代表小数部位 ②如果超出范围，则报out or range异常，并且插入临界值 ③M和D都可以省略，但对于定点数，M默认为10，D默认为0 ④如果精度要求较高，则优先考虑使用定点数 字符型较短的文本：char、varchar 其他：binary和varbinary用于保存较短的二进制，enum用于保存枚举，set用于保存集合 较长的文本：text、blob(较大的二进制) 特点： char varchar 写法 char(M) varchar(M) M的意思 最大的字符数，可以省略，默认为1 最大的字符数，不可以省略 特点 固定长度的字符 可变长度的字符 空间的耗费 比较耗费 比较节省 效率 高 低 日期型 分类 特点 date 只保存日期 time 只保存时间 year 只保存年 datetime 日期+时间 timestamp 日期+时间 字节 范围 时区影响 datetime 8 1000-9999 不受 timestamp 4 1970-2038 受 12345678910111213#案例CREATE TABLE tab_date( t1 DATETIME, t2 TIMESTAMP);INSERT INTO tab_date VALUES(NOW(),NOW());SELECT * FROM tab_date;SHOW VARIABLES LIKE &#39;time_zone&#39;;SET time_zone&#x3D;&#39;+9:00&#39;; 常见约束含义：一种限制，用于限制表中的数据，为了保证表中的数据的准确和可靠性 分类： 特点 NOT NULL 非空，用于保证该字段的值不能为空 DEFAULT 默认，用于保证该字段有默认值 PRIMARY KEY 主键，用于保证该字段的值具有唯一性，并且非空 UNIQUE 唯一，用于保证该字段的值具有唯一性，可以为空 CHECK 检查约束【mysql中不支持】 FOREIGN KEY 外键，用于限制两个表的关系，用于保证该字段的值必须来自于主表的关联列的值，在从表添加外键约束，用于引用主表中某列的值 添加约束的时机：创建表时、修改表时 约束的添加分类： 列级约束： 六大约束语法上都支持，但外键约束没有效果 表级约束： 除了非空、默认，其他的都支持 主键和唯一的区别： 保证唯一性 是否允许为空 一个表中可以有多少个 是否允许组合 主键 √ 至多一个 √，但不推荐 唯一 √ √ 可以多个 √，但不推荐 外键： 1、要求在从表设置外键关系 2、从表的外键列的类型和主表的关联列的类型要求一致或兼容，名称无要求 3、主表的关联列必须是一个key（一般是主键或唯一） 4、插入数据时，先插入主表，再插入从表。删除数据时，先删除从表，再删除主表 123456可以通过以下两种方式来删除主表的记录#方式一：级联删除ALTER TABLE stuinfo ADD CONSTRAINT fk_stu_major FOREIGN KEY(majorid) REFERENCES major(id) ON DELETE CASCADE;#方式二：级联置空ALTER TABLE stuinfo ADD CONSTRAINT fk_stu_major FOREIGN KEY(majorid) REFERENCES major(id) ON DELETE SET NULL; 创建表时添加约束添加列级约束 1234567#只支持：默认、非空、主键、唯一create table 表名( 字段名 字段类型 not null,#非空 字段名 字段类型 primary key,#主键 字段名 字段类型 unique,#唯一 字段名 字段类型 default 值,#默认) 添加表级约束 1234create table 表名( 字段名 字段类型 constraint 约束名 foreign key(字段名) references 主表（被引用列）) 支持类型 起约束名 列级约束 除了外键 不可以 表级约束 除了非空和默认 可以，但是对主键无效 12345678910#案例CREATE TABLE IF NOT EXISTS stuinfo( id INT PRIMARY KEY, stuname VARCHAR(20), sex CHAR(1), age INT DEFAULT 18, seat INT UNIQUE, majorid INT, CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorid) REFERENCES major(id)); 修改表约束12345678#添加&#x2F;删除列级约束alter table 表名 modify column 字段名 字段类型 新约束;#添加表级约束alter table 表名 add 【constraint 约束名】 约束类型(字段名) 【外键的引用】;#删除列级约束ALTER TABLE 表名 DROP 约束类型 字段名; 1234567891011121314151617181920212223242526添加非空alter table 表名 modify column 字段名 字段类型 not null;删除非空alter table 表名 modify column 字段名 字段类型 ;2、默认添加默认alter table 表名 modify column 字段名 字段类型 default 值;删除默认alter table 表名 modify column 字段名 字段类型 ;3、主键添加主键alter table 表名 add【 constraint 约束名】 primary key(字段名);删除主键alter table 表名 drop primary key;4、唯一添加唯一alter table 表名 add【 constraint 约束名】 unique(字段名);删除唯一alter table 表名 drop index 索引名;5、外键添加外键alter table 表名 add【 constraint 约束名】 foreign key(字段名) references 主表（被引用列）;删除外键alter table 表名 drop foreign key 约束名; 自增长列123456789101112131415#创建表时设置自增长列create table 表( 字段名 字段类型 约束 auto_increment)#修改表时设置自增长列alter table 表 modify column 字段名 字段类型 约束 auto_increment#删除自增长列alter table 表 modify column 字段名 字段类型 约束 #相关知识SHOW VARIABLES LIKE &#39;%auto_increment%&#39;;SET auto_increment_increment&#x3D;3; 特点：1、不用手动插入值，可以自动提供序列值，默认从1开始，步长为1auto_increment_increment，如果要更改起始值：手动插入值，如果要更改步长：更改系统变量，set auto_increment_increment=值; 2、一个表至多有一个自增长列 3、自增长列只能支持数值型 4、自增长列必须为一个key TCL语言事务含义：一条或多条sql语句组成一个执行单位，一组sql语句要么都执行要么都不执行特点（ACID） A 原子性：一个事务是不可再分割的整体，要么都执行要么都不执行 C 一致性：一个事务可以使数据从一个一致状态切换到另外一个一致的状态 I 隔离性：一个事务不受其他事务的干扰，多个事务互相隔离的 D 持久性：一个事务一旦提交了，则永久的持久化到本地 隐式（自动）事务：没有明显的开启和结束，本身就是一条事务可以自动提交，比如insert、update、delete 123456789101112131415#显式事务：具有明显的开启和结束#步骤1：开启事务set autocommit&#x3D;0;start transaction; #可省略#步骤2：编写事务中的sql语句(select insert update delete)语句1;语句2;...#可以设置保存点savepoint 回滚点名;#步骤3：结束&#x2F;回滚事务commit;提交事务rollback;回滚事务rollback to 回滚点名; 并发事务多个事务同时操作同一个数据库的相同数据时，并发问题都有哪些？ 脏读：一个事务读取了其他事务还没有提交的数据，读到的是其他事务“更新”的数据 不可重复读：一个事务多次读取，结果不一样 幻读：一个事务读取了其他事务还没有提交的数据，只是读到的是 其他事务“插入”的数据 可以通过设置事务的隔离级别来解决以上的问题。 脏读 不可重复读 幻读 read uncommitted:读未提交 × × × read committed：读已提交 √ × × repeatable read：可重复读 √ √ × serializable：串行化 √ √ √ 123456#mysql中默认 第三个隔离级别 repeatable read#oracle中默认第二个隔离级别 read committed#查看隔离级别select @@tx_isolation;#设置隔离级别set session|global transaction isolation level 隔离级别; 其他视图mysql5.1版本出现的新特性，本身是一个虚拟表，它的数据来自于表，通过执行时动态生成。好处：1、简化sql语句2、提高了sql的重用性3、保护基表的数据，提高了安全性 12345678910111213141516171819202122#创建create view 视图名as查询语句;#修改#方式一：create or replace view 视图名as查询语句;#方式二：alter view 视图名as查询语句#删除drop view 视图1，视图2,...;#查看desc 视图名;show create view 视图名; 注意：视图一般用于查询的，而不是更新的，所以具备以下特点的视图都不允许更新①包含分组函数、group by、distinct、having、union、②join③常量视图④where后的子查询用到了from中的表⑤用到了不可更新的视图 关键字 是否占用物理空间 使用 视图 view 占用较小，只保存sql逻辑 一般用于查询 表 table 保存实际的数据 增删改查 变量系统变量变量由系统提供的，不用自定义语法： 12345678910111213#查看系统变量show 【global|session 】variables like &#39;&#39;; 如果没有显式声明global还是session，则默认是session#查看指定的系统变量的值select @@【global|session】.变量名; 如果没有显式声明global还是session，则默认是session#为系统变量赋值#方式一：set 【global|session 】 变量名&#x3D;值; 如果没有显式声明global还是session，则默认是session#方式二：set @@global.变量名&#x3D;值;set @@变量名&#x3D;值； 全局变量服务器层面上的，必须拥有super权限才能为系统变量赋值，作用域为整个服务器，也就是针对于所有连接（会话）有效 123456789#查看所有全局变量SHOW GLOBAL VARIABLES;#查看满足条件的部分系统变量SHOW GLOBAL VARIABLES LIKE &#39;%char%&#39;;#查看指定的系统变量的值SELECT @@global.autocommit;#为某个系统变量赋值SET @@global.autocommit&#x3D;0;SET GLOBAL autocommit&#x3D;0; 会话变量服务器为每一个连接的客户端都提供了系统变量，作用域为当前的连接（会话） 12345678910#查看所有会话变量SHOW SESSION VARIABLES;#查看满足条件的部分会话变量SHOW SESSION VARIABLES LIKE &#39;%char%&#39;;#查看指定的会话变量的值SELECT @@autocommit;SELECT @@session.tx_isolation;#为某个会话变量赋值SET @@session.tx_isolation&#x3D;&#39;read-uncommitted&#39;;SET SESSION tx_isolation&#x3D;&#39;read-committed&#39;; 自定义变量用户变量作用域：针对于当前连接（会话）生效位置：begin end里面，也可以放在外面 12345678910111213141516#赋值操作符：&#x3D;或:&#x3D;#声明并赋值：set @变量名&#x3D;值;或set @变量名:&#x3D;值;或select @变量名:&#x3D;值;#更新值#方式一：set @变量名&#x3D;值; 或set @变量名:&#x3D;值; 或select @变量名:&#x3D;值;#方式二：select xx into @变量名 from 表;#使用select @变量名; 局部变量作用域：仅仅在定义它的begin end中有效位置：只能放在begin end中，而且只能放在第一句 1234567891011#声明declare 变量名 类型 【default 值】;#赋值或更新#方式一：set 变量名&#x3D;值;或set 变量名:&#x3D;值;或select @变量名:&#x3D;值;#方式二：select xx into 变量名 from 表;#使用select 变量名; 作用域 定义位置 语法 用户变量 当前会话 会话的任何地方 加@符号，不用指定类型 局部变量 定义它的BEGIN END中 BEGIN END的第一句话 一般不用加@,需要指定类型 存储过程创建1234567create procedure 存储过程名(参数模式 参数名 参数类型)begin 存储过程体end注意：1.参数模式：in、out、inout，其中in可以省略2.存储过程体的每一条sql语句都需要用分号结尾 注意：1、参数列表包含三部分：参数模式 参数名 参数类型举例：in stuname varchar(20) 参数模式：in：该参数可以作为输入，也就是该参数需要调用方传入值out：该参数可以作为输出，也就是该参数可以作为返回值inout：该参数既可以作为输入又可以作为输出，也就是该参数既需要传入值，又可以返回值 2、如果存储过程体仅仅只有一句话，begin end可以省略存储过程体中的每条sql语句的结尾要求必须加分号。存储过程的结尾可以使用 delimiter 重新设置 1234#语法delimiter 结束标记#案例：delimiter $ 调用1234567891011call 存储过程名(实参列表)#举例：#调用in模式的参数：call sp1（‘值’）;#调用out模式的参数：set @name; call sp1(@name);select @name;#调用inout模式的参数：set @name&#x3D;值; call sp1(@name); select @name; 123456789101112131415#案例CREATE PROCEDURE myp7(IN beautyName VARCHAR(20),OUT boyName VARCHAR(20),OUT usercp INT) BEGIN SELECT boys.boyname ,boys.usercp INTO boyname,usercp FROM boys RIGHT JOIN beauty b ON b.boyfriend_id &#x3D; boys.id WHERE b.name&#x3D;beautyName ; END $#多个out参数用into，逗号隔开#调用CALL myp7(&#39;小昭&#39;,@name,@cp)$SELECT @name,@cp$ 查看1show create procedure 存储过程名; 删除1drop procedure 存储过程名; 函数","categories":[{"name":"MySql","slug":"MySql","permalink":"https://midkuro.github.io/categories/MySql/"}],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://midkuro.github.io/tags/MySql/"}]},{"title":"'Netty（二）编码 '","slug":"netty-source","date":"2020-08-04T04:00:00.000Z","updated":"2020-09-08T14:22:31.650Z","comments":true,"path":"2020/08/04/netty-source/","link":"","permalink":"https://midkuro.github.io/2020/08/04/netty-source/","excerpt":"","text":"Netty服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;public class NettyServer &#123; public static void main(String[] args) throws Exception &#123; //创建BossGroup 和 WorkerGroup //说明 //1. 创建两个线程组 bossGroup 和 workerGroup //2. bossGroup 只是处理连接请求 , 真正的和客户端业务处理，会交给 workerGroup完成 //3. 两个都是无限循环 //4. bossGroup 和 workerGroup 含有的子线程(NioEventLoop)的个数 // 默认实际 cpu核数 * 2 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); //8 try &#123; //创建服务器端的启动对象，配置参数 ServerBootstrap bootstrap = new ServerBootstrap(); //使用链式编程来进行设置 bootstrap.group(bossGroup, workerGroup) //设置两个线程组 .channel(NioServerSocketChannel.class) //使用NioSocketChannel 作为服务器的通道实现 .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列得到连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动连接状态 //.handler(null) // 该 handler对应 bossGroup , childHandler 对应 workerGroup .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;//创建一个通道初始化对象(匿名对象) //给pipeline 设置处理器 @Override protected void initChannel(SocketChannel ch) throws Exception &#123; System.out.println(\"客户socketchannel hashcode=\" + ch.hashCode()); //可以使用一个集合管理 SocketChannel， 再推送消息时，可以将业务加入到各个channel 对应的 NIOEventLoop 的 taskQueue 或者 scheduleTaskQueue ch.pipeline().addLast(new NettyServerHandler()); &#125; &#125;); // 给我们的workerGroup 的 EventLoop 对应的管道设置处理器 System.out.println(\".....服务器 is ready...\"); //绑定一个端口并且同步, 生成了一个 ChannelFuture 对象 //启动服务器(并绑定端口) ChannelFuture cf = bootstrap.bind(6668).sync(); //给cf 注册监听器，监控我们关心的事件 cf.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (cf.isSuccess()) &#123; System.out.println(\"监听端口 6668 成功\"); &#125; else &#123; System.out.println(\"监听端口 6668 失败\"); &#125; &#125; &#125;); //对关闭通道进行监听 cf.channel().closeFuture().sync(); &#125;finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.Channel;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.channel.ChannelPipeline;import io.netty.util.CharsetUtil;import java.util.concurrent.TimeUnit;/*说明1. 我们自定义一个Handler 需要继续netty 规定好的某个HandlerAdapter(规范)2. 这时我们自定义一个Handler , 才能称为一个handler */public class NettyServerHandler extends ChannelInboundHandlerAdapter &#123; //读取数据实际(这里我们可以读取客户端发送的消息) /* 1. ChannelHandlerContext ctx:上下文对象, 含有 管道pipeline , 通道channel, 地址 2. Object msg: 就是客户端发送的数据 默认Object */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(\"服务器读取线程 \" + Thread.currentThread().getName() + \" channle =\" + ctx.channel()); System.out.println(\"server ctx =\" + ctx); Channel channel = ctx.channel(); ChannelPipeline pipeline = ctx.pipeline(); //本质是一个双向链表, 出栈入栈 //将 msg 转成一个 ByteBuf //ByteBuf 是 Netty 提供的，不是 NIO 的 ByteBuffer. ByteBuf buf = (ByteBuf) msg; System.out.println(\"客户端发送消息是:\" + buf.toString(CharsetUtil.UTF_8)); System.out.println(\"客户端地址:\" + channel.remoteAddress()); &#125; //数据读取完毕 @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; //writeAndFlush 是 write + flush //将数据写入到缓存，并刷新 //一般讲，我们对这个发送的数据进行编码 ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(&gt;^ω^&lt;)喵1\", CharsetUtil.UTF_8)); &#125; //处理异常, 一般是需要关闭通道 @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 客户端1234567891011121314151617181920212223242526272829303132333435363738394041import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;public class NettyClient &#123; public static void main(String[] args) throws Exception &#123; //客户端需要一个事件循环组 EventLoopGroup group = new NioEventLoopGroup(); try &#123; //创建客户端启动对象 //注意客户端使用的不是 ServerBootstrap 而是 Bootstrap Bootstrap bootstrap = new Bootstrap(); //设置相关参数 bootstrap.group(group) //设置线程组 .channel(NioSocketChannel.class) // 设置客户端通道的实现类(反射) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new NettyClientHandler()); //加入自己的处理器 &#125; &#125;); System.out.println(\"客户端 ok..\"); //启动客户端去连接服务器端 //关于 ChannelFuture 要分析，涉及到netty的异步模型 ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 6668).sync(); //给关闭通道进行监听 channelFuture.channel().closeFuture().sync(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.util.CharsetUtil;public class NettyClientHandler extends ChannelInboundHandlerAdapter &#123; //当通道就绪就会触发该方法 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"client \" + ctx); ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, server: (&gt;^ω^&lt;)喵\", CharsetUtil.UTF_8)); &#125; //当通道有读取事件时，会触发 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf buf = (ByteBuf) msg; System.out.println(\"服务器回复的消息:\" + buf.toString(CharsetUtil.UTF_8)); System.out.println(\"服务器的地址： \"+ ctx.channel().remoteAddress()); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 运行","categories":[{"name":"Netty","slug":"Netty","permalink":"https://midkuro.github.io/categories/Netty/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://midkuro.github.io/tags/NIO/"},{"name":"Netty","slug":"Netty","permalink":"https://midkuro.github.io/tags/Netty/"}]},{"title":"'Netty（一）Netty简介 与 零拷贝 '","slug":"netty-model","date":"2020-08-03T04:00:00.000Z","updated":"2020-09-08T14:22:23.254Z","comments":true,"path":"2020/08/03/netty-model/","link":"","permalink":"https://midkuro.github.io/2020/08/03/netty-model/","excerpt":"","text":"Netty简介与零拷贝零拷贝我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的（只有 kernel buffer 有一份数据），也就是说，是没有CPU拷贝的。 零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的 CPU 缓存伪共享以及无 CPU 校验和计算。 在 Java 程序中，常用的零拷贝有 mmap(内存映射) 和 sendFile。 传统IO 传统的IO模型，从数据传输到客户端需要经过3次上下文切换,4次数据拷贝。 上下文切换：从用户态–&gt;内核态–&gt;用户态–&gt;内核态 数据拷贝：DMA–&gt;内核态-&gt;用户态–&gt;Socket缓冲区–&gt;TCP协议(网卡) mmap mmap通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户控件的拷贝次数。 mmap实现了3次上下文切换，3次数据拷贝。 sendFile Linux 2.1 版本 提供了 sendFile 函数，其基本原理如下：数据根本不经过用户态，直接从内核缓冲区进入到 Socket Buffer，同时，由于和用户态完全无关，就减少了一次上下文切换。 Linux 在 2.4 版本中，做了一些修改，避免了从内核缓冲区拷贝到 Socket buffer 的操作，直接拷贝到协议栈，从而再一次减少了数据拷贝。 这里其实有 一次cpu 拷贝： 内核态–&gt; socket buffer，但是，拷贝的信息很少，比如lenght ,offset, 消耗低，可以忽略。 区别mmap 适合小数据量读写，sendFile 适合大文件传输。 mmap 需要 3 次上下文切换，3 次数据拷贝；sendFile 需要 2 次上下文切换，最少 2 次数据拷贝。 sendFile 可以利用DMA 方式，减少 CPU 拷贝，mmap 则不能（必须从内核拷贝到 Socket 缓冲区）。 Netty介绍Netty 是由 JBOSS 提供的一个 Java 开源框架。Netty 提供异步的、基于事件驱动的网络应用程序框架，用以快速开发高性能、高可靠性的网络 IO 程序 Netty 可以帮助你快速、简单的开发出一个网络应用，相当于简化和流程化了 NIO 的开发过程 Netty 是目前最流行的 NIO 框架，Netty 在互联网领域、大数据分布式计算领域、游戏行业、通信行业等获得了广泛的应用，知名的 Elasticsearch 、Dubbo 框架内部都采用了 Netty。 NIO存在的问题NIO 的类库和 API 繁杂，使用麻烦：需要熟练掌握 Selector、ServerSocketChannel、SocketChannel、ByteBuffer 等。需要具备其他的额外技能：要熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，你必须对多线程和网络编程非常熟悉，才能编写出高质量的 NIO 程序。 开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常流的处理等等。 JDK NIO 的 Bug：例如臭名昭著的 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%。直到 JDK 1.7 版本该问题仍旧存在，没有被根本解决。 Netty的优点Netty 对 JDK 自带的 NIO 的 API 进行了封装，解决了上述问题。 设计优雅：适用于各种传输类型的统一 API 阻塞和非阻塞 Socket；基于灵活且可扩展的事件模型，可以清晰地分离关注点；高度可定制的线程模型 - 单线程，一个或多个线程池. 使用方便：详细记录的 Javadoc，用户指南和示例；没有其他依赖项，JDK 5（Netty 3.x）或 6（Netty 4.x）就足够了。高性能、吞吐量更高：延迟更低；减少资源消耗；最小化不必要的内存复制。 安全：完整的 SSL/TLS 和 StartTLS 支持。社区活跃、不断更新：社区活跃，版本迭代周期短，发现的 Bug 可以被及时修复，同时，更多的新功能会被加入。 Netty版本说明netty版本分为 netty3.x 和 netty4.x、netty5.x因为Netty5出现重大bug，已经被官网废弃了，目前推荐使用的是Netty4.x的稳定版本。下载地址 线程模型不同的线程模式，对程序的性能有很大影响，为了搞清Netty 线程模式，我们来系统的讲解下 各个线程模式， 最后看看Netty 线程模型有什么优越性. 目前存在的线程模型有：传统阻塞 I/O 服务模型 和Reactor 模式。 根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现： 单 Reactor 单线程 单 Reactor 多线程 主从 Reactor 多线程 Netty 线程模式：基于主从 Reactor 多线程模型做了一定的改进，其中主从 Reactor 多线程模型有多个 Reactor。 传统阻塞 I/O 服务模型 工作原理图黄色的框表示对象， 蓝色的框表示线程，白色的框表示方法(API)。 模型特点采用阻塞IO模式获取输入的数据，每个连接都需要独立的线程完成数据的输入，业务处理和数据返回。 问题分析当并发数很大，就会创建大量的线程，占用很大系统资源，连接创建后，如果当前线程暂时没有数据可读，该线程会阻塞在read操作，造成线程资源浪费。 Reactor 模式针对传统阻塞 I/O 服务模型的 2 个缺点，解决方案： 基于 I/O 复用模型：多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。 Reactor对应的叫法: 反应器模式 分发者模式(Dispatcher) 通知者模式(notifier) 基于线程池复用线程资源：不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。 Reactor 模式，通过一个或多个输入同时传递给服务处理器的模式(基于事件驱动)。 服务器端程序处理传入的多个请求，并将它们同步分派到相应的处理线程， 因此Reactor模式也叫 Dispatcher模式。 Reactor 模式使用IO复用监听事件， 收到事件后，分发给某个线程(进程), 这点就是网络服务器高并发处理关键。 核心组成Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。 它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人； Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。 单 Reactor 单线程方案说明： Select 是前面 I/O 复用模型介绍的标准网络编程 API，可以实现应用程序通过一个阻塞对象监听多路连接请求。 Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发。 如果是建立连接请求事件，则由Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理。 如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应，Handler 会完成 Read–&gt;业务处理–&gt;Send 的完整业务流程 结合实例：服务器端用一个线程通过多路复用搞定所有的 IO 操作（包括连接，读、写等），编码简单，清晰明了，但是如果客户端连接数量较多，将无法支撑。 方案优缺点分析： 优点：模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成 缺点：性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈缺点：可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。 使用场景：客户端的数量有限，业务处理非常快速，比如 Redis在业务处理的时间复杂度 O(1) 的情况。 单Reactor多线程 方案说明：Reactor 对象通过select 监控客户端请求事件, 收到事件后，通过dispatch进行分发。 如果建立连接请求, 则由Acceptor 通过accept 处理连接请求, 然后创建一个Handler对象处理完成连接后的各种事件。 如果不是连接请求，则由reactor分发调用连接对应的handler 来处理。 handler 只负责响应事件，不做具体的业务处理, 通过read 读取数据后，会分发给后面的worker线程池的某个线程处理业务。 worker 线程池会分配独立线程完成真正的业务，并将结果返回给handler。 handler收到响应后，通过send 将结果返回给client。 方案优缺点分析： 优点：可以充分的利用多核cpu 的处理能力 缺点：多线程数据共享和访问比较复杂，reactor 处理所有的事件的监听和响应，在单线程运行， 在高并发场景容易出现性能瓶颈。 主从 Reactor 多线程 针对单 Reactor 多线程模型中，Reactor 在单线程中运行，高并发场景下容易成为性能瓶颈，可以让 Reactor 在多线程中运行。 方案说明： Reactor主线程 MainReactor 对象通过select 监听连接事件, 收到事件后，通过Acceptor 处理连接事件。 当 Acceptor 处理连接事件后，MainReactor 将连接分配给SubReactor。 Subreactor 将连接加入到连接队列进行监听,并创建handler进行各种事件处理。 当有新事件发生时， Subreactor 就会调用对应的handler处理。 handler 通过read 读取数据，分发给后面的worker 线程处理。 worker 线程池分配独立的worker 线程进行业务处理，并返回结果。 handler 收到响应的结果后，再通过send 将结果返回给client。 Reactor 主线程可以对应多个Reactor 子线程, 即MainRecator 可以关联多个SubReactor。 方案优缺点说明： 优点：父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。 缺点：编程复杂度较高。 结合实例：这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。 总结3 种模式用生活案例来理解：单 Reactor 单线程，前台接待员和服务员是同一个人，全程为顾客服 单 Reactor 多线程，1 个前台接待员，多个服务员，接待员只负责接待 主从 Reactor 多线程，多个前台接待员，多个服务生 Reactor 模式具有如下的优点： 响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的。 可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销。 扩展性好，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源。 复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。 Netty模型 Netty 主要基于主从Reactor 多线程模型（如图）做了一定的改进，其中主从 Reactor 多线程模型有多个Reactor。 BossGroup 线程维护Selector , 只关注Accept。 当接收到Accept事件，获取到对应的SocketChannel, 封装成 NIOScoketChannel并注册到Worker 线程(事件循环), 并进行维护 当Worker线程监听到Selector 中通道发生自己感兴趣的事件后，就由handler进行处理， 注意handler 已经加入到通道。 工作原理 Netty抽象出两组线程池BossGroup专门负责接收客户端的连接,WorkerGroup 专门负责网络的读写。 BossGroup 和 WorkerGroup 类型都是 NioEventLoopGroup。 NioEventLoopGroup 相当于一个事件循环组, 这个组中含有多个事件循环 ，每一个事件循环是 NioEventLoop。 NioEventLoop 表示一个不断循环的执行处理任务的线程， 每个NioEventLoop 都有一个selector , 用于监听绑定在其上的socket的网络通讯。 NioEventLoopGroup 可以有多个线程, 即可以含有多个NioEventLoop。 每个BossGroup的NioEventLoop 循环执行的步骤有3步： 轮询accept 事件。 处理accept 事件，与client建立连接 , 生成NioScocketChannel , 并将其注册到某个workerGroup的NIOEventLoop 上的 selector中。 处理任务队列的任务 ， 即runAllTasks。 每个WorkerGroup的NIOEventLoop 处理业务时，会使用pipeline(管道)，pipeline 中包含了 channel , 即通过pipeline 可以获取到对应通道, 管道中维护了很多的处理器。","categories":[{"name":"Netty","slug":"Netty","permalink":"https://midkuro.github.io/categories/Netty/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://midkuro.github.io/tags/NIO/"},{"name":"Netty","slug":"Netty","permalink":"https://midkuro.github.io/tags/Netty/"}]},{"title":"'RocketMQ（三）整合springBoot '","slug":"rocketmq-springboot","date":"2020-07-20T04:00:00.000Z","updated":"2020-09-22T05:20:24.852Z","comments":true,"path":"2020/07/20/rocketmq-springboot/","link":"","permalink":"https://midkuro.github.io/2020/07/20/rocketmq-springboot/","excerpt":"","text":"RocketMQ 4.x生产者123456&lt;!--pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt; 123# application.propertiesrocketmq.name-server=192.168.1.131:9876rocketmq.producer.group=my-group 123456@SpringBootApplicationpublic class MQProducerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MQSpringBootApplication.class); &#125;&#125; 123456789101112@RunWith(SpringRunner.class)@SpringBootTest(classes = &#123;MQSpringBootApplication.class&#125;)public class ProducerTest &#123; @Autowired private RocketMQTemplate rocketMQTemplate; @Test public void test1()&#123; rocketMQTemplate.convertAndSend(\"springboot-mq\",\"hello springboot rocketmq\"); &#125;&#125; 消费者12345678910@Slf4j@Component@RocketMQMessageListener(topic = \"springboot-mq\",consumerGroup = \"springboot-mq-consumer-1\")public class Consumer implements RocketMQListener&lt;String&gt; &#123; @Override public void onMessage(String message) &#123; log.info(\"Receive message：\"+message); &#125;&#125; 事务消息123456789101112131415161718@RocketMQTransactionListener(txProducerGroup = \"tx-producer-group\")public class MyTransactionListener implements RocketMQLocalTransactionListener &#123; @Override public RocketMQLocalTransactionState executeLocalTransaction(Message message, Object arg) &#123; try &#123; //业务逻辑代码 return RocketMQLocalTransactionState.COMMIT; &#125; catch (Exception e) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; &#125; @Override public RocketMQLocalTransactionState checkLocalTransaction(Message message) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125;&#125; 通过实现RocketMQLocalTransactionListener类，触发调度事务消息发送成半消息时，回调接口。 12345678910111213141516@Servicepublic class ProducerServiceImpl&#123; @Autowired private RocketMQTemplate rocketMQTemplate; private static final String TX_PRODUCER_GROUP = \"tx-producer-group\"; public void sendMessage(String message) &#123; Map&lt;String, Object&gt; headers = new HashMap&lt;&gt;(); headers.put(\"myHeader\", \"myHeader\"); Message&lt;String&gt; message = MessageBuilder.withPayload(message).copyHeaders(headers).build(); rocketMQTemplate.sendMessageInTransaction(TX_PRODUCER_GROUP, \"myDestnation\", message, basic); &#125;&#125; 参考资料","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.github.io/categories/RocketMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.github.io/tags/RocketMQ/"}]},{"title":"'RocketMQ（二）消息类型 '","slug":"rocketmq-message","date":"2020-07-17T04:00:00.000Z","updated":"2020-07-17T09:35:04.378Z","comments":true,"path":"2020/07/17/rocketmq-message/","link":"","permalink":"https://midkuro.github.io/2020/07/17/rocketmq-message/","excerpt":"","text":"RocketMQ 4.x12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.4.0&lt;/version&gt;&lt;/dependency&gt; 消息发送者步骤分析 1234561.创建消息生产者producer，并制定生产者组名2.指定Nameserver地址3.启动producer4.创建消息对象，指定主题Topic、Tag和消息体5.发送消息6.关闭生产者producer 消息消费者步骤分析 123451.创建消费者Consumer，制定消费者组名2.指定Nameserver地址3.订阅主题Topic和Tag4.设置回调函数，处理消息5.启动消费者consumer 生产者发送同步消息这种可靠性同步地发送方式使用的比较广泛，比如：重要的消息通知，短信通知。 1234567891011121314151617181920212223public class SyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送消息到一个Broker SendResult sendResult = producer.send(msg); // 通过sendResult返回消息是否成功送达 System.out.printf(\"%s%n\", sendResult); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 发送异步消息异步消息通常用在对响应时间敏感的业务场景，即发送端不能容忍长时间地等待Broker的响应。 12345678910111213141516171819202122232425262728293031323334public class AsyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); producer.setRetryTimesWhenSendAsyncFailed(0); for (int i = 0; i &lt; 100; i++) &#123; final int index = i; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); // SendCallback接收异步返回结果的回调 producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; System.out.printf(\"%-10d OK %s %n\", index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; System.out.printf(\"%-10d Exception %s %n\", index, e); e.printStackTrace(); &#125; &#125;); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 发送单向消息这种方式主要用在不特别关心发送结果的场景，例如日志发送。 12345678910111213141516171819202122public class OnewayProducer &#123; public static void main(String[] args) throws Exception&#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送单向消息，没有任何返回结果 producer.sendOneway(msg); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 消费者负载均衡模式消费者采用负载均衡方式消费消息，多个消费者共同消费队列消息，每个消费者处理的消息不同. 1234567891011121314151617181920212223public static void main(String[] args) throws Exception &#123; // 实例化消息生产者,指定组名 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group1\"); // 指定Namesrv地址信息. consumer.setNamesrvAddr(\"localhost:9876\"); // 订阅Topic consumer.subscribe(\"Test\", \"*\"); //负载均衡模式消费 consumer.setMessageModel(MessageModel.CLUSTERING); // 注册回调函数，处理消息 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); //启动消息者 consumer.start(); System.out.printf(\"Consumer Started.%n\");&#125; 广播模式消费者采用广播的方式消费消息，每个消费者消费的消息都是相同的. 1234567891011121314151617181920212223public static void main(String[] args) throws Exception &#123; // 实例化消息生产者,指定组名 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group1\"); // 指定Namesrv地址信息. consumer.setNamesrvAddr(\"localhost:9876\"); // 订阅Topic consumer.subscribe(\"Test\", \"*\"); //广播模式消费 consumer.setMessageModel(MessageModel.BROADCASTING); // 注册回调函数，处理消息 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); //启动消息者 consumer.start(); System.out.printf(\"Consumer Started.%n\");&#125; 顺序消息RocketMQ每个主题都会有若干个队列，分布于集群中各个broker上，分布规律如下： 每个queue存储了主题Topic的消息，在默认的情况下，消息发送会采取Round Robin轮询方式把消息发送到不同的queue（分区队列）中，而消费消息的时候，从多个queue上拉取消息，这种情况发送和消费是不能保证顺序的，因为消费者在处于多线程的情况下，无法完全地按照发送消息的queue顺序消费消息。 举个例子：一个订单的顺序流程是：创建(A)、付款(B)、推送(C)、完成(D)。在业务上，需要保证相同订单号，他们消费消息的顺序严格一致，而在默认的情况下，由于多线程地从不同的queue中消费消息，顺序就无法与 A、B、C、D保持一致。 消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。 如何保证消息顺序： 如果控制发送的顺序消息依次发送到同一个queue中，消费的时候只从这个queue上依次拉取，则就保证了顺序。 一个主题中，它只使用一个queue，发送和消费的策略均使用同一个queue，则表示是全局有序。一般情况下，不需要使用全局有序，因为一个主题只使用一个queue的情况下，会严重降低了系统的并发度。 一个主题中，有多个queue参与，同一个业务编号的消息需要被发送到同一个queue中，不同业务编号可以使用不同的queue，则为分区有序，即相对每个queue，消息都是有序的。 如何实现消息顺序： 第一点，消息顺序发送，多线程发送的消息无法保证有序性，因此，需要业务方在发送时，针对同一个业务编号(如同一笔订单)的消息需要保证在一个线程内顺序发送，在上一个消息发送成功后，在进行下一个消息的发送。对应到mq中，消息发送方法就得使用同步发送，异步发送无法保证顺序性 第二点，消息顺序存储，Topic主题下会存在多个queue，要保证消息的顺序存储，同一个业务编号的消息需要被发送到一个queue中。对应到编码中，需要使用MessageQueueSelector来选择要发送的queue，即对业务编号进行hash，然后根据队列数量对hash值取余，将消息发送到一个queue中 第三点，消息顺序消费，要保证消息顺序消费，同一个queue就只能被一个消费者所消费，因此对broker中消费队列加锁是无法避免的。同一时刻，一个消费队列只能被一个消费者消费，消费者内部，也只能有一个消费线程来消费该队列。即，同一时刻，一个消费队列只能被一个消费者中的一个线程消费。 下面用订单进行分区有序的示例。订单号相同的消息会被先后发送到同一个队列中，消费时，同一个OrderId获取到的肯定是同一个队列。 顺序消息生产123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/*** Producer，发送顺序消息*/public class Producer &#123; public static void main(String[] args) throws Exception &#123; DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); producer.setNamesrvAddr(\"127.0.0.1:9876\"); producer.start(); String[] tags = new String[]&#123;\"TagA\", \"TagC\", \"TagD\"&#125;; // 订单列表 List&lt;OrderStep&gt; orderList = new Producer().buildOrders(); Date date = new Date(); SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String dateStr = sdf.format(date); for (int i = 0; i &lt; 10; i++) &#123; // 加个时间前缀 String body = dateStr + \" Hello RocketMQ \" + orderList.get(i); Message msg = new Message(\"TopicTest\", tags[i % tags.length], \"KEY\" + i, body.getBytes()); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Long id = (Long) arg; //根据订单id选择发送queue long index = id % mqs.size(); return mqs.get((int) index); &#125; &#125;, orderList.get(i).getOrderId());//订单id System.out.println(String.format(\"SendResult status:%s, queueId:%d, body:%s\", sendResult.getSendStatus(), sendResult.getMessageQueue().getQueueId(), body)); &#125; producer.shutdown(); &#125; /** * 订单的步骤 */ private static class OrderStep &#123; private long orderId; private String desc; public long getOrderId() &#123; return orderId; &#125; public void setOrderId(long orderId) &#123; this.orderId = orderId; &#125; public String getDesc() &#123; return desc; &#125; public void setDesc(String desc) &#123; this.desc = desc; &#125; @Override public String toString() &#123; return \"OrderStep&#123;\" + \"orderId=\" + orderId + \", desc='\" + desc + '\\'' + '&#125;'; &#125; &#125; /** * 生成模拟订单数据 */ private List&lt;OrderStep&gt; buildOrders() &#123; List&lt;OrderStep&gt; orderList = new ArrayList&lt;OrderStep&gt;(); OrderStep orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"推送\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); return orderList; &#125;&#125; 顺序消费消息123456789101112131415161718192021222324252627282930313233343536373839404142434445/*** 顺序消息消费，带事务方式（应用可控制Offset什么时候提交）*/public class ConsumerInOrder &#123; public static void main(String[] args) throws Exception &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_3\"); consumer.setNamesrvAddr(\"127.0.0.1:9876\"); /** * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt; * 如果非第一次启动，那么按照上次消费的位置继续消费 */ consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\"); consumer.registerMessageListener(new MessageListenerOrderly() &#123; Random random = new Random(); @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; //重点设置 自动提交，否则无法清空本地消费过的mapTemp缓存，以及无法更新偏移量到broker context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序 System.out.println(\"consumeThread=\" + Thread.currentThread().getName() + \"queueId=\" + msg.getQueueId() + \", content:\" + new String(msg.getBody())); &#125; try &#123; //模拟业务逻辑处理中... TimeUnit.SECONDS.sleep(random.nextInt(10)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125; &#125;); consumer.start(); System.out.println(\"Consumer Started.\"); &#125;&#125; 延时消息123456789101112131415161718public class ScheduledMessageProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化一个生产者来产生延时消息 DefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\"); // 启动生产者 producer.start(); int totalMessagesToSend = 100; for (int i = 0; i &lt; totalMessagesToSend; i++) &#123; Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes()); // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel) message.setDelayTimeLevel(3); // 发送消息 producer.send(message); &#125; // 关闭生产者 producer.shutdown(); &#125;&#125; 12// org/apache/rocketmq/store/config/MessageStoreConfig.javaprivate String messageDelayLevel = \"1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\"; 现在RocketMQ并不支持任意时间的延时，需要设置几个固定的延时等级，从1s到2h分别对应着等级1到18 批量消息批量发送消息能显著提高传递小消息的性能。限制是这些批量消息应该有相同的topic，相同的waitStoreMsgOK，而且不能是延时消息。此外，这一批消息的总大小不应超过4MB。 如果您每次只发送不超过4MB的消息，则很容易使用批处理，样例如下： 1234567891011String topic = \"BatchTest\";List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, \"TagA\", \"OrderID001\", \"Hello world 0\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID002\", \"Hello world 1\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID003\", \"Hello world 2\".getBytes()));try &#123; producer.send(messages);&#125; catch (Exception e) &#123; e.printStackTrace(); //处理error&#125; 如果消息的总长度可能大于4MB时，这时候最好把消息进行分割 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123; private final int SIZE_LIMIT = 1024 * 1024 * 4; private final List&lt;Message&gt; messages; private int currIndex; public ListSplitter(List&lt;Message&gt; messages) &#123; this.messages = messages; &#125; @Override public boolean hasNext() &#123; return currIndex &lt; messages.size(); &#125; @Override public List&lt;Message&gt; next() &#123; int nextIndex = currIndex; int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) &#123; Message message = messages.get(nextIndex); int tmpSize = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123; tmpSize += entry.getKey().length() + entry.getValue().length(); &#125; tmpSize = tmpSize + 20; // 增加日志的开销20字节 if (tmpSize &gt; SIZE_LIMIT) &#123; //单个消息超过了最大的限制 //忽略,否则会阻塞分裂的进程 if (nextIndex - currIndex == 0) &#123; //假如下一个子列表没有元素,则添加这个子列表然后退出循环,否则只是退出循环 nextIndex++; &#125; break; &#125; if (tmpSize + totalSize &gt; SIZE_LIMIT) &#123; break; &#125; else &#123; totalSize += tmpSize; &#125; &#125; List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); currIndex = nextIndex; return subList; &#125;&#125;//把大的消息分裂成若干个小的消息ListSplitter splitter = new ListSplitter(messages);while (splitter.hasNext()) &#123; try &#123; List&lt;Message&gt; listItem = splitter.next(); producer.send(listItem); &#125; catch (Exception e) &#123; e.printStackTrace(); //处理error &#125;&#125; 过滤消息在大多数情况下，TAG是一个简单而有用的设计，其可以来选择您想要的消息。例如： 12DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"CID_EXAMPLE\");consumer.subscribe(\"TOPIC\", \"TAGA || TAGB || TAGC\"); 消费者将接收包含TAGA或TAGB或TAGC的消息。但是限制是一个消息只能有一个标签，这对于复杂的场景可能不起作用。在这种情况下，可以使用SQL表达式筛选消息。SQL特性可以通过发送消息时的属性来进行计算。在RocketMQ定义的语法下，可以实现一些简单的逻辑。下面是一个例子： 1234567891011121314------------| message ||----------| a &gt; 5 AND b &#x3D; &#39;abc&#39;| a &#x3D; 10 | --------------------&gt; Gotten| b &#x3D; &#39;abc&#39;|| c &#x3D; true |------------------------| message ||----------| a &gt; 5 AND b &#x3D; &#39;abc&#39;| a &#x3D; 1 | --------------------&gt; Missed| b &#x3D; &#39;abc&#39;|| c &#x3D; true |------------ SQL基本语法RocketMQ只定义了一些基本语法来支持这个特性。你也可以很容易地扩展它。 数值比较，比如：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，=； 字符比较，比如：=，&lt;&gt;，IN； IS NULL 或者 IS NOT NULL； 逻辑符号 AND，OR，NOT； 常量支持类型为： 数值，比如：123，3.1415； 字符，比如：‘abc’，必须用单引号包裹起来； NULL，特殊的常量 布尔值，TRUE 或 FALSE 只有使用push模式的消费者才能用使用SQL92标准的sql语句，接口如下： 1public void subscribe(finalString topic, final MessageSelector messageSelector) 消息生产者发送消息时，你能通过putUserProperty来设置消息的属性 1234567891011DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");producer.start();Message msg = new Message(\"TopicTest\", tag, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) );// 设置一些属性msg.putUserProperty(\"a\", String.valueOf(i));SendResult sendResult = producer.send(msg);producer.shutdown(); 消息消费者用MessageSelector.bySql来使用sql筛选消息 12345678910DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_4\");// 只有订阅的消息有这个属性a, a &gt;=0 and a &lt;= 3consumer.subscribe(\"TopicTest\", MessageSelector.bySql(\"a between 0 and 3\"); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start(); 事务消息流程分析 上图说明了事务消息的大致方案，其中分为两个流程：正常事务消息的发送及提交、事务消息的补偿流程。 事务消息发送及提交(1) 发送消息（half消息）。 (2) 服务端响应消息写入结果。 (3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。 (4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见） 事务补偿(1) 对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查” (2) Producer收到回查消息，检查回查消息对应的本地事务的状态 (3) 根据本地事务状态，重新Commit或者Rollback 其中，补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。 事务消息状态事务消息共有三种状态，提交状态、回滚状态、中间状态： TransactionStatus.CommitTransaction: 提交事务，它允许消费者消费此消息。 TransactionStatus.RollbackTransaction: 回滚事务，它代表该消息将被删除，不允许被消费。 TransactionStatus.Unknown: 中间状态，它代表需要检查消息队列来确定状态。 发送事务消息创建事务性生产者使用 TransactionMQProducer类创建生产者，并指定唯一的 ProducerGroup，就可以设置自定义线程池来处理这些检查请求。执行本地事务后、需要根据执行结果对消息队列进行回复。回传的事务状态在请参考前一节。 1234567891011121314151617181920212223242526public class Producer &#123; public static void main(String[] args) throws MQClientException, InterruptedException &#123; //创建事务监听器 TransactionListener transactionListener = new TransactionListenerImpl(); //创建消息生产者 TransactionMQProducer producer = new TransactionMQProducer(\"group6\"); producer.setNamesrvAddr(\"192.168.25.135:9876;192.168.25.138:9876\"); //生产者这是监听器 producer.setTransactionListener(transactionListener); //启动消息生产者 producer.start(); String[] tags = new String[]&#123;\"TagA\", \"TagB\", \"TagC\"&#125;; for (int i = 0; i &lt; 3; i++) &#123; try &#123; Message msg = new Message(\"TransactionTopic\", tags[i % tags.length], \"KEY\" + i, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(\"%s%n\", sendResult); TimeUnit.SECONDS.sleep(1); &#125; catch (MQClientException | UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; //producer.shutdown(); &#125;&#125; 实现事务的监听接口当发送半消息成功时，我们使用 executeLocalTransaction 方法来执行本地事务。它返回前一节中提到的三个事务状态之一。checkLocalTranscation 方法用于检查本地事务状态，并回应消息队列的检查请求。它也是返回前一节中提到的三个事务状态之一。 123456789101112131415161718192021public class TransactionListenerImpl implements TransactionListener &#123; @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; System.out.println(\"执行本地事务\"); if (StringUtils.equals(\"TagA\", msg.getTags())) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.equals(\"TagB\", msg.getTags())) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; System.out.println(\"MQ检查消息Tag【\"+msg.getTags()+\"】的本地事务执行结果\"); return LocalTransactionState.COMMIT_MESSAGE; &#125;&#125; 使用限制 事务消息不支持延时消息和批量消息。 为了避免单个消息被检查太多次而导致半队列消息累积，我们默认将单个消息的检查次数限制为 15 次，但是用户可以通过 Broker 配置文件的 transactionCheckMax参数来修改此限制。如果已经检查某条消息超过 N 次的话（ N = transactionCheckMax ） 则 Broker 将丢弃此消息，并在默认情况下同时打印错误日志。用户可以通过重写 AbstractTransactionCheckListener 类来修改这个行为。 事务消息将在 Broker 配置文件中的参数 transactionMsgTimeout 这样的特定时间长度之后被检查。当发送事务消息时，用户还可以通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制，该参数优先于 transactionMsgTimeout 参数。 事务性消息可能不止一次被检查或消费。 提交给用户的目标主题消息可能会失败，目前这依日志的记录而定。它的高可用性通过 RocketMQ 本身的高可用性机制来保证，如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制。 事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享。与其他类型的消息不同，事务消息允许反向查询、MQ服务器能通过它们的生产者 ID 查询到消费者。 参考资料","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.github.io/categories/RocketMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.github.io/tags/RocketMQ/"}]},{"title":"'RocketMQ（一）基础概念 '","slug":"rocketmq-install","date":"2020-07-08T04:00:00.000Z","updated":"2020-07-17T08:43:30.631Z","comments":true,"path":"2020/07/08/rocketmq-install/","link":"","permalink":"https://midkuro.github.io/2020/07/08/rocketmq-install/","excerpt":"","text":"RocketMQ 4.x 基础概念安装下载地址 官方文档 启动NameServer 1234#进入rocketMQ的目录nohup sh bin/mqnamesrv &amp;#查看日志tail -f ~/logs/rocketmqlogs/namesrv.log 启动Broker 123nohup sh bin/mqbroker -n localhost:9876 autoCreateTopicEnable=true &amp;#查看日志tail -f ~/logs/rocketmqlogs/broker.log 关闭 1234#关闭Nameserversh bin/mqshutdown namesrv#关闭Brokersh bin/mqshutdown broker 启动遇见的问题 RocketMQ默认的虚拟机内存比较大，启动的时候如果启动失败，可能是机器内存不够，需要编辑启动文件 12vi runbroker.shvi runserver.sh 参考配置： 1JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms512m -Xmx512m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" 测试发送消息 1234# 1.设置环境变量export NAMESRV_ADDR=localhost:9876# 2.使用安装包的Demo发送消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer 接收消息 1234# 1.设置环境变量export NAMESRV_ADDR=localhost:9876# 2.接收消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 集群 Producer：消息的发送者；举例：发信者 Consumer：消息接收者；举例：收信者 Broker：暂存和传输消息；举例：邮局 NameServer：管理Broker；举例：各个邮局的管理机构 Topic：区分消息的种类；一个发送者可以发送消息给一个或者多个Topic；一个消息的接收者可以订阅一个或者多个Topic消息 Message Queue：相当于是Topic的分区；用于并行发送和接收消息 集群特点 NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。 集群模式单Master模式这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用,可以用于本地测试。 多Master模式一个集群无Slave，全是Master，例如2个Master或者3个Master，这种模式的优缺点如下： 优点：配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高； 缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。 多Master多Slave模式（异步）每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下： 优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样； 缺点：Master宕机，磁盘损坏情况下会丢失少量消息。 多Master多Slave模式（同步）每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功，才向应用返回成功，这种模式的优缺点如下： 优点：数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高； 缺点：性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。 单机模式在正常情况下，如果broker和nameserver在同一台机器中访问，并且服务不开放给其他机器使用时，可以直接使用-n localhost:9876作为broker的启动参数。 但是在需要指定具体机器IP的情况下，则会出现broker无法找到对应nameserver的情况，需要自行编写配置文件作为启动参数。 12#假设这里的rocketmq的目录是 /home/local/rocketMQ/rocketmq-all-4.7.1-bin-release/vi ./conf/broker.conf 1234567891011121314151617181920#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-midkuro#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址 分号';'分割namesrvAddr=192.168.1.131:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#检测物理文件磁盘空间，太小会导致无法使用消息队列diskMaxUsedSpaceRatio=90#多网卡时配置，需要外网访问则配置外网IPbrokerIP1=192.168.1.131 启动Broker命令： 1nohup sh bin/mqbroker -n 192.168.1.131:9876 -c ./conf/broker.conf &amp; 双主双从 序号 IP 角色 架构模式 1 192.168.1.131 nameserver、brokerserver Master1、Slave2 2 192.168.1.131 nameserver、brokerserver Master2、Slave1 Host添加信息1vim &#x2F;etc&#x2F;hosts 配置如下: 12345678# nameserver192.168.1.131 rocketmq-nameserver1192.168.1.134 rocketmq-nameserver2# broker192.168.1.131 rocketmq-master1192.168.1.131 rocketmq-slave2192.168.1.134 rocketmq-master2192.168.1.134 rocketmq-slave1 配置完成后, 重启网卡 1systemctl restart network 防火墙配置宿主机需要远程访问虚拟机的rocketmq服务和web服务，需要开放相关的端口号，简单粗暴的方式是直接关闭防火墙 123456# 关闭防火墙systemctl stop firewalld.service # 查看防火墙的状态firewall-cmd --state # 禁止firewall开机启动systemctl disable firewalld.service 或者为了安全，只开放特定的端口号，RocketMQ默认使用3个端口：9876 、10911 、11011 。如果防火墙没有关闭的话，那么防火墙就必须开放这些端口： nameserver 默认使用 9876 端口 master 默认使用 10911 端口 slave 默认使用11011 端口 执行以下命令： 12345678# 开放name server默认端口firewall-cmd --remove-port=9876/tcp --permanent# 开放master默认端口firewall-cmd --remove-port=10911/tcp --permanent# 开放slave默认端口 (当前集群模式可不开启)firewall-cmd --remove-port=11011/tcp --permanent # 重启防火墙firewall-cmd --reload 环境变量配置1vim /etc/profile 在profile文件的末尾加入如下命令 1234#set rocketmqROCKETMQ_HOME=/home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasePATH=$PATH:$ROCKETMQ_HOME/binexport ROCKETMQ_HOME PATH 输入:wq! 保存并退出， 并使得配置立刻生效： 1source /etc/profile 创建消息存储路径1234mkdir &#x2F;home&#x2F;local&#x2F;rocketMQ&#x2F;storemkdir &#x2F;home&#x2F;local&#x2F;rocketMQ&#x2F;commitlogmkdir &#x2F;home&#x2F;local&#x2F;rocketMQ&#x2F;consumequeuemkdir &#x2F;home&#x2F;local&#x2F;rocketMQ&#x2F;index broker配置文件当前目录：/home/local/rocketMQ/rocketmq-all-4.7.1-bin-release/ master1服务器：192.168.1.131 1vi .&#x2F;conf&#x2F;2m-2s-sync&#x2F;broker-a.properties 注释掉原来的配置，并修改配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址 分号';'分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/home/local/rocketMQ/store#commitLog 存储路径storePathCommitLog=/home/local/rocketMQ/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/home/local/rocketMQ/consumequeue#消息索引存储路径storePathIndex=/home/local/rocketMQ/store/index#checkpoint 文件存储路径storeCheckpoint=/home/local/rocketMQ/store/checkpoint#abort 文件存储路径abortFile=/home/local/rocketMQ/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=SYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128 slave2服务器：192.168.1.131 1vi .&#x2F;conf&#x2F;2m-2s-sync&#x2F;broker-b-s.properties 拷贝上面的broker-a.properties内容，并修改相关配置，如下： 12345brokerName=broker-bbrokerId=1#Broker 对外服务的监听端口listenPort=11011brokerRole=SLAVE master2服务器：192.168.1.134 1vi .&#x2F;conf&#x2F;2m-2s-sync&#x2F;broker-b.properties 拷贝上面的broker-a.properties内容，并修改相关配置，如下： 1brokerName=broker-b slave1服务器：192.168.1.134 1vi .&#x2F;conf&#x2F;2m-2s-sync&#x2F;broker-a-s.properties 拷贝上面的broker-a.properties内容，并修改相关配置，如下： 12345brokerName=broker-abrokerId=1#Broker 对外服务的监听端口listenPort=11011brokerRole=SLAVE 修改启动脚本文件如果机器内存首先，则需要先修改runbroker.sh和runserver.sh的启动内存大小。 服务启动启动NameServe集群分别在192.168.1.131和192.168.1.134启动NameServer 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqnamesrv &amp; 启动Broker集群192.168.1.131 master1： 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqbroker -c ./conf/2m-2s-sync/broker-a.properties &amp; 192.168.1.131 slave2： 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqbroker -c ./conf/2m-2s-sync/broker-b-s.properties &amp; 192.168.1.134 master2： 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqbroker -c ./conf/2m-2s-sync/broker-b.properties &amp; 192.168.1.134 slave1： 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqbroker -c ./conf/2m-2s-sync/broker-a-s.properties &amp; 查看进程状态启动后通过JPS查看启动进程 查看日志1234# 查看nameServer日志tail -500f ~/logs/rocketmqlogs/namesrv.log# 查看broker日志tail -500f ~/logs/rocketmqlogs/broker.log 参考资料","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.github.io/categories/RocketMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.github.io/tags/RocketMQ/"}]},{"title":"'Spring Cloud Seata '","slug":"springcloud-seata","date":"2020-06-29T04:00:00.000Z","updated":"2020-07-17T08:41:56.575Z","comments":true,"path":"2020/06/29/springcloud-seata/","link":"","permalink":"https://midkuro.github.io/2020/06/29/springcloud-seata/","excerpt":"","text":"Spring Cloud Seata是什么Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。 官方文档 下载地址 术语TC - 事务协调者 维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM - 事务管理器 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM - 资源管理器 管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 一次分布式事务处理过程是由一个XID和三个组件模型（TC、TM、RM）组成。 处理过程 TM向TC申请开启一个全局事务，全局事务创建成功并声称一个全局唯一的XID; XID在微服务调用链路的上下文中传播； RM向TC注册分支事务，将其纳入XID对应全局事务的管辖； TM向TC发起针对XID的全局提交或回滚决议； TC调度XID下管辖的全部分支事务完成提交或回滚请求。 安装下载seata推荐使用带GA标签的版本，表示是官方推荐的稳定版，截止2020年7月，下载的是v1.0.0-GA版本。 然后备份并修改file.conf配置文件，主要修改：自定义事务组名字、事务日志存储模式（DB）、数据库连接信息。 12345678910111213service &#123; vgroup_mapping.my_test_tx_group = \"midkuro_tx_group\"&#125;store &#123; mode = \"db\"&#125;db &#123; url = \"jdbc:mysql://127.0.0.1:3306/seata\" user = \"账号\" password = \"密码\"&#125; 创建seata库，建表语句db_store.sql在安装目录\\seata\\conf里。 修改registry.conf配置文件，指明注册中心是nacos，并修改其配置信息： 123456789registry &#123; type = \"nacos\" nacos &#123; serveAddr = \"localhost\" namespace = \"\" cluster = \"default\" &#125;&#125; 通过执行bin目录下的seata-server.bat启动程序。 用例用户购买商品的业务逻辑。整个业务逻辑由3个微服务提供支持： 仓储服务：对给定的商品扣除仓储数量。 订单服务：根据采购需求创建订单。 帐户服务：从用户帐户中扣除余额。 架构图 在spring中使用@Transactional注解标记本地事务，而在seata中使用的是@GolbalTransactional注解，我们只需要使用一个 @GlobalTransactional 注解在业务方法上。 编码假设有三个系统，订单系统、库存系统、支付系统，操作流程是【下订单-&gt;减库存-&gt;扣余额-&gt;改订单状态】 1234567891011121314151617&lt;!--pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;!--如果客户端和pom依赖版本不一致，需要排除依赖自行引入--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112#application.ymlserver: port: 2001spring: application: name: seata-order-service cloud: alibaba: seata: #自定义事务组名称需要和seata-server中对应 tx-server-group: midkuro-tx-group 123456789101112131415161718192021222324252627282930@Service@Slf4jpublic class OrderServiceImpl implements OrderService &#123; @Resource private OrderDao orderDao; @Resource private StorageService storageService; @Resource private AccountService accountService; @GlobalTransactional(name = \"midkuro-create-order\",rollbackFor = Exception.class) @Override public void create(Order order) &#123; log.info(\"--------&gt;开始创建新订单\"); orderDao.create(order); log.info(\"--------订单微服务开始调用库存,做扣减\"); storageService.decrease(order.getProductId(),order.getCount()); log.info(\"-------订单微服务开始调用库存，做扣减end\"); log.info(\"-------订单微服务开始调用账户，做扣减\"); accountService.decrease(order.getUserId(),order.getMoney()); log.info(\"-------订单微服务开始调用账户，做扣减end\"); log.info(\"-------修改订单状态\"); orderDao.update(order.getUserId(),0); log.info(\"-------修改订单状态结束\"); log.info(\"--------下订单结束了，哈哈哈哈\"); &#125;&#125; 通过在微服务的调用链上增加注解实现分布式事务全局回滚操作。 原理分布式事务的执行流程： TM开启分布式事务（TM向TC注册全局事务记录）； 按业务场景编排数据库，服务等事务内资源（RM向TC汇报资源准备状态）； TM结束分布式事务，事务一阶段结束（TM通知TC提交/回滚分布式事务）； TC汇总事务信息，决定分布式事务是提交还是回滚； TC通知所有RM提交/回滚资源，事务二阶段结束。 Seata提供了 AT、TCC、SAGA 和 XA 事务模式，默认使用AT模式。 AT模式两阶段提交协议的演变： 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。 二阶段： 提交异步化，非常快速地完成。 回滚通过一阶段的回滚日志进行反向补偿。 Seata的AT模式实现了对业务的无入侵，它是怎么做到的呢？ 一阶段在一阶段，Seata会拦截业务SQL： 解析SQL语义，找到业务SQL要更新的业务数据，在业务数据被更新前，将其保存成before image 执行业务SQL更新业务数据，在业务数据更新后 将其保存成after image，最后生成行锁 以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。 二阶段提交因为业务SQL在一阶段已经提交至数据库，所以二阶段如果是顺利提交的话，seata框架只需异步得将一阶段保存的快照数据和行锁删掉，完成数据清理即可。 二阶段回滚当二阶段是回滚的话，seata就需要回滚一阶段已经执行的业务SQL，还原业务数据。 回滚方式便是用before image还原业务数据；但是在还原前要首先校验脏写，对比数据库当前业务数据和after image，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。 总结","categories":[{"name":"Sentinel","slug":"Sentinel","permalink":"https://midkuro.github.io/categories/Sentinel/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.github.io/tags/SpringCloud/"},{"name":"Seata","slug":"Seata","permalink":"https://midkuro.github.io/tags/Seata/"}]},{"title":"'Spring Cloud Stream '","slug":"springcloud-stream","date":"2020-06-28T05:00:00.000Z","updated":"2020-07-17T08:41:05.690Z","comments":true,"path":"2020/06/28/springcloud-stream/","link":"","permalink":"https://midkuro.github.io/2020/06/28/springcloud-stream/","excerpt":"","text":"Spring Cloud Stream是什么Spring Cloud Stream是一个构件消息驱动微服务的框架。 应用程序通过inputs或者outputs来与Spring Cloud Stream中的binder对象交互。通过我们配置binding，Spring Cloud Stream的binder对象负责与消息中间件交互。 通过使用Spring Integration来链接消息代理中间件以实现消息事件驱动。Spring Cloud Stream为一些供应商的消息中间件产品提供了个性化的自动化配置实现，引用了发布-订阅、消费组、分区的三个核心概念。 官方文档 在没有绑定器这个概念的情况下，SpringBoot应用要直接与消息中间件进行信息交互的时候，由于各个消息中间件构建的初衷不同，他们的实现细节会有较大的差异，通过定义绑定器作为中间件，完美地实现了应用程序与消息中间件细节之间的隔离，通过向应用程序暴露统一的Channel通道，使得应用程序不需要再考虑各种不同的消息中间件实现。 spring官方目前只支持RabbitMQ和Kafka，rocketMQ的由alibaba研发支持。 设计思想 Binder ：很方便的链接中间件，屏蔽差异 Channel：通道，是队列queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过Cahnnel对队列进行配置。 Source和Sink：参照对象是Spring Cloud Stream自身，从Stream发布消息就是输出，接受消息就是输入。 组成 说明 Middleware 中间件，目前只支持RabbitMQ和Kafka Binder Binder是应用与消息中间件之间的封装，目前实行了Kafka和RabbitMQ的Binder，通过Binder可以很方便的连接中间件，可以动态的改变消息类型(对应于Kafka的topic，RabbitMQ的exchange)，这些都可以通过配置文件来实现 @Input 注解标识输入通道，通过该输入通道接收到的消息进入应用程序 @Output 注解标识输出通道，发布的消息将通过该通道离开应用程序 @StreamListener 监听队列，用于消费者的队列的消息接收 @EnableBinding 指信道channel和exchange绑定在一起 生产者新建springBoot工程cloud-stream-privider 12345&lt;!--pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213141516171819202122server: port: 8801spring: application: name: cloud-stream-rocketmq-provider cloud: nacos: discovery: server-addr: localhost:8848 config: #配置中心地址 server-addr: localhost:8848 #指定配置文件后缀 file-extension: yaml stream: rocketmq: binder: #RocketMQ需要配置name-server name-server: localhost:9876 bindings: #服务的整合处理 output: #生产者默认绑定器名称 destination: testChannel #表示要使用的目的地名称 1234package cn.midkuro.com.service;public interface ProviderService &#123; void send(String message);&#125; 123456789101112131415161718import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.messaging.Source;import org.springframework.messaging.MessageChannel;import org.springframework.messaging.support.MessageBuilder;@EnableBinding(Source.class) //定义消息推送通道public class ProviderServiceImpl implements ProviderService &#123; @Autowired private MessageChannel output; //消息发送通道 @Override public String send() &#123; String serial = UUID.randomUUID().toString(); output.send(MessageBuilder.withPayload(serial).build()); System.out.println(\"***********serial:\"+serial); return serial; &#125;&#125; 12345678910@RestController@RefreshScopepublic class ProviderController &#123; @Autowired private ProviderService service; @GetMapping(\"/sendMessage\") public void sendMessage() &#123; service.send(); &#125;&#125; 消费者1234567891011121314151617181920212223server: port: 8802spring: application: name: cloud-stream-rocketmq-consumer cloud: nacos: discovery: server-addr: localhost:8848 config: #配置中心地址 server-addr: localhost:8848 #指定配置文件后缀 file-extension: yaml stream: rocketmq: binder: name-server: localhost:9876 bindings: input: #消费者默认绑定器名称 destination: testChannel #与生产者相同的目的地名称 group: cloud-stream-rocketmq-consumer #rocketMQ要求消费者必须配置分组 123456789101112131415161718192021package cn.midkuro.com.Service;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.cloud.stream.messaging.Sink;import org.springframework.messaging.Message;import org.springframework.stereotype.Component;@Component@EnableBinding(Sink.class)public class ConsumerService &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) &#123; System.out.println(\"我是消费者1号，-----》接受到的消息是：\" + message.getPayload() + \"\\t\" + serverPort); &#125;&#125; 自定义Bindingorg.springframework.cloud.stream.binder.Binder是Spring Cloud对消息容器的抽象，不同的消息容器有不同的实现，通过它可以屏蔽各消息容器的内部细节。 1234567public interface Binder&lt;T, C extends ConsumerProperties, P extends ProducerProperties&gt; &#123; Binding&lt;T&gt; bindConsumer(String name, String group, T inboundBindTarget, C consumerProperties); Binding&lt;T&gt; bindProducer(String name, T outboundBindTarget, P producerProperties);&#125; Binder可以生成Binding，Binding用来绑定消息容器的生产者和消费者。 它有两种类型，INPUT和OUTPUT，INPUT对应于消费者，OUTPUT对应于生产者。 可以通过在配置类上使用@EnableBinding指定需要使用的Binding，它指定的是一个接口，在对应接口中会定义一些标注了@Input或@Output的方法，它们就对应一个Binding了。 Spring提供了两个内置的接口，Source和Sink，Source对应的是OUTPUT生产者，Sink对应的是INPUT消费者。 1234567891011public interface Source &#123; /** * Name of the output channel. */ String OUTPUT = \"output\"; /** * @return output channel */ @Output(Source.OUTPUT) MessageChannel output();&#125; 1234567891011public interface Sink &#123; /** * Input channel name. */ String INPUT = \"input\"; /** * @return input channel. */ @Input(Sink.INPUT) SubscribableChannel input();&#125; 在一个EnableBinding注解中可以同时定义多个Binding，如下： 123@EnableBinding(value = &#123; Source.class, Sink.class &#125;) //或者@EnableBinding(Processor.class) 12public interface Processor extends Source, Sink &#123; //spring内置提供&#125; 默认情况下，它的内置binding是input和output，也就是我们配置文件配置的： 12345spring: cloud: stream: bindings: output: #生产者默认绑定器名称 如果自定义了一个binding配置，如下： 12345spring: cloud: stream: bindings: mybinding: #自定义绑定器名称 12345public interface MyBinding &#123; @Output(\"mybinding\") // 通过@Output指定绑定器名称mybinding MessageChannel output(); // 使用@Output注解标注的输入管道需要使用MessageChannel来订阅通道&#125; 123456@EnableBinding(MyBinding.class)public class ProviderServiceImpl implements ProviderService &#123; @Autowired @Qualifier(\"mybinding\") private MessageChannel output;&#125; 若是消费者频道，则是在方法上通过@StreamListener进行标注，表示它将监听消费某个Binding的消息。 1@StreamListener(\"mybinding\") 当有多个Binding时，可以通过进行组合，并在使用注入时通过@Qualifier进行区分即可，如下： 1234567public interface MutipleMyBinding &#123; @Output(\"mybinding1\") MessageChannel output1(); @Output(\"mybinding2\") MessageChannel output2();&#125; 重复消费比如在如下场景中，订单系统做集群部署，都会从消息队列中获取订单信息，那如果一个订单同时被两个服务获取到，就会造成数据错误，得避免这种情况，这时候需要使用stream中的消息分组来解决。 在stream中处于同一个group中的多个消费者是竞争关系，就能保证消息只会被其中一个应用消费一次。不同组是可以全面消费的(重复消费)。 微服务应用放置于同一个group中，就能够保证消息只会被其中一个应用消费一次。不同的组是可以重复消费的，同一个组内会发生竞争关系，只有一个可以消费。 通过在配置文件配置分组配置实现 123456spring: cloud: stream: bindings: input: group: myGroupName 持久化配置了分组名称的消费者，在程序重新启动时，会接着消费未消费的消息，而没有配置分组的，则会丢失之前未消费的消息。","categories":[{"name":"Stream","slug":"Stream","permalink":"https://midkuro.github.io/categories/Stream/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.github.io/tags/SpringCloud/"},{"name":"Stream","slug":"Stream","permalink":"https://midkuro.github.io/tags/Stream/"}]},{"title":"'Spring Cloud Sentinel '","slug":"springcloud-sentinel","date":"2020-06-28T04:00:00.000Z","updated":"2020-07-17T08:41:34.749Z","comments":true,"path":"2020/06/28/springcloud-sentinel/","link":"","permalink":"https://midkuro.github.io/2020/06/28/springcloud-sentinel/","excerpt":"","text":"Spring Cloud Sentinel是什么随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Sentinel 具有以下特征: 丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。 完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。 Sentinel 的主要特性： Sentinel 的开源生态： 安装Sentinel 分为两个部分: 核心库（Java 客户端）不依赖任何框架/库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持。 控制台（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器。 官方介绍文档 下载地址 环境配置：Java环境必须是JDK1.8及以上，并且8080端口不能被占用！ 下载当前时间对应的最新版本sentinel-dashboard-1.7.2.jar，并通过命令java -jar sentinel-dashboard-1.7.2.jar启动。 通过访问sentinel管理界面http://localhost:8080，如下： 能够看到以上界面则代表sentinel启动成功，默认的账号密码是sentinel，登录进去后能够看到如下界面： 编码新建项目cloudalibba-sentinel-service 1234567891011121314151617&lt;!--pom.xml 引入相关依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- sentinel-datasource-nacos 用于持久化--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324#application.ymlserver: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: #nacos服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置sentinel dashboard地址 dashboard: localhost:8080 #默认8719端口。假如端口被占用会自动从8719依次+1扫描，直到找到未被占用的端口 port: 8719 management: endpoints: web: exposure: include: '*' 12345678910111213@RestControllerpublic class FlowLimitController &#123; @GetMapping(\"/testA\") public String testA() &#123; return \"------testA\"; &#125; @GetMapping(\"/testB\") public String testB() &#123; return \"------testB\"; &#125;&#125; 通过启动项目注册到nacos和sentinel中，并登陆sentinel页面查看是否注册成功，结果如下： 界面空空如也的原因是因为sentlnel默认采用的是懒加载机制，需要先触发一次接口：http://localhost:8401/testA和http://localhost:8401/testB。 再次查看sentinel控制台，结果如下：","categories":[{"name":"Sentinel","slug":"Sentinel","permalink":"https://midkuro.github.io/categories/Sentinel/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.github.io/tags/SpringCloud/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://midkuro.github.io/tags/Sentinel/"}]},{"title":"'Spring Cloud Nacos '","slug":"springcloud-nacos","date":"2020-06-28T03:00:00.000Z","updated":"2020-07-17T08:42:22.930Z","comments":true,"path":"2020/06/28/springcloud-nacos/","link":"","permalink":"https://midkuro.github.io/2020/06/28/springcloud-nacos/","excerpt":"","text":"Spring Cloud Nacos简介Nacos：前四个字母分别为Naming和Configuration的前两个字母，最后s为Service。 Nacos(Dynamic Naming and Configuration Service)是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Nacos就是注册中心 + 配置中心的组合， Nacos = Eureka + Config + Bus。 Spring Cloud Alibaba文档 安装下载地址 帮助文档 从官网下载Nacos，解压压缩包，进入bin目录运行start.cmd，linux环境则运行sh startup.sh -m standalone。 命令运行成功后直接访问http://localhost:8848/nacos，默认的账号密码都是nacos。 看到上述页面则表示安装成功。 服务提供者新建项目nacos-provider，引入服务发现及alibaba依赖： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;!--pom.xml--&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;nacos-provider&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;nacos-provider&lt;/name&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;maven-jar-plugin.version&gt;2.6&lt;/maven-jar-plugin.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring.cloud.version&gt;Hoxton.SR1&lt;/spring.cloud.version&gt; &lt;spring.cloud.alibaba.version&gt;2.1.0.RELEASE&lt;/spring.cloud.alibaba.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.cloud.alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 1234567891011121314151617#application.ymlserver: port: 8081spring: application: name: nacos-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 management: endpoints: web: exposure: include: '*' 12345678910@RestControllerpublic class TestController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/port\") public String port() &#123; return \"My Port : \" + port; &#125;&#125; 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class NacosProdiverApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosProdiverApplication.class, args); &#125;&#125; 通过引入springCloud及alibaba依赖，并编写相关配置文件，并在启动类上增加注解@EnableDiscoveryClient，启动即可注册到nacos中。 nacos天生支持负载均衡，因为nacos集成了netfilx的ribbon依赖。 在启动多个相同实例时，如下： 服务消费者新建nacos-consumer项目，pom.xml与上文nacos-provider项目相同。 1234567891011121314#application.ymlserver: port: 8083spring: application: name: nacos-cunsumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 service: provider-url: http://nacos-provider/ 123456789@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced //注意必须配置负载均衡注解 public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 12345678910111213@RestControllerpublic class TestController &#123; @Value(\"$&#123;service.provider-url&#125;\") private String serviceURL; @Autowired private RestTemplate restTemplate; @GetMapping(\"/consumer/port\") public String port() &#123; return restTemplate.getForObject(serviceURL + \"/port\", String.class); &#125;&#125; 这时候启动nacos-consumer项目，并且运行两个nacos-provider项目，用以测试负载均衡。 通过使用RestTemplate以及@LoadBalanced请求访问nacos-provider服务，达到负载均衡的目的。 配置中心新建nacos-config-client项目，并且新建两个配置文件application.yml和bootstrap.yml。 Nacos和Spring-cloud-config一样，在项目初始化时，要保证先从配置中心进行配置拉取，拉取配置之后，才能保证项目的正常启动。 SpringBoot中配置文件的加载是存在优先顺序的，bootstrap优先级高于application。 1234567891011121314#bootstrap.yamlserver: port: 3377spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: 127.0.0.1:8848 config: server-addr: 127.0.0.1:8848 #配置中心地址 file-extension: yaml #指定配置文件后缀 将主体配置放在bootstrap.yml中。 1234#application.ymlspring: profiles: active: dev #表示开发环境 环境配置放在application.yml中。 在 Nacos Spring Cloud 中，dataId 的完整格式如下： 1$&#123;prefix&#125;-$&#123;spring.profile.active&#125;.$&#123;file-extension&#125; prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix来配置。 也就是说，默认情况是： 1$&#123;spring.application.name&#125;-$&#123;spring.profile.active&#125;.$&#123;file-extension&#125; 例如上述的nacos-config-client的配置文件，则产生的对应的dataId则为：nacos-config-client-dev.yaml。 切记nacos只支持yaml后缀格式，暂不兼容yml，所以在编写的过程中需要注意不要写错。 spring.profile.active 即为当前环境对应的 profile，详情可以参考 Spring Boot文档。 注意：当 spring.profile.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 ${prefix}.${file-extension} file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。 通过 Spring Cloud 原生注解 @RefreshScope 实现配置自动更新。 1234567891011@RestController@RefreshScope // 支持nasos的动态刷新工能public class TestController &#123; @Value(\"$&#123;config.info&#125;\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo() &#123; return configInfo; &#125;&#125; 通过在nacos界面上新建配置，新建``nacos-config-client-dev.yaml的dataId`。 点击右下角的发布保存之后就能够在列表中看到： 通过访问之前编写的Controller能够看到获取得到配置： 自动刷新： 通过在nacos界面上进行调整编辑配置文件，将version = 1改成version = 2，在不重启mtex-config-client的情况下，能够看到配置已经刷新。 命名空间 命名空间类似于java里面的package名和类名，最外层的namespace是可以用于区分部署环境的，Group和DataID逻辑上区分两个目标对象。 默认情况下： 123Namespace=publicGroup=DEFAULT_GROUPCluster=DEFAULT Nacos默认的命名空间是public，Namespace主要用来实现隔离。比放说现在有三个环境：开发、测试、生产环境，我们可以创建三个Namespace，不同的Namespace之间是隔离的。 Group默认是DEFAULT_GROUP，Group可以把不同的微服务划分到同一个分组里面去。 Service就是微服务，一个Service可以包含多个Cluster（集群），Nacos默认Cluster是DEFAULT，Cluster是对指定微服务的一个虚拟划分。 比放说为了容灾，将Service微服务分别部署在杭州机房和广州机房，这时候就可以给杭州机房的Service微服务起一个集群名称，给广州机房的Service微服务起另一个集群名称，还可以尽量让同一个机房的微服务互相调用，以提升性能。 最后Instance，指的是微服务的实例。 DataID 通过在同个分组里，编写不同的运行环境后缀的配置文件 12345spring: profiles: #表示开发环境 active: dev #active:pro 并通过修改application.yml的相关配置切换环境。 Group 通过新建同名称的文件，所属不同分组，以切换分组的形式切换相关配置运行环境。 123spring: profiles: active: info NameSpace 新建命名空间，会生成一个唯一的命名空间ID。 点击切换命名空间，并且在bootstrap.yml中namespace属性配置相关的命名空间ID。 持久化默认Nacos使用嵌入式数据库实现数据的存储，所以，如果启动多个默认配置下的Nacos节点，数据存储是存在一致性问题的，为了解决这个问题，Nacos采用了集中式存储的方式来支持集群化部署，目前只支持Mysql的存储。 Nacos支持三种部署模式： 单机模式 - 用于测试和单机试用。 集群模式 - 用于生产环境，确保高可用。 多集群模式 - 用于多数据中心场景。 单机模式支持mysql： 在0.7版本之前，在单机模式时nacos使用嵌入式数据库实现数据的存储，不方便观察数据存储的基本情况。0.7版本增加了支持mysql数据源能力，具体的操作步骤： 1.安装数据库，版本要求：5.6.5+ 2.初始化mysql数据库，数据库初始化文件：nacos-mysql.sql，拷贝文件内容到mysql中执行。 3.修改conf/application.properties文件，增加支持mysql数据源配置（目前只支持mysql），添加mysql数据源的url、用户名和密码。 123456spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://127.0.0.1:3306/nacos_devtest?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=nacos_devtestdb.password=youdontknow 再以单机模式启动nacos，nacos所有写嵌入式数据库的数据都写到了mysql。 集群启动模式单机模式 1sh startup.sh -m standalone 集群模式 使用内嵌数据源 1sh startup.sh -p embedded 使用外置数据源 1sh startup.sh Cluster配置以linux环境为例，在已经配置好mysql作为持久化的前提下，拷贝cluster.conf.example文件，将新文件重命名为cluster.conf。 并编辑文件配置集群IP和端口 123192.168.1.131:3333192.168.1.131:4444192.168.1.131:5555 这个IP必须是linux命令hostname -i能够识别到的IP。 动态端口在nacos V1.3.0及以上版本中，支持了内嵌式关系型分布式数据库，其默认的startup.sh部分内容如下： 123456789101112131415161718while getopts \":m:f:s:c:p:\" optdo case $opt in m) MODE=$OPTARG;; f) FUNCTION_MODE=$OPTARG;; s) SERVER=$OPTARG;; c) MEMBER_LIST=$OPTARG;; p) EMBEDDED_STORAGE=$OPTARG;; ?) echo \"Unknown parameter\" exit 1;; esacdone 123echo \"$JAVA $&#123;JAVA_OPT&#125;\" &gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp;nohup $JAVA $&#123;JAVA_OPT&#125; nacos.nacos &gt;&gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp;echo \"nacos is starting，you can check the $&#123;BASE_DIR&#125;/logs/start.out\" 可以看到相比之前版本，新增了-p参数，用来提供集群部署时可以不依赖Mysql，以便降低中小用户的集群运维部署成本（大客户，生产环境依然建议依赖Mysql，以便有更高的性能）。 备份startup.sh，并修改startup.sh，达到通过启动命令参数配置启动端口。 12345678910111213141516171819202122#增加 o: 选择while getopts \":m:f:s:c:p:o:\" optdo case $opt in m) MODE=$OPTARG;; f) FUNCTION_MODE=$OPTARG;; s) SERVER=$OPTARG;; c) MEMBER_LIST=$OPTARG;; p) EMBEDDED_STORAGE=$OPTARG;; #增加 o参数配置 o) PORT=$OPTARG;; ?) echo \"Unknown parameter\" exit 1;; esacdone 1234echo \"$JAVA $&#123;JAVA_OPT&#125;\" &gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp;#增加 启动端口参数传递nohup $JAVA -Dserver.port=$&#123;PORT&#125; $&#123;JAVA_OPT&#125; nacos.nacos &gt;&gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp;echo \"nacos is starting，you can check the $&#123;BASE_DIR&#125;/logs/start.out\" 则可以通过在sh startup.sh命令后面增加-o端口参数，如下： 1sh startup.sh -o 8848 -m standalone 集群启动： 123sh startup.sh -o 3333 -p embeddedsh startup.sh -o 4444 -p embeddedsh startup.sh -o 5555 -p embedded 启动成功后，需要通过配置Nginx负载均衡三台nacos，并且在各个微服务的配置文件中改成Nginx的负载均衡端口即可。 1234567891011121314#Nginx.conf部分配置upstream cluster&#123; server 192.168.1.131:3333; server 192.168.1.131:4444; server 192.168.1.131:5555;&#125;server&#123; listen 1111; server_name localhost; location /&#123; proxy_pass http://cluster; &#125;&#125; 123456789101112131415server: port: 3377spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: 192.168.1.131:1111 config: #配置中心地址 server-addr: 192.168.1.131:1111 #指定配置文件后缀 file-extension: yaml","categories":[{"name":"Nacos","slug":"Nacos","permalink":"https://midkuro.github.io/categories/Nacos/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.github.io/tags/SpringCloud/"},{"name":"Nacos","slug":"Nacos","permalink":"https://midkuro.github.io/tags/Nacos/"}]},{"title":"'Java 密码学 非对称加密'","slug":"cryptography-asymmetric","date":"2020-06-15T13:00:00.000Z","updated":"2020-06-17T13:16:32.204Z","comments":true,"path":"2020/06/15/cryptography-asymmetric/","link":"","permalink":"https://midkuro.github.io/2020/06/15/cryptography-asymmetric/","excerpt":"","text":"密码学消息摘要消息摘要（Message Digest）又称为数字摘要(Digital Digest)，它是一个唯一对应一个消息或文本的固定长度的值，它由一个单向Hash加密函数对消息进行作用而产生，使用数字摘要生成的值是不可以篡改的，为了保证文件或者值的安全。 无论输入的消息有多长，计算出来的消息摘要的长度总是固定的。 例如应用MD5算法摘要的消息有128个比特位，用SHA-1算法摘要的消息最终有160比特位的输出，只要输入的消息不同，对其进行摘要以后产生的摘要消息也必不相同，但相同的输入必会产生相同的输出。 消息摘要是单向、不可逆的。常见算法：MD5、SHA1、SHA256、SHA512。 在线加密消息摘要 public abstract class MessageDigest类为应用程序提供小弟摘要算法功能，如SHA-1、SHA-256。消息摘要是采用任意大小的数据并输出固定长度散列值得安全单向散列函数。 字符串消息摘要12345678910111213public class MD5Demo &#123; public static void main(String[] args) throws Exception&#123; // 原文 String input = \"aa\"; // 算法 String algorithm = \"MD5\"; // 获取数字摘要对象 MessageDigest messageDigest = MessageDigest.getInstance(algorithm); // 获取消息数字摘要的字节数组 byte[] bytes = messageDigest.digest(input.getBytes()); System.out.println(new String(bytes)); &#125;&#125; 如果直接输出bytes字节对象会造成以下乱码： 可以像DES一样通过Base64对乱码进行加密处理达到可视化数据的效果。 123byte[] digest = messageDigest.digest(input.getBytes());//输出：QSS8CpM1wn8IbyS6IHpJEg==System.out.println(Base64.encode(digest)); 使用在线 md5 加密 ，发现我们生成的值和代码生成的值不一样，那是因为消息摘要不是使用base64进行编码的，所以我们需要把值转成16进制 12345678910111213141516171819202122232425262728293031323334public class DigestDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"aa\"; String md5 = getDigest(input, \"MD5\"); //4124bc0a9335c27f086f24ba207a4912 System.out.println(md5); &#125; private static String toHex(byte[] digest) throws Exception &#123; StringBuilder sb = new StringBuilder(); for (byte b : digest) &#123; // 转成16进制 String s = Integer.toHexString(b &amp; 0xff); if (s.length() == 1)&#123; // 如果生成的字符只有一个，高位补0 s = \"0\"+s; &#125; sb.append(s); &#125; System.out.println(\"16进制数据的长度：\" + sb.toString().getBytes().length); return sb.toString(); &#125; private static String getDigest(String input, String algorithm) throws Exception &#123; //创建消息摘要 MessageDigest messageDigest = MessageDigest.getInstance(algorithm); // 执行消息摘要算法 byte[] digest = messageDigest.digest(input.getBytes()); System.out.println(\"密文的字节长度:\" + digest.length); return toHex(digest); &#125;&#125; 其他消息摘要： 12345678910111213141516public class DigestDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"aa\"; String md5 = getDigest(input, \"MD5\"); String sha1 = getDigest(input, \"SHA-1\"); System.out.println(sha1); String sha256 = getDigest(input, \"SHA-256\"); System.out.println(sha256); String sha512 = getDigest(input, \"SHA-512\"); System.out.println(sha512); &#125;&#125; 文件消息摘要123456789101112131415private static String getDigestFile(String filePath, String algorithm) throws Exception&#123; FileInputStream fis = new FileInputStream(filePath); int len; byte[] buffer = new byte[1024]; ByteArrayOutputStream baos = new ByteArrayOutputStream(); while ( (len = fis.read(buffer))!=-1)&#123; baos.write(buffer,0,len); &#125; // 获取消息摘要对象 MessageDigest messageDigest = MessageDigest.getInstance(algorithm); // 获取消息摘要 byte[] digest = messageDigest.digest(baos.toByteArray()); System.out.println(\"密文的字节长度：\"+digest.length); return toHex(digest); &#125; 如使用sha-1算法，可以实现秒传功能，不管咱们如何修改文件的名字，最后得到的值是一样的，如果原文修改了，那么sha-1值就会不一样。 总结： MD5算法 : 摘要结果16个字节, 转16进制后32个字节 SHA1算法 : 摘要结果20个字节, 转16进制后40个字节 SHA256算法 : 摘要结果32个字节, 转16进制后64个字节 SHA512算法 : 摘要结果64个字节, 转16进制后128个字节 非对称加密①非对称加密算法又称现代加密算法，常见算法有RSA、ECC ② 非对称加密是计算机通信安全的基石，保证了加密数据不会被破解。 ③ 与对称加密算法不同，非对称加密算法需要两个密钥：公开密钥(publickey) 和私有密钥(privatekey) ④ 公开密钥和私有密钥是一对 ⑤ 如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密。 ⑥ 如果用私有密钥对数据进行加密，只有用对应的公开密钥才能解密。 ⑦ 因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。 特点： 加密和解密使用不同的密钥 如果使用私钥加密, 只能使用公钥解密 如果使用公钥加密, 只能使用私钥解密 处理数据的速度较慢, 因为安全级别高 public abstract class KeyPairGenerator类用于生成公钥和密钥对。密钥对生成器使用getInstance工厂方法构造。 生成公钥和私钥123456789101112131415161718192021222324252627282930313233343536373839404142434445import com.sun.org.apache.xml.internal.security.utils.Base64;import javax.crypto.Cipher;import javax.crypto.spec.SecretKeySpec;import java.io.File;import java.nio.charset.Charset;import java.security.*;import java.security.spec.PKCS8EncodedKeySpec;public class RSADemo &#123; public static void main(String[] args) throws Exception &#123; // 加密算法 String algorithm = \"RSA\"; // 创建密钥对生成器对象 KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(algorithm); // 生成密钥对 KeyPair keyPair = keyPairGenerator.generateKeyPair(); // 生成私钥 PrivateKey privateKey = keyPair.getPrivate(); // 生成公钥 PublicKey publicKey = keyPair.getPublic(); // 获取私钥字节数组 byte[] privateKeyEncoded = privateKey.getEncoded(); // 获取公钥字节数组 byte[] publicKeyEncoded = publicKey.getEncoded(); // 对公私钥进行base64编码 String privateKeyString = Base64.encode(privateKeyEncoded); String publicKeyString = Base64.encode(publicKeyEncoded); // 打印私钥 System.out.println(\"私钥：\" + privateKeyString); // 打印公钥 System.out.println(\"公钥：\" + publicKeyString); String input = \"测试\"; //使用RSA私钥加密 Cipher cipher = Cipher.getInstance(algorithm); cipher.init(Cipher.ENCRYPT_MODE,privateKey); byte[] bytes = cipher.doFinal(input.getBytes()); System.out.println(\"私钥加密：\" + Base64.encode(bytes)); cipher.init(Cipher.DECRYPT_MODE,publicKey); byte[] bytes1 = cipher.doFinal(bytes); System.out.println(\"公钥解密：\" + new String(bytes1)); &#125;&#125; 必须使用私钥加密公钥解密，或者公钥加密私钥解密，若使用同一把钥匙进行加密解密时，将会出现以下错误： 保存公钥和私钥123456789101112131415161718192021222324252627282930313233public static void main(String[] args) throws Exception &#123; // 加密算法 String algorithm = \"RSA\"; //生成密钥对并保存在本地文件中 generateKeyToFile(algorithm, \"a.pub\", \"a.pri\");&#125; /** * 生成密钥对并保存在本地文件中 * * @param algorithm : 算法 * @param pubPath : 公钥保存路径 * @param priPath : 私钥保存路径 * @throws Exception */public static void generateKeyToFile(String algorithm, String pubPath, String priPath) throws Exception &#123; // 获取密钥对生成器 KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(algorithm); // 获取密钥对 KeyPair keyPair = keyPairGenerator.generateKeyPair(); // 获取公钥 PublicKey publicKey = keyPair.getPublic(); // 获取私钥 PrivateKey privateKey = keyPair.getPrivate(); // 获取byte数组 byte[] publicKeyEncoded = publicKey.getEncoded(); byte[] privateKeyEncoded = privateKey.getEncoded(); // 进行Base64编码 String publicKeyString = Base64.encode(publicKeyEncoded); String privateKeyString = Base64.encode(privateKeyEncoded); // 保存文件 FileUtils.writeStringToFile(new File(pubPath), publicKeyString, Charset.forName(\"UTF-8\")); FileUtils.writeStringToFile(new File(priPath), privateKeyString, Charset.forName(\"UTF-8\"));&#125; 读取公钥和私钥1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import com.sun.org.apache.xml.internal.security.utils.Base64;import org.apache.commons.io.FileUtils;import javax.crypto.Cipher;import javax.crypto.spec.SecretKeySpec;import java.io.File;import java.nio.charset.Charset;import java.security.*;import java.security.spec.PKCS8EncodedKeySpec;import java.security.spec.X509EncodedKeySpec;public class RSAdemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试\"; String algorithm = \"RSA\"; PrivateKey privateKey = getPrivateKey(\"a.pri\", algorithm); PublicKey publicKey = getPublicKey(\"a.pub\", algorithm); String encode = encryptRSA(algorithm, privateKey, input); String decode = decryptRSA(algorithm, publicKey, encode); System.out.println(decode); &#125; public static PublicKey getPublicKey(String pulickPath,String algorithm) throws Exception&#123; // 将文件内容转为字符串 String publicKeyString = FileUtils.readFileToString(new File(pulickPath), Charset.defaultCharset()); // 获取密钥工厂 KeyFactory keyFactory = KeyFactory.getInstance(algorithm); // 构建密钥规范 进行Base64解码 X509EncodedKeySpec spec = new X509EncodedKeySpec(Base64.decode(publicKeyString)); // 生成公钥 return keyFactory.generatePublic(spec); &#125; public static PrivateKey getPrivateKey(String priPath,String algorithm) throws Exception&#123; // 将文件内容转为字符串 String privateKeyString = FileUtils.readFileToString(new File(priPath), Charset.defaultCharset()); // 获取密钥工厂 KeyFactory keyFactory = KeyFactory.getInstance(algorithm); // 构建密钥规范 进行Base64解码 PKCS8EncodedKeySpec spec = new PKCS8EncodedKeySpec(Base64.decode(privateKeyString)); // 生成私钥 return keyFactory.generatePrivate(spec); &#125; /** * 使用公钥解密数据 * * @param algorithm : 算法 * @param encrypted : 密文 * @param key : 公钥 * @return : 原文 * @throws Exception */ public static String decryptRSA(String algorithm,Key key,String encrypted) throws Exception&#123; Cipher cipher = Cipher.getInstance(algorithm); cipher.init(Cipher.DECRYPT_MODE,key); byte[] decode = Base64.decode(encrypted); byte[] bytes = cipher.doFinal(decode); return new String(bytes); &#125; /** * 使用密钥加密数据 * * @param algorithm : 算法 * @param input : 原文 * @param key : 私钥 * @return : 密文 * @throws Exception */ public static String encryptRSA(String algorithm,Key key,String input) throws Exception&#123; Cipher cipher = Cipher.getInstance(algorithm); cipher.init(Cipher.ENCRYPT_MODE,key); byte[] bytes = cipher.doFinal(input.getBytes()); return Base64.encode(bytes); &#125;&#125; 数字签名数字签名（又称公钥数字签名）是只有信息的发送者才能产生的别人无法伪造的一段数字串，这段数字串同时也是对信息的发送者发送信息真实性的一个有效证明。它是一种类似写在纸上的普通的物理签名，但是使用了公钥加密领域的技术来实现的，用于鉴别数字信息的方法。一套数字签名通常定义两种互补的运算，一个用于签名，另一个用于验证。数字签名是非对称密钥加密技术与数字摘要技术的应用。 数字签名的含义：在网络中传输数据时候，给数据添加一个数字签名，表示是谁发的数据，而且还能证明数据没有被篡改。 数字签名的主要作用就是保证了数据的有效性（验证是谁发的）和完整性（证明信息没有被篡改）。 基本原理为了理解得清楚，我们通过案例一步一步来讲解。话说张三有俩好哥们A、B。由于工作原因，张三和AB写邮件的时候为了安全都需要加密。于是张三想到了数字签名： 整个思路是这个样子的： 第一步：加密采用非对称加密，张三有三把钥匙，两把公钥，送给朋友。一把私钥留给自己。 第二步：A或者B写邮件给张三：A先用公钥对邮件加密，然后张三收到邮件之后使用私钥解密。 第三步：张三写邮件给A或者B： （1）张三写完邮件，先用hash函数生成邮件的摘要，附着在文章上面，这就完成了数字签名，然后张三再使用私钥加密。就可以把邮件发出去了。 （2）A或者是B收到邮件之后，先把数字签名取下来，然后使用自己的公钥解密即可。这时候取下来的数字签名中的摘要若和张三的一致，那就认为是张三发来的，再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。 上面的流程我们使用一张图来演示一下： 首先把公钥送给朋友A和B： 数字证书上面提到我们对签名进行验证时，需要用到公钥。如果公钥是伪造的，那我们无法验证数字签名了，也就根本不可能从数字签名确定对方的合法性了。这时候证书就闪亮登场了。我们可能都有考各种证书的经历，比如说普通话证书，四六级证书等等，但是归根结底，到任何场合我们都能拿出我们的证书来证明自己确实已经考过了普通话，考过了四六级。这里的证书也是同样的道理。 如果不理解证书的作用，我们可以举一个例子，比如说我们的毕业证书，任何公司都会承认。为什么会承认？因为那是国家发得，大家都信任国家。也就是说只要是国家的认证机构，我们都信任它是合法的。 那么这个证书是如何生成的呢？我们再来看一张图： 网页加密我们看一个应用“数字证书”的实例：https协议。这个协议主要用于网页加密 首先，客户端向服务器发出加密请求。 服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。 客户端（浏览器）的“证书管理器”，有“受信任的根证书颁发机构”列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。 如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。 如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。 如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.security.*;import com.sun.org.apache.xml.internal.security.utils.Base64;public class SignatureDemo &#123; public static void main(String[] args) throws Exception &#123; String a = \"123\"; PrivateKey privateKey = RSADemo.getPrivateKey(\"a.pri\", \"RSA\"); PublicKey publicKey = RSADemo.getPublicKey(\"a.pub\", \"RSA\"); String signaturedData = getSignature(a, \"sha256withrsa\", privateKey); boolean b = verifySignature(a, \"sha256withrsa\", publicKey, signaturedData); &#125; /** * 生成签名 * * @param input : 原文 * @param algorithm : 算法 * @param privateKey : 私钥 * @return : 签名 * @throws Exception */ private static String getSignature(String input, String algorithm, PrivateKey privateKey) throws Exception &#123; // 获取签名对象 Signature signature = Signature.getInstance(algorithm); // 初始化签名 signature.initSign(privateKey); // 传入原文 signature.update(input.getBytes()); // 开始签名 byte[] sign = signature.sign(); // 对签名数据进行Base64编码 return Base64.encode(sign); &#125; /** * 校验签名 * * @param input : 原文 * @param algorithm : 算法 * @param publicKey : 公钥 * @param signaturedData : 签名 * @return : 数据是否被篡改 * @throws Exception */ private static boolean verifySignature(String input, String algorithm, PublicKey publicKey, String signaturedData) throws Exception &#123; // 获取签名对象 Signature signature = Signature.getInstance(algorithm); // 初始化签名 signature.initVerify(publicKey); // 传入原文 signature.update(input.getBytes()); // 校验数据 return signature.verify(Base64.decode(signaturedData)); &#125;&#125; keytool工具keytool工具路径：C:\\Program Files\\Java\\jre1.8.0_91\\bin 常用命令：生成keypair： 12keytool -genkeypairkeytool -genkeypair -alias lisi（后面部分是为证书指定别名，否则采用默认的名称为mykey） 看看keystore中有哪些项目： 12keytool -list 或 keytool -list -vkeytool -exportcert -alias lisi -file lisi.cer 生成可打印的证书： 1keytool -exportcert -alias lisi -file lisi.cer –rfc 显示数字证书文件中的证书信息： 1keytool -printcert -file lisi.cer 直接双击lisi.cer，用window系统的内置程序打开lisi.cer 生成私钥公钥（1）生成密钥证书 下边命令生成密钥证书，采用RSA 算法每个证书包含公钥和私钥 创建一个文件夹，在该文件夹下执行如下命令行： 1keytool -genkeypair -alias midkuro -keyalg RSA -keypass midkuro -keystore midkuro.jks -storepass midkuro Keytool是一个java提供的证书管理工具 12345-alias：密钥的别名 -keyalg：使用的hash算法 -keypass：密钥的访问密码 -keystore：密钥库文件名，xc.keystore保存了生成的证书 -storepass：密钥库的访问密码 （2）查询证书信息 1keytool -list -keystore migkuro.jks （3）删除别名 1keytool -delete -alias midkuro -keystore midkuro.jks 导出公钥openssl是一个加解密工具包，这里使用openssl来导出公钥信息。 安装 openssl，安装资料目录下的Win64OpenSSL-1_1_0g.exe 配置openssl的path环境变量，如下图： 本教程配置在C:\\OpenSSL-Win64\\bin cmd进入midkuro.jks文件所在目录执行如下命令（如下命令在windows下执行，会把-变成中文方式，请将它改成英文的-）： 1keytool -list -rfc --keystore midkuro.jks | openssl x509 -inform pem -pubkey 下面段内容是公钥： 123456789-----BEGIN PUBLIC KEY-----MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvFsEiaLvij9C1Mz+oyAmt47whAaRkRu&#x2F;8kePM+X8760UGU0RMwGti6Z9y3LQ0RvK6I0brXmbGB&#x2F;RsN38PVnhcP8ZfxGUH26kX0RK+tlrxcrG+HkPYOH4XPAL8Q1lu1n9x3tLcIPxq8ZZtuIyKYEmoLKyMsvTviG5flTpDprT25unWgE4md1kthRWXOnfWHATVY7Y&#x2F;r4obiOL1mS5bEa&#x2F;iNKotQNnvIAKtjBM4RlIDWMa6dmz+lHtLtqDD2LF1qwoiSIHI75LQZ&#x2F;CNYaHCfZSxtOydpNKq8eb1&#x2F;PGiLNolD4La2zf0&#x2F;1dlcr5mkesV570NxRmU1tFm8Zd3MZlZmyv9QIDAQAB-----END PUBLIC KEY----- 将上边的公钥拷贝到文本public.key文件中，合并为一行,可以将它放到需要实现授权认证的工程中。","categories":[{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.github.io/categories/Cryptography/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.github.io/tags/Cryptography/"}]},{"title":"'Java 密码学 对称加密'","slug":"cryptography-symmetrical","date":"2020-06-10T13:00:00.000Z","updated":"2020-07-27T07:11:04.971Z","comments":true,"path":"2020/06/10/cryptography-symmetrical/","link":"","permalink":"https://midkuro.github.io/2020/06/10/cryptography-symmetrical/","excerpt":"","text":"密码学Byte和BitByte : 字节. 数据存储的基本单位，比如移动硬盘1T ， 单位是byte bit : 比特, 又叫位. 一个位要么是0要么是1. 数据传输的单位 , 比如家里的宽带100MB，下载速度并没有达到100MB，一般都是12-13MB，那么是因为需要使用 100 / 8 关系: 1Byte = 8bit 英文对应的字节1234567891011121314public class ByteBit &#123; public static void main(String[] args) &#123; String a = \"a\"; byte[] bytes = a.getBytes(); for (byte b : bytes) &#123; int c=b; // 打印发现byte实际上就是ascii码 System.out.println(c); //97 // 我们在来看看每个byte对应的bit，byte获取对应的bit String s = Integer.toBinaryString(c); System.out.println(s); //1100001 &#125; &#125;&#125; 打印英文字符串的字节，实际打印的就是ascii编码！ 中文对应的字节1234567891011public class ByteBitDemo &#123; public static void main(String[] args) throws Exception&#123; String a = \"尚\"; byte[] bytes = a.getBytes(); for (byte b : bytes) &#123; System.out.print(b + \" \"); String s = Integer.toBinaryString(b); System.out.println(s); &#125; &#125;&#125; 在编码UTF-8的中，一个中文是由三个字节组成的！ 12345678910111213public static void main(String[] args) throws Exception&#123; String a = \"尚\"; // 在中文情况下，不同的编码格式，对应不同的字节 //GBK :编码格式占2个字节 // UTF-8：编码格式占3个字节 byte[] bytes = a.getBytes(\"GBK\"); // byte[] bytes = a.getBytes(\"UTF-8\"); for (byte b : bytes) &#123; System.out.print(b + \" \"); String s = Integer.toBinaryString(b); System.out.println(s); &#125;&#125; 在编码GBK的中，一个中文是由两个字节组成的！在UTF-8编码格式中，一个中文由占3个字节组成。 常见加密 采用单钥密码系统的加密方法，同一个密钥可以同时用作信息的加密和解密，这种加密方法称为对称加密，也称为单密钥加密。 示例： 我们现在有一个原文3要发送给B 设置密钥为108, 3 * 108 = 324, 将324作为密文发送给B B拿到密文324后, 使用324/108 = 3 得到原文 常见加密算法： DES : Data Encryption Standard，即数据加密标准，是一种使用密钥加密的块算法，1977年被美国联邦政府的国家标准局确定为联邦资料处理标准（FIPS），并授权在非密级政府通信中使用，随后该算法在国际上广泛流传开来。 AES : Advanced Encryption Standard, 高级加密标准 .在密码学中又称Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。 特点： 加密速度快, 可以加密大文件 密文可逆, 一旦密钥文件泄漏, 就会导致数据暴露 加密后Ascii编码表找不到对应字符, 会出现乱码 一般结合Base64使用 Base64Base64是网络上最常见的用于传输8Bit字节码的可读性编码算法之一，可读性编码算法不是为了保护数据的安全性，而是为了可读性，可读性编码不改变信息内容，只改变信息内容的表现形式。 所谓Base64，即是说在编码过程中使用了64种字符： ① 小写 a - z = 26个字母 ② 大写 A - Z = 26个字母 ③ 数字 0 - 9 = 10 个数字 ④ + / = 2个符号 Base58是Bitcoin(比特币)中使用的一种编码方式，主要用于产生Bitcoin的钱包地址，相比Base64，Base58不使用数字”0”，字母大写”O”，字母大写”I”，和字母小写”i”，以及”+”和”/“符号。 base64 是 3个字节为一组，一个字节 8位，一共 就是24位 ，然后，把3个字节转成4组，每组6位 3 * 8 = 4 * 6 = 24 ，每组6位，缺少的2位，会在高位进行补0，这样做的好处在于 ，base取的是后面6位，去掉高2位 ，那么Base64的取值就可以控制在0-63位了，所以就叫base64，111 111 = 32 + 16 + 8 + 4 + 2 + 1 = 63 可能发现一个问题，base64加密后有个=号，但是在映射表里面没有发现 =号 ， 这个地方需要注意，等号非常特殊，因为base64是三个字节一组 ，如果当我们的位数不够的时候，会使用等号来补齐。 123456789101112import com.sun.org.apache.xerces.internal.impl.dv.util.Base64;public class TestBase64 &#123; public static void main(String[] args) &#123; // 1表示一个字节，不够三个字节，所以需要后面通过 == 号补齐 System.out.println(Base64.encode(\"1\".getBytes())); //MQ== System.out.println(Base64.encode(\"12\".getBytes())); //MTI= System.out.println(Base64.encode(\"123\".getBytes())); //MTIz // 测试:中文(UTF-8)占6个字节，6 * 8 = 48 ，刚刚好被整除，所以没有等号 System.out.println(Base64.encode(\"测试\".getBytes())); //5rWL6K+V &#125;&#125; Base64的相关包默认使用apache提供的即可，不同的依赖包，提供的API略有不同。 在Eclipse中，可以使用import org.apache.tomcat.util.codec.binary.Base64;， 在Idea中，可以使用import com.sun.org.apache.xerces.internal.impl.dv.util.Base64; DES加密Cipher文档 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import javax.crypto.Cipher;import javax.crypto.spec.SecretKeySpec;import org.apache.tomcat.util.codec.binary.Base64;public class DesDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试测试\"; // 密钥 String key = \"12345678\"; // 加密算法 String transformation = \"DES\"; // 算法类型 String algorithm = \"DES\"; System.out.println(\"原文：\" + input); String encryptDes = encryptDes(input, key, transformation, algorithm); System.out.println(\"加密：\" + encryptDes); String decryptDes = decryptDes(encryptDes, key, transformation, algorithm); System.out.println(\"解密：\" + decryptDes); &#125; /** * 加密算法 * * @param input 原文 * @param key 密钥 * @param transformation 算法 * @param algorithm 加密类型 * @return * @throws Exception */ public static String encryptDes(String input, String key, String transformation, String algorithm) throws Exception &#123; // 获取加密对象 Cipher cipher = Cipher.getInstance(transformation); // 创建加密规则 第一个参数key的字节 第二个参数表示加密算法 SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(), algorithm); // 初始化加密模式和算法 Cipher.ENCRYPT_MODE:加密模式 cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec); // 加密 byte[] bytes = cipher.doFinal(input.getBytes()); // 输出加密后的数据 return Base64.encodeBase64String(bytes); &#125; /** * 解密算法 * * @param encryptDes 密文 * @param key 密钥 * @param transformation 加密算法 * @param algorithm 加密类型 * @return * @throws Exception */ public static String decryptDes(String encryptDes, String key, String transformation, String algorithm) throws Exception &#123; Cipher cipher = Cipher.getInstance(transformation); SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(), algorithm); // Cipher.DECRYPT_MODE:解密模式 cipher.init(Cipher.DECRYPT_MODE, secretKeySpec); byte[] bytes = cipher.doFinal(Base64.decodeBase64(encryptDes)); return new String(bytes); &#125;&#125; DES规定密钥key必定是8个字节，如果加密算法的key不足8个字节时，如key=123456 将会出现以下错误： 1234567byte[] bytes = cipher.doFinal(input.getBytes());for (byte b : bytes) &#123; //会打印出负数 System.out.println(b); &#125;//会出现乱码System.out.println(new String(bytes)); 当在加密的过程中执行上述代码，以字符串的形式直接输出加密后的bytes数组，会出现，将会出现以下错误： 出现乱码是因为对应的字节出现负数，但负数，没有出现在 ascii 码表里面，所以常使用base64配合转码！ 123byte[] bytes = cipher.doFinal(input.getBytes());//使用Base64配合输出System.out.println(Base64.encodeBase64String(bytes)); AES加密AES 加密解密和 DES 加密解密代码一样，只需要修改加密算法就行，可以直接拷贝 DSC 加解密代码。 12345678910111213public class AesDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试测试\"; //AES加密算法，比较高级，所以key的大小必须是16个字节 String key = \"1234567812345678\"; String transformation = \"AES\"; String algorithm = \"AES\"; String encryptDes = encryptDes(input, key, transformation, algorithm); //d+tFlhF2ISyzd725BV0bRg== System.out.println(\"加密：\" + encryptDes); &#125;&#125; AES比DES要高级，所以Key的大小必须是16个字节，如果依旧使用8个字节，将会遇见以下错误： 加密模式加密模式：https://docs.oracle.com/javase/8/docs/api/javax/crypto/Cipher.html ECBECB : Electronic codebook, 电子密码本. 需要加密的消息按照块密码的块大小被分为数个块，并对每个块进行独立加密。 优缺点： 优点 : 可以并行处理数据 缺点 : 同样的原文生成同样的密文, 不能很好的保护数据 CBCCBC : Cipher-block chaining, 密码块链接. 每个明文块先与前一个密文块进行异或后，再进行加密。在这种方法中，每个密文块都依赖于它前面的所有明文块。 优缺点： 优点 : 同样的原文生成的密文不一样，加密很安全 缺点 : 串行处理数据，加密速度很慢 填充模式当需要按块处理的数据, 数据长度不符合块处理需求时, 按照一定的方法填充满块长的规则。 NoPadding不填充，在DES加密算法下, 要求原文长度必须是8byte的整数倍，在AES加密算法下, 要求原文长度必须是16byte的整数倍。 PKCS5Padding数据块的大小为8位, 不够就补足 Tips： 如果没有写加密模式和填充模式，则默认使用的加 密模式和填充模式为 : ECB/PKCS5Padding 如果使用CBC模式, 在初始化Cipher对象时, 需要增加参数, 初始化向量IV : IvParameterSpec iv = new IvParameterSpec(key.getBytes()); 加密模式和填充模式 123456789101112131415AES/CBC/NoPadding (128)AES/CBC/PKCS5Padding (128)AES/ECB/NoPadding (128)AES/ECB/PKCS5Padding (128)DES/CBC/NoPadding (56)DES/CBC/PKCS5Padding (56)DES/ECB/NoPadding (56)DES/ECB/PKCS5Padding (56)DESede/CBC/NoPadding (168)DESede/CBC/PKCS5Padding (168)DESede/ECB/NoPadding (168)DESede/ECB/PKCS5Padding (168)RSA/ECB/PKCS1Padding (1024, 2048)RSA/ECB/OAEPWithSHA-1AndMGF1Padding (1024, 2048)RSA/ECB/OAEPWithSHA-256AndMGF1Padding (1024, 2048) ECB案例： 12345678910111213import org.apache.tomcat.util.codec.binary.Base64;public class DesDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试测试\"; String key = \"12345678\"; //加密算法/加密模式/填充模式 String transformation = \"DES/ECB/PKCS5Padding\"; String algorithm = \"DES\"; String encryptDes = encryptDes(input, key, transformation, algorithm); System.out.println(\"加密：\" + encryptDes); &#125;&#125; CBC案例： 12345678910111213141516171819202122//在加密模式为CBC下需要增加IV向量public static String encryptDes(String input, String key, String transformation, String algorithm) throws Exception &#123; Cipher cipher = Cipher.getInstance(transformation); SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(), algorithm); //增加iv向量 IvParameterSpec iv = new IvParameterSpec(key.getBytes()); //传参Iv对象 cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec, iv); byte[] bytes = cipher.doFinal(input.getBytes()); return Base64.encodeBase64String(bytes);&#125;public static String decryptDes(String encryptDes, String key, String transformation, String algorithm) throws Exception &#123; Cipher cipher = Cipher.getInstance(transformation); SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(), algorithm); //增加iv向量 IvParameterSpec iv = new IvParameterSpec(key.getBytes()); //传参Iv对象 cipher.init(Cipher.DECRYPT_MODE, secretKeySpec,iv); byte[] bytes = cipher.doFinal(Base64.decodeBase64(encryptDes)); return new String(bytes);&#125; NoPadding案例： 12345678910111213import org.apache.tomcat.util.codec.binary.Base64;public class DesDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试12\"; String key = \"12345678\"; //加密算法/加密模式/填充模式 String transformation = \"DES/ECB/NoPadding\"; String algorithm = \"DES\"; String encryptDes = encryptDes(input, key, transformation, algorithm); System.out.println(\"加密：\" + encryptDes); &#125;&#125; 使用不填充模式Nopadding时，加密的文本必须是8个字节的倍数，若上述的input = &quot;测试&quot;,只有6个字节时（UTF-8下），将会出现以下错误： 值得一提的是，在使用iv向量进行加密时，加密的key也必须是8个字节的倍数！","categories":[{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.github.io/categories/Cryptography/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.github.io/tags/Cryptography/"}]},{"title":"'Java 密码学 基本概念'","slug":"cryptography-base","date":"2020-06-10T04:00:00.000Z","updated":"2020-06-11T10:48:00.261Z","comments":true,"path":"2020/06/10/cryptography-base/","link":"","permalink":"https://midkuro.github.io/2020/06/10/cryptography-base/","excerpt":"","text":"密码学密码学基本概念密码在我们的生活中有着重要的作用，那么密码究竟来自何方，为何会产生呢？ 密码学是网络安全、信息安全、区块链等产品的基础，常见的非对称加密、对称加密、散列函数等，都属于密码学范畴。 密码学有数千年的历史，从最开始的替换法到如今的非对称加密算法，经历了古典密码学，近代密码学和现代密码学三个阶段。密码学不仅仅是数学家们的智慧，更是如今网络空间安全的重要基础。 古典密码学在古代的战争中，多见使用隐藏信息的方式保护重要的通信资料。比如先把需要保护的信息用化学药水写到纸上，药水干后，纸上看不出任何的信息，需要使用另外的化学药水涂抹后才可以阅读纸上的信息。 这些方法都是在保护重要的信息不被他人获取，但藏信息的方式比较容易被他人识破，例如增加哨兵的排查力度，就会发现其中的猫腻，因而随后发展出了较难破解的古典密码学。 替换法替换法很好理解，就是用固定的信息将原文替换成无法直接阅读的密文信息。例如将 b 替换成 w ，e 替换成p ，这样bee 单词就变换成了wpp，不知道替换规则的人就无法阅读出原文的含义。 替换法有单表替换和多表替换两种形式。单表替换即只有一张原文密文对照表单，发送者和接收者用这张表单来加密解密。在上述例子中，表单即为：a b c d e - s w t r p 。 多表替换即有多张原文密文对照表单，不同字母可以用不同表单的内容替换。 例如约定好表单为：表单 1：abcde-swtrp 、表单2：abcde-chfhk 、表单 3：abcde-jftou。 规定第一个字母用第三张表单，第二个字母用第一张表单，第三个字母用第二张表单，这时 bee单词就变成了 (312)fpk ，破解难度更高，其中 312 又叫做密钥，密钥可以事先约定好，也可以在传输过程中标记出来。 移位法移位法就是将原文中的所有字母都在字母表上向后（或向前）按照一个固定数目进行偏移后得出密文，典型的移位法应用有 “ 恺撒密码 ”。 例如约定好向后移动2位（abcde - cdefg），这样 bee 单词就变换成了dgg。 同理替换法，移位法也可以采用多表移位的方式，典型的多表案例是“维尼吉亚密码”（又译维热纳尔密码），属于多表密码的一种形式。 古典密码破解方式古典密码虽然很简单，但是在密码史上是使用的最久的加密方式，直到“概率论”的数学方法被发现，古典密码就被破解了。 英文单词中字母出现的频率是不同的，e以12.702%的百分比占比最高，z 只占到0.074%，感兴趣的可以去百科查字母频率详细统计数据。如果密文数量足够大，仅仅采用频度分析法就可以破解单表的替换法或移位法。 多表的替换法或移位法虽然难度高一些，但如果数据量足够大的话，也是可以破解的。以维尼吉亚密码算法为例，破解方法就是先找出密文中完全相同的字母串，猜测密钥长度，得到密钥长度后再把同组的密文放在一起，使用频率分析法破解。 近代密码学古典密码的安全性受到了威胁，外加使用便利性较低，到了工业化时代，近现代密码被广泛应用。 恩尼格玛机是二战时期纳粹德国使用的加密机器，后被英国破译，参与破译的人员有被称为计算机科学之父、人工智能之父的图灵。 恩尼格玛机使用的加密方式本质上还是移位和替代，只不过因为密码表种类极多，破解难度高，同时加密解密机器化，使用便捷，因而在二战时期得以使用。 现代密码学散列函数散列函数，也叫杂凑函数、摘要函数或哈希函数，可将任意长度的消息经过运算，变成固定长度数值，常见的有MD5、SHA-1、SHA256，多应用在文件校验，数字签名中。 MD5 可以将任意长度的原文生成一个128位（16字节）的哈希值 SHA-1可以将任意长度的原文生成一个160位（20字节）的哈希值 对称密码对称密码应用了相同的加密密钥和解密密钥。对称密码分为：序列密码(流密码)，分组密码(块密码)两种。流密码是对信息流中的每一个元素（一个字母或一个比特）作为基本的处理单元进行加密，块密码是先对信息流分块，再对每一块分别加密。 例如原文为1234567890，流加密即先对1进行加密，再对2进行加密，再对3进行加密……最后拼接成密文；块加密先分成不同的块，如1234成块，5678成块，90XX(XX为补位数字)成块，再分别对不同块进行加密，最后拼接成密文。前文提到的古典密码学加密方法，都属于流加密。 非对称密码对称密码的密钥安全极其重要，加密者和解密者需要提前协商密钥，并各自确保密钥的安全性，一但密钥泄露，即使算法是安全的也无法保障原文信息的私密性。 在实际的使用中，远程的提前协商密钥不容易实现，即使协商好，在远程传输过程中也容易被他人获取，因此非对称密钥此时就凸显出了优势。 非对称密码有两支密钥，公钥（publickey）和私钥（privatekey），加密和解密运算使用的密钥不同。用公钥对原文进行加密后，需要由私钥进行解密；用私钥对原文进行加密后（此时一般称为签名），需要由公钥进行解密（此时一般称为验签）。公钥可以公开的，大家使用公钥对信息进行加密，再发送给私钥的持有者，私钥持有者使用私钥对信息进行解密，获得信息原文。因为私钥只有单一人持有，因此不用担心被他人解密获取信息原文。 如何设置密码才安全 密码不要太常见，不要使用类似于123456式的常用密码。 各应用软件密码建议不同，避免出现一个应用数据库被脱库，全部应用密码崩塌， 可在设置密码时增加注册时间、注册地点、应用特性等方法。例如tianjin123456，表示在天津注册的该应用。 ASCII编码ASCII（American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统，主要用于显示现代英语和其他西欧语言。它是现今最通用的单字节编码系统，并等同于国际标准ISO/IEC 646。 创建Maven项目，添加pom.xml依赖 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 12345678910111213141516public class AsciiDemo &#123; public static void main(String[] args) &#123; char a = 'A'; int b = a; // 打印ascii码 System.out.println(b); //65 String a = \"AaZ\"; // 获取ascii码，需要把字符串转成字符 char[] chars = a.toCharArray(); for (char c : chars) &#123; int asciiCode = c; System.out.println(asciiCode); //65 97 90 &#125; &#125;&#125; 恺撒加密凯撒密码在密码学中，恺撒密码是一种最简单且最广为人知的加密技术。 凯撒密码最早由古罗马军事统帅盖乌斯·尤利乌斯·凯撒在军队中用来传递加密信息，故称凯撒密码。这是一种位移加密方式，只对26个字母进行位移替换加密，规则简单，容易破解。下面是位移1次的对比： 将明文字母表向后移动1位，A变成了B，B变成了C……，Z变成了A。同理，若将明文字母表向后移动3位： 则A变成了D，B变成了E……，Z变成了C。 字母表最多可以移动25位。凯撒密码的明文字母表向后或向前移动都是可以的，通常表述为向后移动，如果要向前移动1位，则等同于向后移动25位，位移选择为25即可。 它是一种替换加密的技术，明文中的所有字母都在字母表上向后（或向前）按照一个固定数目进行偏移后被替换成密文。 例如，当偏移量是3的时候，所有的字母A将被替换成D，B变成E，以此类推。 这个加密方法是以恺撒的名字命名的，当年恺撒曾用此方法与其将军们进行联系。 恺撒密码通常被作为其他更复杂的加密方法中的一个步骤。 简单来说就是当秘钥为n，其中一个待加密字符ch，加密之后的字符为ch+n，当ch+n超过’z’时，回到’a’计数。 凯撒位移加密123456789101112131415161718192021//把 hello world 往右边移动3位public class KaiserDemo &#123; public static void main(String[] args) &#123; String input = \"Hello world\"; // 往右边移动3位 int key = 3; // 用来拼接 StringBuilder sb = new StringBuilder(); // 字符串转换成字节数组 char[] chars = input.toCharArray(); for (char c : chars) &#123; int asciiCode = c; // 移动3位 asciiCode = asciiCode + key; char newChar = (char) asciiCode; sb.append(newChar); &#125; System.out.println(sb.toString()); //khoor#zruog &#125;&#125; 凯撒加密和解密12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class KaiserDemo &#123; public static void main(String[] args) &#123; String orignal = \"Hello world\"; // 往右边偏移三位 int key = 3; // 选中我即将抽取的代码，按快捷键Ctrl + Alt + M String encryptKaiser = encryptKaiser(orignal,key); System.out.println(\"加密：\" + encryptKaiser); String decryptKaiser = decryptKaiser(encryptKaiser,key); System.out.println(\"解密：\" + decryptKaiser); &#125; /** * 使用凯撒加密方式解密数据 * * @param encryptedData :密文 * @param key :密钥 * @return : 源数据 */ public static String decryptKaiser(String encryptedData, int key) &#123; // 将字符串转为字符数组 char[] chars = encryptedData.toCharArray(); StringBuilder sb = new StringBuilder(); for (char aChar : chars) &#123; // 获取字符的ASCII编码 int asciiCode = aChar; // 偏移数据 asciiCode -= key; // 将偏移后的数据转为字符 char result = (char) asciiCode; // 拼接数据 sb.append(result); &#125; return sb.toString(); &#125; /** * 使用凯撒加密方式加密数据 * * @param orignal :原文 * @param key :密钥 * @return :加密后的数据 */ public static String encryptKaiser(String orignal, int key) &#123; // 将字符串转为字符数组 char[] chars = orignal.toCharArray(); StringBuilder sb = new StringBuilder(); for (char aChar : chars) &#123; // 获取字符的ascii编码 int asciiCode = aChar; // 偏移数据 asciiCode += key; // 将偏移后的数据转为字符 char result = (char) asciiCode; // 拼接数据 sb.append(result); &#125; return sb.toString(); &#125;&#125; 频度分析法加密者选择将组成信息的字母替代成别的字母，比如说将a写成1，这样就不能被解密者直接拿到信息了。 这难不倒解密者，以英文字母为例，为了确定每个英文字母的出现频率，分析一篇或者数篇普通的英文文章，英文字母出现频率最高的是e，接下来是t，然后是a……，然后检查要破解的密文，也将每个字母出现的频率整理出来，假设密文中出现频率最高的字母是j，那么就可能是e的替身，如果密码文中出现频率次高的但是P，那么可能是t的替身，以此类推便就能解开加密信息的内容。这就是频率分析法。 将明文字母的出现频率与密文字母的频率相比较的过程 通过分析每个符号出现的频率而轻易地破译代换式密码 在每种语言中，冗长的文章中的字母表现出一种可对之进行分辨的频率。 e是英语中最常用的字母，其出现频率为八分之一 运行计算article.txt文本中各个符号的出现次数，如下： 然后对该文本进行位移3位，得到密文报，并在此统计密文的符号出现次数： 运行结果 # 出现次数最多， 我们知道在英文当中 e 出现的频率是最高的，我们假设现在 # 号，就是 e ，变形而来的 ，我们可以对照 ascii 编码表 ，我们的凯撒加密当中位移是加了一个 key ，所以我们 猜测 两个值直接相差 -66 ，我们现在就以 -66 进行解密 生成一个文件，我们查看第一个文件发现，根本读不懂，所以解密失败，我们在猜测 h 是 e ，h 和 e 之间相差3 ，所以我们在去看第二个解密文件，发现我们可以读懂，解密成功。","categories":[{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.github.io/categories/Cryptography/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.github.io/tags/Cryptography/"}]},{"title":"'Spring Boot Cache 缓存'","slug":"springboot-cache","date":"2020-06-04T14:00:00.000Z","updated":"2020-06-08T09:05:29.511Z","comments":true,"path":"2020/06/04/springboot-cache/","link":"","permalink":"https://midkuro.github.io/2020/06/04/springboot-cache/","excerpt":"","text":"Spring Boot CacheJSR 规范Java Caching定义了5个核心接口，分别是CachingProvider, CacheManager,Cache, Entry 和 Expiry。 CachingProvider定义了创建、配置、获取、管理和控制多个CacheManager。一个应用可以在运行期访问多个CachingProvider。 CacheManager定义了创建、配置、获取、管理和控制多个唯一命名的Cache，这些Cache存在于CacheManager的上下文中。一个CacheManager仅被一个CachingProvider所拥有。 Cache是一个类似Map的数据结构并临时存储以Key为索引的值。一个Cache仅被一个CacheManager所拥有。Entry是一个存储在Cache中的key-value对。 Expiry 每一个存储在Cache中的条目有一个定义的有效期。一旦超过这个时间，条目为过期的状态。一旦过期，条目将不可访问、更新和删除。缓存有效期可以通过ExpiryPolicy设置。 如果要使用JSR规范，可以引入以下依赖 1234&lt;dependency&gt; &lt;groupId&gt;javax.cache&lt;/groupid&gt; &lt;artifactId&gt;cache-api&lt;/artifactId&gt;&lt;/dependency&gt; Spring CacheSpring从3.1开始定义了org.springframework.cache.Cache和org.springframework.cache.CacheManager接口来统一不同的缓存技术；并支持使用JCache（JSR-107）注解简化我们开发； Cache接口为缓存的组件规范定义，包含缓存的各种操作集合；Cache接口下Spring提供了各种xxxCache的实现；如RedisCache，EhCacheCache , ConcurrentMapCache等； 每次调用需要缓存功能的方法时，Spring会检查检查指定参数的指定的目标方法是否已经被调用过；如果有就直接从缓存中获取方法调用后的结果，如果没有就调用方法并缓存结果后返回给用户。下次调用直接从缓存中获取。 使用Spring缓存抽象时我们需要关注以下两点； 确定方法需要被缓存以及他们的缓存策略 从缓存中读取之前缓存存储的数据 缓存注解 Cache 缓存接口，定义缓存操作。实现有：RedisCache、EhCacheCache、ConcurrentMapCache等 CacheManager 缓存管理器，管理各种缓存（Cache）组件 @Cacheable 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存 @CacheEvict 清空缓存 @CachePut 保证方法被调用，又希望结果被缓存。 @EnableCaching 开启基于注解的缓存 keyGenerator 缓存数据时key生成策略 serialize 缓存数据时value序列化策略 案例： 123456@Cacheable(value = &#123;\"emp\"&#125;)public Employee getEmp(Integer id)&#123; System.out.println(\"查询\"+id+\"号员工\"); Employee emp = employeeMapper.getEmpById(id); return emp;&#125; cacheNames/value：指定缓存组件的名字;将方法的返回结果放在哪个缓存中，是数组的方式，可以指定多个缓存； key：缓存数据使用的key；可以用它来指定。默认是使用方法参数的值：《方法参数，方法返回值》 编写SpEL：#id #a0 #p0 #root.args[0] 都表示参数id的值. cacheManager：指定缓存管理器；或者cacheResolver指定获取解析器 keyGenerator：key的生成器；可以自己指定key的生成器的组件id，和key属性二选一使用 condition：指定符合条件的情况下才缓存；如condition = &quot;#id&gt;0“ unless:否定缓存；当unless指定的条件为true，方法的返回值就不会被缓存；可以获取到结果进行判断 如unless = &quot;#result == null&quot; sync：是否使用异步模式 原理通过自动配置类CacheAutoConfiguration加载 123456789@Configuration@ConditionalOnClass(CacheManager.class)@ConditionalOnBean(CacheAspectSupport.class)@ConditionalOnMissingBean(value = CacheManager.class, name = \"cacheResolver\")@EnableConfigurationProperties(CacheProperties.class)@AutoConfigureAfter(&#123; CouchbaseAutoConfiguration.class, HazelcastAutoConfiguration.class, HibernateJpaAutoConfiguration.class, RedisAutoConfiguration.class &#125;)@Import(CacheConfigurationImportSelector.class)public class CacheAutoConfiguration &#123;&#125; @Import(CacheConfigurationImportSelector.class)主要用于导入容器中需要使用的组件。 1234567891011static class CacheConfigurationImportSelector implements ImportSelector &#123; @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; CacheType[] types = CacheType.values(); String[] imports = new String[types.length]; for (int i = 0; i &lt; types.length; i++) &#123; imports[i] = CacheConfigurations.getConfigurationClass(types[i]); &#125; return imports; &#125;&#125; 具体导入了以下组件： 1234567891011org.springframework.boot.autoconfigure.cache.GenericCacheConfigurationorg.springframework.boot.autoconfigure.cache.JCacheCacheConfigurationorg.springframework.boot.autoconfigure.cache.EhCacheCacheConfigurationorg.springframework.boot.autoconfigure.cache.HazelcastCacheConfigurationorg.springframework.boot.autoconfigure.cache.InfinispanCacheConfigurationorg.springframework.boot.autoconfigure.cache.CouchbaseCacheConfigurationorg.springframework.boot.autoconfigure.cache.RedisCacheConfigurationorg.springframework.boot.autoconfigure.cache.CaffeineCacheConfigurationorg.springframework.boot.autoconfigure.cache.GuavaCacheConfigurationorg.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration【默认】org.springframework.boot.autoconfigure.cache.NoOpCacheConfiguration 默认生效的配置类：SimpleCacheConfiguration。 123456789101112131415161718192021222324@Configuration@ConditionalOnMissingBean(CacheManager.class)@Conditional(CacheCondition.class)class SimpleCacheConfiguration &#123; private final CacheProperties cacheProperties; private final CacheManagerCustomizers customizerInvoker; SimpleCacheConfiguration(CacheProperties cacheProperties, CacheManagerCustomizers customizerInvoker) &#123; this.cacheProperties = cacheProperties; this.customizerInvoker = customizerInvoker; &#125; @Bean public ConcurrentMapCacheManager cacheManager() &#123; ConcurrentMapCacheManager cacheManager = new ConcurrentMapCacheManager(); List&lt;String&gt; cacheNames = this.cacheProperties.getCacheNames(); if (!cacheNames.isEmpty()) &#123; cacheManager.setCacheNames(cacheNames); &#125; return this.customizerInvoker.customize(cacheManager); &#125;&#125; 它主要作用是给容器中注入一个cacheManager(缓存管理器)，cacheManager是一个接口，提供了一个通过name获取一个缓存对象cache的API。 123456public interface CacheManager &#123; @Nullable Cache getCache(String name); Collection&lt;String&gt; getCacheNames();&#125; SimpleCacheConfiguration使用ConcurrentMapCacheManager实例化cacheManager。 123456789101112131415161718192021222324252627public class ConcurrentMapCacheManager implements CacheManager, BeanClassLoaderAware &#123; //使用ConcurrentMap做缓存集合 private final ConcurrentMap&lt;String, Cache&gt; cacheMap = new ConcurrentHashMap&lt;&gt;(16); @Override @Nullable public Cache getCache(String name) &#123; Cache cache = this.cacheMap.get(name); if (cache == null &amp;&amp; this.dynamic) &#123; synchronized (this.cacheMap) &#123; cache = this.cacheMap.get(name); if (cache == null) &#123; //判断无该缓存时初始化 cache = createConcurrentMapCache(name); this.cacheMap.put(name, cache); &#125; &#125; &#125; return cache; &#125; protected Cache createConcurrentMapCache(String name) &#123; SerializationDelegate actualSerialization = (isStoreByValue() ? this.serialization : null); return new ConcurrentMapCache(name, new ConcurrentHashMap&lt;&gt;(256), isAllowNullValues(), actualSerialization); &#125;&#125; 可以看到ConcurrentMapCacheManager使用了ConcurrentMapCache类型作为缓存组件。 1234public class ConcurrentMapCache extends AbstractValueAdaptingCache &#123; private final String name; private final ConcurrentMap&lt;Object, Object&gt; store; //存储缓存数据&#125; ConcurrentMapCacheManager可以获取和创建ConcurrentMapCache类型的缓存组件；他的作用将数据保存在ConcurrentMap中； @Cacheable 方法运行之前，先去查询Cache（缓存组件），按照cacheNames指定的名字获取；（CacheManager先获取相应的缓存），第一次获取缓存如果没有Cache组件会自动创建。 去Cache中查找缓存的内容，使用一个key，默认就是方法的参数； key是按照某种策略生成的；默认是使用keyGenerator生成的，默认使用SimpleKeyGenerator生成key； SimpleKeyGenerator生成key的默认策略； 如果没有参数；key=new SimpleKey()； 如果有一个参数：key=参数的值 如果有多个参数：key=new SimpleKey(params)； 没有查到缓存就调用目标方法； 将目标方法返回的结果，放进缓存中： 核心： 使用CacheManager【ConcurrentMapCacheManager】按照名字得到Cache【ConcurrentMapCache】组件 key使用keyGenerator生成的，默认是SimpleKeyGenerator. @Cacheable标注的方法执行之前先来检查缓存中有没有这个数据，默认按照参数的值作为key去查询缓存 如果没有就运行方法并将结果放入缓存；以后再来调用就可以直接使用缓存中的数据； @CachePut既调用方法，又更新缓存数据；同步更新缓存，修改了数据库的某个数据，同时更新缓存； 运行时机： 先调用目标方法 将目标方法的结果缓存起来 通过调度updateEmp修改员工信息，并指定key才能达到更新缓存的目的，否则无法更新对应的缓存信息。下例使用传入的参数的员工id：key = &quot;#employee.id&quot;或者返回后的id：key = &quot;#result.id&quot;当做key，更新缓存中相同key的Cache对象，达到执行更新语句时更新缓存数据目的。 注意：@Cacheable的key是不能用#result 123456@CachePut(value = \"emp\",key = \"#result.id\")public Employee updateEmp(Employee employee)&#123; System.out.println(\"updateEmp:\"+employee); employeeMapper.updateEmp(employee); return employee;&#125; @CacheEvict缓存清除注解： key：指定要清除的数据 allEntries = true时，将清除这个缓存中的所有数据。 beforeInvocation = false：缓存的清除是否在方法之前执行，默认代表缓存清除操作是在方法执行之后执行;如果出现异常缓存就不会清除 beforeInvocation = true：代表清除缓存操作是在方法运行之前执行，无论方法是否出现异常，缓存都清除 123456@CacheEvict(value=\"emp\",allEntries = true /*,key = \"#id\",*/)public void deleteEmp(Integer id)&#123; System.out.println(\"deleteEmp:\"+id); employeeMapper.deleteEmpById(id); int i = 10/0;&#125; @Caching12345678910111213//定义复杂的缓存规则@Caching( cacheable = &#123; @Cacheable(value=\"emp\",key = \"#lastName\") &#125;, put = &#123; @CachePut(value=\"emp\",key = \"#result.id\"), @CachePut(value=\"emp\",key = \"#result.email\") &#125;)public Employee getEmpByLastName(String lastName)&#123; return employeeMapper.getEmpByLastName(lastName);&#125; @CacheConfig123456789101112//抽取缓存的公共配置@CacheConfig(cacheNames=\"emp\") @Servicepublic class EmployeeService &#123; //不需要再写 value=\"emp\" @CachePut(key = \"#result.id\") public Employee updateEmp(Employee employee)&#123; System.out.println(\"updateEmp:\"+employee); employeeMapper.updateEmp(employee); return employee; &#125;&#125; 自定义KeyGenerator12345678910111213@Configurationpublic class MyCacheConfig &#123; @Bean(\"myKeyGenerator\") public KeyGenerator keyGenerator()&#123; return new KeyGenerator()&#123; @Override public Object generate(Object target, Method method, Object... params) &#123; return method.getName() + Arrays.asList(params).toString(); &#125; &#125;; &#125;&#125; 123456@Cacheable(value = &#123;\"emp\"&#125;, keyGenerator = \"myKeyGenerator\")public Employee getEmp(Integer id)&#123; System.out.println(\"查询\"+ id +\"号员工\"); Employee emp = employeeMapper.getEmpById(id); return emp;&#125; 缓存API12345678910// 使用缓存管理器得到缓存，进行api调用public Employee getEmpById(Integer id)&#123; Employee employee = employeeMapper.getEmpById(id); //获取某个缓存 Cache cache = empCacheManager.getCache(\"emp\"); dept.put(\"emp:1\",employee); return employee;&#125; RedisCache缓存配置类的初始化是有顺序的，当添加了Redis组件后，有一个RedisCacheConfiguration类，当找不到其他缓存配置类时，默认使用SimpleCacheConfiguration。 12345678910111213141516171819@Configuration@ConditionalOnClass(&#123;RedisConnectionFactory.class&#125;)@AutoConfigureAfter(&#123;RedisAutoConfiguration.class&#125;)@ConditionalOnBean(&#123;RedisConnectionFactory.class&#125;)@ConditionalOnMissingBean(&#123;CacheManager.class&#125;)@Conditional(&#123;CacheCondition.class&#125;)class RedisCacheConfiguration &#123; @Bean public RedisCacheManager cacheManager(RedisConnectionFactory redisConnectionFactory, ResourceLoader resourceLoader) &#123; RedisCacheManagerBuilder builder = RedisCacheManager.builder(redisConnectionFactory).cacheDefaults(this.determineConfiguration(resourceLoader.getClassLoader())); List&lt;String&gt; cacheNames = this.cacheProperties.getCacheNames(); if (!cacheNames.isEmpty()) &#123; builder.initialCacheNames(new LinkedHashSet(cacheNames)); &#125; return (RedisCacheManager)this.customizerInvoker.customize(builder.build()); &#125;&#125; 看到使用RedisCacheConfiguration时，默认创建RedisCacheManager作为缓存管理类，以RedisCache作为组件。 默认保存数据以key-value的形式存储到Redis,都是Object对象，利用序列化保存，默认创建的RedisCacheManager操作Redis使用的是RedisTemplate&lt;Object,Object&gt;对象，使用的是JDK序列化机制，正常情况下需要配置redisTemplate的序列化机制，达到以JSON的方式序列化对象。 12345678910111213141516171819202122232425262728293031323334353637@Configurationpublic class MyRedisConfig &#123; @Bean public RedisTemplate&lt;Object, Employee&gt; empRedisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Employee&gt; template = new RedisTemplate&lt;Object, Employee&gt;(); template.setConnectionFactory(redisConnectionFactory); FastJsonRedisSerializer&lt;Employee&gt; ser = new FastJsonRedisSerializer&lt;Employee&gt;(Employee.class); template.setDefaultSerializer(ser); return template; &#125; @Bean public RedisCacheManager employeeCacheManager(RedisConnectionFactory redisConnectionFactory) &#123; RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(RedisSerializer.string())) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new FastJsonRedisSerializer&lt;&gt;(Object.class))) .disableCachingNullValues(); return RedisCacheManager.builder( RedisCacheWriter.nonLockingRedisCacheWriter(redisConnectionFactory)).cacheDefaults(config).build(); &#125; @Override public KeyGenerator keyGenerator() &#123; return (target, method, params) -&gt; &#123; StringBuilder sb = new StringBuilder(); sb.append(target.getClass().getName()); sb.append(method.getName()); for (Object obj : params) &#123; sb.append(obj.toString()); &#125; return sb.toString(); &#125;; &#125;&#125; 当序列化的对象（Employee）里属性包含其他实体类（如Department）时，这时候缓存Employee对象时依旧能存储到redis中，但是无法反序列化回来。 原因是因为我们操作的是RedisTemplate&lt;Object, Employee&gt;对象，无法反序列化非Employee的对象，所以这个时候需要添加Department类的相关RedisCacheManager及RedisTemplate&lt;Object,Department&gt;。","categories":[{"name":"Cache","slug":"Cache","permalink":"https://midkuro.github.io/categories/Cache/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.github.io/tags/SpringBoot/"},{"name":"Cache","slug":"Cache","permalink":"https://midkuro.github.io/tags/Cache/"}]},{"title":"'Spring Boot Starter 启动配置原理'","slug":"springboot-starter","date":"2020-06-03T14:00:00.000Z","updated":"2020-09-15T11:29:57.435Z","comments":true,"path":"2020/06/03/springboot-starter/","link":"","permalink":"https://midkuro.github.io/2020/06/03/springboot-starter/","excerpt":"","text":"SpringBoot 启动配置原理启动配置原理12345public class SpringBootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootApplication.class, args); &#125;&#125; 点进启动类的run方法可以看到，在源码中先创建SpringApplication对象，然后在执行它的run方法。 1234567public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123; return run(new Class&lt;?&gt;[] &#123; primarySource &#125;, args);&#125;public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args);&#125; 创建SpringApplication对象1234567891011121314public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); //保存主配置类 this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); //判断当前是否一个web应用 this.webApplicationType = WebApplicationType.deduceFromClasspath(); //从类路径下找到META‐INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); //从类路径下找到ETA‐INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 运行run方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); //获取SpringApplicationRunListeners；从类路径下META‐INF/spring.factories SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的SpringApplicationRunListener.starting()方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); //准备环境 //创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //加载忽略Bean的配置信息 configureIgnoreBeanInfo(environment); //输出图标 Banner printedBanner = printBanner(environment); //创建IOC容器 ApplicationContext；决定创建web的ioc还是普通的ioc context = createApplicationContext(); //出异常时作报告用 exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); //准备上下文环境;将environment保存到ioc中； //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 //回调所有的SpringApplicationRunListener的contextPrepared()； //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat）； //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置） refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; //所有的SpringApplicationRunListener回调started方法 listeners.started(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调 //ApplicationRunner先回调，CommandLineRunner再回调 callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; //当IOC容器、environment初始化完成，run方法即将结束时回调listeners的running方法 listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; //整个SpringBoot应用启动完成以后返回启动的ioc容器； return context;&#125; 123456789101112131415161718192021222324252627282930313233private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; //准备上下文环境;将environment保存到ioc中； context.setEnvironment(environment); postProcessApplicationContext(context); //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 applyInitializers(context); //回调所有的SpringApplicationRunListener的contextPrepared()； listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton(\"springApplicationArguments\", applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton(\"springBootBanner\", printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, \"Sources must not be empty\"); load(context, sources.toArray(new Object[0])); //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； listeners.contextLoaded(context);&#125; 123456789protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument(initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, \"Unable to call initializer.\"); //回调之前保存的所有的ApplicationContextInitializer的initialize方法 initializer.initialize(context); &#125;&#125; 1234private SpringApplicationRunListeners getRunListeners(String[] args) &#123; Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123;SpringApplication.class, String[].class&#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args));&#125; 配置在META-INF/spring.factories： ApplicationContextInitializer 、SpringApplicationRunListener 只需要放在ioc容器中 ：ApplicationRunner 、CommandLineRunner 事件监听机制ApplicationContextInitializer 123456public class HelloApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println(\"ApplicationContextInitializer...initialize...\"+applicationContext); &#125;&#125; SpringApplicationRunListener 123456789101112131415161718192021222324252627282930313233public class HelloSpringApplicationRunListener implements SpringApplicationRunListener &#123; //必须有的构造器 public HelloSpringApplicationRunListener(SpringApplication application, String[] args)&#123; &#125; @Override public void starting() &#123; System.out.println(\"SpringApplicationRunListener...starting...\"); &#125; @Override public void environmentPrepared(ConfigurableEnvironment environment) &#123; Object o = environment.getSystemProperties().get(\"os.name\"); System.out.println(\"SpringApplicationRunListener...environmentPrepared..\"+o); &#125; @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; System.out.println(\"SpringApplicationRunListener...contextPrepared...\"); &#125; @Override public void contextLoaded(ConfigurableApplicationContext context) &#123; System.out.println(\"SpringApplicationRunListener...contextLoaded...\"); &#125; @Override public void started(ConfigurableApplicationContext context) &#123; System.out.println(\"SpringApplicationRunListener...started...\"); &#125;&#125; 配置（META-INF/spring.factories）\\表示换行，,表示分隔 123org.springframework.context.ApplicationContextInitializer=\\ com.springboot.listener.HelloApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=\\ com.springboot.listener.HelloSpringApplicationRunListener ApplicationRunner 1234567@Componentpublic class HelloApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println(\"ApplicationRunner...run....\"); &#125;&#125; CommandLineRunner 1234567@Componentpublic class HelloCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println(\"CommandLineRunner...run...\"+ Arrays.asList(args)); &#125;&#125; 123456789输出顺序：SpringApplicationRunListener...starting...SpringApplicationRunListener...environmentPrepared...ApplicationContextInitializer...initialize...SpringApplicationRunListener...contextPrepared...SpringApplicationRunListener...contextLoaded...ApplicationRunner...run....CommandLineRunner...run...SpringApplicationRunListener...started... 自定义starterSpringBoot starter机制SpringBoot中的starter是一种非常重要的机制，能够抛弃以前繁杂的配置，将其统一集成进starter，应用者只需要在maven中引入starter依赖，SpringBoot就能自动扫描到要加载的信息并启动相应的默认配置。 starter让我们摆脱了各种依赖库的处理，需要配置各种信息的困扰。SpringBoot会自动通过classpath路径下的类发现需要的Bean，并注册进IOC容器。 SpringBoot提供了针对日常企业应用研发各种场景的spring-boot-starter依赖模块。所有这些依赖模块都遵循着约定成俗的默认配置，并允许我们调整这些配置，即遵循“约定大于配置”的理念。 为什么要自定义starter在我们的日常开发工作中，经常会有一些独立于业务之外的配置模块，我们经常将其放到一个特定的包下，然后如果另一个工程需要复用这块功能的时候，需要将代码硬拷贝到另一个工程，重新集成一遍，麻烦至极。 如果我们将这些可独立于业务代码之外的功配置模块封装成一个个starter，复用的时候只需要将其在pom中引用依赖即可，SpringBoot为我们完成自动装配。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter中集成了spring全家桶的许多依赖支持，如下： 命名规范启动器（starter），启动器模块是一个空 JAR 文件，仅提供辅助性依赖管理，这些依赖可能用于自动装配或者其他类库。 一个完整的Spring Boot Starter可能包含以下组件： autoconfigure模块：包含自动配置的代码 starter模块：提供对autoconfigure模块的依赖，以及一些其它的依赖 如果你不需要区分这两个概念的话，也可以将自动配置代码模块与依赖管理模块合并成一个模块。 官方命名空间： – 前缀：“spring-boot-starter-” – 模式：spring-boot-starter-模块名 – 举例：spring-boot-starter-web、spring-boot-starter-actuator、spring-boot-starter-jdbc 推荐自定义命名空间： – 后缀：“-spring-boot-starter” – 模式：模块-spring-boot-starter – 举例：mybatis-spring-boot-starter 如何编写1234567@Configuration //指定这个类是一个配置类@ConditionalOnXXX //在指定条件成立的情况下自动配置类生效@AutoConfigureAfter //指定自动配置类的顺序@Bean //给容器中添加组件@ConfigurationPropertie //结合相关xxxProperties类来绑定相关的配置@EnableConfigurationProperties //让xxxProperties生效加入到容器中 123456自动配置类要能加载将需要启动就加载的自动配置类，配置在META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ 新建项目新建一个工程名midkuro-spring-boot-starter的maven空项目，只做pom.xml的依赖引入。 新建一个工程名midkuro-spring-boot-starter-autoconfigurer的Spring-boot项目 并修改其``midkuro-spring-boot-starter-autoconfigurer项目的pom.xml文件，引入spring-boot-starter`依赖 123456789101112131415161718192021222324252627282930&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;midkuro-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;maven-jar-plugin.version&gt;2.6&lt;/maven-jar-plugin.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 然后修改midkuro-spring-boot-starter的pom.xml，引入相关依赖： 123456789101112131415161718192021222324&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;midkuro-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;midkuro-spring-boot-starter&lt;/name&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;midkuro-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 定义配置类在midkuro-spring-boot-starter-autoconfigurer工程中增加配置类 12345678910111213141516171819202122232425package cn.midkuro.com.autoconfigurer;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = \"mtex.hello\")public class HelloProperties &#123; private String prefix; private String suffix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public String getSuffix() &#123; return suffix; &#125; public void setSuffix(String suffix) &#123; this.suffix = suffix; &#125;&#125; 123456789101112131415161718package cn.midkuro.com.autoconfigurer;public class HelloService &#123; private HelloProperties properties; public HelloProperties getProperties() &#123; return properties; &#125; public void setProperties(HelloProperties properties) &#123; this.properties = properties; &#125; public String sayHello(String name) &#123; return properties.getPrefix() + \"-\" + name + \"-\" + properties.getSuffix(); &#125;&#125; 123456789101112131415161718192021222324package cn.midkuro.com.autoconfigurer;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration@ConditionalOnWebApplication //只有在web环境中生效@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration &#123; @Autowired private HelloProperties properties; @Bean public HelloService helloService() &#123; HelloService helloService = new HelloService(); helloService.setProperties(properties); return helloService; &#125;&#125; 配置spring.factories想要xxxAutoConfiguration配置默认生效，需要在META-INF/spring.factories增加启动类相关配置 123# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\cn.midkuro.com.autoconfigurer.HelloServiceAutoConfiguration \\斜杠符号表示换行，多个类以,逗号分开，具体可以参考spring-boot-starter的配置文件： 123456789101112131415161718192021222324252627# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer# Auto Configuration Import Listenersorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnBeanCondition,\\org.springframework.boot.autoconfigure.condition.OnClassCondition,\\org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\... 测试新建工程名midkuro-spring-boot-starter-test的spring-boot项目，引入打包好的自定义starter依赖： 123456789101112131415161718192021222324252627282930313233343536373839&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.mastercom&lt;/groupId&gt; &lt;artifactId&gt;mtex-spring-boot-starter-test&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;maven-jar-plugin.version&gt;2.6&lt;/maven-jar-plugin.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;midkuro-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 新建测试Controller： 12345678910@RestControllerpublic class HelloController &#123; @Autowired private HelloService helloService; @GetMapping(\"/sayHello\") public void sayHello(String name) &#123; helloService.sayHello(name); &#125;&#125; 添加配置到application.properties中： 12mtex.hello.prefix=hellomtex.hello.suffix=world 运行启动类SpringBootStarterTestApplication： 1234567891011package cn.midkuro.com;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class SpringBootStarterTestApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootStarterTestApplication.class, args); &#125;&#125;","categories":[{"name":"Source","slug":"Source","permalink":"https://midkuro.github.io/categories/Source/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.github.io/tags/SpringBoot/"},{"name":"Source","slug":"Source","permalink":"https://midkuro.github.io/tags/Source/"}]},{"title":"'Spring Boot 数据访问&整合Druid监控'","slug":"springboot-druid","date":"2020-06-03T13:00:00.000Z","updated":"2020-06-03T14:04:31.150Z","comments":true,"path":"2020/06/03/springboot-druid/","link":"","permalink":"https://midkuro.github.io/2020/06/03/springboot-druid/","excerpt":"","text":"SpringBoot 数据访问简介对于数据访问层，无论是SQL还是NOSQL，Spring Boot默认采用整合Spring Data的方式进行统一处理，添加大量自动配置，屏蔽了很多设置。引入各种xxxTemplate，xxxRepository来简化我们对数据访问层的操作。对我们来说只需要进行简单的设置即可。 JDBC12345678910&lt;!--pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql‐connector‐java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 1234567#application.ymlspring: datasource: username: root password: 123456 url: jdbc:mysql://localhost:3306/jdbc driver‐class‐name: com.mysql.jdbc.Driver 12345678910111213141516@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringBoot06DataJdbcApplicationTests &#123; @Autowired DataSource dataSource; @Test public void contextLoads() throws SQLException &#123; //org.apache.tomcat.jdbc.pool.DataSource System.out.println(dataSource.getClass()); Connection connection = dataSource.getConnection(); System.out.println(connection); connection.close(); &#125;&#125; 在默认的情况下，使用org.apache.tomcat.jdbc.pool.DataSource作为数据源，数据源的所有配置都在DataSourceProperties中能找到。 自动配置原理： org.springframework.boot.autoconfifigure.jdbc： 1、参考DataSourceConfifiguration，根据配置创建数据源，默认使用Tomcat连接池；可以使用 spring.datasource.type指定自定义的数据源类型； 2、SpringBoot默认可以支持； 1org.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource 3、自定义数据源类型 12345678910/*** Generic DataSource configuration. */ @ConditionalOnMissingBean(DataSource.class) @ConditionalOnProperty(name = \"spring.datasource.type\") static class Generic &#123; @Bean public DataSource dataSource(DataSourceProperties properties) &#123; //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); &#125;&#125; 4、DataSourceInitializer：implement ApplicationListener 作用： runSchemaScripts(); 运行建表语句； runDataScripts(); 运行插入数据的sql语句； 默认只需要将文件命名为： 123456chema‐*.sql、data‐*.sql 默认规则：schema.sql，schema‐all.sql； 可以使用 schema: ‐ classpath:department.sql 指定位置 5、操作数据库：自动配置了JdbcTemplate操作数据库 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package org.springframework.boot.autoconfigure.jdbc;@Configuration@ConditionalOnClass(&#123; DataSource.class, JdbcTemplate.class &#125;)@ConditionalOnSingleCandidate(DataSource.class)@AutoConfigureAfter(DataSourceAutoConfiguration.class)@EnableConfigurationProperties(JdbcProperties.class)public class JdbcTemplateAutoConfiguration &#123; @Configuration static class JdbcTemplateConfiguration &#123; private final DataSource dataSource; private final JdbcProperties properties; JdbcTemplateConfiguration(DataSource dataSource, JdbcProperties properties) &#123; this.dataSource = dataSource; this.properties = properties; &#125; @Bean @Primary @ConditionalOnMissingBean(JdbcOperations.class) public JdbcTemplate jdbcTemplate() &#123; JdbcTemplate jdbcTemplate = new JdbcTemplate(this.dataSource); JdbcProperties.Template template = this.properties.getTemplate(); jdbcTemplate.setFetchSize(template.getFetchSize()); jdbcTemplate.setMaxRows(template.getMaxRows()); if (template.getQueryTimeout() != null) &#123; jdbcTemplate .setQueryTimeout((int) template.getQueryTimeout().getSeconds()); &#125; return jdbcTemplate; &#125; &#125; @Configuration @Import(JdbcTemplateConfiguration.class) static class NamedParameterJdbcTemplateConfiguration &#123; @Bean @Primary @ConditionalOnSingleCandidate(JdbcTemplate.class) @ConditionalOnMissingBean(NamedParameterJdbcOperations.class) public NamedParameterJdbcTemplate namedParameterJdbcTemplate( JdbcTemplate jdbcTemplate) &#123; return new NamedParameterJdbcTemplate(jdbcTemplate); &#125; &#125;&#125; 整合druid数据源123456&lt;!--pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627#application.ymlspring: datasource: username: root password: 123456 url: jdbc:mysql://localhost:3306/jdbc driver-class-name: com.mysql.jdbc.Driver #配置使用druid数据源 type: com.alibaba.druid.pool.DruidDataSource #druid数据源的相关配置 initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙 filters: stat,wall,log4j maxPoolPreparedStatementPerConnectionSize: 20 useGlobalDataSourceStat: true connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 默认情况下，druid的数据源的连接池等相关配置信息是不会被自动注入配置的，需要手动配置。 12345678910111213141516171819202122232425262728293031323334353637383940414243@Configurationpublic class DruidConfig &#123; //通过前缀相同，将属性注入到druidDataSource中 @ConfigurationProperties(prefix = \"spring.datasource\") @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), \"/druid/*\"); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"loginUsername\",\"admin\"); initParams.put(\"loginPassword\",\"123456\"); initParams.put(\"allow\",\"\");//默认就是允许所有访问 initParams.put(\"deny\",\"192.168.15.21\"); //禁止该IP访问 bean.setInitParameters(initParams); return bean; &#125; //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); //设置不拦截掉静态资源、druid请求 Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"exclusions\",\"*.js,*.css,/druid/*\"); bean.setInitParameters(initParams); //设置过滤器拦截所有请求 bean.setUrlPatterns(Arrays.asList(\"/*\")); return bean; &#125;&#125;","categories":[{"name":"Druid","slug":"Druid","permalink":"https://midkuro.github.io/categories/Druid/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.github.io/tags/SpringBoot/"},{"name":"Druid","slug":"Druid","permalink":"https://midkuro.github.io/tags/Druid/"}]},{"title":"'NIO New IO/Non-Blocking IO'","slug":"java-nio","date":"2020-05-28T03:00:00.000Z","updated":"2020-05-28T12:14:20.435Z","comments":true,"path":"2020/05/28/java-nio/","link":"","permalink":"https://midkuro.github.io/2020/05/28/java-nio/","excerpt":"","text":"NIONIO的简介Java NIO（New IO）是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲区的、基于通道的IO操作。NIO将以更加高效的方式进行文件的读写操作。 与IO的区别 IO NIO 面向流(Stream Oriented) 面向缓冲区(Buffer Oriented) 阻塞IO(Blocking IO) 非阻塞IO(Non Blocking IO) (无) 选择器(Selectors) 传统IO是通过建立管道，把数据以流的方式发送，类似于生活中的水流，并且是单向传输。 而NIO是通过创建一条通道，文件传输的对端通过把文件内容存储在缓冲区中，发送到另一端后，另一端从缓冲区中读取内容，通道类似于生活中的火车轨道，它不具备存储功能，它只负责传输，而缓冲区则负责存储。 通道和缓冲区Java NIO系统的核心在于：通道(Channel)和缓冲区(Buffer)。通道表示打开到 IO 设备(例如：文件、套接字)的连接。若需要使用 NIO 系统，需要获取用于连接 IO 设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。 简而言之，Channel 负责传输，Buffer 负责存储。 缓冲区缓冲区（Buffer）：在 Java NIO 中负责数据的存取。缓冲区就是数组。用于存储不同数据类型的数据。 缓冲区（Buffer）：一个用于特定基本数据类型的容器。由 java.nio 包定义的，所有缓冲区都是 Buffer 抽象类的子类。Java NIO 中的 Buffer 主要用于与NIO 通道进行交互，数据是从通道读入缓冲区，从缓冲区写入通道中的。 Buffer 就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean 除外) ，有以下 Buffer 常用子类：ByteBuffer、CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。 上述 Buffer 类 他们都采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。都是通过如下方法获取一个 Buffer对象： 123456//创建一个容量为 capacity 的 ByteBuffer 对象方法 public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity);&#125; 属性Buffer 中的重要概念： 容量 (capacity) ：表示 Buffer 最大数据容量，缓冲区容量不能为负，并且创建后不能更改。 限制 (limit)：第一个不应该读取或写入的数据的索引，即位于limit 后的数据不可读写。缓冲区的限制不能为负，并且不能大于其容量。 位置 (position)：下一个要读取或写入的数据的索引。缓冲区的位置不能为负，并且不能大于其限制 标记 (mark)与重置 (reset)：标记是一个索引，通过 Buffer 中的mark() 方法指定 Buffer 中一个特定的 position，之后可以通过调用 reset()方法恢复到这个 position。 标记、位置、限制、容量遵守以下不变式： 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity。 方法 描述 Buffer clear() 清空缓冲区并返回对缓冲区的引用 Buffer flip() 将缓冲区的界限设置为当前位置，并将当前位置重置为 0 int capacity() 返回 Buffer 的 capacity 大小 boolean hasRemaining() 判断缓冲区中是否还有元素 int limit() 返回 Buffer 的界限(limit) 的位置 Buffer limit(int n) 将设置缓冲区界限为 n, 并返回 Buffer mark() 对缓冲区设置标记 int position() 返回缓冲区的当前位置 position Buffer position(int n) 将设置缓冲区的当前位置为 n , 并返回修改后的 Buffer 对象 int remaining() 返回 position 和 limit 之间的元素个数 Buffer reset() 将位置 position 转到以前设置的 mark 所在的位置 Buffer rewind() 将位置设为 0， 取消设置的 mark Buffer 所有子类提供了两个用于数据操作的方法：get() 与 put() 方法 获取 Buffer 中的数据 get() ：读取单个字节 get(byte[] dst)：批量读取多个字节到 dst 中 get(int index)：读取指定索引位置的字节(不会移动 position) 放入数据到 Buffer 中 put(byte b)：将给定单个字节写入缓冲区的当前位置 put(byte[] src)：将 src 中的字节写入缓冲区的当前位置 put(int index, byte b)：将指定字节写入缓冲区的索引位置(不会移动 position) 案例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Testpublic void test1() &#123; String str = \"abcde\"; //1. 分配一个指定大小的缓冲区 ByteBuffer buf = ByteBuffer.allocate(1024); System.out.println(\"-----------------allocate()----------------\"); System.out.println(buf.position());//0 System.out.println(buf.limit());//1024 System.out.println(buf.capacity());//1024 //2. 利用 put() 存入数据到缓冲区中 buf.put(str.getBytes()); System.out.println(\"-----------------put()----------------\"); System.out.println(buf.position());//5 System.out.println(buf.limit());//1024 System.out.println(buf.capacity());//1024 //3. 切换读取数据模式 buf.flip(); System.out.println(\"-----------------flip()----------------\"); System.out.println(buf.position());//0 System.out.println(buf.limit());//5 System.out.println(buf.capacity());//1024 //4. 利用 get() 读取缓冲区中的数据 byte[] dst = new byte[buf.limit()]; buf.get(dst); System.out.println(new String(dst, 0, dst.length));//abcde System.out.println(\"-----------------get()----------------\"); System.out.println(buf.position()); //5 System.out.println(buf.limit());//5 System.out.println(buf.capacity());//1024 //5. rewind() : 可重复读 buf.rewind(); System.out.println(\"-----------------rewind()----------------\"); System.out.println(buf.position());//0 System.out.println(buf.limit());//5 System.out.println(buf.capacity());//1024 //6. clear() : 清空缓冲区. 但是缓冲区中的数据依然存在，但是处于“被遗忘”状态 buf.clear(); System.out.println(\"-----------------clear()----------------\"); System.out.println(buf.position());//0 System.out.println(buf.limit());//1024 System.out.println(buf.capacity());//1024 System.out.println((char)buf.get());//a&#125; 123456789101112131415161718192021222324252627282930@Testpublic void test2()&#123; String str = \"abcde\"; ByteBuffer buf = ByteBuffer.allocate(1024); buf.put(str.getBytes()); buf.flip(); byte[] dst = new byte[buf.limit()]; buf.get(dst, 0, 2); System.out.println(new String(dst, 0, 2));//ab System.out.println(buf.position());//2 //mark() : 标记 buf.mark(); buf.get(dst, 2, 2); System.out.println(new String(dst, 2, 2));//cd System.out.println(buf.position());4 //reset() : 恢复到 mark 的位置 buf.reset(); System.out.println(buf.position());//2 //判断缓冲区中是否还有剩余数据 if(buf.hasRemaining())&#123; //获取缓冲区中可以操作的数量 System.out.println(buf.remaining());//3 &#125;&#125; 字节缓冲区字节缓冲区（ByteBuffer）比较特殊，它能够创建两种类型的缓冲区，分别是直接缓冲区和非直接缓冲区。直接缓冲区通过API的allocateDirect（）方法创建，而非直接缓冲区则是平时使用的allocate()方法。 非直接缓冲区 正常情况下，应用程序都是在操作系统上的用户地址空间，俗称用户空间，我们的IO请求都是需要先经过用户空间，用户空间向内核空间发起IO请求，内核空间去物理磁盘加载数据，然后内核空间将加载后的数据拷贝到用户空间，用户空间才将数据返回给应用程序，也就是说，非直接缓冲区都需要经过一次数据从内核空间拷贝到用户空间的一个过程。 直接缓冲区 当使用直接缓冲区时， Java 虚拟机会尽最大努力直接在此缓冲区上执行本机IO 操作。也就是说，在每次调用基础操作系统的一个本机 I/O 操作之前（或之后），虚拟机都会尽量避免将缓冲区的内容复制到中间缓冲区中（或从中间缓冲区中复制内容）。 直接字节缓冲区可以通过调用此类的allocateDirect()工厂方法来创建。此方法返回的缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不明显。 直接缓冲区有一个很严重的劣势，就是当应用程序把数据存放到直接缓冲区时，它什么时候向物理磁盘触发IO操作是无法控制被应用程序控制的，它是由操作系统掌控的。 并且响应结果到应用程序的效率不固定，很有可能出现磁盘IO操作已经完成，但是应用程序尚未得到回应，导致内存数据无法被释放，当大规模的并发产生时，它带来的影响是致命的，但是不可否认的是，即时它短时间内未响应，效率也依旧比非直接缓冲区快！ 所以，建议将直接缓冲区主要分配给那些易受基础系统的本机 I/O 操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处时分配它们。 直接字节缓冲区还可以通过 FileChannel的map()方法将文件区域直接映射到内存中来创建。该方法返回MappedByteBuffer 。 如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或稍后的某个时间导致抛出不确定的异常。 123456@Testpublic void test3() &#123; //分配直接缓冲区 ByteBuffer buf = ByteBuffer.allocateDirect(1024); System.out.println(buf.isDirect()); //true&#125; 判断字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其 isDirect() 方法来确定。提供此方法是为了能够在性能关键型代码中执行显式缓冲区管理。 1234567891011121314151617181920212223//使用直接缓冲区完成文件的复制(内存映射文件)@Testpublic void test4() throws IOException&#123; long start = System.currentTimeMillis(); FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"2.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE); //内存映射文件 MappedByteBuffer inMappedBuf = inChannel.map(MapMode.READ_ONLY, 0, inChannel.size()); MappedByteBuffer outMappedBuf = outChannel.map(MapMode.READ_WRITE, 0, inChannel.size()); //直接对缓冲区进行数据的读写操作 byte[] dst = new byte[inMappedBuf.limit()]; inMappedBuf.get(dst); outMappedBuf.put(dst); inChannel.close(); outChannel.close(); long end = System.currentTimeMillis(); System.out.println(\"耗费时间为：\" + (end - start));&#125; 通道通道（Channel）：由 java.nio.channels 包定义的。Channel 表示 IO 源与目标打开的连接。 Channel 类似于传统的 流。只不过 Channel 本身不能直接访问数据，Channel 只能与Buffer 进行交互。 在以前，内核空间请求物理磁盘都需要通过请求CPU提供的IO接口才能访问，由于这样导致CPU阻塞，利用率降低，所以分发了一块机器内存专门处理IO接口，传统IO流通过访问IO接口，并由DMA（直接存储器）向CPU申请权限许可，当许可获得后，就可以将IO操作授权给DMA全权处理，而不需要占用CPU的处理时间，大大提高了CPU的利用率。 当有大量的应用程序向操作系统发起IO请求时，会造成创建多个DMA数据总线，当DMA总线过多时，会造成总线冲突的问题。因为它们都会向CPU申请权限许可，最终也会影响CPU的性能。 通道Channel附属于CPU中央处理器，是一个完全独立的处理器，有一套自身定义的命令和传输方式，专门用于IO操作，无需像CPU获得权限许可，和CPU彻底断绝关系，通道本质上和IO流没什么区别，只是在大型IO请求时，通道相较原来的IO流，CPU的利用率会更高。 实现类： Java 为 Channel 接口提供的最主要实现类如下： FileChannel：用于读取、写入、映射和操作文件的通道。 DatagramChannel：通过 UDP 读写网络中的数据通道。 SocketChannel：通过 TCP 读写网络中的数据。 ServerSocketChannel：可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个SocketChannel。 获取通道： 获取通道的一种方式是对支持通道的对象调用getChannel()方法。支持通道的类如下： FileInputStream FileOutputStream RandomAccessFile DatagramSocket Socket ServerSocket 获取通道的其他方式是使用 Files 类的静态方法 newByteChannel() 获取字节通道。或者通过通道的静态方法 open()打开并返回指定通道。 123456public static FileChannel open(Path path, OpenOption... options) throws IOException &#123; Set&lt;OpenOption&gt; set = new HashSet&lt;OpenOption&gt;(options.length); Collections.addAll(set, options); return open(path, set, NO_ATTRIBUTES);&#125; 其中可变参数OpenOption是指对文件的操作权限，具体可参考StandardOpenOption.class。 StandardOpenOption.READ 只读模式 StandardOpenOption.WRITE 写模式 StandardOpenOption.CREATE 文件不存在则创建，存在则覆盖 StandardOpenOption.CREATE_NEW 文件不存在则创建，存在则报错 FileChannel的常用方法： 方法 描述 int read(ByteBuffer dst) 从 Channel 中读取数据到 ByteBuffer long read(ByteBuffer[] dsts) 将 Channel 中的数据“分散”到 ByteBuffer[] int write(ByteBuffer src) 将 ByteBuffer 中的数据写入到 Channel long write(ByteBuffer[] srcs) 将 ByteBuffer[]中的数据“聚集”到 Channel long position() 返回此通道的文件位置 FileChannel position(long p) 设置此通道的文件位置 long size() 返回此通道的文件的当前大小 FileChannel truncate(long s) 将此通道的文件截取为给定大小 void force(boolean metaData) 强制将所有对此通道的文件更新写入到存储设备中 数据传输通道之间的传输可以通过write()、read()接口，如下： 1234//将Buffer 中数据写入Channelint bytesWritten = outChannel.write(buf);//从 Channel 读取数据到 Bufferint bytesRead = inChannel.read(buf); 也可以使用更简便的 transferFrom()、transferTo()接口，通过直接缓冲区实现，如下： 1234//将数据从源通道(inChannel)传输到outChannel中inChannel.transferTo(0, inChannel.size(), outChannel);//与上同义outChannel.transferFrom(inChannel, 0, inChannel.size()); 案例： 123456789101112131415161718192021222324252627//利用通道完成文件的复制（非直接缓冲区）@Testpublic void test1() throws Exception &#123; long start = System.currentTimeMillis(); FileInputStream fis = new FileInputStream(\"1.jpg\"); FileOutputStream fos = new FileOutputStream(\"2.jpg\"); //1、获取通道 FileChannel inChannel = fis.getChannel(); FileChannel outChannel = fos.getChannel(); //2、分配指定大小的缓冲区 ByteBuffer buf = ByteBuffer.allocate(1024); //3、将通道中的数据存入缓冲区中 while(inChannel.read(buf) != -1)&#123; buf.flip(); //切换读取数据的模式 //4、将缓冲区中的数据写入通道中 outChannel.write(buf); buf.clear(); //清空缓冲区 &#125; outChannel.close(); inChannel.close(); fos.close(); fis.close(); long end = System.currentTimeMillis(); System.out.println(\"耗费时间为：\" + (end - start));&#125; 12345678910111213//通道之间的数据传输(直接缓冲区)@Testpublic void test3() throws IOException&#123; FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"2.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE); //inChannel.transferTo(0, inChannel.size(), outChannel); outChannel.transferFrom(inChannel, 0, inChannel.size()); inChannel.close(); outChannel.close();&#125; 分散和聚集分散读取（Scattering Reads）是指从 Channel中读取的数据分散到多个 Buffer 中，按照缓冲区的顺序，从 Channel 中读取的数据依次将 Buffer 填满。 聚集写入（Gathering Writes）是指将多个 Buffer 中的数据聚集到 Channel，按照缓冲区的顺序，写入 position 和 limit 之间的数据到 Channel 。 123456789101112131415161718192021222324252627282930//分散和聚集 @Test public void test4() throws IOException&#123; RandomAccessFile raf1 = new RandomAccessFile(\"1.txt\", \"rw\"); //1. 获取通道 FileChannel channel1 = raf1.getChannel(); //2. 分配指定大小的缓冲区 ByteBuffer buf1 = ByteBuffer.allocate(100); ByteBuffer buf2 = ByteBuffer.allocate(1024); //3. 分散读取 ByteBuffer[] bufs = &#123;buf1, buf2&#125;; channel1.read(bufs); for (ByteBuffer byteBuffer : bufs) &#123; byteBuffer.flip(); &#125; System.out.println(new String(bufs[0].array(), 0, bufs[0].limit())); System.out.println(\"-----------------\"); System.out.println(new String(bufs[1].array(), 0, bufs[1].limit())); //4. 聚集写入 RandomAccessFile raf2 = new RandomAccessFile(\"2.txt\", \"rw\"); FileChannel channel2 = raf2.getChannel(); channel2.write(bufs); &#125; 字符集Charset用来处理字符串和字节数组相互转换的编码问题。 1234567891011@Testpublic void test5() &#123; Map&lt;String, Charset&gt; map = Charset.availableCharsets(); Set&lt;Entry&lt;String, Charset&gt;&gt; set = map.entrySet(); //输出所有支持的字符集编码格式 for (Entry&lt;String, Charset&gt; entry : set) &#123; System.out.println(entry.getKey() + \"=\" + entry.getValue()); &#125;&#125; 用什么编码格式转义的，就需要用什么编码格式反转义。 1234567891011121314@Testpublic void test6() throws IOException &#123; Charset cs1 = Charset.forName(\"GBK\"); CharBuffer cBuf = CharBuffer.allocate(1024); cBuf.put(\"测试测试！\"); cBuf.flip(); // 编码 ByteBuffer bBuf = cs1.encode(cBuf); // 解码 bBuf.flip(); CharBuffer cBuf2 = cs1.decode(bBuf); System.out.println(cBuf2.toString());&#125; 阻塞传统的 IO 流都是阻塞式的。也就是说，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务。因此，在完成网络通信进行 IO 操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量客户端时，性能急剧下降。 当客户端向服务端起请求时，服务端调度accept()创建Socket链接，客户端发送的数据首先会先到达内核空间，这时候的服务端需要等待内核空间完全接收完数据，数据准备完成后，将数据从内核空间拷贝到用户空间。 内核空间并不知道客户端数据是否发送完毕，或者是否有新数据发送，所以只能一直等待着客户端的响应，而在内核空间等待的这段时间中，服务端一直处于阻塞状态，它在等待着内核空间将数据拷贝到用户空间。 1234567891011121314151617181920212223242526272829//阻塞客户端@Testpublic void client() throws IOException&#123; SocketChannel sChannel = SocketChannel.open(new InetSocketAddress(\"127.0.0.1\", 9898)); FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ); ByteBuffer buf = ByteBuffer.allocate(1024); while(inChannel.read(buf) != -1)&#123; buf.flip(); sChannel.write(buf); buf.clear(); &#125; //告诉服务端已经传送完毕 //如果不加这段代码，服务端将一直阻塞，而客户端也一直阻塞等待服务端的反馈 sChannel.shutdownOutput(); //接收服务端的反馈 int len = 0; while((len = sChannel.read(buf)) != -1)&#123; buf.flip(); System.out.println(new String(buf.array(), 0, len)); buf.clear(); &#125; inChannel.close(); sChannel.close();&#125; 12345678910111213141516171819202122232425262728//服务端@Testpublic void server() throws IOException&#123; ServerSocketChannel ssChannel = ServerSocketChannel.open(); FileChannel outChannel = FileChannel.open(Paths.get(\"2.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.CREATE); ssChannel.bind(new InetSocketAddress(9898)); SocketChannel sChannel = ssChannel.accept(); ByteBuffer buf = ByteBuffer.allocate(1024); while(sChannel.read(buf) != -1)&#123; buf.flip(); outChannel.write(buf); buf.clear(); &#125; //发送反馈给客户端 buf.put(\"服务端接收数据成功\".getBytes()); buf.flip(); sChannel.write(buf); sChannel.close(); outChannel.close(); ssChannel.close();&#125; 非阻塞Java NIO 是非阻塞模式的。当线程从某通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞 IO 的空闲时间用于在其他通道上执行 IO 操作，所以单独的线程可以管理多个输入和输出通道。因此，NIO 可以让服务器端使用一个或有限几个线程来同时处理连接到服务器端的所有客户端。 当用户线程发起一个read操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。 客户端的所有通道都将注册到Selector选择器上，选择器将监控通道上的IO状况，当通道上的数据准备就绪后，选择器才会将这个任务分配到服务端一个或者多个线程上运行。 选择器选择器（Selector） 是 SelectableChannle 对象的多路复用器，Selector 可以同时监控多个 SelectableChannel 的 IO 状况，也就是说，利用 Selector可使一个单独的线程管理多个 Channel，Selector 是非阻塞 IO 的核心。 12//通过调用 Selector.open() 方法创建一个 Selector。Selector selector = Selector.open(); 1234567891011121314//1. 获取通道ServerSocketChannel ssChannel = ServerSocketChannel.open();//2. 切换非阻塞模式ssChannel.configureBlocking(false);//3. 绑定连接ssChannel.bind(new InetSocketAddress(9898));//4. 获取选择器Selector selector = Selector.open();//5. 将通道注册到选择器上, 并且指定“监听接收事件”ssChannel.register(selector, SelectionKey.OP_ACCEPT); 当调度上面的第五步的regitster接口将通道注册选择器时，选择器对通道的监听事件，需要通过第二个参数 ops 指定。 可以监听的事件类型（可使用 SelectionKey 的四个常量表示）： 读 : SelectionKey.OP_READ （1） 写 : SelectionKey.OP_WRITE （4） 连接 : SelectionKey.OP_CONNECT （8） 接收 : SelectionKey.OP_ACCEPT （16） 若注册时不止监听一个事件，则可以使用“位或”操作符连接。 1int ops = SelectionKey.OP_READ | SelectionKey.OP_WRITE; SelectionKey：表示 SelectableChannel 和 Selector 之间的注册关系。每次向选择器注册通道时就会选择一个事件(选择键)。选择键包含两个表示为整数值的操作集。操作集的每一位都表示该键的通道所支持的一类可选择操作。 Selector 常用方法： 方法 描述 Set keys() 所有的 SelectionKey 集合。代表注册在该Selector上的Channel selectedKeys() 被选择的 SelectionKey 集合。返回此Selector的已选择键集 int select() 监控所有注册的Channel，当它们中间有需要处理的 IO 操作时，该方法返回，并将对应得的 SelectionKey 加入被选择的SelectionKey 集合中，该方法返回这些 Channel 的数量。 int select(long timeout) 可以设置超时时长的 select() 操作 int selectNow() 执行一个立即返回的 select() 操作，该方法不会阻塞线程 Selector wakeup() 使一个还未返回的 select() 方法立即返回 void close() 关闭该选择器 SelectionKey 常用方法： 方法 描述 int interestOps() 获取感兴趣事件集合 int readyOps() 获取通道已经准备就绪的操作的集合 SelectableChannel channel() 获取注册通道 Selector selector() 返回选择器 boolean isReadable() 检测 Channal 中读事件是否就绪 boolean isWritable() 检测 Channal 中写事件是否就绪 boolean isConnectable() 检测 Channel 中连接是否就绪 boolean isAcceptable() 检测 Channel 中接收是否就绪 案例： 1234567891011121314151617181920212223242526//客户端@Testpublic void client() throws IOException&#123; //1. 获取通道 SocketChannel sChannel = SocketChannel.open(new InetSocketAddress(\"127.0.0.1\", 9898)); //2. 切换非阻塞模式 sChannel.configureBlocking(false); //3. 分配指定大小的缓冲区 ByteBuffer buf = ByteBuffer.allocate(1024); //4. 发送数据给服务端 Scanner scan = new Scanner(System.in); while(scan.hasNext())&#123; String str = scan.next(); buf.put((new Date().toString() + \"\\n\" + str).getBytes()); buf.flip(); sChannel.write(buf); buf.clear(); &#125; //5. 关闭通道 sChannel.close();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//服务端@Testpublic void server() throws IOException&#123; //1. 获取通道 ServerSocketChannel ssChannel = ServerSocketChannel.open(); //2. 切换非阻塞模式 ssChannel.configureBlocking(false); //3. 绑定连接 ssChannel.bind(new InetSocketAddress(9898)); //4. 获取选择器 Selector selector = Selector.open(); //5. 将通道注册到选择器上, 并且指定“监听接收事件” ssChannel.register(selector, SelectionKey.OP_ACCEPT); //6. 轮询式的获取选择器上已经“准备就绪”的事件 while(selector.select() &gt; 0)&#123; //7. 获取当前选择器中所有注册的“选择键(已就绪的监听事件)” Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator(); while(it.hasNext())&#123; //8. 获取准备“就绪”的是事件 SelectionKey sk = it.next(); //9. 判断具体是什么事件准备就绪 if(sk.isAcceptable())&#123; //10. 若“接收就绪”，获取客户端连接 SocketChannel sChannel = ssChannel.accept(); //11. 切换非阻塞模式 sChannel.configureBlocking(false); //12. 将该通道注册到选择器上 sChannel.register(selector, SelectionKey.OP_READ); &#125;else if(sk.isReadable())&#123; //13. 获取当前选择器上“读就绪”状态的通道 SocketChannel sChannel = (SocketChannel) sk.channel(); //14. 读取数据 ByteBuffer buf = ByteBuffer.allocate(1024); int len = 0; while((len = sChannel.read(buf)) &gt; 0 )&#123; buf.flip(); System.out.println(new String(buf.array(), 0, len)); buf.clear(); &#125; &#125; //15. 取消选择键 SelectionKey it.remove(); &#125; &#125;&#125; 管道Java NIO 管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取。 123456789101112131415161718192021222324@Testpublic void test1() throws IOException&#123; //1. 获取管道 Pipe pipe = Pipe.open(); //---------------线程A[start]---------------- //2. 将缓冲区中的数据写入管道 ByteBuffer buf = ByteBuffer.allocate(1024); Pipe.SinkChannel sinkChannel = pipe.sink(); buf.put(\"通过单向管道发送数据\".getBytes()); buf.flip(); sinkChannel.write(buf); //---------------线程A[end]------------------ //---------------线程B[start]---------------- //3. 读取缓冲区中的数据 Pipe.SourceChannel sourceChannel = pipe.source(); buf.flip(); int len = sourceChannel.read(buf); System.out.println(new String(buf.array(), 0, len)); //---------------线程B[end]------------------ sourceChannel.close(); sinkChannel.close();&#125;","categories":[{"name":"NIO","slug":"NIO","permalink":"https://midkuro.github.io/categories/NIO/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"NIO","slug":"NIO","permalink":"https://midkuro.github.io/tags/NIO/"}]},{"title":"'Redis（四） Spring Boot 整合 Redis'","slug":"springboot-redis","date":"2020-05-27T12:00:00.000Z","updated":"2020-06-05T15:38:33.195Z","comments":true,"path":"2020/05/27/springboot-redis/","link":"","permalink":"https://midkuro.github.io/2020/05/27/springboot-redis/","excerpt":"","text":"Spring Boot 整合 RedisRedis配置文件12345&lt;!-- pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; Redis的配置文件集中在RedisProperties中，配置文件中以spring.redis前缀开头。 以下列出一些常用配置： 1234567891011121314151617181920212223242526272829@ConfigurationProperties(prefix = \"spring.redis\")public class RedisProperties &#123; private int database = 0; //使用的数据库下标 private String host = \"localhost\"; private String password; private int port = 6379; private boolean ssl; private Duration timeout; //超时时间 private RedisProperties.Sentinel sentinel; //哨兵模式 private RedisProperties.Cluster cluster; //集群模式 public static class Sentinel &#123; private String master; private List&lt;String&gt; nodes; &#125; public static class Cluster &#123; private List&lt;String&gt; nodes; private Integer maxRedirects; &#125; public static class Pool &#123; private int maxIdle = 8; private int minIdle = 0; private int maxActive = 8; private Duration maxWait = Duration.ofMillis(-1L); private Duration timeBetweenEvictionRuns; &#125;&#125; 1234#application.propertiesspring.redis.host= localhostspring.redis.port=6379spring.redis.password= 自动配置123456789101112131415161718192021222324@Configuration@ConditionalOnClass(RedisOperations.class)@EnableConfigurationProperties(RedisProperties.class)@Import(&#123; LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class &#125;)public class RedisAutoConfiguration &#123; @Bean @ConditionalOnMissingBean(name = \"redisTemplate\") public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; &#125; @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; &#125;&#125; 可以看到RedisAutoConfiguration默认创建两个Bean，其中创建了一个主要以String类型操作的stringRedisTemplate，也就是说可以直接通过注解使用这些Bean。 RedisAutoConfiguration初始化两个Bean时使用了@ConditionalOnMissingBean注解，如果我们想要自己实现初始化Bean，只需要自行编写个配置类注入Bean组件即可。 序列化redisTemplate如果保存的是对象时，默认使用JdkSerializationRedisSerializer类作为序列化机制，将对象序列化后的数据（非明文）存储到redis数据库中。Redis规定序列化机制的实现类需要实现RedisSerializer接口。 123456789101112131415public interface RedisSerializer&lt;T&gt; &#123; @Nullable static RedisSerializer&lt;Object&gt; java(@Nullable ClassLoader classLoader) &#123; return new JdkSerializationRedisSerializer(classLoader); &#125; static RedisSerializer&lt;Object&gt; json() &#123; return new GenericJackson2JsonRedisSerializer(); &#125; static RedisSerializer&lt;String&gt; string() &#123; return StringRedisSerializer.UTF_8; &#125;&#125; 在不配置的情况下，默认JDK序列化机制，普遍情况下，我们习惯把对象以String或者JSON的结构存储到Redis，这时候需要手动配置序列化机制，而只要我们引入了相关的依赖包，如FastJson，就能够找到对应的序列化器FastJsonRedisSerializer。 12345678910111213141516@Configurationpublic class MyRedisConfig &#123; //手动配置redisTemplate @Bean public RedisTemplate&lt;Object, Object&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;Object, Object&gt;(); template.setConnectionFactory(redisConnectionFactory); FastJsonRedisSerializer&lt;Object&gt; ser = new FastJsonRedisSerializer&lt;Object&gt;(Object.class); //设置默认序列化器，对所有的key-value类型都生效 template.setDefaultSerializer(ser); return template; &#125;&#125; 测试1234567891011121314151617181920212223242526272829303132333435363738394041@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringbootApplicationTests &#123; @Autowired EmployeeMapper employeeMapper; @Autowired StringRedisTemplate stringRedisTemplate; //操作k-v都是字符串的 @Autowired RedisTemplate redisTemplate; //k-v都是对象的 /** * Redis常见的五大数据类型 * String（字符串）、List（列表）、Set（集合）、Hash（散列）、ZSet（有序集合） * stringRedisTemplate.opsForValue()[String（字符串）] * stringRedisTemplate.opsForList()[List（列表）] * stringRedisTemplate.opsForSet()[Set（集合）] * stringRedisTemplate.opsForHash()[Hash（散列）] * stringRedisTemplate.opsForZSet()[ZSet（有序集合）] */ @Test public void test01()&#123; //给redis中保存数据 stringRedisTemplate.opsForValue().append(\"msg\",\"hello\"); String msg = stringRedisTemplate.opsForValue().get(\"msg\"); System.out.println(msg); stringRedisTemplate.opsForList().leftPush(\"mylist\",\"1\"); stringRedisTemplate.opsForList().leftPush(\"mylist\",\"2\"); &#125; //测试保存对象 @Test public void test02()&#123; Employee emp = new Employee(\"张三\",\"男\"); //默认如果保存对象，使用jdk序列化机制，序列化后的数据保存到redis中 //配置redisTemplate的序列化机制，将对象数据以JSON的方式保存 redisTemplate.opsForValue().set(\"emp-01\",emp); &#125;","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/tags/Redis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.github.io/tags/SpringBoot/"}]},{"title":"'Redis（三） 集群'","slug":"redis-cluster","date":"2020-05-26T03:00:00.000Z","updated":"2020-05-26T12:21:33.001Z","comments":true,"path":"2020/05/26/redis-cluster/","link":"","permalink":"https://midkuro.github.io/2020/05/26/redis-cluster/","excerpt":"","text":"Redis集群Redis复制(Master/Slave)Redis的复制，也就是我们所说的主从复制，主机数据更新后根据配置和策略，自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主的策略。主要用来读写分离和容灾恢复。 配从(库)不配主(库)，配置主从复制，只需要把从库指向一个主库，实现对主库的复制即可，不需要主库做任何操作。 可以通过命令配置达到效果，但是每次与master断开之后，都需要重新执行命令连接，除非配置进redis.conf文件 1slaveof 主库IP 主库端口 建议配置时拷贝多个redis.conf文件，通过redis-server启动时指定启动的配置文件即可。配置文件需要修改相应的配置： 开启守护线程后台运行 修改PID文件名称 修改指定端口 修改Log文件名称 修改dump.rdb名称 12#redis.conf配置slaveof &lt;masterip&gt; &lt;masterport&gt; 一主二仆 可以看到从库（6380端口）配置了主库（6379端口）后，能够看到他的role标识为slave。 可以看到主库的role标识为master，其中connected_slaves连接的salve是1个。 当有多个slave时，他们配置的master都是同一个，即所有salve都直接和master进行数据同步策略。 薪火相传上一个slave可以是下一个slave的master，slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中下一个的master,可以有效减轻master的写压力。 就好比如slave1（6380端口）配置了主库master（6379），然后salve2（6381端口）配置了slave1做master，那么当6379端口的主库修改了数据时，会先同步到slave1，然后再由slave1同步到slave2。 中途变更转向:会清除之前的数据，重新建立拷贝最新的。 反客为主当主库master故障时，从库slave是不会自动上位成master，将依旧保持slave从库，这并不是我们想要的结果，可以通过手动将从库转换成主库，并修改其他从库的master配置，使当前数据库停止与其他数据库的同步，转成主数据库 1SLAVEOF no one 复制原理slave启动成功连接到master后会发送一个sync命令,master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步。 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制：master继续将新的所有收集到的修改命令依次传给slave,完成增量同步。 但是只要是重新连接master,一次完全同步（全量复制)将被自动执行 哨兵模式哨兵模式是反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库 通过创建sentinel.conf配置文件，并新增监控机器的配置，一组sentinel能同时监控多个Master。 12345# sentinel monitor 自定义的名称 127.0.0.1 6379 1#上面最后一个数字1，表示主机挂掉后salve投票看让谁接替成为主机，得票数多的成为主机sentinel monitor host6379 127.0.0.1 6379 1sentinel monitor host6380 127.0.0.1 6380 1sentinel monitor host6381 127.0.0.1 6381 1 1234#linux系统执行命令redis-sentinel sentinel.conf#window系统执行命令redis-server.exe sentinel.conf --sentinel 通过执行启动哨兵，当master节点挂了后，哨兵模式会自动从salve中投票选举出新的master，原来的master节点重新加入时，将会变成salve节点。哨兵模式最低限度能够达到仅剩一台slave时，将之升级为master，即支持当master机器没有slave节点时，依旧能够正常工作。 由于所有的写操作都是先在master上操作，然后同步更新到slave上，所以从master同步到slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave机器数量的增加也会使这个问题更加严重。 Redis-Cluster自从redis 3.0版本开始支持redis-cluster集群，redis-cluster采用无中心结构，每个节点保存数据和整个集群的状态，每个节点都和其他所有节点连接。 无需proxy代理，客户端直接与redis集群的每个节点连接，根据同样的hash算法计算出key对应的slot，然后直接在slot对应的redis节点上执行命令。 在redis看来，响应时间是最苛刻的条件，增加一层带来的开销是redis不能接受的。因此，redis实现了客户端对节点的直接访问，为了去中心化，节点之间通过gossip协议交换互相的状态，以及探测新加入的节点信息。redis集群支持动态加入节点，动态迁移slot，以及自动故障转移。 数据分片redis 集群使用数据分片（sharding）而非一致性哈希（consistency hashing）来实现，Redis Cluster 采用的是虚拟槽分区算法，这个槽是用来存放缓存信息的单位，一个redis 集群包含 16384 个哈希槽（hash slot），槽的范围是 0 -16383，数据库中的每个键都属于这 16384 个哈希槽的其中一个。 集群使用公式 CRC16(key) % 16384 来计算键key属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。集群中的每个节点负责处理一部分哈希槽。 举个例子， 一个集群可以有三个节点， 其中： 节点 A 负责处理 0 号至 5500 号哈希槽。 节点 B 负责处理 5501 号至 11000 号哈希槽。 节点 C 负责处理 11001 号至 16383 号哈希槽。 此时 Redis Client 需要根据一个Key获取对应的 Value 的数据，首先通过 CRC16(key)%16384 计算出 Slot 的值，假设计算的结果是 5000，将这个数据传送给 Redis Cluster，集群接收到以后会到一个对照表中查找这个 Slot=5000 属于那个缓存节点。发现属于“节点 A ”负责，于是顺着红线的方向调用节点 A中存放的 Key-Value 的内容并且返回给 Redis Client。 这种将哈希槽分布到不同节点的做法使得用户可以很容易地向集群中添加或者删除节点。 比如说： 如果用户将新节点 D 添加到集群中， 那么集群只需要将节点 A 、B 、 C 中的某些槽移动到节点 D 就可以了。 如果用户要从集群中移除节点 A ， 那么集群只需要将节点 A 中的所有哈希槽移动到节点 B 和节点 C ， 然后再移除空白（不包含任何哈希槽）的节点 A 就可以了。 因为将一个哈希槽从一个节点移动到另一个节点不会造成节点阻塞，且成本很低， 所以无论是添加新节点还是移除已存在节点， 又或者改变某个节点包含的哈希槽数量， 都不会造成集群下线。 数据访问客户端在初始化的时候只需要知道一个节点的地址即可，客户端会先尝试向这个节点执行命令，比如“get key”，如果key所在的slot刚好在该节点上，则能够直接执行成功。如果slot不在该节点，则节点会返回MOVED错误，同时把该slot对应的节点告诉客户端。客户端可以去该节点执行命令。 集群支持hash tags功能，即可以把一类key定位到同一个slot，tag的标识目前不支持配置，只能使用{}，redis处理hash tag的逻辑也很简单，redis只计算从第一次出现{，到第一次出现}的substring的hash值，substring为空，则仍然计算整个key的值，这样对于foo{}{bar}、{foo}{bar}、foo这些冲突的{}，也能取出tag值。 123456127.0.0.1:6379&gt; CLUSTER KEYSLOT foo&#123;hash_tag&#125;(integer) 2515127.0.0.1:6379&gt; CLUSTER KEYSLOT fooadfasdf&#123;hash_tag&#125;(integer) 2515127.0.0.1:6379&gt; CLUSTER KEYSLOT fooaaasdf&#123;hash_tag&#125;(integer) 2515 我们都知道，redis单机支持mutl-key操作（mget、mset）。redis cluster对mutl-key命令的支持，只能支持多key都在同一个slot上，即使多个slot在同一个节点上也不行。通过hash tag可以很好的做到这一点。 数据结构Redis Cluster中的每个节点都保存了集群的配置信息，并且存储在clusterState中，结构如下： 上图的各个变量语义如下: clusterState 记录了从集群中某个节点视角，来看集群配置状态； currentEpoch 表示整个集群中最大的版本号，集群信息每变更一次，改版本号都会自增。 nodes 是一个列表，包含了本节点所感知的，集群所有节点的信息（clusterNode），也包含自身的信息。 clusterNode 记录了每个节点的信息，其中包含了节点本身的版本 Epoch；自身的信息描述：节点对应的数据分片范围（slot）、为master时的slave列表、为slave时的master等。 每个节点包含一个全局唯一的NodeId。 当集群的数据分片信息发生变更（数据在节点间迁移时），Redis Cluster仍然保持对外服务。 当集群中某个master出现宕机时，Redis Cluster 会自动发现，并触发故障转移的操作。会将master的某个slave晋升为新的 master。 由此可见，每个节点都保存着Node视角的集群结构。它描述了数据的分片方式，节点主备关系，并通过Epoch作为版本号实现集群结构信息的一致性，同时也控制着数据迁移和故障转移的过程。 节点通信在Redis Cluster中，这个配置信息交互通过Redis Cluster Bus来完成（独立端口）。Redis Cluster Bus上交互的信息结构如下： clusterMsg 中的type指明了消息的类型，配置信息的一致性主要依靠PING/PONG。每个节点向其他节点频繁的周期性的发送PING/PONG消息。对于消息体中的Gossip部分，包含了sender/receiver 所感知的其他节点信息，接受者根据这些Gossip 跟新对集群的认识。 对于大规模的集群，如果每次PING/PONG 都携带着所有节点的信息，则网络开销会很大。此时Redis Cluster 在每次PING/PONG，只包含了随机的一部分节点信息。由于交互比较频繁，短时间的几次交互之后，集群的状态也会达成一致。 一致性当Cluster 结构不发生变化时，各个节点通过gossip 协议在几轮交互之后，便可以得知Cluster的结构信息，达到一致性的状态。但是当集群结构发生变化时（故障转移/分片迁移等），优先得知变更的节点通过Epoch变量，将自己的最新信息扩散到Cluster，并最终达到一致。 clusterNode 的Epoch描述的单个节点的信息版本；clusterState 的currentEpoch 描述的是集群信息的版本，它可以辅助Epoch 的自增生成。因为currentEpoch 是维护在每个节点上的，在集群结构发生变更时，Cluster 在一定的时间窗口控制更新规则，来保证每个节点的currentEpoch都是最新的。更新规则如下： 当某个节点率先知道了变更时，将自身的currentEpoch 自增，并使之成为集群中的最大值。再用自增后的currentEpoch 作为新的Epoch 版本； 当某个节点收到了比自己大的currentEpoch时，更新自己的currentEpoch； 当收到的Redis Cluster Bus 消息中的某个节点的Epoch &gt; 自身的时，将更新自身的内容； 当Redis Cluster Bus 消息中，包含了自己没有的节点时，将其加入到自身的配置中。 上述的规则保证了信息的更新都是单向的，最终朝着Epoch更大的信息收敛。同时Epoch也随着currentEpoch的增加而增加，最终将各节点信息趋于稳定。 为了使得集群在一部分节点下线或者无法与集群的大多数（majority）节点进行通讯的情况下， 仍然可以正常运作， Redis 集群对节点使用了主从复制功能： 集群中的每个节点都有 1 个至 N 个复制品（replica）， 其中一个复制品为主节点（master）， 而其余的 N-1 个复制品为从节点（slave）。 集群间节点支持主从关系，复制的逻辑基本复用了单机版的实现。不过还是有些地方需要注意。 首先集群间节点建立主从关系不再使用原有的SLAVEOF命令和SLAVEOF配置，而是通过cluster replicate命令，这保证了主从节点需要先完成握手，才能建立主从关系。 集群是不能组成链式主从关系的，也就是说从节点不能有自己的从节点。不过对于集群外的没开启集群功能的节点，redis并不干预这些节点去复制集群内的节点，但是在集群故障转移时，这些集群外的节点，集群不会处理。 集群内节点想要复制另一个节点，需要保证本节点不再负责任何slot，不然redis也是不允许的。 集群内的从节点在与其他节点通信的时候，传递的消息中数据分布表和epoch是master的值。 集群主节点出现故障，发生故障转移，其他主节点会把故障主节点的从节点自动提为主节点，原来的主节点恢复后，自动成为新主节点的从节点。 这里先说明，把一个master和它的全部slave描述为一个group，故障转移是以group为单位的，集群故障转移的方式跟sentinel的实现很类似。 均衡集群在集群运行过程中，有的master的slave宕机，导致了该master成为孤儿master（orphaned masters），而有的master有很多slave。 此处孤儿master的定义是那些本来有slave，但是全部离线的master，对于那些原来就没有slave的master不能认为是孤儿master。 redis集群支持均衡slave功能，官方称为Replica migration，而我觉得均衡集群的slave更好理解该概念。集群能把某个slave较多的group上的slave迁移到那些孤儿master上，该功能通过cluster-migration-barrier参数配置，默认为1。 slave在每次定时任务都会检查是否需要迁移slave，即把自己变成孤儿master的slave。 满足以下条件，slave就会成为孤儿master的slave： 自己所在的group是slave最多的group。 目前存在孤儿master。 自己所在的group的slave数目至少超过2个，只有自己一个的话迁移到其他group，自己原来的group的master又成了孤儿master。 自己所在的group的slave数量大于cluster-migration-barrier配置。 与group内的其他slave基于memcmp比较node id，自己的node id最小。这个可以防止多个slave并发复制孤儿master，从而原来的group失去过多的slave。 优势 去中心化，集群最大可增加1000个节点，性能随节点增加而线性扩展。 解耦 数据 和 节点 之间的关系，简化了节点 扩容 和 收缩 难度。 节点自身 维护槽的 映射关系，不需要 客户端 或者 代理服务 维护 槽分区元数据。 劣势 key 批量操作 支持有限。类似 mset、mget 操作，目前只支持对具有相同 slot 值的key 执行 批量操作。对于 映射为不同 slot 值的key 由于执行 mget、mget 等操作可能存在于多个节点上，因此不被支持。 只支持 多 key 在 同一节点上 的 事务操作，当多个 key 分布在 不同 的节点上时 无法 使用事务功能。 key 作为 数据分区 的最小粒度，不能将一个 大的键值 对象如 hash、list 等映射到 不同的节点。 不支持多数据库空间，单机下的Redis可以支持 16 个数据库（db0 ~ db15），集群模式下只能使用一个 数据库空间，即 db0。 复制结构 只支持一层，从节点 只能复制 主节点，不支持 嵌套树状复制 结构。 集群搭建1234567891011121314151617181920212223#redis.conf相关集群配置#配置为cluster模式cluster-enabled yes#集群节点配置信息，包括nodeid，集群信息。此文件非常关键，要确保故障转移或者重启的时候此文件还在，所以如果在docker环境下要外挂到外部存储cluster-config-file nodes-6379.conf#节点连接超时，如果集群规模小，都在同一个网络环境下，可以配置的短些，更快的做故障转移cluster-node-timeout 2000#慢查询日志，用于性能分析，生产环境可设置为1000（毫秒）slowlog-log-slower-than 1000#保存慢查询的队列长度 ，设置为1000slowlog-max-len 1000#设置为0，默认为10如果master slave都挂掉，slave跟master失联又超过这个数值*timeout的数值，就不会发起选举了。#如果设置为0，就是永远都会尝试发起选举，尝试从slave变为matercluster-slave-validity-factor 10#设置为no，默认为yes，故障发现到自动完成转移期间整个集群是不可用状态，对于大多数业务无法容忍这种情况#因此要设置为no，当主节点故障时只影 响它负责槽的相关命令执行，不会影响其他主节点的可用性cluster-require-full-coverage yes 123456789101112131415161718192021222324252627#分别修改不同的redis.conf，注意，不同的redis.conf分开文件夹#端口分别为6301~6306port 6301#dir ./ 修改成每个conf的路径dir /usr/local/redis1#cluster-enabled yes 开启集群模式cluster-enabled yes#打开配置集群结点信息文件(6301~6306)cluster-config-file nodes-6301.conf#打开结点超时配置cluster-node-timeout 15000# 持久化配置appendonly yes#修改`PID`文件名称pidfile /var/run/redis-6301.pid#修改`Log`文件名称logfile redis-6301.log#修改`dump.rdb`名称dbfilename dump-6301.rdb 12#--cluster-replicas 1表示给每个master分配一个slave，系统会自动分配master和salveredis-cli --cluster create --cluster-replicas 1 127.0.0.1:6301 127.0.0.1:6302 127.0.0.1:6303 127.0.0.1:6304 127.0.0.1:6305 127.0.0.1:6306 1234567#查看集群状态redis-cli -p 6301 cluster info#查看集群节点状态redis-cli -p 6301 cluster nodes#使用redis-cli连接到集群，指定-c参数redis-cli -p 6001 -c 当访问的slot在当前机器时，直接返回，当数据在其他master管理的slot中时，会自动重定位到负责该slot的master机器 可以看到当我把6303端口的master停止后，6304端口的slave上位成master。 当我重启6303端口的redis时，6303端口的redis自动成为6304端口master的salve。 部分内容出自文章： https://blog.csdn.net/wuxian90/article/details/81590252 https://www.cnblogs.com/pingyeaa/p/11294773.html https://www.jianshu.com/p/84dbb25cc8dc https://nealli.gitee.io/2020/05/21/Redis%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://midkuro.github.io/tags/NoSql/"}]},{"title":"'Redis（二） Hash算法'","slug":"redis-hash","date":"2020-05-26T02:00:00.000Z","updated":"2020-07-09T09:01:17.256Z","comments":true,"path":"2020/05/26/redis-hash/","link":"","permalink":"https://midkuro.github.io/2020/05/26/redis-hash/","excerpt":"","text":"Redis算法数据分布算法普通Hash算法比如你有 N 个 redis实例，那么如何将一个key映射到redis上呢，你很可能会采用类似下面的通用方法计算 key的 hash 值，然后均匀的映射到到 N 个 redis上： hash(key)%N 如果增加一个redis，映射公式变成了 hash(key)%(N+1) 如果一个redis宕机了，映射公式变成了 hash(key)%(N-1) 在这两种情况下，每一个redis管理的数据全部要重新计算移动，几乎所有的缓存都失效了。会导致数据库访问的压力陡增，严重情况，还可能导致数据库宕机。 一致性Hash算法 将内存想象成一个环，由于hash值有32位，因此将内存分出2 ^32（0~2 ^32-1）个地址 将节点的IP+算法确定唯一的哈希值，之后在内存中确定节点的位置 当保存数据时，根据key进行哈希运算，确定唯一的一个位置 根据当前key位置顺时针查找最近的node节点进行挂载（在内存中，加法计算快于减法运算，因此采用顺时针查找） 将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。 假设将中四台服务器使用ip地址哈希后在环空间的位置如下： 将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。 假设4个存储对象 Object A、B、C、D，经过对 Key 的哈希计算后，它们的位置如下： 根据一致性哈希算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。 容错性和可扩展性假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。 如果在系统中增加一台服务器Node X，如下图所示： 此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。 综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 虚拟节点但一致性哈希算法也有一个严重的问题，就是数据倾斜。如果在分片的集群中，节点太少，并且分布不均，一致性哈希算法就会出现部分节点数据太多，部分节点数据太少。也就是说无法控制节点存储数据的分配。如下图，大部分数据都在 A 上了，B 的数据比较少。 节点数越少，越容易出现节点在哈希环上的分布不均匀，导致各节点映射的对象数量严重不均衡(数据倾斜)；相反，节点数越多越密集，数据在哈希环上的分布就越均匀。 以删除节点为例，假设删除了Node B节点，原来Node B节点的数据将转移到Node C上，这样Node C的内存使用率会骤增，如果Node B上存在热点数据，Node C会扛不住甚至会可能挂掉，挂掉之后数据又转移给Node D,如此循环会造成所有节点崩溃，也就是缓存雪崩。 为了解决雪崩现象和数据倾斜现象，提出了虚拟节点这个概念。就是将真实节点计算多个哈希形成多个虚拟节点并放置到哈希环上，定位算法不变，只是多了一步虚拟节点到真实节点映射的过程 但实际部署的物理节点有限，我们可以用有限的物理节点，虚拟出足够多的虚拟节点(Virtual Node)，最终达到数据在哈希环上均匀分布的效果。 如下图，实际只部署了2个节点 Node A/B，每个节点都复制成3倍，结果看上去是部署了6个节点。可以想象，当复制倍数为 2^32 时，就达到绝对的均匀，通常可取复制倍数为32或更高。 这就解决了雪崩的问题，当某个节点宕机后，其数据并没有全部分配给某一个节点，而是被分到了多个节点，数据倾斜的问题也随之解决。 哈希槽redis 集群（cluster）并没有选用上面一致性哈希，而是采用了哈希槽（slot）的这种概念。主要的原因就是上面所说的，一致性哈希算法对于数据分布、节点位置的控制并不是很友好。 首先哈希槽其实是两个概念，第一个是哈希算法。redis cluster 的 hash 算法不是简单的hash()，而是 crc16 算法，一种校验算法。另外一个就是槽位的概念，空间分配的规则。 其实哈希槽的本质和一致性哈希算法非常相似，不同点就是对于哈希空间的定义。一致性哈希的空间是一个圆环，节点分布是基于圆环的，无法很好的控制数据分布。而 redis cluster 的槽位空间是自定义分配的，类似于 windows 盘分区的概念。这种分区是可以自定义大小，自定义位置的。 redis cluster 包含了16384个哈希槽，每个 key 通过计算后都会落在具体一个槽位上，而这个槽位是属于哪个存储节点的，则由用户自己定义分配。例如机器硬盘小的，可以分配少一点槽位，硬盘大的可以分配多一点。如果节点硬盘都差不多则可以平均分配。所以哈希槽这种概念很好地解决了一致性哈希的弊端。 另外在容错性和扩展性上，表象与一致性哈希一样，都是对受影响的数据进行转移。而哈希槽本质上是对槽位的转移，把故障节点负责的槽位转移到其他正常的节点上。扩展节点也是一样，把其他节点上的槽位转移到新的节点上。 缓存缓存穿透key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。 解决办法： 一个一定不存在缓存及查询不到的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。 最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 另外也有一个更为简单的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 缓存击穿key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 业界比较常用的做法是使用互斥锁(mutex key)，简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作，比如Redis的SETNX（SET if Not eXists），去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 缓存雪崩当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。 大多数系统设计者考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。 锁排队的解决方式分布式环境的并发问题，有可能还要解决分布式锁的问题；线程还会被阻塞，用户体验很差！因此，在真正的高并发场景下很少使用！ 还有一个简单方案就是将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 部分内容出自文章： https://blog.csdn.net/qq_42695926/java/article/details/83090131 https://www.cnblogs.com/lihonglin2016/p/10039670.html https://blog.csdn.net/kefengwang/java/article/details/81628977 https://www.cnblogs.com/xichji/p/11286443.html","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://midkuro.github.io/tags/NoSql/"}]},{"title":"'Redis（一） NoSql 之 Redis'","slug":"redis-nosql","date":"2020-05-23T02:00:00.000Z","updated":"2020-06-11T09:24:21.535Z","comments":true,"path":"2020/05/23/redis-nosql/","link":"","permalink":"https://midkuro.github.io/2020/05/23/redis-nosql/","excerpt":"","text":"NoSql之RedisNoSQLNoSQL（Not Only SQL），不仅仅是SQL，泛指非关系型的数据库，随着互联网web2.0网站的兴起，传统的关系型数据库在应付web2.0网站，特别是超大规模和高并发地SNS类型的web2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，尤其是大数据应用难题，包括超大规模数据的存储。 这些类型的数据存储不需要固定的模式，无需多余操作就可以横向扩展。 ACID关系型数据库遵循ACID规则事务在英文中是transaction，和现实世界中的交易很类似，它有如下四个特性： 1、A (Atomicity) 原子性原子性很容易理解，也就是说事务里的所有操作要么全部做完，要么都不做，事务成功的条件是事务里的所有操作都成功，只要有一个操作失败，整个事务就失败，需要回滚。 2、C (Consistency) 一致性一致性也比较容易理解，也就是说数据库要一直处于一致的状态，事务的运行不会改变数据库原本的一致性约束。 3、I (Isolation) 独立性所谓的独立性是指并发的事务之间不会互相影响，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响。 4、D (Durability) 持久性持久性是指一旦事务提交后，它所做的修改将会永久的保存在数据库上，即使出现宕机也不会丢失。 CAP在分布式数据库中的CAP原理： 1、C (Consistency) 强一致性 2、A (Availability) 可用性 3、P (Partition tolerance) 分区容错性 CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。 因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三 大类： CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。 CP - 满足一致性，分区容忍必的系统，通常性能不是特别高。 AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。 分布式和集群的简介： 分布式：不同的多台服务器上面部署不同的服务模块（工程），他们之间通过Rpc/Rmi之间通信和调用，对外提供服务和组内协作。 集群：不同的多台服务器上面部署相同的服务模块，通过分布式调度软件进行统一的调度，对外提供服务和访问。 Redisredis采用单进程模型来处理客户端的请求、对读写等事件的响应。 默认16个数据库，类似数组下表从零开始，初始默认使用零号库 默认端口6379 索引都是从零开始 常见命令文档 客户端访问redis-cli -h host -p port -a password 命令 描述 SELECT 切换数据库 Dbsize 查看当前数据库的key的数量 Flushdb 清空当前库 Flushall 通杀全部库 五大数据类型Stringstring是redis最基本的类型，可以理解成与Memcached一模一样的类型，一个key对应一个value。 string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。 string类型是redis最基本的数据类型，一个redis中字符串value最多可以是512M。 HashHash（哈希） 是一个键值对集合，以string类型的field和value的映射表，hash特别适合用于存储对象。类似Java里面的Map&lt;String,Object&gt;。 ListList（列表） 是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。它的底层实际是个链表。 SetSet（集合）是string类型的无序集合。它是通过HashTable实现实现的。 zsetzset(sorted set：有序集合)和set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。 常用命令Redis 键(Key) Redis 字符串(String) 案例： getrange：获取指定区间范围内的值，类似between......and的关系，从零到负一表示全部 setrange设置指定区间范围内的值，格式是setrange key值 具体值 setex:设置带过期时间的key和value，原子操作结合,动态设置。 setnx:只有在 key 不存在时设置 key 的值。 mset:同时设置一个或多个 key-value 对。 Redis 列表(List) 案例： lpop/rpop：从列表左端/右端移除第一个元素并返回 lindex：通过索引获取列表中的元素 lindex key index lrem：从left往right删除2个值等于v1的元素，返回的值为实际删除的数量，LREM list3 0 value，表示删除全部给定的值。零个就是全部值 ltrim：截取指定索引区间的元素，格式是ltrim list的key 起始索引 结束索引 rpoplpush：移除列表的最后一个元素，并将该元素添加到另一个列表并返回 linsert：在list某个已有值的前/后再添加具体值 性能总结它是一个字符串链表，left、right都可以插入添加；如果键不存在，创建新的链表；如果键已存在，新增内容；如果值全移除，对应的键也就消失了。链表的操作无论是头和尾效率都极高，但假如是对中间元素进行操作，效率就很惨淡了。 Redis 集合(Set) 案例： scard：获取集合里面的元素个数 serm key value ：删除集合中元素 srandmember：从set集合里面随机取出2个，如果超过最大数量就全部取出，如果写的值是负数，比如-3 ，表示需要取出3个，但是可能会有重复值。 spop key：随机出栈 sdiff：在第一个set里而不在后面任何一个set里的项 sinter：取交集 sunion：取并集 Redis 哈希(Hash) Hash十分常用的命令有hset/hget/hmset/hmget/hgetall/hdel/hkeys/hvals Redis 有序集合(Zset)在set基础上，加一个score值。之前set是k1 v1 v2 v3，现在zset是k1 score1 v1 score2 v2。 zadd/zrange： zrangebyscore：zrangebyscore key 开始sorce 结束sorce ，withscores表示携带分数，(表示不包含，limit 用户限制返回数量 limit 开始下标 数量 zrem：删除元素，格式是zrem zset的key 项的值，项的值可以是多个 zcard ：获取集合中元素个数 zcount ：获取分数区间内元素个数，zcount key 开始分数区间 结束分数区间 zrank： 获取value在zset中的下标位置 zscore：按照值获得对应的分数 zrevrank key values：正序、逆序获得下标索引值 zrevrange：按照分数反序输出 zrevrangebyscore：zrevrangebyscore key 结束score 开始score 配置文件redis的配置文件在redis的安装目录下，在linux环境下，配置文件命名是redis.conf，在windows系统下是redis.window.conf Units单位12345678910111213#`redis`在配置文件的开头定义了一些基本的度量单位，并且不区分大小写。# Redis configuration file example# Note on units: when memory size is needed, it is possible to specify# it in the usual form of 1k 5GB 4M and so forth:## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive so 1GB 1Gb 1gB are all the same. GENERAL通用12345678910111213141516171819202122232425262728293031323334353637383940#Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程daemonize no#当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定pidfile /var/run/redis.pid#指定Redis监听端口，默认端口为6379port 6379#绑定redis对外提供的IP地址bind 127.0.0.1#设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。#在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。tcp-backlog 511#当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能timeout 300#单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60tcp-keepalive 0#指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，生产上一般选择为noticeloglevel notice#日志记录方式，默认为标准输出#如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/nulllogfile redis.log#是否把日志输出到syslog中sys-enabled no#指定syslog里的日志标志syslog-ident redis#设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库iddatabases 16#设置当本机为slave服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步slaveof &lt;masterip&gt; &lt;masterport&gt; SHAPSHOTTING快照1234567891011121314151617181920212223242526272829# Save the DB on disk:# save &lt;seconds&gt; &lt;changes&gt;#触发RDB持久化的三种策略#指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合#当900秒内出现一次key的变化save 900 1#当300秒内出现10次key的变化save 300 10#当60秒内出现10000次key的变化save 60 10000#如果想禁用RDB持久化的策略，只要不设置任何save指令，或者给save传入一个空字符串参数也可以#save \"\"#如果配置成no，表示你不在乎数据不一致或者有其他的手段发现和控制stop-writes-on-bgsave-error yes#对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。#如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能rdbcompression yes#在存储快照后，还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗#如果希望获取到最大的性能提升，可以关闭此功能rdbchecksum yes#指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb#指定本地数据库存放目录dir ./ SECURITY安全12345#当master服务设置了密码保护时，slav服务连接master的密码masterauth &lt;master-password&gt; #设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭requirepass foobared LIMITS限制12345678910111213141516#设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数#如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxclients 128 #指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，移除规则可以通过maxmemory-policy来指定。#当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区maxmemory &lt;bytes&gt;#六种移除数据的策略：#volatile-lru：使用LRU算法移除key，只对设置了过期时间的键#allkeys-lru：使用LRU算法移除key#volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键#allkeys-random：移除随机的key#volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key#noeviction：不进行移除。针对写操作，只是返回错误信息Maxmemory-policy noeviction APPEND ONLY MODE追加12345678910111213141516171819#指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。#因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为noappendonly no#指定更新日志文件名，默认为appendonly.aofappendfilename appendonly.aof#指定更新日志条件，共有3个可选值： #no：表示等操作系统进行数据缓存同步到磁盘（快） #always：表示每次更新操作后手动调用fsync()将数据写到磁盘（性能差，完整性好） #everysec：表示每秒同步一次（折衷，默认值）appendfsync everysec#重写时是否可以运用Appendfsync，用默认no即可，保证数据安全性。no-appendfsync-on-rewrite no#当文件大小是上次重写后大小的一倍且文件大于64M时触发重写auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 其他配置1234567891011121314151617181920212223242526272829303132#指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中vm-enabled no #虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享vm-swap-file /tmp/redis.swap #将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys)#当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0vm-max-memory 0 #Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的#建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值vm-page-size 32 #设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。vm-pages 134217728 #设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4vm-max-threads 4 #设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启glueoutputbuf yes #指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法hash-max-zipmap-entries 64hash-max-zipmap-value 512 #指定是否激活重置哈希，默认为开启activerehashing yes #3指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件include /path/to/local.conf Redis持久化Redis支持两种数据的持久化方式，分别是RDB和AOF，并且支持两种方式共存。 RDB（Redis DataBase）Redis的RDB持久化策略是指在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里。 Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。 RDB的缺点是最后一次持久化后的数据可能丢失。 Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。 保存RDB持久化默认保存的是dump.rdb文件，路径于Redis的安装目录一致，通过save或bgsave命令配置触发规则。 1234567#redis.conf配置文件的三种策略，关闭则配置 save \"\"#当900秒内出现一次key的变化save 900 1#当300秒内出现10次key的变化save 300 10#当60秒内出现10000次key的变化save 60 10000 使用save命令时只管保存，其他命令均阻塞，使用bgsave时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。可以通过lastsave命令获取最后一次成功执行快照的时间。 执行flushall命令，会马上产生dump.rdb文件，但里面是空的，无意义。 恢复可以通过定时备份dump.rdb文件到其他目录，当redis故障时，将备份文件 dump.rdb 移动到 Redis 安装目录并启动服务即可。 优势适合大规模的数据恢复，对数据完整性和一致性要求不高的数据。 劣势RDB是在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改，而且Fork子进程备份时，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑。 可以通过动态配置停止RDB保存规则的方法：redis-cli config set save &quot;&quot; 总结 RDB是一个非常紧凑的文件 RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程，接下来的工作全部由子进程来做，父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能 与AOF相比，在恢复大的数据集的时候，RDB方式会更快一些 数据丢失风险大 RDB需要经常fork子进程来保存数据到硬盘上，当数据集比较大的时候，fork的过程是非常耗时的，可能会导致redis在一些毫秒级别不能响应客户端请求 AOF(Append Only File)AOF持久化策略是以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据。 换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 保存AOF持久化默认保存的是appendonly.aof文件，路径于Redis的安装目录一致，需要通过配置才能开启AOF持久化 12#redis.conf中的AOF持久化开关appendonly yes 恢复当appendonly.aof文件无损时，直接将该文件拷贝到redis的安装目录下，重启redis即可完成恢复。 当appendonly.aof文件受损时，可以在redis的安装目录下执行redis-check-aof --fix appendonly.aof进行文件修复，然后重启redis进行恢复。 AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制,当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。 AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，遍历新进程的内存中数据，每条记录有一条的Set语句。重写AOF文件的操作，并没有读取旧的AOF文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的AOF文件，这点和快照有点类似。 Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次重写后大小的一倍且文件大于64M时触发。 1234#redis.conf配置文件#可以配置重写的百分比及文件大小auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 优势数据丢失率降低，最多丢失1秒内的数据。 12345#指定更新日志条件，共有3个可选值： #no：表示等操作系统进行数据缓存同步到磁盘（快） #always：同步持久化，每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好 #everysec：异步操作，每秒记录一次，如果一秒内宕机，有数据丢失appendfsync everysec 劣势相同数据集的数据而言AOF文件要远大于RDB文件，恢复速度慢于RDB，AOF运行效率要慢于RDB,每秒同步策略效率较好，不同步效率和RDB相同。 总结 AOF文件是一个只进行追加的日志文件 Redis可以在AOF文件体积变得过大时，自动地在后台对AOF进行重写 AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析也很轻松 对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积 根据所使用的fsync策略，AOF的速度可能会慢于RDB 总结 RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储 AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以Redis协议追加保存每次写的操作到文件末尾。Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大 只做缓存：如果你只希望你的数据在服务器运行的时候存在,也可以不使用任何持久化方式 同时开启两种持久化方式： 在这种情况下,当Redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。 RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？ 建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)，快速重启，留着作为一个万一的手段。 性能建议：因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。 如果Enable AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只加载自己的AOF文件就可以了。 代价一是带来了持续的IO，二是AOF重写的最后将重写过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。 只要硬盘许可，应该尽量减少AOF重写的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。 如果不Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了重写时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。 Redis事务Redis事务是指可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞。 可以用来一个队列中，一次性、顺序性、排他性的执行一系列命令。 常用命令 正常执行 放弃事务 全体连坐 不符合Redis协议的语法错误，类似于Java的编译错误一样，会导致整个事务执行失败。 冤头债主 符合Redis协议的语法，但是在运行中异常，类似于Java的运行时错误一样，只会导致该条命令执行失败，不会影响及回滚其他命令。 Watch监控悲观锁悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁 乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。 乐观锁策略:提交版本必须大于记录当前版本才能执行更新 无加塞 先监控再开启multi，保证两笔金额变动在同一个事务内。 有加塞 监控了key，如果key被修改了，后面一个事务的执行失效。 unwatch 小结 一旦执行了exec之前加的监控锁都会被取消掉了 Watch指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会被执行 通过watch命令在事务执行之前监控了多个Keys，倘若在watch之后有任何Key的值发生了变化，exec命令执行的事务都将被放弃，同时返回Nullmulti-bulk应答以通知调用者事务执行失败 如果watch监控后Key值发生了变化，只能通过重新查询新值再重新开启事务进行操作 总结开启事务后的三个阶段： 开启：以MULTI开始一个事务 入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面 执行：由EXEC命令触发事务 开启事务后的三个特性： 单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题 不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 Redis发布订阅 必须要先订阅后发布才能收到消息。 执行PUBLISH c2 hello-redis即可对c2频道发布消息，支持订阅多个的通配符PSUBSCRIBE new*，发送消息PUBLISH new1 redis2015。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://midkuro.github.io/tags/NoSql/"}]},{"title":"'ActiveMQ（八） 高级特性'","slug":"activemq-feature","date":"2020-05-22T17:00:08.000Z","updated":"2020-05-26T05:38:49.275Z","comments":true,"path":"2020/05/23/activemq-feature/","link":"","permalink":"https://midkuro.github.io/2020/05/23/activemq-feature/","excerpt":"","text":"ActiveMQ高级特性异步投递ActiveMQ支持同步、异步两种发送的模式将消息发送到Broker，模式的选择对发送延时有巨大的影响。producer能够达到怎样的产出率（产出率=发送数据总量/时间）主要受发送延时的影响，使用异步发送可以显著的提高发送的性能。 ActiveMQ默认使用异步发送的模式，除非明确指定使用同步发送的方式或者在未使用事务的前提下发送持久化的消息，这两种情况都是同步发送的。 如果没有使用事务且发送的是持久化消息，每一次发送都是同步发送的且会阻塞producer直到broker返回一个确认，表示消息已经被安全的持久化到磁盘。确认机制提供了消息安全的保障，但同时会阻塞客户端，带来了很大的延时。 很多高性能的应用，允许在失败的情况下有少量的数据丢失，如果你的应用满足这个这点，你可以使用异步发送来提高生产率，即使发送的是持久化的消息。 异步发送可以最大化producer端的发送效率。我们通常在发送消息量比较密集的情况下使用异步发送，它可以很大的提升producer性能。 不过这也带来了额外的问题，就是需要消耗较多的Client端内存，同时也会导致broker端的性能增加。 此外它不能有效的确保消息的发送成功，在useAsyncSend=true的情况下客户端需要容忍消息丢失的可能。 可以参考官网的三种异步投递配置方式： 异步发送确认机制异步发送丢失消息的场景是：生产者设置了UseAsyncSend=true，使用producer.send(msg)持久发送消息。由于消息不阻塞，生产者会认为所有send的消息均被成功发送至MQ。 如果MQ突然宕机，此时生产者端内存中尚未被发送至MQ的消息都会丢失。所以正确的异步发送方式是需要接收回调的。 同步发送和异步发送的区别： 同步发送等send不阻塞了就表示一定发送成功了。 异步发送需要接收回执并由客户端再判断一次是否发送成功。 12345678910111213141516171819202122232425262728293031323334353637public class JmsProducer &#123; //ActiveMQ服务器的链接地址 private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; //队列名称 private static final String QUEUE_NAME = \"queue01\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //设置异步投递 factory.setUseAsyncSend(true); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); //注意：强转成ActiveMQMessageProducer类 ActiveMQMessageProducer producer = (ActiveMQMessageProducer)session.createProducer(queue); for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"message---\" + i); message.setJMSMessageID(UUID.randomUUID.toString()); String messageID = message.getJMSMessageID(); //使用具备回调函数的API发送消息 producer.send(message, new AsyncCallback() &#123; @Override public void onSuccess() &#123; System.out.println(messageID + \"has been send\"); &#125; @Override public void onException(JMSException exception) &#123; System.out.println(messageID + \"fail to send\"); &#125; &#125;); &#125; producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列queue01完毕\"); &#125;&#125; 延迟投递和定时投递12&lt;!--activemq.xml在boker属性上配置schedulerSupport=\"true\"--&gt;&lt;broker xmlns=\"http://activemq.apache.org/schema/core\" brokerName=\"localhost\" dataDirectory=\"$&#123;activemq.data&#125;\" schedulerSupport=\"true\"&gt; Property name type description AMQ_SCHEDULED_DELAY long 延迟投递的时间 AMQ_SCHEDULED_PERIOD long 重复投递的时间间隔 AMQ_SCHEDULED_REPEAT int 重复投递次数 AMQ_SCHEDULED_CRON String Cron表达式 通过在ActiveMQ的配置文件中开启定时调度SchedulerSupport=&quot;true&quot;，默认为false。然后使用ScheduleMessage类进行消息属性配置。 1234567891011121314151617181920212223242526272829//生产者public class JmsProducer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue-delay\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); MessageProducer producer = session.createProducer(queue); //设置延迟投递时间 long delay = 3 * 1000; //设置重复投递的时间间隔 long period = 4 * 1000; //重复投递次数 int repeat = 5; for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"delay-message---\" + i); message.setLongProperty(ScheduleMessage.AMQ_SCHEDULED_DELAY, delay); message.setLongProperty(ScheduleMessage.AMQ_SCHEDULED_PERIOD, period); message.setIntProperty(ScheduleMessage.AMQ_SCHEDULED_REPEAT, repeat); producer.send(message); &#125; producer.close(); session.close(); connection.close(); &#125;&#125; 重试机制那些情况会引发消息重发？ Client用了transactions且在session中调用了rollback() Client用了transactions且在调用commit()之前关闭或者没有commit Client在CLINET_ACKNOWLEDGE的传递模式下，在session中调用了recover() 默认消息重发的时间间隔是每秒钟，重发次数是6次。 有毒消息Poison ACK： 一个消息被redelivedred超过默认的最大重发次数（默认6次）时。消费端会给MQ发送一个Poison ack表示这个消息有毒，告诉broker不要再发了。这个时候broker会把这个消息放到DLQ（死信队列），详情请参照官网。 属性 默认值 描述 collisionAvoidanceFactor 0.15 设置防止冲突范围的政府百分比，只有启动UseCollisionAvoidance参数时才生效，也就是在延迟时间再加一个 maximumRedelivers 6 最大重传次数，达到最大重连次数后抛出异常。为-1时不限制次数，为0时表示不进行重传。 maximumRedeliveryDelay -1 最大传送延迟，只在UseExponentialBackOff为true时有效（V5.5），假设首次重连间隔为10ms，倍数为2，那么第二次重连时间间隔为20ms，第三次重连时间间隔为40ms，当重连时间间隔的大于最大重连时间间隔时，以后每次重连时间间隔都为最大重连时间间隔。 initialRedeliveryDelay 1000L 初始重发延迟时间 redeliveryDelay 1000L 重发延迟时间，当initialRedeliveryDelay=0时生效 useCollisionAvoidance false 启用防止冲装功能 useExponentialBackOff false 启用指数倍数递增的方式增加延迟时间 backOffMultiplier 5 重连时间间隔递增倍数，只有值大于1和启动useExponentialBackOff参数时才生效 配置重试次数12345678910111213//修改最大重试次数public class JmsConsumer_Redelivery &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue-redelivery\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //使用自身的配置类，设置重试次数3次 RedeliveryPolicy redeliveryPolicy = new RedeliveryPolicy(); redeliveryPolicy.setMaximumRedeliveries(3); activeMQConnectionFactory.setRedeliveryPolicy(redeliveryPolicy); //省略后续代码... &#125;&#125; 整合Spring123456789&lt;!--定义reDelivery重发机制--&gt;&lt;bean id=\"activeMQRedeliveryPolicy\" class=\"org.apache.activemq.RedeliveryPolicy\"&gt; &lt;property name=\"maximumRedeliveries\" value=\"3\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--创建连接工厂并指定配置--&gt;&lt;bean id=\"connectionFactory\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.1.132:61616\"&gt;&lt;/property&gt; &lt;property name=\"redeliveryPolicy\" ref=\"activeMQRedelivery\" /&gt;&lt;/bean&gt; 死信队列ActiveMQ中引入了死信队列（Dead Letter queue）的概念，即一条消息再被重发了多次后（默认为重发6次redeliveryConter==6），将会被ActiveMQ移入私信队列，开发人员可以在这个Queue中查看处理出错的消息，进行人工干预，主要用来处理失败的消息，详情请查看官网。 一般生产环境中在使用MQ的时候设计两个队列：一个是核心业务队列，一个是死信队列。 核心业务队列，就是比如上图专门用来让订单系统发送订单消息的，然后另外一个私信队列就是用来处理异常情况的。 假设第三方物流系统故障了，此时无法请求，那么仓储系统每次消费到一条订单消息，尝试通知发货和配送都会遇到对方的接口报错。此时仓储系统就可以把这条消息拒绝访问或者标志位处理失败。一旦表这条消息处理失败后，MQ就会把这条消息转入提前设置好的一个死信队列中。 然后看到的就是，在第三方物流系统故障期间，所有订单消息全部处理失败，全部都会转入私信队列，然后你的仓储系统得专门有一个后台线程，监控第三方系统是否正常。一旦发现对方回复正常，这个后台线程就从私信队列消费处理失败的订单，重新执行发货和配送的通知逻辑。 共享死信队列SharedDeadLetterStrategy（共享死信队列），将所有的DeadLetter保存在一个共享的队列中，这是ActiveMQ broker端默认的策略。 共享队列默认为ActiveMQ.DLQ，可以通过deadLetterQueue属性来设定。 123&lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy deadLetterQueue=\"DLQ-QUEUE\" /&gt;&lt;/deadLetterStrategy&gt; 个人死信队列IndividualDeadLetterStrategy（个人死信队列），把DeadLetter放入各自的死信通道中。 对于Queue而言，死信通道的前缀默认为ActiveMQ.DLQ.Queue. 对于Topic而言，死信通道的前缀默认为ActiveMQ.DLQ.Topic. 比如队列Order，那么它对应的死信队列通道为ActiveMQ.DLQ.Queue.Order，我们使用queuePrefix、topicPrefix来指定上述前缀。 默认情况下，无论是Topic还是Queue，Broker将使用Queue来保存DeadLetter，即死信通道通常为Queue，不过开发也可以指定为Topic。 12345&lt;policyEntry queue=\"order\"&gt; &lt;deadLetterStrategy&gt; &lt;individualDeadLetterStrategy queuePrefix=\"DLQ.\" useQueueForQueueMessages=\"false\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 将队列Order中出现的DeadLetter保存在DLQ.Order中，不过此时DLQ.Order为Topic。 属性useQueueForQueueMessages设置使用队列保存死信队列，还可以设置useQueueForTopicMessages，使用Topic来保存死信队列，默认为true。 自动删除过期消息有时需要直接删除过期的消息而不需要发送到死信队列中，processExpired表示是否将过期消息放入私信队列，默认为true。 123456&lt;!--\"&gt; \"类似SQL的 * --&gt;&lt;policyEntry queue=\"&gt; \" &gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStragegy processExpired=\"false\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 存放非持久消息默认情况下，ActiveMQ不会把非持久的死消息发送到死信队列中。processNonPersistent表示是否将非持久化消息放入死信队列，默认为false。 如果想把非持久化的消息发送到死信队列中，需要设置属性processNonPersistent=&quot;true&quot; 12345&lt;policyEntry queue=\"&gt; \"&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processNonPersistent=\"true\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 重复消费如何保证消息不被重复消费？幂等性问题？ ​ 网络延迟传输中，会造成进行MQ重试中，在重试过程中，可能会造成重复消费。 如果消息是做数据库的插入操作，给这个消息做一个唯一主键，那么就算出现重复消息的情况，就会导致主键冲突，避免数据库出现脏数据。 或者准备个第三方来做消息记录，以redis为例，给消息分配一个全局id，只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis，消费者开始消费前，先去redis中查询有没有消费记录即可。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/categories/ActiveMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（七） 多节点集群'","slug":"activemq-cluster","date":"2020-05-22T17:00:07.000Z","updated":"2020-05-26T05:38:30.662Z","comments":true,"path":"2020/05/23/activemq-cluster/","link":"","permalink":"https://midkuro.github.io/2020/05/23/activemq-cluster/","excerpt":"","text":"ActiveMQActiveMQ多节点集群引入消息队列之后该如何保证其高可用性？ 基于Zookeeper和LevelDB搭建ActiveMQ集群，提供主备方式的高可用集群功能，避免单点故障。 三种集群方式：官网介绍 在ActiveMQ V5.6版本之后推出LevelDB的持久化引擎，它使用了自定义的索引代替常用的BTree索引，其持久化性能高于KahaDB，虽然默认的持久化方式还是KahaDB，但是LevelDB可能会是趋势。 在ActiveMQ V5.9版本还提供了基于LevelDB和Zookeeper的数据复制方式，作为Master-Slave方式的首选数据复制方案。 ZK+R LevelDB Store从ActiveMQ V5.9开始，ActiveMQ的集群实现方式取消了传统的Master-Slave方式，增加了基于Zookeeper+LevelDB的Master-Slave实现方式，从V5.9版本后也是官网推荐的。 原理说明： ​ 使用Zookeeper集群注册所有的ActiveMQ Broker但只有其中一个Broker可以提供服务，它将被视为Master，其他Broker处于待机状态被视为Slave。 如果Master因故障而不能提供服务ZooKeeper会从Slave中选举出一个Broker充当Master。 Slave连接Master并同步他们的存储状态，Slave不接受客户端连接。所有存储操作都将被复制到连接至Master的Slaves。 如果Master宕机，得到了最新更新的Slave会成为Master。故障节点在恢复会重新加入到集群中并连接Master进入Slave模式。 所有需要同步的消息操作都将等待存储状态被复制到其他法定节点的操作完成才能算完成。 所以，如果你配置了replicas=3，那么法定大小是（3/2+1）=2。Master将会存储并更新然后等待（2-1）=1个Slave存储和更新完成，才汇报success。至于为什么是2-1个，可以结合Zookeeper的watch机制、选举算法、原子广播ZAB协议。 有一个节点要作为观察者存在，当一个新的Master被选中，需要至少保障一个法定节点在线，以能够找到拥有最新状态的节点，这个节点才可以成为新的Master。 部署规划和步骤要求关闭防火墙并保证可以ping通ActiveMQ服务器，要求具备Zookeeper集群并可以成功启动。 集群部署规划列表 主机 Zookeeper集群端口 AMQ集群Bind端口 AMQ消息TCP端口 管理控制台端口 AMQ安装目录 192.168.1.132 2191 bind=”tcp://0.0.0.0:63631” 61616 8161 /mq_node01 192.168.1.132 2192 bind=”tcp://0.0.0.0:63632” 61617 8162 /mq_node02 192.168.1.132 2193 bind=”tcp://0.0.0.0:63633” 61618 8163 /mq_node03 修改控制台端口12345&lt;!--AMQ目录/conf/jetty.xml--&gt;&lt;bean id=\"jettyPort\" class=\"org.apache.activemq.web.WebConsolePort\" init-method=\"start\"&gt; &lt;property name=\"host\" value=\"0.0.0.0\" /&gt; &lt;property name=\"port\" value=\"8161\"&gt;&lt;/bean&gt; HostName映射1234#hostname名字映射vim /etc/hosts#增加自己机器配置192.168.1.132 mq-server brokerName一致123&lt;!--三个节点的brokerName要求全部一致--&gt;&lt;!--修改每个AMQ的activemq.xml文件--&gt;&lt;broker xmlns=\"http://activemq.apache.org/schema/core\" brokerName=\"kuromq\" dataDirectory=\"$&#123;activemq.data&#125;\"&gt; 持久化配置三个节点的持久化配置要求一致，Bind根据不同MQ实例调整 12345678910&lt;persistenceAdapter&gt; &lt;replicatedLevelDB directory=\"$&#123;activemq.data&#125;/leveldb\" replicas=\"3\" bind=\"tcp://0.0.0.0:63633\" zkAdress=\"localhost2191,localhost2192,localhost2193\" hostname=\"#mq-server\" sync=\"local_disk\" zkPath=\"/activemq/leveldb-stores\" /&gt;&lt;/persistenceAdapter&gt; 修改消息端口修改activemq.xml的消息协议的端口，调整为上述规划的端口。 然后按照顺序启动3个ActiveMQ节点，前提是Zookeeper集群已经成功启动运行。 zk集群的节点状态12#进入任意一台zookeeper目录下的bin./zkCli.sh -server 127.0.0.1:2191 集群启动后对Zookeeper数据抓图，可以看到ActiveMQ的三个节点，分别是00000000000，00000000001，00000000002。 第二张图00000000000的值可以看到elected的值不为空，说明这个节点是Master，其他两个是Slave。 集群可用性测试ActiveMQ的客户端只能访问Master的Broker，其他处于Slave的Broker不能访问，所以客户端连接的Broker应该使用failover协议(失败转移)。 当一个ActiveMQ节点挂掉或者一个Zookeeper节点挂掉，ActiveMQ服务依然正常运行，如果仅剩一个ActiveMQ节点，由于不能选举Master，所以ActiveMQ不能正常运行。 同样的，如果Zookeeper仅剩一个节点活动，不管ActiveMQ各个节点存活与否，ActiveMQ也不能正常提供服务，ActiveMQ集群的高可用依赖于Zookeeper集群的高可用。 12//BrokerURL调整public static final String ACTIVE_URL=\"failover:(tcp://192.168.1.132:61616,tcp://192.168.1.132:61617,tcp://192.168.1.132:61618)?randomize=false\"; 测试：3台机器中的ActiveMQ只会有一个MQ可以被客户端连接使用，在测试时可以把Master关掉，然后再重试客户端消息发送和消息还可以正常使用，则说明集群搭建正常。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/categories/ActiveMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（六） 消息持久化'","slug":"activemq-persistent","date":"2020-05-22T17:00:06.000Z","updated":"2020-05-26T05:37:58.281Z","comments":true,"path":"2020/05/23/activemq-persistent/","link":"","permalink":"https://midkuro.github.io/2020/05/23/activemq-persistent/","excerpt":"","text":"ActiveMQ消息持久化消息持久化是一种MQ服务器宕机了，消息不会丢失的机制。为避免意外宕机以后丢失信息，需要做到重启后可以恢复消息队列，消息系统一般都会采用持久化机制。 ActiveMQ消息持久化机制有JDBC,AMQ，KahaDB和LevelDB，无论使用哪种持久化方式，消息的存储逻辑都是一致的。 就是在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等再试图将消息发送给接收者，成功则将消息从存储中删除，失败则继续尝试发送。 消息中心启动以后首先要检查指定的存储位置，如果有未发送成功的消息，则需要把消息发送出去。 AMQ Message StoreAMQ是一种文件存储形式，它具有写入速度快和容易恢复的特点。消息存储在一个个文件中，文件的默认大小为32M，当一个存储文件中的消息已经全部被消费，那么这个文件将被标识为可删除，在下一个清除阶段，这个文件被删除。AMQ适用于ActiveMQ5.3之前的版本，现在已经不使用了。 KahaDB消息存储KahaDB是从ActiveMQ5.4开始到至今的默认持久化插件，可用于任何场景，提高性能和恢复能力。 消息存储使用一个事务日志和仅仅用一个索引文件来存储它所有的地址。 KahaDB是一个专门针对消息持久化的解决方案，它对典型的消息使用模型进行了优化。 数据被追加到data logs中，当不在需要log文件中的数据的时候，log会被丢弃。 1234&lt;!--activemq.xml的配置--&gt;&lt;persistenceAdapter&gt; &lt;kahaDB directory=\"$&#123;activemq.data&#125;/kahadb\" /&gt;&lt;/persistenceAdapter&gt; 在ActiveMQ安装目录下的data/kahadb文件夹中，只有四类文件和一个lock，跟ActiveMQ的其他几种文件存储引擎相比十分简洁。 db-&lt;Number&gt;.log： KahaDB存储消息到预定义大小的数据记录文件中，文件命名为db-&lt;Number&gt;.log。当数据文件已满时，一个新的文件会随之创建，Number数值也会随之递增，它随着消息数量的增加，如每32M一个文件，文件名按照数字进行编号，如db-1.log、db-2.log、db-3.log……当不再有引用到数据文件中的任何消息时，文件会被删除或者归档。 db.data： 该文件包含了持久化的BTree索引，索引了消息数据记录中的消息，他是消息的索引文件，本质上是B-Tree（B树），使用B-Tree作为索引指向db-&lt;Number&gt;.log里面存储的消息。 db.free： 当db.data文件里哪些页面是空闲的，文件具体内容是所有的空闲页的ID，方便后续db.data建立索引时使用，保证索引的连续性，没有碎片。 db.redo： 用来进行消息恢复，如果KahaDB消息存储在强制退出后启动，用于恢复Btree索引。 Lock： 文件锁，标识当前获得KahaDB读取权限的Broker。 LevelDB消息存储这种文件系统时从ActiveMQ5.8之后引进的，它和KahaDB非常相似，也是基于文件的本地数据库储存形式，但是它提供比KahaDB更快的持久性。 但它不能使用自定义B-Tree实现来索引与写日志，而是使用基于LevelDB的索引。 1234&lt;!--默认的配置如下:--&gt;&lt;persistenceAdapter&gt; &lt;levelDB directory=\"activemq-data\" /&gt;&lt;/persistenceAdapter&gt; JDBC消息存储以Mysql数据库为例，需要将Mysql数据库的驱动包mysql-connector-java-5.1.38.jar添加到ActiveMQ目录下的lib文件夹中。 然后修改activemq.xml配置文件，按照如下修改： 12345678&lt;!--原KahaDB的配置--&gt;&lt;persistenceAdapter&gt; &lt;kahaDB directory=\"$&#123;activemq.data&#125;/kahadb\" /&gt;&lt;/persistenceAdapter&gt;&lt;!--修改成JDBC配置--&gt;&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource=\"#mysql-ds\" createTablesOnStartup=\"true\" /&gt;&lt;/persistenceAdapter&gt; dataSource指定将要引用的持久化数据库的bean名称，createTablesOnStartup参数表示是否在启动的时候创建数据库表，默认值是true，这样每次启动都会去创建数据库表了，一般是第一次启动的时候设置为true，之后改成false。 上文指定了一个数据库实例mysql-ds，所以需要创建一个mysql-ds的实例，通过activemq.xml中的&lt;broker&gt;标签外设置bean 1234567&lt;bean id=\"mysql-ds\" class=\"org.apache.commons.dbcp2.BasicDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost/activemq?relaxAutoCommit=true\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;property name=\"poolPreparedStatements\" value=\"true\"/&gt; &lt;/bean&gt; 其中的org.apache.commons.dbcp2.BasicDataSource是JDBC驱动包自带的，当然也可以替换成C3P0或者Druid，但是lib文件夹就需要再添加C3p0或者Druid相关的依赖包。 然后创建一个与上方配置相同的数据库（activemq），执行语句CREATE DATABASE activemq 。 如果配置正常且启动成功，将会在数据库创建三张表ACTIVEMQ_MSGS、ACTIVEMQ_ACKS、ACTIVEMQ_LOCK。 ACTIVE_MSGS 列名 意义 ID 自增的数据库主键 CONTAINER 消息的Destination MSGID_PROD 消息发送者的主键 MSG_SEQ 消息发送的顺序，MSGID_PROD+MSG_SEQ可以组成JMS的MessageID EXPIRATION 消息过期时间，存储的是从1970-01-01到现在的毫秒数 MSG 消息本体的Java序列化对象的二进制数据 PRIORITY 优先级，0-9，数值越大优先级越高 ACTIVEMQ_ACKSactivemq_acks用于存储订阅关系。如果是持久化Topic，订阅者和服务器的订阅关系在这个表保存。 列名 意义 CONTAINER 消息的Destination SUB_DEST 如果是使用Static集群，这个字段会有集群其他系统的信息 CLIENT_ID 每个订阅者都必须有一个唯一的客户端ID用以区分 SUB_NAME 订阅者名称 SELECTOR 选择器，可以只消费满足条件的消息。条件可以用自定义属性实现，可支持多属性AND和OR操作 LAST_ACKED_ID 记录消费过的消息的ID ACTIVEMQ_LOCK表activemq_lock在集群环境中才有用，只有一个Broker可以获得消息，称为Master Broker，其他的只能作为备份等待Master Broker不可用，才可能称为下一个Master Broker。这个表用于记录哪个Broker是当前的Master Broker。 队列在点对点类型中： 当DeliveryMode设置为NON_PERSISTENCE时，消息被保存在内存中； 当DeliveryMode设置为PERSISTENCE时，消息保存在broker的相应的文件或者数据库中。 而且点对点类型中消息一旦被Consumer消费就从broker中删除。 12//开启消息持久化producer.setDeliveryMode(DeliveryMode.PERSISTENT); 能够看到开启消息持久化后，生产者发送消息到队列中，通过查询activemq_msgs表能够看到数据变化情况。 主题开启消息持久化，先启动消费者订阅再运行生产者，可以看到activemq_acks的变化情况。 总结一定要开启消息持久化： 如果是队列： 在没有消费者消费的情况下会将消息保存到activemq_msgs表中，只要有任意一个消费者已经消费国了，消费之后这些消息将会被立刻删除。 如果是主题： 一般是先启动消费者订阅然后再生产的情况下会将消息保存到activemq_acks。 数据库Jar包： 记得需要使用到的相关Jar文件放置到ActiveMQ安装路径下的lib目录。mysql-jdbc驱动包和对应的数据库连接池Jar包 createTablesOnStartup属性： 在jdbcPersistenceAdapter标签中设置了这个属性为true时，在第一次启动ActiveMQ时，ActiveMQ服务节点会自动创建所需要的数据表，启动完成后可以更改为false。 下划线： java.lang.illeglStateException:BeanFactory not initalized or already closed，这是因为操作系统机器名中有“_”符号，请更改机器名并重启后即可解决问题。 JDBC增强版 JDBC Message store With ActiveMQ Journal，简称JDBC增强版，这种方式客服了JDBC Store的不足，JDBC每次消息过来，都需要去写库和读库。 ActiveMQ Journal，使用高速缓存写入技术，大大提高了性能。 当消费者的消费速度能够及时跟上生产者消息的生产速度时，Journal文件能够大大减少需要写入到DB中的消息。 举个例子： ​ 生产者生产了1000条消息，这1000条消息会保存到journal文件，如果消费者的消费速度很快的情况下，在journal文件还没有同步到DB之前，消费者已经消费了90%以上的消息，那么这个时候只需要同步剩余的10%的消息到DB。 如果消费者消费的速度很慢，这时候journal文件可以使消息以批量方式写到DB。 1234567891011121314&lt;!--原JDBC的配置--&gt;&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource=\"#mysql-ds\" createTablesOnStartup=\"true\" /&gt;&lt;/persistenceAdapter&gt;&lt;!--修改成JDBC Journal配置--&gt;&lt;persistenceAdapter&gt; &lt;journalPersistenceAdapterFactory journalLogFiles=\"4\" journalLogFilSize=\"32768\" useJournal=\"true\" useQuickJournal=\"true\" dataSource=\"#mysql-ds\" dataDirectory=\"activemq-data\" /&gt;&lt;/persistenceAdapter&gt; 总结持久化消息主要是指MQ所在的服务器宕机后消息不会丢失的机制。 持久化机制演化过程： 从最初的AMQ Message Store方案到ActiveMQ V4版本中推出的High performance journal（高性能事务支持）附件，并且同步推出了关于关系型数据库的存储方案。 ActiveMQ V5.3版本中又推出了对KahaBD的支持（V5.4版本后成为ActiveMQ默认的持久化方案），后来AciveMQ V5.8版本开始支持LevelDB，到现在，v5.9+版本提供了标准的Zookeeper+LevelDB集群化方案。 ActiveMQ的消息持久化机制： AMQ： 基于日志文件 KahaDB：基于日志文件，从ActiveMQ 5.4开始默认的持久化插件 JDBC：基于第三方数据库 LevelDB：基于文件的本地数据库储存，从ActiveMQ 5.8版本之后又推出了LevelDB的持久化引擎性能高于KahaDB Replicated LevelDB Store：从ActiveMQ 5.9提供了基于LevelDB和Zookeeper的数据复制方式，用于Master-slave方式的首选数据复制方案。 无论使用哪种持久化方式，消息的存储逻辑都是一致的： 就是在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等，然后试图将消息发送给接收者，发送成功则将消息从存储中删除，失败则继续尝试。消息中心启动以后首先要检查指定的存储位置，如果有未发送的消息，则需要把消息发送出去。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/categories/ActiveMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（五） SpringBoot整合ActiveMQ'","slug":"activemq-springboot","date":"2020-05-22T17:00:05.000Z","updated":"2020-05-26T05:37:25.522Z","comments":true,"path":"2020/05/23/activemq-springboot/","link":"","permalink":"https://midkuro.github.io/2020/05/23/activemq-springboot/","excerpt":"","text":"ActiveMQSpringBoot整合ActiveMQpom.xml1234567&lt;!-- pom.xml增加依赖--&gt;&lt;!-- activemq所对JMS的支持，整合Spring和Activemq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; application.yml123456789#application.ymlspring: activemq: broker-url: tcp://192.168.1.132:61616 user: admin password: admin jms: #fasle = Queue true = Topic 默认Queue pub-sub-domain: false Bean12345678910111213@Component@EnableJms //开启SpringBoot对Jms的支持public class ConfigBean &#123; @Bean public Queue queue() &#123; return new ActiveMQQueue(\"myQueueName\"); &#125; @Bean public Topic topic() &#123; return new ActiveMQTopic(\"myTopicName\"); &#125;&#125; 生产者-定时调度123456789101112131415161718192021@Componentpublic class Queue_Produce &#123; @Autowired private JmsMessagingTemplate jmsMessagingTmplate; @Autowired private Queue queue; //@Autowired //private Topic topic; public void produceMsg() &#123; //convertAndSend自动转换消息的类型 jmsMessagingTemplate.convertAndSend(queue,\"SpringBoot队列发送消息\"); //jmsMessagingTemplate.convertAndSend(topic,\"SpringBoot主题发送消息\"); &#125; //间隔3秒定投 @Scheduled(fixedDelay = 3000) public void produceMsgScheduled() &#123; jmsMessagingTemplate.convertAndSend(queue,\"SpringBoot定时投递消息\"); &#125;&#125; 1234567@SpringBootApplication@EnableScheduling //激活定时调度public class MainApp_Produce &#123; public static void main(String[] args) &#123; SpringApplication.run(MainApp_Produce.class, args); &#125;&#125; Junits12345678910111213//单元测试执行@SpringBootTest(classes = MainApp_Produce.class)@RunWith(SpringJUnit4ClassRunner.class)@WebAppConfigurationpublic class TestActiveMQ &#123; @Autowired private Queue_Produce queue_produce; @Test public void testSend() throws Exception &#123; queue_produce.produceMsg(); &#125;&#125; 消费者-监听器12345678@Componentpublic class Queue_Consumer &#123; //设置监听器 @JmsListener(destination = \"myQueueName\") public void receive(TextMessage textMessage) throws JMSException &#123; System.out.println(\"消费者收到消息：\" + textMessage.getText()); &#125;&#125;","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/categories/ActiveMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（四） Spring整合ActiveMQ'","slug":"activemq-spring","date":"2020-05-22T17:00:04.000Z","updated":"2020-05-26T09:09:11.818Z","comments":true,"path":"2020/05/23/activemq-spring/","link":"","permalink":"https://midkuro.github.io/2020/05/23/activemq-spring/","excerpt":"","text":"ActiveMQSpring整合ActiveMQpom.xml依赖123456789101112131415161718192021222324&lt;!-- pom.xml增加依赖--&gt;&lt;!-- activemq所对JMS的支持，整合Spring和Activemq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.3.23.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--activemq所需要的pool包配置--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt;&lt;!--activemq相关依赖配置--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.xbean&lt;/groupId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt;&lt;/dependency&gt; applicationContext.xml123456789101112131415161718192021222324252627282930313233&lt;!-- applicationContext.xml--&gt;&lt;!-- 开启包的自动扫描--&gt;&lt;context:component-scan bean-package=\"*\" /&gt;&lt;!--配置生产者--&gt;&lt;bean id =\"jmsFactory\" class=\"org.apache.activemq.pool.PooledConnectionFactory\" destroy-method=\"stop\"&gt; &lt;property name=\"connectionFactory\"&gt; &lt;!--真正可以产生Connection的ConnectionFactory，由对应的JMS服务厂商提供--&gt; &lt;bean class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.1.132:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=\"maxConnections\" value=\"100\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--这是个队列目的地，点对点的--&gt;&lt;bean id =\"destinationQueue\" class=\"org.apache.activemq.command.ActiveMQQueue\"&gt; &lt;!--构造注入--&gt; &lt;constructor-arg index=\"0\" value=\"spring-active-queue\" /&gt;&lt;/bean&gt; &lt;!-- &lt;bean id =\"desctinationTopic\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;constructor-arg index=\"0\" value=\"spring-active-topic\"&gt;&lt;/bean&gt; --&gt;&lt;!--Spring提供的JMS工具类，它可以进行消息、接收等--&gt;&lt;bean id=\"jmsTemplate\" class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"jmsFactory\" /&gt; &lt;!--消息默认目的地，ref根据提供的bean配置Queue/Topic的bean id--&gt; &lt;property name=\"defaultDestination\" ref=\"destinationQueue\" /&gt; &lt;property name=\"messageConverter\"&gt; &lt;bean class=\"org.springframework.jms.support.converter.SimpleMessageConverter\" /&gt; &lt;/property&gt;&lt;/bean&gt; 生产者12345678910111213141516@Servicepublic class SpringMQ_Produce &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlAppalicationContext(\"applicationContext.xml\"); SpringMQ_Produce produce = (SpringMQ_Produce)ctx.getBean(\"springMQ_Produce\"); produce.jmsTemplate.send(new MessageCreator() &#123; @Override public Message createMessage(Session session) throws JMSException &#123; TextMessage message = session.createTextMessage(\"Spring和ActiveMQ的整合\"); return message; &#125; &#125;); &#125;&#125; 消费者1234567891011@Servicepublic class SpringMQ_Consumer &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); SpringMQ_Consumer consumer = (SpringMQ_Consumer)ctx.getBean(\"springMQ_Consumer\"); String value = (String)consumer.jmsTemplate.receiveAndConvert(); System.out.println(\"消费者收到消息：\" + value); &#125;&#125; 监听器配置12345678&lt;!-- applicationContext.xml 增加bean id--&gt;&lt;!--配置监听程序--&gt;&lt;bean id=\"jmsContainer\" class=\"org.springframework.jms.listener.DefaultMessageListenerContainer\"&gt; &lt;property name=\"connectionFactory\" ref=\"jmsFactory\" /&gt; &lt;property name=\"destination\" ref=\"destinationQueue\" /&gt; &lt;!--public class MyMessageListener implements MessageListener--&gt; &lt;property name=\"messageListener\" ref=\"myMessageListener\"/&gt;&lt;/bean&gt; 1234567891011121314@Componentpublic class MyMessageListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 配置监听器后，只需要启动生产者，消费者不用启动，自动会监听记录。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/categories/ActiveMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（三） 传输协议'","slug":"activemq-protocol","date":"2020-05-22T17:00:02.000Z","updated":"2020-05-26T05:36:20.316Z","comments":true,"path":"2020/05/23/activemq-protocol/","link":"","permalink":"https://midkuro.github.io/2020/05/23/activemq-protocol/","excerpt":"","text":"ActiveMQ传输协议ActiveMQ支持client和Broker的通讯协议有：TCP、NIO、UDP、SSL、Http(s)、VM。 其中配置Transport Connector的文件在ActiveMQ的安装目录的conf/activemq.xml中的&lt;transportConnectors&gt;标签中。 123456789&lt;!--配置传输官网 http://activemq.apache.org/configuring-transports.html--&gt;&lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name=\"openwire\" uri=\"tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&amp;trace=true\"/&gt; &lt;transportConnector name=\"amqp\" uri=\"amqp://0.0.0.0:5672?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"stomp\" uri=\"stomp://0.0.0.0:61613?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"mqtt\" uri=\"mqtt://0.0.0.0:1883?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"ws\" uri=\"ws://0.0.0.0:61614?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt;&lt;/transportConnectors&gt; TCP协议ActiveMQ中默认的消息协议就是openwire，也就是Transmission Control Protocal(TCP)协议。 这是默认的Broker配置，TCP的Client监听端口61616 在网络传输数据前，必须要序列化数据，消息是通过一个叫wire protocol的来序列化成字节流。 默认情况下ActiveMQ把wire protocol叫做OpenWire，它的目的是促使网络上的效率和数据快速交互。 TCP连接的URI形式如：tcp:hostname:port?key=value&amp;key=value，后面的参数是可选的 TCP传输的优点： TCP协议传输可靠性高，稳定性强 高效性：字节流方式传递，效率很高 有效性、可用性：应用广泛，支持任何平台 关于Transport协议的可配置参数可以参考官网 NIO协议 即New I/O API Protocol(NIO)，和TCP协议类似但NIO侧重底层的访问操作。它允许开发人员对统一资源可有更多的client调用和服务端有更多的负载。 适合NIO协议的场景： 可能有大量的Client去连接到Broker上，一般情况下，大量的Client去连接Broker是被操作系统的现成所限制的。因此，NIO的实现比TCP需要更少的线程去运行，工作中常用NIO协议，建议使用NIO协议 可能对于Broker有一个很迟钝的网络传输，NIO比TCP提供更好的性能。 NIO连接的URI形式：nio://hostname:port?key=value Transport Conector配置示例，参考官网 1234567&lt;broker&gt; ... &lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61616\"/&gt; &lt;/transportConnectors&gt; ...&lt;/broker&gt; 123&lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61618?trace=true\"/&gt; &lt;/transportConnectors&gt; AMQP协议即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。 STOMP协议即Streaming Text Orientated Message Protocol，是流文本定向消息协议，是一种为MOM（Message Oriented Middleware，面向消息的中间件） 设计的简单文本协议。 SSL协议Secure Sockets Layer Protocol（SSL）安全加固协议 MQTT协议MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分，该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和制动器（比如通过Twitter让房屋联网）的通信协议。 WS协议Web Socket协议 ActiveMQ支持的网络协议 协议 描述 TCP 默认的协议，性能相对可以 NIO 基于TCP协议智商的，进行了扩展和优化，具有更好的扩展性 UDP 性能比TCP更好，但是不具备可靠性 SSL 安全链接 HTTP(S) 基于HTTP或者HTTPS VM VM本身不是协议，当客户端和代理在同一个Java虚拟机(VM)中运行时，他们之间需要通信，但不想占用网络通道，而是直接通信，可以使用该方式 NIO增强123&lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61618?trace=true\"/&gt; &lt;/transportConnectors&gt; 当配置了activemq.xml配置了NIO协议之后，项目中的配置broker-url= nio://192.168.1.132:61618后，表示61618端口使用以TCP协议为基础的NIO网络IO模型。 但是这样的设置智能使这个端口支持Openwire协议，那么我们怎么既让这个端口支持NIO网络IO模型，又让它支持多个协议呢？ 可以通过使用auto关键字，组合+符号来为端口设置多种特性，达到基于NIO网络IO模型支持多种协议。 1&lt;transportConnector name=\"auto+nio\" uri=\"auto+://0.0.0.0:61608?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&amp;amp;org.apache.activemq.transport.nio.SelectorManager.corePoolSize=20&amp;amp;org.apache.activemq.transport.nio.SelectorManager.maxmumPoolSize=50\"/&gt;","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/categories/ActiveMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（二） Java消息服务'","slug":"activemq-jms","date":"2020-05-22T17:00:01.000Z","updated":"2020-05-26T09:08:19.729Z","comments":true,"path":"2020/05/23/activemq-jms/","link":"","permalink":"https://midkuro.github.io/2020/05/23/activemq-jms/","excerpt":"","text":"ActiveMQJMSJavaEE是一套使用JAVA进行企业级Web应用开发的大家一致遵循的工业标准。JavaEE平台提供了一个基于组件的方法来加快设计、开发、装配及部署企业应用程序。 JavaEE的13种核心技术规范： JDBC（Java Database）数据库连接 JNDI（Java Naming and Directory Interfaces）Java 的命名和目录接口 EJB（Enterprise JavaBean） RMI（Remote Method Invoke）远程方法调用 Java IDL（Interface Description Language）/CORBA（Common Object Broker Architecture）Java 接口定义语言/公用对象请求代理程序体系结构 JSP（Java Server Pages） Servlet XML（Extensible Markup Language）可扩展标记语言 JMS（Java Message Service）Java 消息服务 JTA（Java Transaction API）Java 事务 API JTS（Java Transaction Service）Java 事务服务 JavaMail JAF（JavaBean Activation Framework） JMS全称是Java Message Service（Java消息服务是JAVA EE的一门技术）。JMS的客户端之间可以通过JMS服务进行异步的消息传输。JMS用于和面向消息的中间件相互通信的应用程序接口(API)。它既支持点对点的域，有支持发布/订阅(publish/subscribe)类型的域，并且提供对下列类型的支持： 经认可的消息传递 事务型消息的传递 一致性消息和具有持久性的订阅者支持。 JMS消息系统带来的好处： 提供消息灵活性； 松散耦合 异步性。 JMS消息系统带来的好处：1、提供消息灵活性；2、松散耦合；3、异步性。 消息队列的比较 特性 ActiveMQ RabbitMQ Kafka RocketMQ PRODUCER-COMSUMER 支持 支持 支持 支持 PUBLISH-SUBSCRIBE 支持 支持 支持 支持 REQUEST-REPLY 支持 支持 - 支持 API完备性 高 高 高 低（静态配置） 多语言支持 支持，JAVA优先 语言无关 支持，JAVA优先 支持 单机呑吐量 万级 万级 十万级 单机万级 消息延迟 - 微秒级 毫秒级 - 可用性 高（主从） 高（主从） 非常高（分布式） 高 消息丢失 - 低 理论上不会丢失 - 消息重复 - 可控制 理论上会有重复 - 文档的完备性 高 高 高 中 提供快速入门 有 有 有 无 首次部署难度 - 低 中 高 JMS的组成结构和特点 JMS provider：实现JMS接口和规范的消息中间件 JMS producer：消息生产者，创建和发送JMS消息的客户端应用 JMS consumer：消息消费者，接受和处理JMS消息的客户端应用 JMS message ：消息，包括消息头、消息体、消息属性 消息头 JMSDestination：消息发送的目的地，主要指Queue和Topic JMSDeliveryMode：持久和持久模式 一条持久性消息：应该被传送一次仅仅一次，意味着如果JMS提供者出现故障，该消息并不会丢失，它会在服务器恢复之后再次传递。 一条非持久的消息：最多传送一次，这意味着服务器出现故障，该消息将永远丢失。 JMSExpiration：消息过期时间，默认永不过期 消息过期时间等于Destnation的send方法中的timeToLive值加上发送时刻的GMT时间值。 如果消息TimeToLive值等于零，则JMSExpiration被设置为零，表示该消息永不过期。 如果发送后，在消息过期时间之后消息还没有被发送到目的地，则该消息被清除。 JMSPriority：消息优先级 从0-9 十个级别，0到4是普通消息，5到9是加急消息。 JMS不要求MQ严格按照这是个优先级发送消息，但必须保证加急消息要先于普通消息到达，默认是4级。 JMSMessageID：唯一识别每个消息的标识，由MQ产生。 消息体 TextMessage：普通字符串消息，包含一个String MapMessage：一个Map类型的消息，Key为String类型，而值为Java的基本类型 BytesMessage：二进制数组消息，包含一个byte[] StreamMessage：Java数据流，用标准流操作来顺序的填充和读取 ObjectMessage：对象消息，包含一个可序列化的Java对象 123//例子MapMessage mapMessage = session.createMapMessage();mapMessage.setBoolean(\"key\", false); 发送和接受的消息体类型必须一致对应。 消息属性如果需要除消息头字段以外的值，那么可以使用消息属性，主要用于识别/去重/重点标注消息。 他们是以属性名和属性值对的形式制定的。可以将属性，可以看做是消息头的扩展，属性指定一些消息头没有包括的附加消息。比如可以在属性里指定消息选择器。 1234TextMessage message = session.createTextMessage();message.setText(text);//自定义属性message.setStringProperty(\"userName\",\"张三\"); JMS的可靠性持久性Persistent持久性参数说明： 非持久：当服务器宕机，消息不存在 12MessageProducer producer = session.createProducer(queue);producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); 持久：当服务器宕机，消息依然存在 12MessageProducer producer = session.createProducer(queue);producer.setDeliveryMode(DeliveryMode.PERSISTENT); 当不配置持久化时，队列默认的消息默认是持久化消息，此模式保证这些消息只被传送一次和成功使用一次。对这些消息，可靠性是优先考虑因素。 可靠性的另一个重要方面是确保持久化消息传递至目标后，消息服务在向消费者传送他们之前不会丢失这些消息。 持久化Topic-订阅主题123456789101112131415161718192021222324//生产者public class JmsTopicProducer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String TOPIC_NAME = \"topic-Persist\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Topic topic = session.createTopic(TOPIC_NAME); MessageProducer producer = session.createProducer(topic); //设置生产者的持久化消息 producer.setDeliveryMode(DeliveryMode.PERSISTENT); //设置完了持久化配置，然后再启动连接 connection.start(); for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"持久化消息：message---\" + i); producer.send(message); &#125; producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列topic完毕\"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334//订阅者public class JmsTopicConsumer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String TOPIC_NAME = \"topic-Persist\"; public static void main(String[] args) throws JMSException, IOException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); //设置订阅者的ID connection.setClientID(\"zhangsan\"); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Topic topic = session.createTopic(TOPIC_NAME); //创建持久化的订阅者 TopicSubscriber subscriber = session.createDurableSubscriber(topic, \"remark...\"); //设置完毕后再启动start connection.start(); //监听主题 subscriber.setMessageListener((message) -&gt; &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(\"收到持久化订阅消息：\" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); // 控制台不灭 System.in.read(); subscriber.close(); session.close(); connection.close(); System.out.println(\"订阅消费完毕\"); &#125;&#125; 需要先启动订阅者，再启动生产者，订阅主题需要为每个订阅者设置ClientID并创建订阅者，这时候生产消息时可以看到，订阅者处于激活状态并接收并消费了三条消息。 这时候把订阅者后台关闭，订阅者从激活状态变为离线状态，可以看到如下图： 当订阅者重新订阅时，会从离线状态重新变为激活状态。 切记：一定要先运行一次消费者，等于向MQ注册，类似于我订阅了这个主题，然后再运行生产者发送信息，此时无论消费者是否在线，都会接收到，不在线的话，下次链接时，会把没有收过的消息都接收下来。 事务Transaction事务偏生产者，签收偏消费者 123456//第一个参数是事务开关，第二个是签收参数Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);//提交事务session.commit();//回滚事务session.rollback(); false：只要执行send，就会进入到队列中。关闭事务，那第二个签收参数的设置需要有效 true：先执行send再执行commit，消息才被真正的提交到队列中，消息需要批量发送，需要缓冲区处理 生产者/消费者设置了事务开关等于true时，只有执行了session.commit();消息才会被生产/消费，所以事务的级别是比签收的级别高的。 签收123456789//Acknowledge签收方式//1.自动签收--常用Session.AUTO_ACKNOWLEDGE;//2.手动签收--常用Session.CLIENT_ACKNOWLEDGE;//3.可允许重复的签收Session.UPS_OK_ACKNOWLEDGE;//4.和事务组合的签收Session.SESSION_TRANSACTED; 非事务的情况下，默认行为是自动签收，当使用手动签收时，客户端需要调用message.acknowledge()方法手动签收。 在事务的情况下，只有commit后才能将全部消息变为已消费。在事务性会话中，当一个事务被成功提交则消息被自动签收，如果事务回滚，则消息会再次被传送。 非事务性会话中，消息何时被确认取决于创建会话时的应答模式（acknowledgement mode） JMS的点对点总结点对点模型是基于队列的，生产者发消息到队列，消费者从队列接收消息，队列的存在使消息的异步传输称为可能。 如果在Session关闭是有部分消息已被收到但还没有被签收（acknowledged），那么当消费者下次连接到相同的队列时，这些消息还会被再次接收。 队列可以长久地保存消息直到消费者收到消息。消费者不需要因为担心消息会丢西而时刻和队列保持激活的连接状态，充分体现了异步传输模式的优势。 JMS的发布订阅总结JMS Pub/Sub模型定义了如何向一个内容节点发布和订阅消息，这些节点被称作topic。 主题可以被认为是消息的传输中介，发布者（publisher）发布消息到主题，订阅者（subscribe）从主题订阅消息。 非持久订阅主题使得消息订阅和消息发布者保持互相独立，不需要接触 即可保证消息的传送。 非持久订阅只有当客户处于激活状态，也就是和MQ保持连接状态才能收到发送到某个主题的消息。 如果消费者处于离线状态，生产者发送的主题消息将会丢失作废，消费者永远不会收到。 持久订阅客户端首先向MQ注册一个自己的身份ID识别号，当这个客户端处于离线时，生产者会为这个ID保存所有发送到主题的消息，当客户端再次连接到MQ时会根据消费者的ID得到所有当自己处于离线时发送到主题的消息。 非持久订阅状态下，不能恢复或重新派送一个未签收的消息。持久订阅才能恢复或重新派送一个未签收的消息。 BrokerMQ消息服务器实例被称作Broker，作为server提供消息核心服务。 在linux环境下通过指定不同的配置文件启动多个MQ服务器实例的命令如下 1./activemq start xbean:file/apache-active-5.15.9/conf/my-activemq.xml 嵌入式Broker12345678910111213141516&lt;!-- pom.xml增加依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.xbean&lt;/groupId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.5&lt;/version&gt;&lt;/dependency&gt; 123456789public class EmbedBroker &#123; public static void main(String[] args) throws Exception&#123; //ActiveMQ也支持在vm中通信基于嵌入式的broker BrokerService brokerService = newBrokerService(); brokerService.setUseJmx(true); brokerService.addConnector(\"tcp://localhost:61616\"); brokerService.start(); &#125;&#125;","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/categories/ActiveMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（一） 基础概念'","slug":"activemq-mq","date":"2020-05-22T17:00:00.000Z","updated":"2020-05-26T09:07:07.640Z","comments":true,"path":"2020/05/23/activemq-mq/","link":"","permalink":"https://midkuro.github.io/2020/05/23/activemq-mq/","excerpt":"","text":"ActiveMQ消息队列的产品种类 常见的四大消息队列，其中RabbitMQ是使用erlang语言编写的，其他三个是Java语言编写的，kafka在大数据场景下比较常用，ActiveMQ是Apache公司研发的消息队列，而RocketMQ是阿里基于ActiveMQ和kafka的研发的。 消息队列种类繁多，但是从技术的维度来讲，每个消息队列应该都具备以上各种机制，本篇文章主要针对ActiveMQ进行讲解，举一反三。 为什么要引入MQ在没引入MQ之前，举个生活场景的例子，学生排队向老师请教问题，每个学生需要耗费5分钟的时间，这样导致学生将会被占用很长的时间，如下图： 在引入MQ后，可以将学生的问题以某种约定约束的格式进行收集，收集到指定的问题库中，当老师空闲出时间时将会去回答学生的问题，如下图： 在这种场景下，每个学生都只需要提交问题到问题库，然后可以做自己想做的事情，而不需要在原地等待老师解决完问题再离开，实现了微服务的异步通信。 微服务架构后，链式调用是我们写程序的一般流程，为了完成一个整体功能会将其拆分成多个函数（子模块），比如模块A调用模块B，模块B调用模块C，模块C调用模块D。 但是在大型分布式应用中，一个功能别后要调用许多接口，从单机架构过渡到分布式微服务架构的时候，会产生哪些问题？ 系统之间接口耦合比较严重 面对大流量并发时，容易被冲垮 等待同步存在性能问题 根据上述的问题，在设计系统时可以明确要达到的目标： 要做到系统解耦，当新模块接进来时，可以做到代码改动最小：能够解耦 设置流量缓冲池，可以让后端系统按照自身吞吐能力进行消费，不被冲垮：能够削峰 强弱依赖梳理能将非关键调用链路的操作异步化并提升整体系统的吞吐能力：能够异步 MQ的作用定义面向消息的中间件(message-orented middleware)MOM能够很好的解决以上的问题。 是指利用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。 通过提供消息传递和消息排队模型在分布式环境下提供应用解耦、弹性伸缩、冗余存储、流量削峰、异步通信、数据同步等功能。 大致的过程是这样的： 发送者把消息发送给消息服务器，消息服务器将消息存放在若干队列/主题中，在合适的时候，消息服务器会将消息转发给接受者。 在这个过程中，发布和接受是异步的，也就是发送无需等待，而且发送者和接受者的生命周期也没有必然关系； 尤其在发布pub/订阅sub模式下，也可以完成一对多的通信，即让一个消息有多个接受者。 ActiveMQ基础ActiveMQ官网 ActiveMQ下载 通过解压下载包，进入bin目录执行activemq即可启动 默认进程端口是61616； WEB网页地址：http://IP:8161 默认用户名/密码：admin/admin 备注：ActiveMQ采用61616端口提供JMS服务，采用8161端口提供管理控制台服务 MQ标准API讲解1234567891011&lt;!-- activeMQ所需要的jar包配置--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.xbean&lt;/groupId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt;&lt;/dependency&gt; 通过连接工厂ConnectionFactory创建连接，获取Session会话，Session会话按照约定格式创建消息Message、生产者Producer、消费者Consumer， 通过将消息发送给目的地Destination（队列Queue/主题Topic），生产者消费者通过目的地 生产 / 消费 消息。 在点对点的消息传递域中，目的地被称为队列(Queue) 在发布订阅消息作用域中，目的地被称为主题(Topic) 创建连接工厂123456789101112131415161718192021222324//1.ActiveMQConnectionFactory的构造器public ActiveMQConnectionFactory() &#123; this(DEFAULT_BROKER_URL);&#125;public ActiveMQConnectionFactory(String brokerURL) &#123; this(createURI(brokerURL));&#125;public ActiveMQConnectionFactory(URI brokerURL) &#123; setBrokerURL(brokerURL.toString());&#125;public ActiveMQConnectionFactory(String userName, String password, URI brokerURL) &#123; setUserName(userName); setPassword(password); setBrokerURL(brokerURL.toString());&#125;public ActiveMQConnectionFactory(String userName, String password, String brokerURL) &#123; setUserName(userName); setPassword(password); setBrokerURL(brokerURL);&#125; 可以看到，创建连接工厂的构造器支持传参ActiveMQ的URL，当不传参用户名和密码时，将采用默认admin/admin，其中当使用无参的构造器时，会默认使用DEFAULT_BROKER_URL常量中的URL当做链接串。 123456789101112131415public static final String DEFAULT_BROKER_URL = \"failover://\"+DEFAULT_BROKER_BIND_URL;public static final String DEFAULT_BROKER_BIND_URL; static&#123; //可以看到，默认的URL是以TCP协议开头 final String defaultURL = \"tcp://\" + DEFAULT_BROKER_HOST + \":\" + DEFAULT_BROKER_PORT; //用户配置的MQ服务器地址 String bindURL = null; /* 省略部分代码 */ //当不存在用户配置的地址时，使用默认地址defaultURL bindURL = (bindURL == null || bindURL.isEmpty()) ? defaultURL : bindURL; DEFAULT_BROKER_BIND_URL = bindURL; &#125; 1234567891011121314private static final String DEFAULT_BROKER_HOST;private static final int DEFAULT_BROKER_PORT;static&#123; String host = null; String port = null; /* 省略部分代码 */ //当找不到用户配置的IP、端口时，使用默认的localhost和61616 host = (host == null || host.isEmpty()) ? \"localhost\" : host; port = (port == null || port.isEmpty()) ? \"61616\" : port; DEFAULT_BROKER_HOST = host; DEFAULT_BROKER_PORT = Integer.parseInt(port);&#125; 生产者编码1234567891011121314151617181920212223242526272829303132public class JmsProducer &#123; //ActiveMQ服务器的链接地址 private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; //队列名称 private static final String QUEUE_NAME = \"queue01\"; public static void main(String[] args) throws JMSException &#123; //1.创建连接工厂，按照给定的URL地址，采用默认的用户名和密码 ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //2.通过连接工厂，获得连接Connection并访问 Connection connection = factory.createConnection(); connection.start(); //3.创建会话session //两个参数，第一个叫事务，第二个叫签收 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //4.创建目的地（具体是队列还是主题） Queue queue = session.createQueue(QUEUE_NAME); //5.创建消息的生产者 MessageProducer producer = session.createProducer(queue); //6.使用MessageProducer生产3条消息发送到MQ队列里面 for (int i = 1; i &lt;= 3; i++) &#123; //7.创建消息 TextMessage message = session.createTextMessage(\"message---\" + i); //8.通过MessageProducer发送给MQ producer.send(message); &#125; //9.关闭资源 producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列queue01完毕\"); &#125;&#125; 通过访问http://192.168.1.132:8161，登录后能够看到产生了3条消息 消费者编码12345678910111213141516171819202122232425262728public class JmsConsumer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue01\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); //创建消费者 MessageConsumer consumer = session.createConsumer(queue); //循环监听 while (true) &#123; //发送的什么消息类型，就需要使用什么消息类型接收 //接收消息等待四秒，当四秒后依旧没消息返回则不等待 TextMessage message = (TextMessage) consumer.receive(4000L); if (message != null) &#123; System.out.println(message.getText()); &#125; else &#123; break; &#125; &#125; consumer.close(); session.close(); connection.close(); System.out.println(\"消费者消费消息队列query01完毕\"); &#125;&#125; 当执行消费者之后，被消费的消息Messages Dequeued为3。消息被消费，然后等待四秒后消费者退出循环，所以待消费者数量Number Of Consumers为0，没有消费者继续等待消费消息。 12345//消费者接收消息的方式//1.阻塞式接收消息，当无消息则一直等待直到有消息返回Message receive() throws JMSException;//2.设置等待时长，当超过该时长则不等待，直接返回Message receive(long timeout) throws JMSException; 1234567891011121314151617181920212223242526272829//通过使用监听的方式消费消息，用于替换上述while循环//异步非阻塞方式（监听器onMessage()）//订阅者或接受者通过MessageConsumer的setMessage(MessageListener)注册一个消息监听器//当消息到达之后，系统自动调用监听器的onMessage(Message message)方法consumer.setMessageListener(new MessageListener() &#123; @Override public void onMessage(Message message) &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(\"消费消息：\" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;);//或者使用lambda表达式consumer.setMessageListener((message) -&gt; &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(\"消费消息：\" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125;); JMS开发步骤 创建一个ConnectionFactory工厂 通过ConnectionFactory来创建JMS Connection 启动JMS Connection 通过Connection创建JMS Session 创建JMS Destination 创建JMS Producer或者创建JMS Message并设置Destination 创建JMS Consumer或者注册JMS Message Listener 发送或者接受JMS message(s) 关闭所有JMS资源（Connection、Session、Producer、Consumer） 队列在点对点的消息传递域中，目的地被称为队列（queue） 每个消息只能有一个消费者，类似1对1的关系。好比个人快递自己领取自己的。 消息的生产者和消费者之间没有时间上的相关性、无论消费者在生产者发送消息的时候是否处于运行状态，消费者都可以提取消息。好比我们的发送短信，发送者发送后不见得接受者会即收即看。 当有多个消费者时，将采取类似负载均衡的策略，将消息均分到各个消费者中。 消息被消费后队列中不会再存储，所以消费者不会消费到已经被消费掉的消息。 主题在发布订阅消息传递域中，目的地被称为主题（topic） 生产者将消息发布到topic中，每个消息可以有多个消费者，属于 1：N的关系 生产者和消费者之间有时间上的相关性。订阅某一个主题的消费者只能消费自它订阅之后发布的消息 生产者生产时，topic不保存消息，它是无状态的不落地，假设无人订阅就去生产，那就是一条废消息，所以，一般先启动消费者再启动生产者。 JMS规范允许客户创建持久订阅，在这一程度上放松了时间上的相关性要求。持久订阅允许消费者消费它在未处于激活状态时发送的消息，好比如微信公众号订阅。 123//与队列不同的编码在于创建目的地//Queue queue = session.createQueue(QUEUE_NAME);Topic topic = session.createTopic(TOPIC_NAME); JMSJavaEE是一套使用JAVA进行企业级Web应用开发的大家一致遵循的工业标准。JavaEE平台提供了一个基于组件的方法来加快设计、开发、装配及部署企业应用程序。 JavaEE的13种核心技术规范： JDBC（Java Database）数据库连接 JNDI（Java Naming and Directory Interfaces）Java 的命名和目录接口 EJB（Enterprise JavaBean） RMI（Remote Method Invoke）远程方法调用 Java IDL（Interface Description Language）/CORBA（Common Object Broker Architecture）Java 接口定义语言/公用对象请求代理程序体系结构 JSP（Java Server Pages） Servlet XML（Extensible Markup Language）可扩展标记语言 JMS（Java Message Service）Java 消息服务 JTA（Java Transaction API）Java 事务 API JTS（Java Transaction Service）Java 事务服务 JavaMail JAF（JavaBean Activation Framework） JMS全称是Java Message Service（Java消息服务是JAVA EE的一门技术）。JMS的客户端之间可以通过JMS服务进行异步的消息传输。JMS用于和面向消息的中间件相互通信的应用程序接口(API)。它既支持点对点的域，有支持发布/订阅(publish/subscribe)类型的域，并且提供对下列类型的支持： 经认可的消息传递 事务型消息的传递 一致性消息和具有持久性的订阅者支持。 JMS消息系统带来的好处： 提供消息灵活性； 松散耦合 异步性。 JMS消息系统带来的好处：1、提供消息灵活性；2、松散耦合；3、异步性。 消息队列的比较 特性 ActiveMQ RabbitMQ Kafka RocketMQ PRODUCER-COMSUMER 支持 支持 支持 支持 PUBLISH-SUBSCRIBE 支持 支持 支持 支持 REQUEST-REPLY 支持 支持 - 支持 API完备性 高 高 高 低（静态配置） 多语言支持 支持，JAVA优先 语言无关 支持，JAVA优先 支持 单机呑吐量 万级 万级 十万级 单机万级 消息延迟 - 微秒级 毫秒级 - 可用性 高（主从） 高（主从） 非常高（分布式） 高 消息丢失 - 低 理论上不会丢失 - 消息重复 - 可控制 理论上会有重复 - 文档的完备性 高 高 高 中 提供快速入门 有 有 有 无 首次部署难度 - 低 中 高 JMS的组成结构和特点 JMS provider：实现JMS接口和规范的消息中间件 JMS producer：消息生产者，创建和发送JMS消息的客户端应用 JMS consumer：消息消费者，接受和处理JMS消息的客户端应用 JMS message ：消息，包括消息头、消息体、消息属性 消息头 JMSDestination：消息发送的目的地，主要指Queue和Topic JMSDeliveryMode：持久和持久模式 一条持久性消息：应该被传送一次仅仅一次，意味着如果JMS提供者出现故障，该消息并不会丢失，它会在服务器恢复之后再次传递。 一条非持久的消息：最多传送一次，这意味着服务器出现故障，该消息将永远丢失。 JMSExpiration：消息过期时间，默认永不过期 消息过期时间等于Destnation的send方法中的timeToLive值加上发送时刻的GMT时间值。 如果消息TimeToLive值等于零，则JMSExpiration被设置为零，表示该消息永不过期。 如果发送后，在消息过期时间之后消息还没有被发送到目的地，则该消息被清除。 JMSPriority：消息优先级 从0-9 十个级别，0到4是普通消息，5到9是加急消息。 JMS不要求MQ严格按照这是个优先级发送消息，但必须保证加急消息要先于普通消息到达，默认是4级。 JMSMessageID：唯一识别每个消息的标识，由MQ产生。 消息体 TextMessage：普通字符串消息，包含一个String MapMessage：一个Map类型的消息，Key为String类型，而值为Java的基本类型 BytesMessage：二进制数组消息，包含一个byte[] StreamMessage：Java数据流，用标准流操作来顺序的填充和读取 ObjectMessage：对象消息，包含一个可序列化的Java对象 123//例子MapMessage mapMessage = session.createMapMessage();mapMessage.setBoolean(\"key\", false); 发送和接受的消息体类型必须一致对应。 消息属性如果需要除消息头字段以外的值，那么可以使用消息属性，主要用于识别/去重/重点标注消息。 他们是以属性名和属性值对的形式制定的。可以将属性，可以看做是消息头的扩展，属性指定一些消息头没有包括的附加消息。比如可以在属性里指定消息选择器。 1234TextMessage message = session.createTextMessage();message.setText(text);//自定义属性message.setStringProperty(\"userName\",\"张三\"); JMS的可靠性持久性Persistent持久性参数说明： 非持久：当服务器宕机，消息不存在 1producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); 持久：当服务器宕机，消息依然存在 1producer.setDeliveryMode(DeliveryMode.PERSISTENT); 当不配置持久化时，队列默认的消息默认是持久化消息，此模式保证这些消息只被传送一次和成功使用一次。对这些消息，可靠性是优先考虑因素。 可靠性的另一个重要方面是确保持久化消息传递至目标后，消息服务在向消费者传送他们之前不会丢失这些消息。 持久化Topic-订阅主题123456789101112131415161718192021222324//生产者public class JmsTopicProducer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String TOPIC_NAME = \"topic-Persist\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Topic topic = session.createTopic(TOPIC_NAME); MessageProducer producer = session.createProducer(topic); //设置生产者的持久化消息 producer.setDeliveryMode(DeliveryMode.PERSISTENT); //设置完了持久化配置，然后再启动连接 connection.start(); for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"持久化消息：message---\" + i); producer.send(message); &#125; producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列topic完毕\"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334//订阅者public class JmsTopicConsumer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String TOPIC_NAME = \"topic-Persist\"; public static void main(String[] args) throws JMSException, IOException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); //设置订阅者的ID connection.setClientID(\"zhangsan\"); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Topic topic = session.createTopic(TOPIC_NAME); //创建持久化的订阅者 TopicSubscriber subscriber = session.createDurableSubscriber(topic, \"remark...\"); //设置完毕后再启动start connection.start(); //监听主题 subscriber.setMessageListener((message) -&gt; &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(\"收到持久化订阅消息：\" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); // 控制台不灭 System.in.read(); subscriber.close(); session.close(); connection.close(); System.out.println(\"订阅消费完毕\"); &#125;&#125; 需要先启动订阅者，再启动生产者，订阅主题需要为每个订阅者设置ClientID并创建订阅者，这时候生产消息时可以看到，订阅者处于激活状态并接收并消费了三条消息。 这时候把订阅者后台关闭，订阅者从激活状态变为离线状态，可以看到如下图： 当订阅者重新订阅时，会从离线状态重新变为激活状态。 切记：一定要先运行一次消费者，等于向MQ注册，类似于我订阅了这个主题，然后再运行生产者发送信息，此时无论消费者是否在线，都会接收到，不在线的话，下次链接时，会把没有收过的消息都接收下来。 事务Transaction事务偏生产者，签收偏消费者 123456//第一个参数是事务开关，第二个是签收参数Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);//提交事务session.commit();//回滚事务session.rollback(); false：只要执行send，就会进入到队列中。关闭事务，那第二个签收参数的设置需要有效 true：先执行send再执行commit，消息才被真正的提交到队列中，消息需要批量发送，需要缓冲区处理 生产者/消费者设置了事务开关等于true时，只有执行了session.commit();消息才会被生产/消费，所以事务的级别是比签收的级别高的。 签收123456789//Acknowledge签收方式//1.自动签收--常用Session.AUTO_ACKNOWLEDGE;//2.手动签收--常用Session.CLIENT_ACKNOWLEDGE;//3.可允许重复的签收Session.UPS_OK_ACKNOWLEDGE;//4.和事务组合的签收Session.SESSION_TRANSACTED; 非事务的情况下，默认行为是自动签收，当使用手动签收时，客户端需要调用message.acknowledge()方法手动签收。 在事务的情况下，只有commit后才能将全部消息变为已消费。在事务性会话中，当一个事务被成功提交则消息被自动签收，如果事务回滚，则消息会再次被传送。 非事务性会话中，消息何时被确认取决于创建会话时的应答模式（acknowledgement mode） JMS的点对点总结点对点模型是基于队列的，生产者发消息到队列，消费者从队列接收消息，队列的存在使消息的异步传输称为可能。 如果在Session关闭是有部分消息已被收到但还没有被签收（acknowledged），那么当消费者下次连接到相同的队列时，这些消息还会被再次接收。 队列可以长久地保存消息直到消费者收到消息。消费者不需要因为担心消息会丢西而时刻和队列保持激活的连接状态，充分体现了异步传输模式的优势。 JMS的发布订阅总结JMS Pub/Sub模型定义了如何向一个内容节点发布和订阅消息，这些节点被称作topic。 主题可以被认为是消息的传输中介，发布者（publisher）发布消息到主题，订阅者（subscribe）从主题订阅消息。 非持久订阅主题使得消息订阅和消息发布者保持互相独立，不需要接触 即可保证消息的传送。 非持久订阅只有当客户处于激活状态，也就是和MQ保持连接状态才能收到发送到某个主题的消息。 如果消费者处于离线状态，生产者发送的主题消息将会丢失作废，消费者永远不会收到。 持久订阅客户端首先向MQ注册一个自己的身份ID识别号，当这个客户端处于离线时，生产者会为这个ID保存所有发送到主题的消息，当客户端再次连接到MQ时会根据消费者的ID得到所有当自己处于离线时发送到主题的消息。 非持久订阅状态下，不能恢复或重新派送一个未签收的消息。持久订阅才能恢复或重新派送一个未签收的消息。 BrokerMQ消息服务器实例被称作Broker，作为server提供消息核心服务。 在linux环境下通过指定不同的配置文件启动多个MQ服务器实例的命令如下 1./activemq start xbean:file/apache-active-5.15.9/conf/my-activemq.xml 嵌入式Broker123456&lt;!-- pom.xml增加依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.5&lt;/version&gt;&lt;/dependency&gt; 123456789public class EmbedBroker &#123; public static void main(String[] args) throws Exception&#123; //ActiveMQ也支持在vm中通信基于嵌入式的broker BrokerService brokerService = newBrokerService(); brokerService.setUseJmx(true); brokerService.addConnector(\"tcp://localhost:61616\"); brokerService.start(); &#125;&#125; Spring整合ActiveMQ12345678910111213&lt;!-- pom.xml增加依赖--&gt;&lt;!-- activemq所对JMS的支持，整合Spring和Activemq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.3.23.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--activemq所需要的pool包配置--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233&lt;!-- applicationContext.xml--&gt;&lt;!-- 开启包的自动扫描--&gt;&lt;context:component-scan bean-package=\"*\" /&gt;&lt;!--配置生产者--&gt;&lt;bean id =\"jmsFactory\" class=\"org.apache.activemq.pool.PooledConnectionFactory\" destroy-method=\"stop\"&gt; &lt;property name=\"connectionFactory\"&gt; &lt;!--真正可以产生Connection的ConnectionFactory，由对应的JMS服务厂商提供--&gt; &lt;bean class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.1.132:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=\"maxConnections\" value=\"100\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--这是个队列目的地，点对点的--&gt;&lt;bean id =\"destinationQueue\" class=\"org.apache.activemq.command.ActiveMQQueue\"&gt; &lt;!--构造注入--&gt; &lt;constructor-arg index=\"0\" value=\"spring-active-queue\" /&gt;&lt;/bean&gt; &lt;!-- &lt;bean id =\"desctinationTopic\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;constructor-arg index=\"0\" value=\"spring-active-topic\"&gt;&lt;/bean&gt; --&gt;&lt;!--Spring提供的JMS工具类，它可以进行消息、接收等--&gt;&lt;bean id=\"jmsTemplate\" class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"jmsFactory\" /&gt; &lt;!--消息默认目的地，ref根据提供的bean配置Queue/Topic的bean id--&gt; &lt;property name=\"defaultDestination\" ref=\"destinationQueue\" /&gt; &lt;property name=\"messageConverter\"&gt; &lt;bean class=\"org.springframework.jms.support.converter.SimpleMessageConverter\" /&gt; &lt;/property&gt;&lt;/bean&gt; 生产者12345678910111213141516@Servicepublic class SpringMQ_Produce &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlAppalicationContext(\"applicationContext.xml\"); SpringMQ_Produce produce = (SpringMQ_Produce)ctx.getBean(\"springMQ_Produce\"); produce.jmsTemplate.send(new MessageCreator() &#123; @Override public Message createMessage(Session session) throws JMSException &#123; TextMessage message = session.createTextMessage(\"Spring和ActiveMQ的整合\"); return message; &#125; &#125;); &#125;&#125; 消费者1234567891011@Servicepublic class SpringMQ_Consumer &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); SpringMQ_Consumer consumer = (SpringMQ_Consumer)ctx.getBean(\"springMQ_Consumer\"); String value = (String)consumer.jmsTemplate.receiveAndConvert(); System.out.println(\"消费者收到消息：\" + value); &#125;&#125; 监听器配置12345678&lt;!-- applicationContext.xml 增加bean id--&gt;&lt;!--配置监听程序--&gt;&lt;bean id=\"jmsContainer\" class=\"org.springframework.jms.listener.DefaultMessageListenerContainer\"&gt; &lt;property name=\"connectionFactory\" ref=\"jmsFactory\" /&gt; &lt;property name=\"destination\" ref=\"destinationQueue\" /&gt; &lt;!--public class MyMessageListener implements MessageListener--&gt; &lt;property name=\"messageListener\" ref=\"myMessageListener\"/&gt;&lt;/bean&gt; 1234567891011121314@Componentpublic class MyMessageListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 配置监听器后，只需要启动生产者，消费者不用启动，自动会监听记录。 SpringBoot整合ActiveMQ1234567&lt;!-- pom.xml增加依赖--&gt;&lt;!-- activemq所对JMS的支持，整合Spring和Activemq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; 123456789#application.ymlspring: activemq: broker-url: tcp://192.168.1.132:61616 user: admin password: admin jms: #fasle = Queue true = Topic 默认Queue pub-sub-domain: false 12345678910111213@Component@EnableJms //开启SpringBoot对Jms的支持public class ConfigBean &#123; @Bean public Queue queue() &#123; return new ActiveMQQueue(\"myQueueName\"); &#125; @Bean public Topic topic() &#123; return new ActiveMQTopic(\"myTopicName\"); &#125;&#125; 生产者-定时调度123456789101112131415161718192021@Componentpublic class Queue_Produce &#123; @Autowired private JmsMessagingTemplate jmsMessagingTmplate; @Autowired private Queue queue; //@Autowired //private Topic topic; public void produceMsg() &#123; //convertAndSend自动转换消息的类型 jmsMessagingTemplate.convertAndSend(queue,\"SpringBoot队列发送消息\"); //jmsMessagingTemplate.convertAndSend(topic,\"SpringBoot主题发送消息\"); &#125; //间隔3秒定投 @Scheduled(fixedDelay = 3000) public void produceMsgScheduled() &#123; jmsMessagingTemplate.convertAndSend(queue,\"SpringBoot定时投递消息\"); &#125;&#125; 1234567@SpringBootApplication@EnableScheduling //激活定时调度public class MainApp_Produce &#123; public static void main(String[] args) &#123; SpringApplication.run(MainApp_Produce.class, args); &#125;&#125; 12345678910111213//单元测试执行@SpringBootTest(classes = MainApp_Produce.class)@RunWith(SpringJUnit4ClassRunner.class)@WebAppConfigurationpublic class TestActiveMQ &#123; @Autowired private Queue_Produce queue_produce; @Test public void testSend() throws Exception &#123; queue_produce.produceMsg(); &#125;&#125; 消费者-监听器12345678@Componentpublic class Queue_Consumer &#123; //设置监听器 @JmsListener(destination = \"myQueueName\") public void receive(TextMessage textMessage) throws JMSException &#123; System.out.println(\"消费者收到消息：\" + textMessage.getText()); &#125;&#125; 传输协议ActiveMQ支持client和Broker的通讯协议有：TCP、NIO、UDP、SSL、Http(s)、VM。 其中配置Transport Connector的文件在ActiveMQ的安装目录的conf/activemq.xml中的&lt;transportConnectors&gt;标签中。 123456789&lt;!--配置传输官网 http://activemq.apache.org/configuring-transports.html--&gt;&lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name=\"openwire\" uri=\"tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&amp;trace=true\"/&gt; &lt;transportConnector name=\"amqp\" uri=\"amqp://0.0.0.0:5672?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"stomp\" uri=\"stomp://0.0.0.0:61613?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"mqtt\" uri=\"mqtt://0.0.0.0:1883?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"ws\" uri=\"ws://0.0.0.0:61614?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt;&lt;/transportConnectors&gt; TCP协议ActiveMQ中默认的消息协议就是openwire，也就是Transmission Control Protocal(TCP)协议。 这是默认的Broker配置，TCP的Client监听端口61616 在网络传输数据前，必须要序列化数据，消息是通过一个叫wire protocol的来序列化成字节流。 默认情况下ActiveMQ把wire protocol叫做OpenWire，它的目的是促使网络上的效率和数据快速交互。 TCP连接的URI形式如：tcp:hostname:port?key=value&amp;key=value，后面的参数是可选的 TCP传输的优点： TCP协议传输可靠性高，稳定性强 高效性：字节流方式传递，效率很高 有效性、可用性：应用广泛，支持任何平台 关于Transport协议的可配置参数可以参考官网 NIO协议 即New I/O API Protocol(NIO)，和TCP协议类似但NIO侧重底层的访问操作。它允许开发人员对统一资源可有更多的client调用和服务端有更多的负载。 适合NIO协议的场景： 可能有大量的Client去连接到Broker上，一般情况下，大量的Client去连接Broker是被操作系统的现成所限制的。因此，NIO的实现比TCP需要更少的线程去运行，工作中常用NIO协议，建议使用NIO协议 可能对于Broker有一个很迟钝的网络传输，NIO比TCP提供更好的性能。 NIO连接的URI形式：nio://hostname:port?key=value Transport Conector配置示例，参考官网 1234567&lt;broker&gt; ... &lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61616\"/&gt; &lt;/transportConnectors&gt; ...&lt;/broker&gt; 123&lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61618?trace=true\"/&gt; &lt;/transportConnectors&gt; AMQP协议即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。 STOMP协议即Streaming Text Orientated Message Protocol，是流文本定向消息协议，是一种为MOM（Message Oriented Middleware，面向消息的中间件） 设计的简单文本协议。 SSL协议Secure Sockets Layer Protocol（SSL）安全加固协议 MQTT协议MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分，该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和制动器（比如通过Twitter让房屋联网）的通信协议。 WS协议Web Socket协议 ActiveMQ支持的网络协议 协议 描述 TCP 默认的协议，性能相对可以 NIO 基于TCP协议智商的，进行了扩展和优化，具有更好的扩展性 UDP 性能比TCP更好，但是不具备可靠性 SSL 安全链接 HTTP(S) 基于HTTP或者HTTPS VM VM本身不是协议，当客户端和代理在同一个Java虚拟机(VM)中运行时，他们之间需要通信，但不想占用网络通道，而是直接通信，可以使用该方式 NIO增强123&lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61618?trace=true\"/&gt; &lt;/transportConnectors&gt; 当配置了activemq.xml配置了NIO协议之后，项目中的配置broker-url= nio://192.168.1.132:61618后，表示61618端口使用以TCP协议为基础的NIO网络IO模型。 但是这样的设置智能使这个端口支持Openwire协议，那么我们怎么既让这个端口支持NIO网络IO模型，又让它支持多个协议呢？ 可以通过使用auto关键字，组合+符号来为端口设置多种特性，达到基于NIO网络IO模型支持多种协议。 1&lt;transportConnector name=\"auto+nio\" uri=\"auto+://0.0.0.0:61608?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&amp;amp;org.apache.activemq.transport.nio.SelectorManager.corePoolSize=20&amp;amp;org.apache.activemq.transport.nio.SelectorManager.maxmumPoolSize=50\"/&gt; 消息持久化消息持久化是一种MQ服务器宕机了，消息不会丢失的机制。为避免意外宕机以后丢失信息，需要做到重启后可以恢复消息队列，消息系统一般都会采用持久化机制。 ActiveMQ消息持久化机制有JDBC,AMQ，KahaDB和LevelDB，无论使用哪种持久化方式，消息的存储逻辑都是一致的。 就是在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等再试图将消息发送给接收者，成功则将消息从存储中删除，失败则继续尝试发送。 消息中心启动以后首先要检查指定的存储位置，如果有未发送成功的消息，则需要把消息发送出去。 AMQ Message StoreAMQ是一种文件存储形式，它具有写入速度快和容易恢复的特点。消息存储在一个个文件中，文件的默认大小为32M，当一个存储文件中的消息已经全部被消费，那么这个文件将被标识为可删除，在下一个清除阶段，这个文件被删除。AMQ适用于ActiveMQ5.3之前的版本，现在已经不使用了。 KahaDB消息存储KahaDB是从ActiveMQ5.4开始到至今的默认持久化插件，可用于任何场景，提高性能和恢复能力。 消息存储使用一个事务日志和仅仅用一个索引文件来存储它所有的地址。 KahaDB是一个专门针对消息持久化的解决方案，它对典型的消息使用模型进行了优化。 数据被追加到data logs中，当不在需要log文件中的数据的时候，log会被丢弃。 1234&lt;!--activemq.xml的配置--&gt;&lt;persistenceAdapter&gt; &lt;kahaDB directory=\"$&#123;activemq.data&#125;/kahadb\" /&gt;&lt;/persistenceAdapter&gt; 在ActiveMQ安装目录下的data/kahadb文件夹中，只有四类文件和一个lock，跟ActiveMQ的其他几种文件存储引擎相比十分简洁。 db-&lt;Number&gt;.log： KahaDB存储消息到预定义大小的数据记录文件中，文件命名为db-&lt;Number&gt;.log。当数据文件已满时，一个新的文件会随之创建，Number数值也会随之递增，它随着消息数量的增加，如每32M一个文件，文件名按照数字进行编号，如db-1.log、db-2.log、db-3.log……当不再有引用到数据文件中的任何消息时，文件会被删除或者归档。 db.data： 该文件包含了持久化的BTree索引，索引了消息数据记录中的消息，他是消息的索引文件，本质上是B-Tree（B树），使用B-Tree作为索引指向db-&lt;Number&gt;.log里面存储的消息。 db.free： 当db.data文件里哪些页面是空闲的，文件具体内容是所有的空闲页的ID，方便后续db.data建立索引时使用，保证索引的连续性，没有碎片。 db.redo： 用来进行消息恢复，如果KahaDB消息存储在强制退出后启动，用于恢复Btree索引。 Lock： 文件锁，标识当前获得KahaDB读取权限的Broker。 LevelDB消息存储这种文件系统时从ActiveMQ5.8之后引进的，它和KahaDB非常相似，也是基于文件的本地数据库储存形式，但是它提供比KahaDB更快的持久性。 但它不能使用自定义B-Tree实现来索引与写日志，而是使用基于LevelDB的索引。 1234&lt;!--默认的配置如下:--&gt;&lt;persistenceAdapter&gt; &lt;levelDB directory=\"activemq-data\" /&gt;&lt;/persistenceAdapter&gt; JDBC消息存储以Mysql数据库为例，需要将Mysql数据库的驱动包mysql-connector-java-5.1.38.jar添加到ActiveMQ目录下的lib文件夹中。 然后修改activemq.xml配置文件，按照如下修改： 12345678&lt;!--原KahaDB的配置--&gt;&lt;persistenceAdapter&gt; &lt;kahaDB directory=\"$&#123;activemq.data&#125;/kahadb\" /&gt;&lt;/persistenceAdapter&gt;&lt;!--修改成JDBC配置--&gt;&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource=\"#mysql-ds\" createTablesOnStartup=\"true\" /&gt;&lt;/persistenceAdapter&gt; dataSource指定将要引用的持久化数据库的bean名称，createTablesOnStartup参数表示是否在启动的时候创建数据库表，默认值是true，这样每次启动都会去创建数据库表了，一般是第一次启动的时候设置为true，之后改成false。 上文指定了一个数据库实例mysql-ds，所以需要创建一个mysql-ds的实例，通过activemq.xml中的&lt;broker&gt;标签外设置bean 1234567&lt;bean id=\"mysql-ds\" class=\"org.apache.commons.dbcp2.BasicDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost/activemq?relaxAutoCommit=true\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;property name=\"poolPreparedStatements\" value=\"true\"/&gt; &lt;/bean&gt; 其中的org.apache.commons.dbcp2.BasicDataSource是JDBC驱动包自带的，当然也可以替换成C3P0或者Druid，但是lib文件夹就需要再添加C3p0或者Druid相关的依赖包。 然后创建一个与上方配置相同的数据库（activemq），执行语句CREATE DATABASE activemq 。 如果配置正常且启动成功，将会在数据库创建三张表ACTIVEMQ_MSGS、ACTIVEMQ_ACKS、ACTIVEMQ_LOCK。 ACTIVE_MSGS 列名 意义 ID 自增的数据库主键 CONTAINER 消息的Destination MSGID_PROD 消息发送者的主键 MSG_SEQ 消息发送的顺序，MSGID_PROD+MSG_SEQ可以组成JMS的MessageID EXPIRATION 消息过期时间，存储的是从1970-01-01到现在的毫秒数 MSG 消息本体的Java序列化对象的二进制数据 PRIORITY 优先级，0-9，数值越大优先级越高 ACTIVEMQ_ACKSactivemq_acks用于存储订阅关系。如果是持久化Topic，订阅者和服务器的订阅关系在这个表保存。 列名 意义 CONTAINER 消息的Destination SUB_DEST 如果是使用Static集群，这个字段会有集群其他系统的信息 CLIENT_ID 每个订阅者都必须有一个唯一的客户端ID用以区分 SUB_NAME 订阅者名称 SELECTOR 选择器，可以只消费满足条件的消息。条件可以用自定义属性实现，可支持多属性AND和OR操作 LAST_ACKED_ID 记录消费过的消息的ID ACTIVEMQ_LOCK表activemq_lock在集群环境中才有用，只有一个Broker可以获得消息，称为Master Broker，其他的只能作为备份等待Master Broker不可用，才可能称为下一个Master Broker。这个表用于记录哪个Broker是当前的Master Broker。 队列在点对点类型中： 当DeliveryMode设置为NON_PERSISTENCE时，消息被保存在内存中； 当DeliveryMode设置为PERSISTENCE时，消息保存在broker的相应的文件或者数据库中。 而且点对点类型中消息一旦被Consumer消费就从broker中删除。 12//开启消息持久化producer.setDeliveryMode(DeliveryMode.PERSISTENT); 能够看到开启消息持久化后，生产者发送消息到队列中，通过查询activemq_msgs表能够看到数据变化情况。 主题开启消息持久化，先启动消费者订阅再运行生产者，可以看到activemq_acks的变化情况。 总结一定要开启消息持久化： 如果是队列： 在没有消费者消费的情况下会将消息保存到activemq_msgs表中，只要有任意一个消费者已经消费国了，消费之后这些消息将会被立刻删除。 如果是主题： 一般是先启动消费者订阅然后再生产的情况下会将消息保存到activemq_acks。 数据库Jar包： 记得需要使用到的相关Jar文件放置到ActiveMQ安装路径下的lib目录。mysql-jdbc驱动包和对应的数据库连接池Jar包 createTablesOnStartup属性： 在jdbcPersistenceAdapter标签中设置了这个属性为true时，在第一次启动ActiveMQ时，ActiveMQ服务节点会自动创建所需要的数据表，启动完成后可以更改为false。 下划线： java.lang.illeglStateException:BeanFactory not initalized or already closed，这是因为操作系统机器名中有“_”符号，请更改机器名并重启后即可解决问题。 JDBC增强版 JDBC Message store With ActiveMQ Journal，简称JDBC增强版，这种方式客服了JDBC Store的不足，JDBC每次消息过来，都需要去写库和读库。 ActiveMQ Journal，使用高速缓存写入技术，大大提高了性能。 当消费者的消费速度能够及时跟上生产者消息的生产速度时，Journal文件能够大大减少需要写入到DB中的消息。 举个例子： ​ 生产者生产了1000条消息，这1000条消息会保存到journal文件，如果消费者的消费速度很快的情况下，在journal文件还没有同步到DB之前，消费者已经消费了90%以上的消息，那么这个时候只需要同步剩余的10%的消息到DB。 如果消费者消费的速度很慢，这时候journal文件可以使消息以批量方式写到DB。 1234567891011121314&lt;!--原JDBC的配置--&gt;&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource=\"#mysql-ds\" createTablesOnStartup=\"true\" /&gt;&lt;/persistenceAdapter&gt;&lt;!--修改成JDBC Journal配置--&gt;&lt;persistenceAdapter&gt; &lt;journalPersistenceAdapterFactory journalLogFiles=\"4\" journalLogFilSize=\"32768\" useJournal=\"true\" useQuickJournal=\"true\" dataSource=\"#mysql-ds\" dataDirectory=\"activemq-data\" /&gt;&lt;/persistenceAdapter&gt; 总结持久化消息主要是指MQ所在的服务器宕机后消息不会丢失的机制。 持久化机制演化过程： ​ 从最初的AMQ Message Store方案到ActiveMQ V4版本中推出的High performance journal（高性能事务支持）附件，并且同步推出了关于关系型数据库的存储方案。 ActiveMQ V5.3版本中又推出了对KahaBD的支持（V5.4版本后成为ActiveMQ默认的持久化方案），后来AciveMQ V5.8版本开始支持LevelDB，到现在，v5.9+版本提供了标准的Zookeeper+LevelDB集群化方案。 ActiveMQ的消息持久化机制： AMQ： 基于日志文件 KahaDB：基于日志文件，从ActiveMQ 5.4开始默认的持久化插件 JDBC：基于第三方数据库 LevelDB：基于文件的本地数据库储存，从ActiveMQ 5.8版本之后又推出了LevelDB的持久化引擎性能高于KahaDB Replicated LevelDB Store：从ActiveMQ 5.9提供了基于LevelDB和Zookeeper的数据复制方式，用于Master-slave方式的首选数据复制方案。 无论使用哪种持久化方式，消息的存储逻辑都是一致的： 就是在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等，然后试图将消息发送给接收者，发送成功则将消息从存储中删除，失败则继续尝试。消息中心启动以后首先要检查指定的存储位置，如果有未发送的消息，则需要把消息发送出去。ActiveMQ多节点集群引入消息队列之后该如何保证其高可用性？ 基于Zookeeper和LevelDB搭建ActiveMQ集群，提供主备方式的高可用集群功能，避免单点故障。 三种集群方式：官网介绍 在ActiveMQ V5.6版本之后推出LevelDB的持久化引擎，它使用了自定义的索引代替常用的BTree索引，其持久化性能高于KahaDB，虽然默认的持久化方式还是KahaDB，但是LevelDB可能会是趋势。 在ActiveMQ V5.9版本还提供了基于LevelDB和Zookeeper的数据复制方式，作为Master-Slave方式的首选数据复制方案。 ZK+R LevelDB Store从ActiveMQ V5.9开始，ActiveMQ的集群实现方式取消了传统的Master-Slave方式，增加了基于Zookeeper+LevelDB的Master-Slave实现方式，从V5.9版本后也是官网推荐的。 原理说明： ​ 使用Zookeeper集群注册所有的ActiveMQ Broker但只有其中一个Broker可以提供服务，它将被视为Master，其他Broker处于待机状态被视为Slave。 如果Master因故障而不能提供服务ZooKeeper会从Slave中选举出一个Broker充当Master。 Slave连接Master并同步他们的存储状态，Slave不接受客户端连接。所有存储操作都将被复制到连接至Master的Slaves。 如果Master宕机，得到了最新更新的Slave会成为Master。故障节点在恢复会重新加入到集群中并连接Master进入Slave模式。 所有需要同步的消息操作都将等待存储状态被复制到其他法定节点的操作完成才能算完成。 所以，如果你配置了replicas=3，那么法定大小是（3/2+1）=2。Master将会存储并更新然后等待（2-1）=1个Slave存储和更新完成，才汇报success。至于为什么是2-1个，可以结合Zookeeper的watch机制、选举算法、原子广播ZAB协议。 有一个节点要作为观察者存在，当一个新的Master被选中，需要至少保障一个法定节点在线，以能够找到拥有最新状态的节点，这个节点才可以成为新的Master。 部署规划和步骤要求关闭防火墙并保证可以ping通ActiveMQ服务器，要求具备Zookeeper集群并可以成功启动。 集群部署规划列表 主机 Zookeeper集群端口 AMQ集群Bind端口 AMQ消息TCP端口 管理控制台端口 AMQ安装目录 192.168.1.132 2191 bind=”tcp://0.0.0.0:63631” 61616 8161 /mq_node01 192.168.1.132 2192 bind=”tcp://0.0.0.0:63632” 61617 8162 /mq_node02 192.168.1.132 2193 bind=”tcp://0.0.0.0:63633” 61618 8163 /mq_node03 修改控制台端口12345&lt;!--AMQ目录/conf/jetty.xml--&gt;&lt;bean id=\"jettyPort\" class=\"org.apache.activemq.web.WebConsolePort\" init-method=\"start\"&gt; &lt;property name=\"host\" value=\"0.0.0.0\" /&gt; &lt;property name=\"port\" value=\"8161\"&gt;&lt;/bean&gt; HostName映射1234#hostname名字映射vim /etc/hosts#增加自己机器配置192.168.1.132 mq-server brokerName一致123&lt;!--三个节点的brokerName要求全部一致--&gt;&lt;!--修改每个AMQ的activemq.xml文件--&gt;&lt;broker xmlns=\"http://activemq.apache.org/schema/core\" brokerName=\"kuromq\" dataDirectory=\"$&#123;activemq.data&#125;\"&gt; 持久化配置三个节点的持久化配置要求一致，Bind根据不同MQ实例调整 12345678910&lt;persistenceAdapter&gt; &lt;replicatedLevelDB directory=\"$&#123;activemq.data&#125;/leveldb\" replicas=\"3\" bind=\"tcp://0.0.0.0:63633\" zkAdress=\"localhost2191,localhost2192,localhost2193\" hostname=\"#mq-server\" sync=\"local_disk\" zkPath=\"/activemq/leveldb-stores\" /&gt;&lt;/persistenceAdapter&gt; 修改消息端口修改activemq.xml的消息协议的端口，调整为上述规划的端口。 然后按照顺序启动3个ActiveMQ节点，前提是Zookeeper集群已经成功启动运行。 zk集群的节点状态12#进入任意一台zookeeper目录下的bin./zkCli.sh -server 127.0.0.1:2191 集群启动后对Zookeeper数据抓图，可以看到ActiveMQ的三个节点，分别是00000000000，00000000001，00000000002。 第二张图00000000000的值可以看到elected的值不为空，说明这个节点是Master，其他两个是Slave。 集群可用性测试ActiveMQ的客户端只能访问Master的Broker，其他处于Slave的Broker不能访问，所以客户端连接的Broker应该使用failover协议(失败转移)。 当一个ActiveMQ节点挂掉或者一个Zookeeper节点挂掉，ActiveMQ服务依然正常运行，如果仅剩一个ActiveMQ节点，由于不能选举Master，所以ActiveMQ不能正常运行。 同样的，如果Zookeeper仅剩一个节点活动，不管ActiveMQ各个节点存活与否，ActiveMQ也不能正常提供服务，ActiveMQ集群的高可用依赖于Zookeeper集群的高可用。 12//BrokerURL调整public static final String ACTIVE_URL=\"failover:(tcp://192.168.1.132:61616,tcp://192.168.1.132:61617,tcp://192.168.1.132:61618)?randomize=false\"; 测试：3台机器中的ActiveMQ只会有一个MQ可以被客户端连接使用，在测试时可以把Master关掉，然后再重试客户端消息发送和消息还可以正常使用，则说明集群搭建正常。 高级特性异步投递ActiveMQ支持同步、异步两种发送的模式将消息发送到Broker，模式的选择对发送延时有巨大的影响。producer能够达到怎样的产出率（产出率=发送数据总量/时间）主要受发送延时的影响，使用异步发送可以显著的提高发送的性能。 ActiveMQ默认使用异步发送的模式，除非明确指定使用同步发送的方式或者在未使用事务的前提下发送持久化的消息，这两种情况都是同步发送的。 如果没有使用事务且发送的是持久化消息，每一次发送都是同步发送的且会阻塞producer直到broker返回一个确认，表示消息已经被安全的持久化到磁盘。确认机制提供了消息安全的保障，但同时会阻塞客户端，带来了很大的延时。 很多高性能的应用，允许在失败的情况下有少量的数据丢失，如果你的应用满足这个这点，你可以使用异步发送来提高生产率，即使发送的是持久化的消息。 异步发送可以最大化producer端的发送效率。我们通常在发送消息量比较密集的情况下使用异步发送，它可以很大的提升producer性能。 不过这也带来了额外的问题，就是需要消耗较多的Client端内存，同时也会导致broker端的性能增加。 此外它不能有效的确保消息的发送成功，在useAsyncSend=true的情况下客户端需要容忍消息丢失的可能。 可以参考官网的三种异步投递配置方式： 异步发送确认机制异步发送丢失消息的场景是：生产者设置了UseAsyncSend=true，使用producer.send(msg)持久发送消息。由于消息不阻塞，生产者会认为所有send的消息均被成功发送至MQ。 如果MQ突然宕机，此时生产者端内存中尚未被发送至MQ的消息都会丢失。所以正确的异步发送方式是需要接收回调的。 同步发送和异步发送的区别： 同步发送等send不阻塞了就表示一定发送成功了。 异步发送需要接收回执并由客户端再判断一次是否发送成功。 12345678910111213141516171819202122232425262728293031323334353637public class JmsProducer &#123; //ActiveMQ服务器的链接地址 private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; //队列名称 private static final String QUEUE_NAME = \"queue01\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //设置异步投递 factory.setUseAsyncSend(true); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); //注意：强转成ActiveMQMessageProducer类 ActiveMQMessageProducer producer = (ActiveMQMessageProducer)session.createProducer(queue); for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"message---\" + i); message.setJMSMessageID(UUID.randomUUID.toString()); String messageID = message.getJMSMessageID(); //使用具备回调函数的API发送消息 producer.send(message, new AsyncCallback() &#123; @Override public void onSuccess() &#123; System.out.println(messageID + \"has been send\"); &#125; @Override public void onException(JMSException exception) &#123; System.out.println(messageID + \"fail to send\"); &#125; &#125;); &#125; producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列queue01完毕\"); &#125;&#125; 延迟投递和定时投递12&lt;!--activemq.xml在boker属性上配置schedulerSupport=\"true\"--&gt;&lt;broker xmlns=\"http://activemq.apache.org/schema/core\" brokerName=\"localhost\" dataDirectory=\"$&#123;activemq.data&#125;\" schedulerSupport=\"true\"&gt; Property name type description AMQ_SCHEDULED_DELAY long 延迟投递的时间 AMQ_SCHEDULED_PERIOD long 重复投递的时间间隔 AMQ_SCHEDULED_REPEAT int 重复投递次数 AMQ_SCHEDULED_CRON String Cron表达式 通过在ActiveMQ的配置文件中开启定时调度SchedulerSupport=&quot;true&quot;，默认为false。然后使用ScheduleMessage类进行消息属性配置。 1234567891011121314151617181920212223242526272829//生产者public class JmsProducer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue-delay\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); MessageProducer producer = session.createProducer(queue); //设置延迟投递时间 long delay = 3 * 1000; //设置重复投递的时间间隔 long period = 4 * 1000; //重复投递次数 int repeat = 5; for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"delay-message---\" + i); message.setLongProperty(ScheduleMessage.AMQ_SCHEDULED_DELAY, delay); message.setLongProperty(ScheduleMessage.AMQ_SCHEDULED_PERIOD, period); message.setIntProperty(ScheduleMessage.AMQ_SCHEDULED_REPEAT, repeat); producer.send(message); &#125; producer.close(); session.close(); connection.close(); &#125;&#125; 重试机制那些情况会引发消息重发？ Client用了transactions且在session中调用了rollback() Client用了transactions且在调用commit()之前关闭或者没有commit Client在CLINET_ACKNOWLEDGE的传递模式下，在session中调用了recover() 默认消息重发的时间间隔是每秒钟，重发次数是6次。 有毒消息Poison ACK： 一个消息被redelivedred超过默认的最大重发次数（默认6次）时。消费端会给MQ发送一个Poison ack表示这个消息有毒，告诉broker不要再发了。这个时候broker会把这个消息放到DLQ（死信队列），详情请参照官网。 属性 默认值 描述 collisionAvoidanceFactor 0.15 设置防止冲突范围的政府百分比，只有启动UseCollisionAvoidance参数时才生效，也就是在延迟时间再加一个 maximumRedelivers 6 最大重传次数，达到最大重连次数后抛出异常。为-1时不限制次数，为0时表示不进行重传。 maximumRedeliveryDelay -1 最大传送延迟，只在UseExponentialBackOff为true时有效（V5.5），假设首次重连间隔为10ms，倍数为2，那么第二次重连时间间隔为20ms，第三次重连时间间隔为40ms，当重连时间间隔的大于最大重连时间间隔时，以后每次重连时间间隔都为最大重连时间间隔。 initialRedeliveryDelay 1000L 初始重发延迟时间 redeliveryDelay 1000L 重发延迟时间，当initialRedeliveryDelay=0时生效 useCollisionAvoidance false 启用防止冲装功能 useExponentialBackOff false 启用指数倍数递增的方式增加延迟时间 backOffMultiplier 5 重连时间间隔递增倍数，只有值大于1和启动useExponentialBackOff参数时才生效 配置重试次数12345678910111213//修改最大重试次数public class JmsConsumer_Redelivery &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue-redelivery\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //使用自身的配置类，设置重试次数3次 RedeliveryPolicy redeliveryPolicy = new RedeliveryPolicy(); redeliveryPolicy.setMaximumRedeliveries(3); activeMQConnectionFactory.setRedeliveryPolicy(redeliveryPolicy); //省略后续代码... &#125;&#125; 整合Spring123456789&lt;!--定义reDelivery重发机制--&gt;&lt;bean id=\"activeMQRedeliveryPolicy\" class=\"org.apache.activemq.RedeliveryPolicy\"&gt; &lt;property name=\"maximumRedeliveries\" value=\"3\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--创建连接工厂并指定配置--&gt;&lt;bean id=\"connectionFactory\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.1.132:61616\"&gt;&lt;/property&gt; &lt;property name=\"redeliveryPolicy\" ref=\"activeMQRedelivery\" /&gt;&lt;/bean&gt; 死信队列ActiveMQ中引入了死信队列（Dead Letter queue）的概念，即一条消息再被重发了多次后（默认为重发6次redeliveryConter==6），将会被ActiveMQ移入私信队列，开发人员可以在这个Queue中查看处理出错的消息，进行人工干预，主要用来处理失败的消息，详情请查看官网。 一般生产环境中在使用MQ的时候设计两个队列：一个是核心业务队列，一个是死信队列。 核心业务队列，就是比如上图专门用来让订单系统发送订单消息的，然后另外一个私信队列就是用来处理异常情况的。 假设第三方物流系统故障了，此时无法请求，那么仓储系统每次消费到一条订单消息，尝试通知发货和配送都会遇到对方的接口报错。此时仓储系统就可以把这条消息拒绝访问或者标志位处理失败。一旦表这条消息处理失败后，MQ就会把这条消息转入提前设置好的一个死信队列中。 然后看到的就是，在第三方物流系统故障期间，所有订单消息全部处理失败，全部都会转入私信队列，然后你的仓储系统得专门有一个后台线程，监控第三方系统是否正常。一旦发现对方回复正常，这个后台线程就从私信队列消费处理失败的订单，重新执行发货和配送的通知逻辑。 共享死信队列SharedDeadLetterStrategy（共享死信队列），将所有的DeadLetter保存在一个共享的队列中，这是ActiveMQ broker端默认的策略。 共享队列默认为ActiveMQ.DLQ，可以通过deadLetterQueue属性来设定。 123&lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy deadLetterQueue=\"DLQ-QUEUE\" /&gt;&lt;/deadLetterStrategy&gt; 个人死信队列IndividualDeadLetterStrategy（个人死信队列），把DeadLetter放入各自的死信通道中。 对于Queue而言，死信通道的前缀默认为ActiveMQ.DLQ.Queue. 对于Topic而言，死信通道的前缀默认为ActiveMQ.DLQ.Topic. 比如队列Order，那么它对应的死信队列通道为ActiveMQ.DLQ.Queue.Order，我们使用queuePrefix、topicPrefix来指定上述前缀。 默认情况下，无论是Topic还是Queue，Broker将使用Queue来保存DeadLetter，即死信通道通常为Queue，不过开发也可以指定为Topic。 12345&lt;policyEntry queue=\"order\"&gt; &lt;deadLetterStrategy&gt; &lt;individualDeadLetterStrategy queuePrefix=\"DLQ.\" useQueueForQueueMessages=\"false\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 将队列Order中出现的DeadLetter保存在DLQ.Order中，不过此时DLQ.Order为Topic。 属性useQueueForQueueMessages设置使用队列保存死信队列，还可以设置useQueueForTopicMessages，使用Topic来保存死信队列，默认为true。 自动删除过期消息有时需要直接删除过期的消息而不需要发送到死信队列中，processExpired表示是否将过期消息放入私信队列，默认为true。 123456&lt;!--\"&gt; \"类似SQL的 * --&gt;&lt;policyEntry queue=\"&gt; \" &gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStragegy processExpired=\"false\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 存放非持久消息默认情况下，ActiveMQ不会把非持久的死消息发送到死信队列中。processNonPersistent表示是否将非持久化消息放入死信队列，默认为false。 如果想把非持久化的消息发送到死信队列中，需要设置属性processNonPersistent=&quot;true&quot; 12345&lt;policyEntry queue=\"&gt; \"&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processNonPersistent=\"true\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 重复消费如何保证消息不被重复消费？幂等性问题？ ​ 网络延迟传输中，会造成进行MQ重试中，在重试过程中，可能会造成重复消费。 如果消息是做数据库的插入操作，给这个消息做一个唯一主键，那么就算出现重复消息的情况，就会导致主键冲突，避免数据库出现脏数据。 或者准备个第三方来做消息记录，以redis为例，给消息分配一个全局id，只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis，消费者开始消费前，先去redis中查询有没有消费记录即可。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/categories/ActiveMQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/tags/ActiveMQ/"}]},{"title":"'Thread（二） 线程同步容器'","slug":"thread-containers","date":"2020-05-21T15:30:00.000Z","updated":"2020-05-26T04:01:36.575Z","comments":true,"path":"2020/05/21/thread-containers/","link":"","permalink":"https://midkuro.github.io/2020/05/21/thread-containers/","excerpt":"","text":"线程同步容器同步容器类同步容器类包括Vector和Hashtable，二者是早期JDK的一部分，这些同步的封装器类是由Conllections.synchronizedXxx等工厂方法创建的。 这些类实现线程安全的模式是：将他们的状态封装起来，并对每个公有方法进行同步，使得每次只有一个线程能访问容器的状态。 同步容器类的问题同步容器类都是线程安全的，但是在某些情况下可能需要额外的客户端加锁来保护复合操作。容器上常见的复合操作包括：迭代、跳转（根据指定顺序找到当前元素的下一个元素）以及条件运算。 例如 “若没有则添加”，当其他线程并发地修改容器时，他们可能会表现出意料之外的行为。 123456789public static Object getLast(Vector list) &#123; int lastIndex = list.size() - 1; return list.get(lastIndex);&#125;public static void deleteLast(Vector list) &#123; int lastIndex = list.size() -1; list.remove(liastIndex);&#125; 这些方法看似没有任何问题，从某种程度来说也确实如此——无论多少个线程同时调度他们，也不破坏Vector。但是从这些调用者角度来看，情况就不同了。 如果 线程A 在包含10个元素的Vector上调用getLast，同时 线程B 在同一个Vector上调用deleteLast，这些操作的交替执行如下图。 交替调用getLast和deleteList时将抛出ArrayIndexOutOfBoundsException，同步容器类通过其自身的锁来保护它的每个方法，通过获得容器类的锁，我们可以使getLast和deleteLast成原子操作，并确保Vector的大小在调用size和get之间不会发生变化。 12345678910111213public static Object getLast(Vector list) &#123; synchronized (list) &#123; int lastIndex = list.size() - 1; return list.get(lastIndex); &#125;&#125;public static void deleteLast(Vector list) &#123; synchronized (list) &#123; int lastIndex = list.size() -1; list.remove(liastIndex); &#125;&#125; 在调用size和相应的get之间，Vector的长度可能会发生变化，这种风险在对Vector中的元素进行迭代时仍然会出现。 123for(int i = 0; i &lt; vector.size(); i++) &#123; doSomething(vector.get(i));&#125; 在迭代的过程中，有其他线程并发地修改Vector时，可能抛出异常，但并不意味着Vector就不是线程安全的。Vector的状态仍然是有效的，但是迭代中抛异常显然不是人们所期望的。 我们可以通过加锁来解决不可靠迭代的问题，但是要牺牲一些伸缩性，通过在迭代期间持有Vector的锁，然而，这样同样会导致其他线程在迭代期间无法访问它，因此降低了并发性。 12345synchronized (vector) &#123; for(int i = 0; i &lt; vector.size(); i++) &#123; doSomething(vector.get(i)); &#125;&#125; ConcurrentModificationException无论直接迭代还是for-each循环，对容器类进行迭代的标准方式都是使用Iterator，如果有其他线程并发地修改容器，即使是使用迭代器也无法避免在迭代期间对容器加锁。 在设计同步容器类的迭代器时并没有考虑并发修改的问题，并且它们表现出的行为是 “及时失败” 的。这意味着，当他们发现容器在迭代过程中被修改时，就会抛出一个ConcurrentModificationException异常。 这种 “及时失败” 的迭代器并不是一种完善的处理机制，而只是善意的捕获并发错误，因此只能作为并发问题的预警指示器。它们采用的实现方式是，将计数器的变化于容器关联起来：如果迭代期间计数器被修改，那么hasNext或next将抛出ConcurrentModificationException。 然而有些时候开发人员并不希望在迭代期间对容器加锁，如果容器的规模很大，或者执行时间很长，长时间对容器加锁会降低程序的可伸缩性，持有锁的时间越长，那么在锁上的竞争就可能越激烈，如果许多线程都在等待锁被释放，那么将极大地降低吞吐量和CPU的利用率。 如果不希望在迭代期间对容器加锁，那么一种替代方法就是 “克隆容器“，并在副本上进行迭代，由于副本被封闭在线程内，因此其他线程不会在迭代期间对其进行修改，这样就避免了抛出异常，但是在克隆过程中仍然需要对容器加锁。 隐藏迭代器虽然加锁可以防止迭代器抛出ConcurrentModificationException，但在某些情况下，迭代器会隐藏起来，如以下程序 123456789101112131415public class HiddenIterator &#123; private final Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); public synchronized void add(Integer i) &#123; set.add(i); &#125; public synchronized void remove(Integer i) &#123; set.remove(i); &#125; public void addTenThings() &#123; Random r = new Random(); for(int i = 0; i &lt; 10; i++) add(r.nextInt()); System.out.println(\"printSet:\" + set); &#125;&#125; 该方法可能会抛出ConcurrentModificationException，因为在打印的过程中，toString对容器进行迭代，当然真正的问题在于HiddenIterator不是线程安全的。在使用println中的set之前必须先获得锁，但是在代码中通常会忽略。 ConcurrentHashMap与HashMap一样，ConcurrentHashMap也是基于散列的Map，但它使用了一种完全不同的加锁策略来提供更高的并发性和伸缩性，ConcurrentHashMap并不是将每个方法都在同一个锁上同步并使得每次只有一个线程访问容器，而是使用一种粒度更细的加锁机制来实现更大程度的共享，这种机制称为分段锁。 在这种机制中，任意数量的读取线程可以并发地访问Map，执行读取操作的线程和执行写入的操作的线程可以并发地访问Map，并且一定数量的写入线程可以并发修改Map，ConcurrentHashMap带来的结果是，在并发访问环境下将实现更高的吞吐量，而在单线程环境中只损失非常小的性能。 ConcurrentHashMap与其他并发容器一起增强了同步容器类：它提供的迭代器不会抛出ConcurrentModificationException因此不需要再迭代过程中对容器加锁，ConcurrentHashMap返回的迭代器具有弱一致性，弱一致性的迭代器可以容忍并发的修改，当创建迭代器时会遍历已有的元素，并可以（但是不保证）在迭代器被构造后将修改操作反应给容器。 与Hashtable和synchronizedMap相比，ConcurrentHashMap有着更多的优势以及更少的劣势，因此在大多数情况下，用ConcurrentHashMap来替代同步Map能进一步提高代码的可申缩性。 额外的原子Map操作一些常见的复合操作，例如：若没有则添加、若相等则移除和若相等则替换等，都已经实现为原子操作并且在ConcurrentMap的接口中声明。 1234567891011public interface ConcurrentMap&lt;K, V&gt; extends Map&lt;K, V&gt; &#123; //仅当K没有相应的映射值才插入 V putIfAbsent(K key, V value); //仅当K被映射到V时才移除 boolean remove(Object key, Object value); //仅当K被映射到oldValue时才替换为newValue V replace(K key, V value); //仅当K呗银蛇到某个值时才替换为newValue boolean replace(K key, V oldValue, V newValue); &#125; CopyOnWriteArrayList “本篇文章主要摘自《JAVA 并发编程实战》”","categories":[{"name":"Thread","slug":"Thread","permalink":"https://midkuro.github.io/categories/Thread/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.github.io/tags/Thread/"}]},{"title":"'Thread（一） 线程安全性'","slug":"thread-safety","date":"2020-05-21T15:20:00.000Z","updated":"2020-05-26T04:01:20.446Z","comments":true,"path":"2020/05/21/thread-safety/","link":"","permalink":"https://midkuro.github.io/2020/05/21/thread-safety/","excerpt":"","text":"线程安全性什么是线程安全性多线程访问某个类时，不管运行环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或者异步，这个类都能表现出正确的行为，那么就称这个类是线程安全的。 示例：一个无状态的Servlet 123456//Servlet容器是一个单例多线程的容器对象public class StatelessServlet implements Servlet &#123; public void service(String param) &#123; //多线程调度该方法 &#125;&#125; StatelessServlet是无状态的，它既不包含任何域，也不包含任何对其他类中域的引用。计算过程中的临时状态存储在线程栈帧的局部变量表中，并且只能由正在执行的线程访问。 访问StatelessServlet的线程不会影响另一个访问StatelessServlet的线程计算结果。由于线程访问无状态对象的行为并不会影响其他线程中操作的正确性，因此，无状态对象一定是线程安全的。 原子性当我们在无状态对象中增加一个状态时，会出现什么情况？假设我们希望增加一个 “命中计数器” 来统计所处理的请求数量。一种直观的方法是增加一个long类型的域，并且每次处理一个请求就将这个值加1。 12345678@NotThreadSafepublic class UnsafeCountingServlet implements Servlet &#123; private long count = 0; public void service(String param) &#123; //执行方法逻辑 ++count; &#125;&#125; 不幸的是，UnsafeContingServlet并非线程安全的，尽管它在单线程环境中能够正确运行，这个类可能会丢失一些更新操作，++count并非原子的，它包含了三个独立的操作 ：读取count值，将值加1，然后将计算结果写入count。这是一个 “读取-修改-写入” 的操作，并且其结果状态依赖于之前的状态。 上述例子给出了两个线程在没有同步的情况下，同时对一个计数器执行递增操作时发生的情况。如果计数器的初始值为9，那么在某些情况下，每个线程读到的值都为9，接着执行递增操作，并且都将计数器的值设置为10。命中计数器的值就讲偏差1。 竟态条件在并发编程中，这种由于不恰当的执行时序而出现不正确的结果是一种非常重要的情况，它有一个正式的名字：竟态条件（Race Condition）。 最常见的竟态条件类型就是 “先检查后执行(Check-then-Act)” 操作，即通过一个可能失效的观测结果来决定下一步的动作。 123456789@NotThreadSafepublic class LazyInitRace &#123; private Object instance = null; public Object getInstance() &#123; if(instance == null) instance = new Object(); return instance; &#125;&#125; 在LazyInitRace中包含一个竟态条件，它可能会破坏这个类的正确性。假定 线程A 和 线程B 同时执行getInstance，A看到instance为空，因而创建一个新的Object实例，B同样需要判断instance是否为空，此时的instance是否为空，取决于不可预测的时序，包括线程的调度方式，以及A需要花多长时间来初始化Object并设置instance，如果当B检查时，instance为空，那么两次调用getInstance时可能会得到不同的结果。 在UnsafeCountingServlet的统计命中计数器中存在另一种竟态条件。在 “读取-修改-写入” 操作中，基于对象之前的状态来定义对象状态的转换，要递增一个计数器，你必须知道它之前的值，并确保在执行更新的过程中没有其他线程会修改或使用这个值。 12345678@ThreadSafepublic class CountingServlet implements Servlet &#123; private final AtomicLong count = new AtomicLong(0); public void service(String param) &#123; //执行方法逻辑 count.incrementAndGet(); &#125;&#125; 在java.util.concurrent.atomic包中包含一些原子变量类，通过用AtomicLong来代替long类型的计数器，能够确保所有对计数器状态的访问都是原子的。 内置锁Java提供了一种内置的锁机制来支持原子性：同步代码块(Synchronized Block)，同步代码块包括两个部分：一个作为锁的对象引用，一个作为由这个锁保护的代码块。 以关键字synchronized来修饰方法就是一种横跨整个方法体的同步代码快，其中该同步代码块的锁就是方法调用所在的对象。静态的synchronized方法以Class对象作为锁。 123synchronized (lock) &#123; //访问或者修改由锁保护的共享状态&#125; 每个Java对象都可以用作一个实现同步的锁，这些锁被称为内置锁或监视器锁。线程在进入同步代码块之前会自动获得锁，并且在退出同步代码块时自动释放锁。 Java的内置锁相当于一种互斥锁，最多只有一个线程能够持有这种锁，当 线程A 尝试获取一个由 线程B 持有的锁时，线程A 必须等待或者阻塞，直到 线程B 释放这个锁，如果B永远不释放锁，那么A也将永远地等下去。 重入当某个线程请求一个由其他线程持有的锁时，发出的请求的线程就会阻塞。然而，由于内置锁是可重入的，因此如果某个线程试图获得一个已经由它持有的锁，那么这个请求就会成功。 “重入”获取锁的操作粒度是“线程”，重入的实现方法是，为每一个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁就被认为是没有被任何线程持有，当线程请求一个未被持有的锁时，JVM将几下锁的持有者，并且将获取计数值置为1，如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码快时，计数器会相应递减，当计数值为0时，这个锁将被释放。 1234567891011public class Father &#123; public synchronized void method() &#123; //逻辑 &#125;&#125;public class Son extends Father &#123; public synchronized void method() &#123; System.out.println(\"calling\"); super.method(); &#125;&#125; 子类改写了父类的synchronized方法，然后调用父类中的方法，由于Father和Son都是synchronized方法，因此每个method方法在执行前都会获取Father上的锁，然而如果内置锁不是可重入的，那么在调用super.method()时将无法获得Father上的锁。 对象的共享可见性123456@NotThreadSafepublic class MutableInteger &#123; private int value; public int get() &#123; return value;&#125; public void set(int value) &#123;this.value = value;&#125;&#125; 1234567891011121314151617181920public static void main(String[] args) &#123; MutableInteger object = new MutableInteger(); for (int i = 0; i &lt; 10; i++) &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; while (true) &#123; int i = object.get(); System.out.println(i + \"-\" + new Date().toString()); if (i == 100) &#123; break; &#125; &#125; &#125; &#125;); thread.start(); &#125; object.set(100); System.out.println(new Date().toString());&#125; 输出结果： 123456789101112131415100-Thu Apr 16 16:17:04 CST 20200-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 20200-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020设置Value时间:Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 20200-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 20200-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020 MutableInteger不是线程安全的，因为 get 和 set 都是在没同步的情况下访问 value 的，如果某个线程调用了set，那么另一个正在调用 get 的线程可能会看到更新后的 value 值，也可能看不到。 123456@ThreadSafepublic class SynchronizedInteger &#123; private int value; public synchronized int get() &#123; return value;&#125; public synchronized void set(int value) &#123;this.value = value;&#125;&#125; Volatile变量volatile变量用来确保将变量的更新操作通知到其他线程，当把变量申明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序，因此在读取volatile类型的变量时总会返回最新写入的值。 123456@ThreadSafepublic class VolatileInteger &#123; private volatile int value; public int get() &#123; return value;&#125; public void set(int value) &#123;this.value = value;&#125;&#125; 然而在访问volatile时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比synchronized关键字更轻量级的同步机制。 从内存的可见性角度来看，写入volatile变量相当于退出同步代码块，而读取volatile变量就相当于进入同步代码块，但并不建议过度依赖volatile变量提供的可见性，如果在代码中依赖volatile变量来控制状态的可见性，通常比使用锁的代码更脆弱，更难以理解。 尽管volatile只能确保可见性，在复合操作情况下，无法确保其正确性，如count++，具备了”读取-修改-写入”的复合操作。 加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。 当且仅当满足以下所有条件时，才应该使用volatile变量： 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。 该变量不会与其他状态变量一起纳入不变性条件中。 在访问变量时不需要加锁。 逸出提供一个对象的引用给作用域之外的代码，我们称做发布该对象。如果在对象构造完成之前就发布该对象，就会破坏线程安全性，当某个不应该发布的对象被发布时，这种情况被称为逸出。 1234567891011public class ThisEscape &#123; public ThisEscape() &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; //多线程代码 &#125; &#125;); thread.start(); &#125;&#125; 在ThisEscape中给出了一个this引用在构造函数中逸出的示例。this引用逸出的一个常见错误是，在构造函数中启动一个线程，当对象在其构造函数中创建一个线程时，this引用都会被新创建的线程共享，在对象未完全构造之前，新的线程就可以看见它。在构造函数创建线程并没有错误，但最好不要立即启动它。 当且仅当对象的构造函数返回时，对象才处于可预测和一致的状态。当从构造函数中发布对象时，只是发布了一个尚未构造完成的对象，即使发布语句位于构造函数的最后一行，那么这种对象被认为是不正确构造。 不要再构造过程中使this引用逸出。 线程封闭当访问共享的可变数据时，通常需要使用同步，一种避免使用同步的方式就是不共享数据。如果仅在单线程内访问数据，就不需要同步。这种技术被称为线程封闭（Thread Confinement），它是实现线程安全性的最简单方式之一。 栈封闭是线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问对象，局部变量固有属性就是封闭在执行线程中，他们位于执行线程的栈中，其他线程无法访问这个栈。 1234public int execute() &#123; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); return 0;&#125; 此时只有一个引用指向集合list，这个引用被封闭在局部变量中，因此也被封闭在执行线程中，然而如果发布了对集合list（或者该对象中的任何内部数据）的引用，那么封闭性呗破坏，并导致对象list逸出。 不变性如果某个对象在被创建后其状态就不能被修改，那么这个对象就称为不可变对象。线程安全性是不可变对象的固有属性之一，他们的不变性条件是由构造函数创建的，不可变对象一定是线程安全的。 不可变性不等于将对象所有域都声明为final类型，即使对象中所有域都是final类型的，这个对象也仍然是可变的，因为final类型的域中可以保存对可变对象的引用。 123456public final class MutableClass &#123; private final List&lt;String&gt; lists = new ArrayList&lt;&gt;(); public void setValue(String value) &#123; lists.add(value); &#125;&#125; 当满足以下条件时，对象才是不可变的： 对象创建以后其状态就不能修改。 对象的所有域都是final类型。 对象是正确创建的（在对象的创建期间，this引用没有逸出） 12345678910public final class ImmutableClass &#123; private final List&lt;String&gt; lists = new ArrayList&lt;&gt;(); public ImmutableClass() &#123; lists.add(\"apple\"); lists.add(\"banana\"); &#125; public boolean isContains(String value) &#123; return lists.contains(value); &#125;&#125; 即使对象是可变的，通过将对象的某些域声明为final类型，仍然可以简化对状态的判断，相当于限制了该对象可能的状态变化。 除非需要更高的可见性，否则应将所有域都声明为私有域是一个良好的变成习惯，除非需要某个域是可变的，否则应将其声明为final域，也是一个良好的变成习惯。 要安全地发布一个对象，对象的引用以及对象的状态必须同时对其他线程可见，一个正确构造的对象可以通过以下方式来安全地发布： 在静态初始化函数中初始化一个对象引用。 将对象的引用保存到valatile类型的域或者AtomicReferance对象中 将对象的引用保存到某个正确的构造对象的final类型域中。 将对象的引用保存到一个由锁保护的域中。 在线程安全容器内部同步意味着，将对象放到某个容器，例如Vector或者synchronizedList时将满足上述最后一条需求。 线程安全库中的容器提供了以下的安全发布保证： 通过将一个键或者值放入Hashtable、synchronizedMap或者ConcurrentMap中，可以安全将它发布给任何从这些容器中访问它的线程。 通过将某个元素放入Vector、CopyOnWriteArrayList、CopyOnWriteArraySet、SynchronizedList或者synchronizedSet中，可以将该元素安全地发布到任何从这些队列中访问该元素的线程。 事实不可变对象如果对象从技术上来说事可变的，但其状态在发布后不会再改变，那么把这种对象称之为事实不可变对象。这些对象不需要满足不可变性的严格定义，在这些对象发布后，程序只需将它们视为不可变对象即可。 在没有额外的同步的情况下，任何线程都可以安全地使用被安全发布的事实不可变对象。 可变对象如果对象在构造后可以修改，那么安全发布只能确保 “发布当时” 状态的可见性，对于可变对象，不仅在发布对象时需要使用同步，而且每次对象访问时同样需要使用同步来确保后续修改操作的可见性。要安全地共享可变对象，这些对象就必须被安全地发布，并且必须是线程安全的或者由某个锁保护起来。 对象发布需求取决于它的可变性： 不可变对象可以通过任意机制来发布。 事实不可变对象必须通过安全方式来发布。 可变对象必须通过安全方式来发布，并且必须是线程安全的或者由某个锁保护起来的。 “本篇文章主要摘自《JAVA 并发编程实战》”","categories":[{"name":"Thread","slug":"Thread","permalink":"https://midkuro.github.io/categories/Thread/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.github.io/tags/Thread/"}]},{"title":"'JVM（三） 垃圾收集器'","slug":"garbage-collector","date":"2020-05-21T14:40:00.000Z","updated":"2020-05-26T03:59:30.267Z","comments":true,"path":"2020/05/21/garbage-collector/","link":"","permalink":"https://midkuro.github.io/2020/05/21/garbage-collector/","excerpt":"","text":"垃圾收集器与内存分配策略GC回收的区间 清理Eden区和Survivor区叫Minor GC； 清理Old区叫Major GC； 清理整个堆空间————包括年轻代和老年代叫Full GC； GC回收的定位保守式 GC在进行 GC 的时候，会从一些已知的位置（也就是GC Roots）开始扫描内存，扫描到一个数字就判断他是不是可能是指向GC堆中的一个指针,然后一直递归的扫描下去，最后完成可达性分析。 这里扫描会涉及上下边界检查，GC堆的上下界是已知的、对齐检查，通常分配空间的时候会有对齐要求，假如说是4字节对齐，那么不能被4整除的数字就肯定不是指针。 这种模糊的判断方法因为无法准确判断一个位置上是否是真的指向 GC ，GC 采取一种保守的态度，把所有可疑的引用均当作指针，所以被命名为保守式 GC。 优点：不需要准确的判断出一个指针，所以效率快。 缺点：不能识别指针和非指针，对于一些已经死掉的对象，很可能会被误认为仍有地方引用他们，引起无用的内存占用，造成资源浪费。 准确式 GC与保守式 GC 相对的就是准确式 GC，何为 准确式 GC？就是我们准确的知道，某个位置上面是否是指针。 也就是说给定某个位置上的某块数据，要能知道它的准确类型是什么，这样才可以合理地解读数据的含义； GC 所关心的含义就是 这块数据是不是指针。要实现这样的 GC，JVM就要能够判断出所有位置上的数据是不是指向 GC 堆里的引用，包括活动记录（栈、寄存器）里的数据。 在java中实现的方式是：从外部记录下类型信息，存成映射表，在HotSpot虚拟机中把这种映射表称之为OopMap，不同的虚拟机名称可能不一样。 GC开始的时候，就通过OopMap这样的一个映射表知道，在对象内的什么偏移量上是什么类型的数据，而且特定的位置记录下栈和寄存器中哪些位置是引用。 生成映射表的两种方式： 每次都遍历原始的映射表，循环的一个个偏移量扫描过去；这种用法也叫 “ 解释式 ”。 为每个映射表生成一块定制的扫描代码（想像扫描映射表的循环被展开的样子），以后每次要用映射表就直接执行生成的扫描代码；这种用法也叫 “ 编译式 ”。 半保守式 GCJVM可以选择在栈上不记录类型信息，而是通过让数据自身带上标记，也就是对象上记录类型信息。这样的话，扫描栈的时候仍然会跟保守式 GC的过程一样，但扫描到 GC 堆内的对象时因为对象带有足够类型信息了，JVM就能够判断出在该对象内什么位置的数据是引用类型了，这种是半保守式 GC。 垃圾收集器如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。这里讨论的收集器基于JDK 1.7 Update 14之后的 HotSpot 虚拟机，这个虚拟机包含的所有收集器如下图所示 上图展示了 7 种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。接下来将逐一介绍这些收集器的特性、基本原理和使用场景，并重点分析 CMS 和 G1 这两款相对复杂的收集器，了解它们的部分运作细节。 先明确一点：下文是各个收集器的比较，但不是为了挑出最好的收集器，而是挑选最合适的收集器。 Serial收集器 (串行收集器)Serial收集器是最基本、发展历史最悠久的收集器，曾经是虚拟机新生代收集的唯一选择。这是一个单线程的收集器，但它的 “ 单线程 ” 的意义并不仅仅说明它只会使用一个 CPU 或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。 “Stop The World“ 这个名字也许听起来很酷，但这项工作实际上是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难以接受的。下图示意了 Serial/Serial Old 收集器的运行过程。 实际上到现在为止，它依然是虚拟机运行在 Client 模式下的默认新生代收集器。它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 在用户的桌面应用场景中，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本上不会再大了），停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，只要不是频繁发生，这点停顿是可以接受的。所以，Serial 收集器对于运行在 Client 模式下的虚拟机来说是一个很好的选择。 ParNew收集器ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括 Serial 收集器可用的所有控制参数（例如：-XX:SurvivorRatio、-XX:PretenureSizeThreshold、-XX:HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与 Serial 收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。ParNew 收集器的工作过程如下图所示。 ParNew 收集器除了多线程收集之外，其他与 Serial 收集器相比并没有太多创新之处，但它却是许多运行在 Server 模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了 Serial 收集器外，目前只有它能与 CMS 收集器（并发收集器，后面有介绍）配合工作。 ParNew 收集器在单 CPU 的环境中不会有比 Serial 收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证可以超越 Serial 收集器。 当然，随着可以使用的 CPU 的数量的增加，它对于 GC 时系统资源的有效利用还是很有好处的。它默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多（如 32 个)的环境下，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。 注意，从 ParNew 收集器开始，后面还会接触到几款并发和并行的收集器。这里有必要先解释两个名词：并发和并行。这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，它们可以解释如下。 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个 CPU 上。 Parallel Scavenge收集器Parallel Scavenge 收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器……看上去和 ParNew 都一样，那它有什么特别之处呢？ Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS 等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标则是达到一个可控制的吞吐量（Throughput）。 所谓吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了 100 分钟，其中垃圾收集花掉1分钟，那吞吐量就是99% 。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。 MaxGCPauseMillis参数允许的值是一个大于 0 的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值。 不过大家不要认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些，收集 300MB 新生代肯定比收集 500MB 快吧，这也直接导致垃圾收集发生得更频繁一些，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每次停顿70毫秒。停顿时间的确在下降，但吞吐量也降下来了。 GCTimeRatio 参数的值应当是一个 0 到 100 的整数，也就是垃圾收集时间占总时间的比率，相当于是吞吐量的倒数。如果把此参数设置为 19，那允许的最大 GC 时间就占总时间的 5%（即 1/（1+19）），默认值为 99 ，就是允许最大 1%（即 1/（1+99））的垃圾收集时间。 由于与吞吐量关系密切，Parallel Scavenge 收集器也经常称为“吞吐量优先”收集器。除上述两个参数之外，Parallel Scavenge 收集器还有一个参数-XX:+UseAdaptiveSizePolicy值得关注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden 与 Survivor 区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为 GC 自适应的调节策略（GC Ergonomics）。 Serial Old 收集器Serial Old 是 Serial 收集器的老年代版本，它同样是一个单线程收集器，使用“标记-整理”算法。这个收集器的主要意义也是在于给 Client 模式下的虚拟机使用。如果在 Server 模式下，那么它主要还有两大用途：一种用途是在 JDK 1.5 以及之前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途就是作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。这两点都将在后面的内容中详细讲解。Serial Old 收集器的工作过程如下图所示。 Parallel Old收集器Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和“标记-整理”算法。这个收集器是在 JDK 1.6 中才开始提供的，在此之前，新生代的 Parallel Scavenge 收集器一直处于比较尴尬的状态。 原因是，如果新生代选择了 Parallel Scavenge 收集器，老年代除了 Serial Old（PS MarkSweep）收集器外别无选择（Parallel Scavenge 收集器无法与 CMS 收集器配合工作）。 由于老年代 Serial Old 收集器在服务端应用性能上的 “ 拖累 ”，使用了 Parallel Scavenge 收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集中无法充分利用服务器多 CPU 的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有 ParNew 加 CMS 的组合 “ 给力 ”。 直到 Parallel Old 收集器出现后，“ 吞吐量优先 ” 收集器终于有了比较名副其实的应用组合，在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。Parallel Old 收集器的工作过程如下图所示。 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。 目前很大一部分的 Java 应用集中在互联网站或者 B/S 系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS 收集器就非常符合这类应用的需求。 从名字（包含”Mark Sweep”）上就可以看出，CMS 收集器是基于“标记—清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤，包括： 初始标记（CMS initial mark） 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） 其中，初始标记、重新标记这两个步骤仍然需要 “Stop The World“。初始标记仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，并发标记阶段就是进行 GC RootsTracing 的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 CMS 是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、低停顿，但是 CMS 还远达不到完美的程度，它有以下 3 个明显的缺点： 第一、导致吞吐量降低。CMS 收集器对 CPU 资源非常敏感。其实，面向并发设计的程序都对 CPU 资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。 CMS 默认启动的回收线程数是（CPU数量+3）/4，也就是当 CPU 在4个以上时，并发回收时垃圾收集线程不少于 25% 的 CPU 资源，并且随着 CPU 数量的增加而下降。但是当 CPU 不足 4 个（譬如2个）时，CMS 对用户程序的影响就可能变得很大，如果本来 CPU 负载就比较大，还分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了 50%，其实也让人无法接受。 第二、CMS 收集器无法处理浮动垃圾（Floating Garbage），可能出现”Concurrent Mode Failure”失败而导致另一次 Full GC（新生代和老年代同时回收） 的产生。由于 CMS 并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留待下一次 GC 时再清理掉。这一部分垃圾就称为 “ 浮动垃圾 ” 。 也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS 收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。 在 JDK 1.5 的默认设置下，CMS收集器当老年代使用了 68% 的空间后就会被激活，这是一个偏保守的设置，如果在应用中老年代增长不是太快，可以适当调高参数-XX:CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数从而获取更好的性能，在 JDK 1.6 中，CMS 收集器的启动阈值已经提升至 92% 。 要是 CMS 运行期间预留的内存无法满足程序需要，就会出现一次 “Concurrent Mode Failure” 失败，这时虚拟机将启动后备预案：临时启用 Serial Old 收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX:CM SInitiatingOccupancyFraction设置得太高很容易导致大量 “Concurrent Mode Failure” 失败，性能反而降低。 第三、产生空间碎片。 CMS 是一款基于“标记—清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次 Full GC 。 为了解决这个问题，CMS 收集器提供了一个-XX:+UseCMSCompactAtFullCollection开关参数（默认就是开启的），用于在CMS收集器顶不住要进行 Full GC 时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。虚拟机设计者还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction，这个参数是用于设置执行多少次不压缩的 Full GC 后，跟着来一次带压缩的（默认值为0，表示每次进入Full GC时都进行碎片整理）。 G1收集器G1（Garbage-First）收集器是当今收集器技术发展的最前沿成果之一，G1 是一款面向服务端应用的垃圾收集器。HotSpot 开发团队赋予它的使命是（在比较长期的）未来可以替换掉 JDK 1.5 中发布的 CMS 收集器。与其他 GC 收集器相比，G1 具备如下特点。 并行与并发： G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短 Stop-The-World 停顿的时间，部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 Java 程序继续执行。 分代收集： 与其他收集器一样，分代概念在 G1 中依然得以保留。虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次 GC 的旧对象以获取更好的收集效果。 空间整合： 与 CMS 的 “ 标记—清理 ” 算法不同，G1 从整体来看是基于 “ 标记—整理 ” 算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着 G1 运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 GC 。 可预测的停顿： 这是 G1 相对于 CMS 的另一大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时 Java（RTSJ）的垃圾收集器的特征了。 在 G1 之前的其他收集器进行收集的范围都是整个新生代或者老年代，而 G1 不再是这样。使用 G1 收集器时，Java 堆的内存布局就与其他收集器有很大差别，它将整个 Java 堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分 Region （不需要连续）的集合。 G1 收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1 在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region（这也就是Garbage-First名称的来由），保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。 在 G1 收集器中，Region 之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使用 Remembered Set 来避免全堆扫描的。 G1 中每个Region 都有一个与之对应的 Remembered Set，虚拟机发现程序在对 Reference 类型的数据进行写操作时，会产生一个 Write Barrier暂时中断写操作，检查 Reference 引用的对象是否处于不同的 Region 之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过 CardTabl 把相关引用信息记录到被引用对象所属的 Region 的 Remembered Set 之中。当进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描也不会有遗漏。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤： 初始标记（Initial Marking） 并发标记（Concurrent Marking） 最终标记（Final Marking） 筛选回收（Live Data Counting and Evacuation） G1 的前几个步骤的运作过程和 CMS 有很多相似之处。 初始标记阶段仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改 TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的 Region 中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记阶段是从 GC Root 开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 而最终标记阶段则是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中，这阶段需要停顿线程，但是可并行执行。 最后在筛选回收阶段首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划，从Sun公司透露出来的信息来看，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。通过下图可以比较清楚地看到G1收集器的运作步骤中并发和需要停顿的阶段。 GC日志阅读 GC 日志是处理 Java 虚拟机内存问题的基础技能，它只是一些人为确定的规则，没有太多技术含量。 每一种收集器的日志形式都是由它们自身的实现所决定的，换而言之，每个收集器的日志格式都可以不一样。但虚拟机设计者为了方便用户阅读，将各个收集器的日志都维持一定的共性，例如以下两段典型的 GC 日志： 1233.125 : [GC [DefNew : 3324K-＞152K（3712K），0.0025925 secs] 3324K-＞152K（11904K），0.0031680 secs]100.667 : [Full GC [Tenured : 0 K-＞210K（10240K），0.0149142secs] 4603K-＞210K（19456K），[Perm:2999K-＞2999K（21248K）]，0.0150007 secs] [Times:user&#x3D;0.01 sys&#x3D;0.00，real&#x3D;0.02 secs] 最前面的数字33.125： 和 100.667： 代表了 GC 发生的时间，这个数字的含义是从 Java 虚拟机启动以来经过的秒数。 GC 日志开头的 [GC 和 [Full GC 说明了这次垃圾收集的停顿类型，而不是用来区分新生代 GC 还是老年代 GC 的。 如果有 Full ，说明这次 GC 是发生了 Stop-The-World的，例如下面这段新生代收集器 ParNew 的日志也会出现 [Full GC（这一般是因为出现了分配担保失败之类的问题，所以才导致 STW）。如果是调用 System.gc() 方法所触发的收集，那么在这里将显示 [Full GC（System）。 1[Full GC 283.736 : [ParNew : 261599K-＞261599K（261952K），0.0000288 secs] 接下来的 [DefNew、[Tenured、[Perm 表示 GC 发生的区域，这里显示的区域名称与使用的 GC 收集器是密切相关的，例如上面样例所使用的 Serial 收集器中的新生代名为 “Default New Generation“，所以显示的是 [DefNew。 如果是 ParNew 收集器，新生代名称就会变为 [ParNew，意为 “Parallel New Generation“。如果采用 Parallel Scavenge 收集器，那它配套的新生代称为 PSYoungGen，老年代和永久代同理，名称也是由收集器决定的。 后面方括号内部的 3324K-＞152K（3712K含义是 GC 前该内存区域已使用容量 -＞ GC 后该内存区域已使用容量 （该内存区域总容量）。而在方括号之外的 3324K-＞152K（11904K） 表示 GC 前 Java 堆已使用容量 -＞ GC 后 Java 堆已使用容量 （Java 堆总容量）。 再往后，0.0025925 secs 表示该内存区域 GC 所占用的时间，单位是秒。有的收集器会给出更具体的时间数据，如 [Times:user=0.01 sys=0.00，real=0.02 secs] ，这里面的 user、sys 和 real 与 Linux 的 time 命令所输出的时间含义一致，分别代表用户态消耗的 CPU 时间、内核态消耗的 CPU 事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time）。 CPU 时间与墙钟时间的区别是，墙钟时间包括各种非运算的等待耗时，例如等待磁盘 I/O、等待线程阻塞，而 CPU 时间不包括这些耗时，但当系统有多 CPU 或者多核的话，多线程操作会叠加这些 CPU 时间，所以读者看到 user 或 sys 时间超过 real 时间是完全正常的。 垃圾收集器参数总结JDK 1.7 中的各种垃圾收集器到此已全部介绍完毕，在描述过程中提到了很多虚拟机非稳定的运行参数，在下图中整理了这些参数供读者实践时参考。 内存分配与回收策略对象的内存分配，往大方向讲，就是在堆上分配，对象主要分配在新生代的Eden区上。少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。 对象优先在Eden分配大多数情况下，对象在新生代 Eden 区中分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。 虚拟机提供了-XX:+PrintGCDetails这个收集器日志参数，告诉虚拟机在发生垃圾收集行为时打印内存回收日志，并且在进程退出的时候输出当前的内存各区域分配情况。 123456789101112private static final int_1MB=1024 * 1024; /** *VM参数：-verbose:gc-Xms20M-Xmx20M-Xmn10M-XX:+PrintGCDetails -XX:SurvivorRatio=8 */ public static void testAllocation () &#123; byte[] allocation1,allocation2,allocation3,allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; allocation4 = new byte[4 * _1MB];//出现一次Minor GC &#125; 运行结果： 123456789101112[GC [DefNew : 6651K-＞148K（9216K），0.0070106 secs]6651K-＞6292K（19456K），0.0070426 secs][Times:user&#x3D;0.00 sys&#x3D;0.00，real&#x3D;0.00 secs]Heapdef new generation total 9216K,used 4326K[0x029d0000，0x033d0000，0x033d0000）eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）from space 1024K，14%used[0x032d0000，0x032f5370，0x033d0000）to space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）tenured generation total 10240K,used 6144K[0x033d0000，0x03dd0000，0x03dd0000）the space 10240K，60%used[0x033d0000，0x039d0030，0x039d0200，0x03dd0000）compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）the space 12288K，17%used[0x03dd0000，0x03fe0998，0x03fe0a00，0x049d0000）No shared spaces configured. 上方代码的 testAllocation() 方法中，尝试分配 3 个 2MB 大小和 1 个 4MB 大小的对象，在运行时通过-Xms20M、-Xmx20M、-Xmn10M这 3 个参数限制了 Java 堆大小为 20MB ，不可扩展，其中 10MB 分配给新生代，剩下的 10MB 分配给老年代。 -XX:SurvivorRatio=8决定了新生代中 Eden 区与一个 Survivor 区的空间比例是 8:1，从输出的结果也可以清晰地看到 eden space 8192K、from space 1024K、to space 1024K 的信息，新生代总可用空间为 9216KB（Eden区+1个Survivor区的总容量）。 执行 testAllocation() 中分配 allocation4 对象的语句时会发生一次 Minor GC，这次 GC 的结果是新生代 6651KB 变为 148KB ，而总内存占用量则几乎没有减少（因为 allocation1、allocation2、allocation3 三个对象都是存活的，虚拟机几乎没有找到可回收的对象）。 这次 GC 发生的原因是给 allocation4 分配内存的时候，发现 Eden 已经被占用了 6MB，剩余空间已不足以分配 allocation4 所需的 4MB 内存，因此发生 Minor GC。 GC 期间虚拟机又发现已有的 3 个 2MB 大小的对象全部无法放入 Survivor 空间（Survivor 空间只有 1MB 大小），所以只好通过分配担保机制提前转移到老年代去。 这次 GC 结束后，4MB 的 allocation4 对象顺利分配在 Eden 中，因此程序执行完的结果是 Eden 占用 4MB（被allocation4占用），Survivor 空闲，老年代被占用 6MB（被allocation1、allocation2、allocation3占用）。通过 GC 日志可以证实这一点。 Minor GC 和 Full GC 有什么不一样吗？ 新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。 老年代 GC（Major GC/Full GC）：指发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 Parallel Scavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程）。Major GC 的速度一般会比 Minor GC 慢 10 倍以上。 大对象直接进入老年代所谓的大对象是指，需要大量连续内存空间的 Java 对象，最典型的大对象就是那种很长的字符串以及数组（ byte[] 数组就是典型的大对象）。大对象对虚拟机的内存分配来说就是一个坏消息（特别是短命大对象，写程序的时候应当避免），经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。 虚拟机提供了一个 -XX:PretenureSizeThreshold 参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在 Eden 区及两个 Survivor 区之间发生大量的内存复制。 123456789private static final int_1MB=1024 * 1024; /** *VM参数：-verbose:gc-Xms20M-Xmx20M-Xmn10M-XX:+PrintGCDetails-XX:SurvivorRatio=8 *-XX:PretenureSizeThreshold=3145728 */ public static void testPretenureSizeThreshold () &#123; byte[] allocation; allocation = new byte[4 * _1MB];//直接分配在老年代中 &#125; 运行结果： 12345678910Heapdef new generation total 9216K,used 671K[0x029d0000，0x033d0000，0x033d0000）eden space 8192K，8%used[0x029d0000，0x02a77e98，0x031d0000）from space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）tenured generation total 10240K,used 4096K[0x033d0000，0x03dd0000，0x03dd0000）the space 10240K，40%used[0x033d0000，0x037d0010，0x037d0200，0x03dd0000）compacting perm gen total 12288K,used 2107K[0x03dd0000，0x049d0000，0x07dd0000）the space 12288K，17%used[0x03dd0000，0x03fdefd0，0x03fdf000，0x049d0000）No shared spaces configured. 执行以上代码中的 testPretenureSizeThreshold() 方法后，我们看到 Eden 空间几乎没有被使用，而老年代的 10MB 空间被使用了 40%，也就是 4MB 的 allocation 对象直接就分配在老年代中，这是因为 PretenureSizeThreshold 参数被设置为 3MB（就是 3145728，这个参数不能像 -Xmx 之类的参数一样直接写 3MB），因此超过 3MB 的对象都会直接在老年代进行分配。 注意 PretenureSizeThreshold 参数只对 Serial 和 ParNew 两款收集器有效，Parallel Scavenge 收集器不认识这个参数，Parallel Scavenge 收集器一般并不需要设置。如果遇到必须使用此参数的场合，可以考虑 ParNew 加 CMS 的收集器组合。 长期存活的对象将进入老年代虚拟机给每个对象定义了一个对象年龄（Age）计数器。 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并且对象年龄设为 1 。对象在 Survivor 区中每“熬过”一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就将会被晋升到老年代中。 对象晋升老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold设置。 动态对象年龄判定为了能更好地适应不同程序的内存状况，无须等到 MaxTenuringThreshold 中要求的年龄，同年对象达到 Survivor 空间的一半后，他们以及年龄大于他们的对象都将直接进入老年代。 空间分配担保在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。 如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败，如果允许，将继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次Minor GC，如果小于或者HandlePromotionFailure设置不允许，那么将进行Full GC。 “本篇文章主要摘自《深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》”","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/tags/JVM/"}]},{"title":"'JVM（二） 垃圾回收机制'","slug":"garbage-collection","date":"2020-05-21T14:30:00.000Z","updated":"2020-09-23T08:23:23.968Z","comments":true,"path":"2020/05/21/garbage-collection/","link":"","permalink":"https://midkuro.github.io/2020/05/21/garbage-collection/","excerpt":"","text":"垃圾回收机制想要了解垃圾收集策略，需要先了解 Java内存区域 说起垃圾收集（Garbage Collection，GC），经过半个多世纪的发展，目前的内存的动态分配与内存回收技术已经相当成熟，一切看起来都进入了 “ 自动化 ” 时代，那为什么还要去了解GC和内存分配呢？ 答案很简单：需要排查各种内存溢出、内存泄漏问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，就需要对这些 “ 自动化 ” 的技术实施必要的监控和调节。 上篇文章介绍了在内存运行时区域的各个部分，其中程序计数器、虚拟机栈、本地方法区随线程而生，随线程而灭，不需要过多考虑回收问题，因为方法结束或者线程结束时，内存自然就回收了，这里主要讨论的是 Java 堆和方法区，本章后续讨论中的 “ 内存 ”分配和回收也仅指着一部分内存。 GC完成需要思考的三件事： 哪些内存需要回收？ 什么时候回收？ 如何回收？ 对象判断机制引用计数法引用计数法（Reference Counting）：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；计数器为 0 时，对象就是不可能再被使用的。简单高效，缺点是无法解决对象之间相互循环引用的问题。 举个简单的例子： 12345678910111213141516public class ReferenceTest &#123; public Object instance = null; public static void test() &#123; ReferenceTest objA = new ReferenceTest(); ReferenceTest objB = new ReferenceTest(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; System.gc(); &#125;&#125; 很显然，在这种情况下，引用计数法是无法解决的，而虚拟机并没有因为这两个对象互相引用就不回收它们，这也从说明虚拟机并不是通过引用计数法来判断对象是否存活的。 可达性分析算法可达性分析（Reachability Analysis），通过一系列的称为 “GC Roots”，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是不可用的。 在 Java 语言中，可作为 GC Roots 的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中 JNI（Native方法）引用的对象 作为 GC Roots 的节点主要在全局性的引用与执行上下文中。要明确的是，Tracing GC必须以当前存活的对象集为 Roots，因此必须选取确定存活的引用类型对象。 GC 管理的区域是 Java 堆，虚拟机栈、方法区和本地方法栈不被 GC 所管理，因此选用这些区域内引用的对象作为 GC Roots，是不会被 GC 所回收的。 其中虚拟机栈和本地方法栈都是线程私有的内存区域，只要线程没有终止，就能确保它们中引用的对象的存活。而方法区中类静态属性引用的对象是显然存活的。常量引用的对象在当前可能存活，因此，也可能是 GC roots 的一部分。 再谈引用JDK1.2 以前，一个对象只有被引用和没有被引用两种状态。 后来，Java 对引用的概念进行了扩充，将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4 种，这 4 种引用强度依次逐渐减弱。 强引用：指在程序代码之中普遍存在的，类似 “ Object obj=new Object() ” 这类的引用，垃圾收集器永远不会回收存活的强引用对象。 软引用：还有用但并非必需的对象。在系统将要发生内存溢出异常之前 ，将会把这些对象列进回收范围之中进行第二次回收。 弱引用：也是用来描述非必需对象的，被弱引用关联的对象 只能生存到下一次垃圾收集发生之前 。当垃圾收集器工作时，无论内存是否足够，都会回收掉只被弱引用关联的对象。 虚引用：是最弱的一种引用关系。 无法通过虚引用来取得一个对象实例 。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 生存与死亡不可达的对象将暂时处于“ 缓刑 ”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程： 如果对象在进行可达性分析后发现没有与 GC Roots 相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize() 方法。 当对象没有覆盖 finalize() 方法，或者 finalize() 方法已经被虚拟机调用过，虚拟机将这两种情况都视为 “没有必要执行”，直接进行第二次标记。 如果这个对象被判定为有必要执行 finalize() 方法，那么这个对象将会放置在一个叫做 F-Queue 的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的 Finalizer 线程去执行它。 这里所谓的 “ 执行 ” 是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，因为如果一个对象在 finalize() 方法中执行缓慢，将很可能会一直阻塞 F-Queue队列，甚至导致整个内存回收系统崩溃。 来看一段代码： 12345678910111213141516171819202122232425262728293031323334353637public class FinalizerTest &#123; public static FinalizerTest object = null; public void isAlive() &#123; System.out.println(\"I'm alive\"); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println(\"method finalize is executed\"); object = this; &#125; public static void main(String[] args) throws Exception &#123; object = new FinalizerTest(); // 第一次执行，finalize方法会自救 object = null; System.gc(); // 因为Finalizer方法优先级低，所以暂停0.5秒等待它 Thread.sleep(500); if (object != null) &#123; object.isAlive(); &#125; else &#123; System.out.println(\"I'm dead\"); &#125; // 下面代码和上面的完全一样，但是这次自救失败了 object = null; System.gc(); Thread.sleep(500); if (object != null) &#123; object.isAlive(); &#125; else &#123; System.out.println(\"I'm dead\"); &#125; &#125;&#125; 输出结果： 123method finalize is executedI&#39;m aliveI&#39;m dead 如果不重写finalize()方法，输出将会是： 12I&#39;m deadI&#39;m dead 值得注意的地方是，代码中有两段完全一样的代码片段，执行结果却是一次逃脱成功，一次失败，这是因为任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。 应该尽量避免使用finalize()方法拯救对象，它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序，finalize()能做的所有工作，使用try-finally或者其他方法能都可以做的更好、更及时。 回收方法区永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类 回收废弃常量与回收 Java 堆中的对象非常类似。以常量池中字面量的回收为例，假如一个字符串 “abc” 已经进入了常量池中，但是当前系统没有任何一个 String 对象引用它，也没有其他地方引用了这个字面量，如果这时发生内存回收，而且必要的话，这个 “abc” 常量就会被系统清理出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。 类需要满足下面3个条件才能算是无用的类： 该类所有实例都已经被回收，也就是说 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader已经被回收。 该类对应的 java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是 “ 可以 ” ，而并不是和对象一样，不使用了就必然会回收。 在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 垃圾收集算法标记-清除算法最基础的收集算法是 标记-清除（Mark-Sweep）算法，算法分为 “ 标记 ” 和 “ 清除 ”两个阶段：首先标记处所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 它主要不足有两个： 效率问题 ： 标记和清除两个过程都不高 空间问题 ： 标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 标记清除算法的执行过程如图所示： 复制算法为了解决效率问题，一种称为 “ 复制 ”(Copying)的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只是用其中的一块。当这块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次性清理掉。 这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要一动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。 复制算法的执行过程如图所示： 现在的商业虚拟机都采用这种算法来回收新生代，IBM 研究指出新生代中的对象 98% 是 “朝生夕死” 的，所以并不需要按照 1:1 的比例来划分内存空间，而是将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor 。 当回收时，将 Eden 和 Survivor 中还存活着的对象一次性地复制到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才用过的 Survivor 空间。HotSpot 虚拟机默认Eden:Survivor = 8:1，也就是每次新生代中可用内存空间为整个新生代容量的 90%（其中一块Survivor不可用），只有 10% 的内存会被“浪费”。 当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于 10% 的对象存活，当 Survivor 空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。 内存的分配担保就好比我们去银行借款，如果我们信誉很好，在 98% 的情况下都能按时偿还，于是银行可能会默认我们下一次也能按时按量地偿还贷款，只需要有一个担保人能保证如果我不能还款时，可以从他的账户扣钱，那银行就认为没有风险了。 内存的分配担保也一样，如果另外一块 Survivor 空间没有足够空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。关于对新生代进行分配担保的内容，在本章稍后在讲解垃圾收集器执行规则时还会再详细讲解。 标记-整理算法复制算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费 50% 的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都 100% 存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，有人提出了另外一种 “ 标记-整理 ”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 标记-整理算法的执行过程如图所示： 第一个过程和标记清除算法的第一个过程一样。然后是整理，最后在清除。 标记整理算法的优缺点： 优点：解决内存碎片问题。 缺点：不仅要标记所有存活对象，还要移动所有存活对象的地址并更新被移动的对象相关的引用。从效率上来说，要低于复制算法。 分代收集策略当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，根据对象存活周期的不同将内存划分为几块并采用不用的垃圾收集算法。 一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。 而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。 HotSpot的算法实现枚举根节点以可达性分析中从 GC Roots 节点找引用链这个操作为例，可作为 GC Roots 的节点主要在全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表）中，现在很多应用仅仅方法区就有数百兆，如果要逐个检查这里面的引用，那么必然会消耗很多时间。 另外，可达性分析对执行时间的敏感还体现在 GC 停顿上，因为这项分析工作必须在一个能确保 一致性 的快照中进行。这里的 一致性 指的是整个分析期间整个执行系统看起来就像被冻结在某个时间点上，不可以出现分析过程中对象引用关系还在不断变化的情况，否则分析结果准确性就无法得到保证。 这点是导致 GC 进行时必须停顿所有 Java 执行线程（Sun将这件事情称为”Stop The World,STW“）的其中一个重要原因，即使是在号称（几乎）不会发生停顿的 CMS 收集器中，枚举根节点时也是必须要停顿的。 因此，目前的主流 Java 虚拟机使用的都是准确式 GC（即虚拟机可以知道内存中某个位置的数据具体是什么类型。），所以当执行系统停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。 在 HotSpot 的实现中，是使用一组称为 OopMap 的数据结构来达到枚举 GC Roots的目的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在 JIT 编译过程中，也会在特定的位置记录栈和寄存器中哪些位置是引用。这样， GC 在扫描时就可以直接得知这些信息了。 OopMap垃圾收集时，收集线程会对栈上的内存进行扫描，看看哪些位置存储了 Reference 类型。如果发现某个位置确实存的是 Reference 类型，就意味着它所引用的对象这一次不能被回收。 但问题是，栈上的本地变量表里面只有一部分数据是 Reference 类型的（它们是 GC 所需要的），那些非 Reference 类型的数据对 GC 而言毫无用处，但 GC 还是不得不对整个栈全部扫描一遍，这是对时间和资源的一种浪费。 一个很自然的想法是，能不能用空间换时间，在某个时候把栈上代表引用的位置全部记录下来，这样到真正 GC 的时候就可以直接读取，而不用再一点一点的扫描了。事实上，大部分主流的虚拟机也正是这么做的，比如 HotSpot ，它使用一种叫做 OopMap 的数据结构来记录这类信息。 OopMap 记录了栈上本地变量到堆上对象的引用关系。枚举根节点时，递归遍历每个栈帧的 OopMap ，通过栈中记录的被引用对象的内存地址，即可找到这些对象（ GC Roots ）。 RememberedSetRememberedSet 主要用来处理频繁的新生代 GC。 目的：执行新生代 GC而不执行老年代 GC 背景：一般来说，GC 的过程是先枚举根节点。根节点有可能在新生代中，也有可能在老年代中。这里由于我们只想回收新生代（换句话说，不想回收老年代），所以没有必要对位于老年代的 GC Roots 做全面的可达性分析。 问题：可能存在位于老年代的某个 GC Root，它引用了新生代的某个对象，这个对象你是不能清除的。那怎么办呢？ 通过空间换时间的办法。事实上，对于位于不同年代对象之间的引用关系，虚拟机会在程序运行过程中给记录下来。对应上面所举的例子，“ 老年代对象引用新生代对象 ” 这种关系，会在引用关系发生时，在新生代边上专门开辟一块空间记录下来，这就是 RememberedSet 。 所以新生代的 GC Roots + RememberedSet 存储的内容，才是新生代收集时真正的 GC Roots 。然后就可以以此为据，在新生代上做可达性分析，进行垃圾回收。 安全点在 OopMap 的协助下，HotSpot 可以快速且准确地完成 GC Roots 枚举，但一个很现实的问题随之而来：可能导致引用关系变化，或者说 OopMap 内容变化的指令非常多，如果为每一条指令都生成对应的 OopMap，那将会需要大量的额外空间，这样 GC 的空间成本将会变得很高。 实际上，HotSpot 也的确没有为每条指令都生成 OopMap，前面已经提到，只是在 “ 特定的位置 ” 记录了这些信息，这些位置称为安全点(SafePoint)，即程序执行时并非在所有地方都能停顿下来开始 GC ，只有在到达安全点时才能暂停。 Safepoint 的选定既不能太少以致于 GC 过少，也不能过于频繁以致于过分增大运行时的负荷。 对于 Safepoint，另一个需要考虑的问题是如何在 GC 发生时让所有线程都 “跑” 到最近的安全点上再停顿下来。这里有两种方案可供选择： 抢先式中断（Preemptive Suspension） 主动式中断（Voluntary Suspension）。 其中抢先式中断不需要线程的执行代码主动去配合，在 GC 发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它 “跑” 到安全点上。现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而响应 GC 事件。 而主动式中断的思想是当 GC 需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地方。 一个线程意味着一个栈，一个栈由多个栈帧组成，一个栈帧对应着一个方法，一个方法里面可能有多个安全点。 GC 发生时，程序首先运行到最近的一个安全点停下来，然后更新自己的 OopMap ，记下栈上哪些位置代表着引用。 安全区域使用 Safepoint 似乎已经完美地解决了如何进入 GC 的问题，但实际情况却并不一定。Safepoint 机制保证了程序执行时，在不太长的时间内就会遇到可进入 GC 的Safepoint。但是，程序“不执行”的时候呢？ 所谓的程序不执行就是没有分配 CPU 时间，典型的例子就是线程处于 Sleep 状态或者 Blocked 状态，这时候线程无法响应 JVM 的中断请求，“走”到安全的地方去中断挂起，JVM 也显然不太可能等待线程重新被分配 CPU 时间。对于这种情况，就需要安全区域（Safe Region）来解决。 安全区域是指在一段代码片段之中，引用关系不会发生变化。 在这个区域中的任意地方开始 GC 都是安全的。我们也可以把 Safe Region 看做是被扩展了的 Safepoint。在线程执行到 Safe Region 中的代码时，首先标识自己已经进入了 Safe Region，那样，当在这段时间里 JVM 要发起 GC 时，就不用管标识自己为 Safe Region状态的线程了。 在线程要离开 Safe Region 时，它要检查系统是否已经完成了根节点枚举（或者是整个 GC 过程），如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开 Safe Region 的信号为止。 “本篇文章主要摘自《深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》”","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/tags/JVM/"}]},{"title":"'JVM（一） 运行时数据区域'","slug":"jvm-memory","date":"2020-05-21T14:20:00.000Z","updated":"2020-05-26T03:59:37.098Z","comments":true,"path":"2020/05/21/jvm-memory/","link":"","permalink":"https://midkuro.github.io/2020/05/21/jvm-memory/","excerpt":"","text":"运行时数据区域Java 虚拟机在执行 Java 程序过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随虚拟机进程的启动而存在，有的区域则依赖用户线程的启动和结束而建立和销毁。 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。 由于 Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器内核都只会执行一条线程中的指令。 因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是 Native 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何OutOfMemoryError 情况的区域。 Java虚拟机栈与程序计数器一样，Java 虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。 虚拟机栈描述的是Java方法执行的内存模型：每个方法执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。 经常有人把Java内存区分为堆内存（Heap）和栈内存（Stack），这种划分方式的流行只能说明大多数程序员最关注的、域对象内存分配关系最密切的内存区是这两块。Java 内存区域的划分实际上远比这复杂。 其中所指的“栈”就是虚拟机栈，或者说是虚拟机栈中的局部变量表。 局部变量表局部变量表存放了编译期可知的各种基本数据类型、对象引用和returnAddress类型。 基本数据类型：boolean、byte、char、short、int、float、long、double 对象引用：reference类型，它不等同于对象本身，可能是个对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他于此对象相关的位置 returnAddress类型：指向了一条字节码指令的地址 其中64位长度的 long 和 double 类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。Slot是栈帧中的局部变量表的最小单位。 局部变量表所需的内存空间在编译期完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 虚拟机栈规定了两种异常情况： 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。 如果虚拟机栈可以动态扩展，在扩展时无法申请到足够的内存，将抛出OutOfMemoryError(OOM)异常。 操作数栈Java 虚拟机的解释执行引擎被称为“ 基于栈的执行引擎 ”，其中所指的栈就是指－操作数栈。 操作数栈也常被称为操作栈，它是一个后入先出栈。 和局部变量表一样，操作数栈也是被组织成一个以字长为单位的数组。但是和前者不同的是，它不是通过索引来访问，而是通过标准的栈操作 压栈和出栈 来访问的。 比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用。 虚拟机在操作数栈中存储数据的方式和在局部变量表中是一样的。 虚拟机把操作数栈作为它的工作区，大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。 举例来说，在JVM中执行 a = b + c的字节码执行过程中操作数栈以及局部变量表的变化如下图所示。 局部变量表中存储着 a、b、c 三个局部变量，首先将 b 和 c 分别压入栈中将栈顶的两个数出栈执行求和操作，并将结果再次压入栈顶中，之后将栈顶的数出栈赋值给 a 看一个比较经典的例子 1234567891011public class IncrementTest &#123; public static void main(String[] args) &#123; int i = 1; i = i++; int j = i++; int k = i + ++i * i++; System.out.println(\"i = \" + i); System.out.println(\"j = \" + j); System.out.println(\"k = \" + k); &#125;&#125; 答案： 123i = 4j = 1k = 11 代码分析： 代码 i = i++，自增操作是在局部变量中的，而不是在操作数栈中。 把局部变量表中的 i 的值 1 压入操作数栈中 把局部变量表中的 i 变量自增 1，此时 i 的值为 2 把操作数栈中的值 1 赋值给局部变量表中的 i 变量，此时 i 的值又变为了 1 代码 int j = i++，赋值操作发生在自增前。 把局部变量表中的 i 的值 1 压入操作数栈中 把操作数栈中的值 1 赋值给局部变量表中的 j 变量，此时 j 的值为 1 把局部变量表中的 i 变量自增 1，此时 i 的值为 2 代码 int k = i + ++i * i++ 把局部变量表中的 i 的值 2 压入操作数栈中 把局部变量表中的 i 变量自增 1，此时 i 的值为 3 把局部变量表中的 i 的值 3 压入操作数栈中（++i），此时 i 的值为 3 再把局部变量表中的 i 的值 3 压入操作数栈中（i++），此时 i 的值为 3 把局部变量表中的 i 变量自增 1，此时 i的值为 4 把操作数栈中前两个弹出求乘积（3 * 3 = 9），将结果再次压入操作数栈中 把操作数栈中前两个弹出求和（9 + 2 = 11），将结果再次压入操作数栈中 将操作数栈中的值 11 赋值给局部变量表中的 k 变量，此时 k 的值为 11 总结： 赋值 =，最后计算 = 右边的从左到右加载值依次压入操作数栈 根据运算符的优先级判断先算哪个 自增和自减操作都是直接修改变量的值，不经过操作数栈 最后赋值之前，临时结果都是保存在操作数栈中的 值得提醒的是，i++和++i都不是原子操作，因为它并不会作为一个不可分割的操作来执行，实际上它包含三个独立的操作： 读取i的值 将值加1 然后将计算结果写入i这是一个读取-修改-写入的操作序列，并且其结果状态依赖于之前的状态。 即使使用 volatile 修饰，保证了多个线程多i的可见性，每次从局部变量表读取的都是最新的值，也不是线程安全的。 如果假设 i=9，在某些情况下，多个线程读到的值都为 9，接着执行递增操作，并且都将i设置成 10 ，显然不是线程安全的。 动态链接每个栈帧中包含一个在常量池中对当前方法的引用， 目的是支持方法调用过程的动态连接。 Class 文件中存放了大量的符号引用，这些符号引用一部分会在类加载阶段或第一次使用时转化为直接引用，这种转化称为静态解析，如静态方法、私有方法等等，另一部分将在每一次运行期间转化为直接引用，这部分称为动态连接。栈帧中保存了一个引用，指向该方法在运行时常量池中的位置，通过运行时常量池的符号引用（指向堆），完成将符号引用转化为直接引用。 方法返回地址方法执行时有两种退出情况： 正常退出，即正常执行到任何方法的返回字节码指令，如 return等 异常退出，即某些指令导致了 Java 虚拟机抛出异常并且没有处理 无论何种退出情况，都将返回至方法当前被调用的位置。方法退出的过程相当于弹出当前栈帧，退出可能有三种方式： 返回值压入上层调用栈帧。 异常信息抛给能够处理的栈帧。 PC计数器指向方法调用后的下一条指令。 当方法执行正常退出时，当前栈帧承担着恢复调用者状态的责任，包括恢复调用者的局部变量表和操作数栈，以及正确递增程序计数器、跳过刚才执行的方法调用指令等。调用者的代码在被调用方法的返回值压入调用者栈帧的操作数栈后，会继续正常执行。 本地方法栈本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。Sun HotSpot虚拟机直接就把本地方法栈和虚拟机栈合二为一。 与虚拟机栈一样，本地方法栈区域也会抛出 StackOverflowError 和 OutOfMemoryError 异常。 Java堆对于大多数应用来说，Java 堆（Java Heap）是 Java 虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做 “ GC堆 ”（Garbage Collected Heap）。从内存回收的角度来看，由于现在收集器基本都采用分代收集算法，所以 Java 堆中还可以细分为：新生代和老年代；再细致一点的有 Eden 空间、From Survivor 空间、To Survivor 空间等。 从内存分配的角度来看，线程共享的 Java 堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer,TLAB）。不过无论如何划分，都与存放的内容无关，无论哪个区域，存储的都是对象实例，进一步划分的目的是为了更好的回收内存，或者更快的分配内存。 Java 堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，当前主流的虚拟机都是按照可扩展来实现的（通过 -Xmx 和 -Xms 控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出 OutOfMemoryError异常。 方法区方法区（Method Area）与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 Java 虚拟机规范对方法区的限制非常宽松，除了和 Java 堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。垃圾收集行为在这个区域是比较少出现的，其内存回收目标主要是针对常量池的回收和对类型的卸载。当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError 异常。 HotSpot 虚拟机它是Sun JDK和OpenJDK中所带的虚拟机，也是目前使用范围最广的 Java 虚拟机。在2008年和2009年，Oracle公司分别收购了BEA公司和Sun公司，Oracle同时拥有了两款优秀的Java虚拟机：JRockit VM和HotSpot VM。 永久代对于习惯在HotSpot 虚拟机上开发、部署程序的开发者来说,很多人更愿意把方法区称为“永久代”(Permanent Generation)，本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队把 GC 分代收集扩展至方法区，或者说，使用永久代来实现方法区而已。 目的是为了方法区也可以用堆内存的 GC 垃圾回收器，而不用重新针对方法区做 GC 操作，所以称永久代是方法区的一个存储实现。 方法区只是 JVM 的一种规范，不同的虚拟机实现的原理不一样，只有HotSpot虚拟机才有永久代的概念。 常量池class常量池我们写的每一个 Java 类被编译后，就会形成一份class 文件。class 文件中除了包含类的版本、字段、方法、接口等描述信息外，还有一项信息就是常量池(constant pool table)，用于存放编译器生成的各种字面量(Literal)和符号引用(Symbolic References)。 每个class文件都有一个class常量池。 字面量包括： 文本字符串 八大基本类型的值 被申明为final的常量 符号引用包括： 类和方法的全限定名 字段的名称和描述符 方法的名称和描述符 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。class文件常量池将在类加载后进入方法区的运行时常量池中存放。 一般来说，除了保存 Class 文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。 运行时常量池相对于 Class 文件常量池的另外一个重要特征是具备动态性，Java 语言并不要求常量一定只有编译期才能产生，也就是并非预置入 Class 文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是 String 类的 intern() 方法。 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。 字符串常量池 在HotSpot虚拟机里实现的字符串常量池(string pool)功能的是一个StringTable类，它是一个Hash表，这个StringTable在每个HotSpot虚拟机的实例只有一份，被所有的类共享。字符串常量由一个一个字符组成，放在了StringTable上。 JDK版本变化JDK1.6及以前的版本，字符串常量池是存放在永久代中。 在JDK1.7的版本中，字符串常量池从永久代移出到正常的Java 堆(Java Heap)中，原因是因为永久代空间太小，容易造成OOM。 在JDK1.8的版本中，Hotspot虚拟机废除了永久代，开始使用元空间（Metaspace）实现方法区，字符串常量池依旧保留在堆内存中，其他内容移至元空间，元空间直接在本地内存分配，而不需要占用堆内存，所以不会造成OOM现象。 值得注意的是，方法区只是Jvm的一种规范，Hotspot通过废除永久代，使用元空间实现方法区，并不存在废除方法区、方法区被元空间代替这种说法。 为什么要使用元空间取代永久代的实现？ 字符串存在永久代中，容易出现性能问题和内存溢出 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低 将 HotSpot 与 JRockit 合二为一 1234567public static void main(String[] args) &#123; String str = \"String\"; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; str.intern(); str = str + str; &#125;&#125; 使用JDK1.7 或者 1.8 能够看到，往字符串常量池中无限增加，最终 OOM 的位置是在Java 堆（Java heap）中。 String.intern()用来返回常量池中的某字符串，如果常量池中已经存在该字符串，则直接返回常量池中该对象的引用。否则，在常量池中加入该对象，然后返回引用。 看一道比较常见的面试题，在不考虑 GC 的情况下，下面的代码创建了多少个 String 对象，输出结果是什么？ 123String str1 = new String(\"he\") + new String(\"llo\");String str2 = str1.intern();System.out.println(str1 == str2); 答案： 在 JDK 1.6 下输出是 false，创建了 6 个对象 在 JDK 1.7 之后的版本输出是 true，创建了 5 个对象 代码分析： 为什么输出会有这些变化呢？主要还是字符串池从永久代中脱离、移入堆区的原因， intern() 方法也相应发生了变化： 在 JDK 1.6 中，调用 intern() 首先会在字符串池中寻找equal() 相等的字符串，假如字符串存在就返回该字符串在字符串池中的引用；假如字符串不存在，虚拟机会重新在永久代上创建一个实例，将 StringTable 的一个表项指向这个新创建的实例。 在 JDK 1.7 中，由于字符串池不在永久代了，intern() 做了一些修改，更方便地利用堆中的对象。字符串存在时和 JDK 1.6一样，但是字符串不存在时不再需要重新创建实例，可以直接指向堆上的实例。 我们基于JDK1.7版本，来看个例子： 123String str1 = new String(\"abc\");String str2 = str1.intern();System.out.println(str1 == str2); //false 由于字符串常量池中已存在abc，所以返回了字符串常量池中的引用，如下图所示 再来看个例子： 1234String str1 = new String(\"he\") + new String(\"llo\");str1.intern();String str2 = \"hello\";System.out.println(str1 == str2); //true 该结果等于true应该是能够理解的，不理解的可以查看上文针对该代码的实例分析图 这里扩展一点，若是把str1.intern();代码注释掉，则产生的结果为false。 其原因在于str1对象是通过new对象拼接产生的，字符串常量池中并不存在字符串hello，当调用String str2=&quot;hello&quot;;代码时字符串常量池中产生才该字符串，所以他们并不是同一个地址引用。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域。 在 JDK 1.4 中新加入了 NIO，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。 显然，本机直接内存的分配不会受到 Java 堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括 RAM 以及 SWAP 区或者分页文件）大小以及处理器寻址空间的限制。服务器管理员在配置虚拟机参数时，会根据实际内存设置 -Xmx 等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现 OutOfMemoryError 异常。 “本篇文章主要摘自《深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》”","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/tags/JVM/"}]},{"title":"'kubernetes（二） 环境搭建'","slug":"kubernetes-install","date":"2020-05-21T14:00:00.000Z","updated":"2020-09-23T08:24:17.097Z","comments":true,"path":"2020/05/21/kubernetes-install/","link":"","permalink":"https://midkuro.github.io/2020/05/21/kubernetes-install/","excerpt":"","text":"K8S的安装方式最简单的方法是使用yum install kubernetes命令安装Kubernetes集群，但仍需修改各组件的启动参数，才能完成对Kubernetes集群的配置，整个过程比较复杂，也容易出错。但是对于新手来说是一个熟悉k8s的一个过程，可以适当借鉴学习。 Kubernetes从1.4版本开始引入了命令行工具kubeadm，致力于简化集群的安装过程，并解决Kubernetes集群的高可用问题。在Kubernetes 1.13版本中，kubeadm工具进入GA阶段，宣称已经为生产环境应用准备就绪。比较推荐使用这种方式，安装便捷并且容错率高 本节先讲解基于 yum install kubernetes命令安装 Master节点：192.168.1.132 Node节点：192.168.1.134 K8S基于yum的安装安装前先关闭防火墙 1systemctl stop firewalld 修改系统文件/etc/sysconfig/selinux，将SELINUX=enforcing修改成SELINUX=disabled，然后重启Linux。或者执行以下命令 1setenforce 0 编辑/etc/sysctl.conf添加以下内容 123456net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward=1vm.swappiness = 0fs.inotify.maxuserwatches = 24576vm.max_map_count=655360 然后执行命令 sysctl -p,如果报错，执行命令modprobe br_netfilter 安装Master节点1、安装Docker 安装docker教程 2、Master节点安装etcd 1yum install etcd -y etcd用于K8S的数据存储，原生支持做集群，修改/etc/etcd/etcd.conf配置,指向Master节点 123[root@localhost /]# vim /etc/etcd/etcd.conf6 行：ETCD_LISTEN_CLIENT_URLS=\"http://0.0.0.0:2379\"22行：ETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.1.132:2379\" 启动etcd服务并且设置开机自启 12[root@localhost /]# systemctl start etcd.service[root@localhost /]# systemctl enable etcd.service 检查 12345678[root@localhost /]# netstat -lntup|grep 2379tcp6 0 0 :::2379 :::* LISTEN 117472/etcd#检查健康状态[root@localhost /]# etcdctl -C http://192.168.1.132:2379 cluster-healthmember 8e9e05c52164694d is healthy: got healthy result from http://192.168.1.132:2379cluster is healthy 测试 1234567891011# 插入数据 键（目录）值（123456）[root@localhost /]# etcdctl set /test/word 123456 123456[root@localhost /]# etcdctl ls //test[root@localhost /]# etcdctl ls /test/test/word[root@localhost /]# etcdctl get /test/word # 查看值123456[root@localhost /]#etcdctl rm /test/word # 删除键值对[root@localhost /]#etcdctl rmdir /test # 删除目录 3、Master节点192.168.1.132安装K8S 以下命令根据需求二选一即可 12345#安装Master节点和Node节点的服务，适用于服务器数量不够时共用同一台服务器yum install kubernetes -y#安装Master节点需要的服务，适用于服务器数量充足分离Master和Node节点yum install kubernetes-master.x86_64 -y 本人Master节点[192.168.1.132]也安装了Node节点服务,可以用于测试两个不同宿主机上Node节点通信。 kubelet默认把数据存放在/var/lib/kubelet下面，如果根目录下空间太小，可能会把磁盘撑爆。可以将数据挂载在充足空间的盘上 1234mkdir -p /home/kubeletcp -r /var/lib/kubelet /home/rm -rf /var/lib/kubeletln -sf /home/kubelet /var/lib/kubelet 4、修改apiserver配置文件 安装好了后进入/etc/kubernetes/配置目录修改相关配置 12345678910111213[root@localhost /]# vim /etc/kubernetes/apiserver#服务的监听地址8 行: KUBE_API_ADDRESS=\"--insecure-bind-address=0.0.0.0\"#服务监听的端口11行：KUBE_API_PORT=\"--port=8080\"#通过10250端口控制kubelet14行：KUBELET_PORT=\"--kubelet-port=10250\" #APIserver是通过那个地址和端口连接etcd数据17行：KUBE_ETCD_SERVERS=\"--etcd-servers=http://192.168.1.132:2379\"#K8S创建service服务的网段配置 20行：KUBE_SERVICE_ADDRESSES=\"--service-cluster-ip-range=10.254.0.0/16\"#默认的管理控制插件---将后面的ServiceAccount去掉23行：KUBE_ADMISSION_CONTROL=\"--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota\" 5、修改通用的配置文件config 123[root@localhost kubernetes]# vim /etc/kubernetes/config#通过那个地址端口找到API服务22行：KUBE_MASTER=\"--master=[http://192.168.1.132:8080] 6、启动服务并设置开启自启 123456systemctl enable kube-apiserver.servicesystemctl start kube-apiserver.servicesystemctl enable kube-controller-manager.servicesystemctl start kube-controller-manager.servicesystemctl enable kube-scheduler.servicesystemctl start kube-scheduler.service 7、测试集群是否正常 12345[root@localhost /]# kubectl get componentstatusNAME STATUS MESSAGE ERRORetcd-0 Healthy &#123;\"health\":\"true\"&#125; controller-manager Healthy ok scheduler Healthy ok 安装Node节点1、Node节点192.168.1.134安装K8S 如果没有第二台服务器，Master节点和Node节点同一台服务器时跳过安装步骤 1yum install kubernetes-node.x86_64 -y (自动会安装docker) 值得一提的是，如果Master节点也安装了Node节点的服务，Master节点机器也需要修改以下的所有相关配置 2、修改kube-proxy服务配置文件 12[root@localhost ~]# vim /etc/kubernetes/config22行：KUBE_MASTER=\"--master=[http://192.168.1.132:8080] 3、修改kubelet服务配置文件 1234567891011[root@localhost ~]# vim /etc/kubernetes/kubelet# 监听的地址5行：KUBELET_ADDRESS=\"--address=0.0.0.0\"#kubelet端口 8行：KUBELET_PORT=\"--port=10250\"# 给自己定义唯一的名字 不能冲突 IP地址或者主机名（各自节点改各自节点的IP）11行：KUBELET_HOSTNAME=\"--hostname-override=192.168.1.134\"# Master节点的连接api的地址14行：KUBELET_API_SERVER=\"--api-servers=[http://192.168.1.132:8080]# 节点的DNS配置KUBELET_ARGS=\"--cluster-dns=192.168.1.1 --cluster-domain=cluster.local\" 如果不知道DNS配置，可以执行下列命令 12345[root@localhost kubernetes]# cat /etc/resolv.conf# Generated by NetworkManagernameserver 192.168.1.1nameserver 114.114.114.114search localdomain 如果没有任何信息显示，vim /etc/resolv.conf并增加以下内容nameserver 114.114.114.114然后把该DNS增加到kubelet文件配置中 4、修改服务通用的配置文件config 123[root@localhost kubernetes]# vim /etc/kubernetes/config#通过那个地址端口找到API服务22行：KUBE_MASTER=\"--master=[http://192.168.1.132:8080] 5、启动服务并设置开机自启 12345systemctl start kubelet.service systemctl enable kubelet.service systemctl start kube-proxy.servicesystemctl enable kube-proxy.service 6、在Master节点测试是否有节点加入集群 1234[root@localhost /]# kubectl get nodeNAME STATUS AGE192.168.1.132 Ready 8d192.168.1.134 Ready 9d 安装flanneld网络通讯由于K8S创建的Service、Pod服务均是生成的虚拟IP，两台Node节点之间的Pod通信需要通过第三方插件实现.Master节点和Node节点都需要安装和配置 1、安装flanneld 1yum install flannel -y 2、修改flanneld配置文件 1sed -i 's#http://127.0.0.1:2379#http://192.168.1.132:2379#g' /etc/sysconfig/flanneld 多网卡的话需要在LANNEL_ETCD_ENDPOINTS项中增加--iface=网卡名 这里/etc/sysconfig/flanneld可以设置密钥验证，详情请自行百度! 3、Master节点配置etcd中关于flanneld的Key 12etcdctl mk /atomic.io/network/config '&#123; \"Network\": \"172.16.0.0/16\" &#125;'etcdctl get /atomic.io/network/config 这里的/atomic.io/network需要和/etc/sysconfig/flanneld里的FLANNEL_ETCD_PREFIX配置对应。 4、设置flanneld启动配置 1234567891011121314151617181920[root@localhost /]# vim /usr/lib/systemd/system/flanneld.service[Unit]Description=Flanneld overlay address etcd agentAfter=network.targetAfter=network-online.targetWants=network-online.targetAfter=etcd.serviceBefore=docker.service[Service]Type=notifyEnvironmentFile=/etc/sysconfig/flanneldEnvironmentFile=-/etc/sysconfig/docker-networkExecStart=/usr/bin/flanneld-start $FLANNEL_OPTIONSExecStartPost=/usr/libexec/flannel/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/dockerRestart=on-failure[Install]WantedBy=multi-user.targetWantedBy=docker.service 5、设置Docker启动配置 1234567891011121314151617181920212223242526272829303132[root@localhost /]# vim /usr/lib/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=http://docs.docker.comAfter=network.targetWants=docker-storage-setup.serviceRequires=docker-cleanup.timer[Service]Type=notifyNotifyAccess=mainEnvironmentFile=/run/flannel/subnet.env #增加该行配置EnvironmentFile=-/etc/sysconfig/dockerEnvironmentFile=-/etc/sysconfig/docker-storageEnvironmentFile=-/etc/sysconfig/docker-networkEnvironment=GOTRACEBACK=crashEnvironment=DOCKER_HTTP_HOST_COMPAT=1Environment=PATH=/usr/libexec/docker:/usr/bin:/usr/sbin#更改启动方式 如果没有更改过docker存储路径，不需要配置 --graph /home/dockerExecStart=/usr/bin/dockerd --graph /home/docker $DOCKER_NETWORK_OPTIONS#增加docker启动的防火墙拦截允许配置ExecStartPost=/sbin/iptables -I FORWARD -s 0.0.0.0/0 -j ACCEPTExecReload=/bin/kill -s HUP $MAINPIDLimitNOFILE=1048576LimitNPROC=1048576LimitCORE=infinityTimeoutStartSec=0Restart=on-abnormalKillMode=process[Install]WantedBy=multi-user.target 6、启动flanneld 12345678910111213141516systemctl daemon-reloadsystemctl start flanneld.servicesystemctl enable flanneld.service#重启Master节点服务systemctl restart dockersystemctl restart kube-apiserversystemctl restart kube-controller-managersystemctl restart kube-schedulersystemctl restart kubeletsystemctl restart kube-proxy#重启Node节点服务systemctl restart dockersystemctl restart kubeletsystemctl restart kube-proxy 7、测试网段 以上的一系列操作，主要是为了让flanneld和docker创建的网络处于同一个网段，先通过设置etcd设置flanneld的网段范围，再配置docker启动前加载flanneld的配置从图中能够看到docker0和flannel0都处于同一个网段172.16.0.0中,可以用一个轻巧的容器测试一下 1234#docker拉取网络镜像[root@localhost /]# docker pull docker.io/busybox#分别在Master节点及Node节点执行命令[root@localhost /]# docker run -it docker.io/busybox:latest 从图中可以看到，创建了两个容器，IP分别是172.16.43.6和172.16.43.4互相能够Ping通。 如果不能Ping通，则在每个Node节点上都配置相应的静态路由项 1234#Master节点 #172.16.9.0 为Node节点的flannel0的IP[root@localhost ~]# route add -net 172.16.9.0 netmask 255.255.255.0 gw 192.168.1.134 #Node节点 #172.16.43.0 为Master节点的flannel0的IP[root@localhost ~]# route add -net 172.16.43.0 netmask 255.255.255.0 gw 192.168.1.132 这意味着，每一个新部署的容器都将使用这个Node（docker0的网桥IP）作为它的默认网关。而这些Node（类似路由器）都有其他docker0的路由信息，这样它们就能够相互连通了。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/categories/Kubernetes/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/tags/Kubernetes/"}]},{"title":"'kubernetes（一） 基础概念'","slug":"kubernetes-introduction","date":"2020-05-21T13:50:00.000Z","updated":"2020-05-26T04:00:00.066Z","comments":true,"path":"2020/05/21/kubernetes-introduction/","link":"","permalink":"https://midkuro.github.io/2020/05/21/kubernetes-introduction/","excerpt":"","text":"Docker基本概念什么是DockerDocker是使用 Google公司推出的Go 语言进行开发实现，基于Linux 内核的cgroup、namespace、以及AUFS类的Union FS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术，由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 Docker在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得Docker技术比虚拟机技术更为轻便、快捷。下面的图片比较了Docker和传统虚拟化方式的不同之处。 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程。 而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比 传统虚拟机更为轻便。 为什么要使用Docker作为一种新兴的虚拟化方式，Docker跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源：由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker对系统资源的利用率更高。 更快速的启动时间： Docker容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间 一致的运行环境： Docker的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现这段代码在我机器上没问题啊这类问题。 持续交付和部署： Docker可以通过定制应用镜像来实现持续集成、持续交付、部署。可以通过Dockerfile来进行镜像构建，结合持续集成系统进行集成测试、自动部署。 更轻松的迁移： 由于Docker确保了执行环境的一致性，使得应用的迁移更加容易，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展： Docker使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker团队提供了一大批高质量的官方镜像，既可以直接使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 基本概念镜像Image 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含任何动态数据，其内容在构建之后也不会被改变。 Docker设计时，将其设计为分层存储的架构。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除 前一层的文件，而是仅在当前层标记为该文件已删除。分层存储的特征使得镜像的复用、定制变的更为容易。 容器Container 镜像和容器的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。因此容器可以拥有自己的root文件系统、自己的网络配置、自己的进程空间，甚至自己的用户ID空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。容器也具备分层存储的特征。 Kubernetes什么是KubernetesKubernetes是一个完备的分布式系统支撑平台。Kubernetes具有完备的集群管理能力，包括多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和服务发现机制、内建的智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制，以及多粒度的资源配额管理能力。同时，Kubernetes提供了完善的管理工具，这些工具涵盖了包括开发、部署测试、运维监控在内的各个环节。因此，Kubernetes是一个全新的基于容器技术的分布式架构解决方案，并且是一个一站式的完备的分布式系统开发和支撑平台。 Kubernetes英文中字母K和S中间有8个英文，所以也简称为K8S。 为什么要使用Kubernetes 轻装上阵地开发复杂系统 可以全面拥抱微服务架构 可以随时随地迁移系统 拥有横向弹性扩容机制 Kubernetes基本概念Kubernetes中的大部分概念如Node、Pod、Replication Controller、Service等都可以被看作一种资源对象，几乎所有资源对象都可以通过Kubernetes提供的kubectl工具（或者API编程调用）执行增、删、改、查等操作并将其保存在etcd中持久化存储。从这个角度来看，Kubernetes其实是一个高度自动化的资源控制系统，它通过跟踪对比etcd库里保存的“资源期望状态”与当前环境中的“实际资源状态”的差异来实现自动控制和自动纠错的高级功能。 MasterKubernetes里的Master指的是集群控制节点，在每个Kubernetes集群里都需要有一个Master来负责整个集群的管理和控制，基本上Kubernetes的所有控制命令都发给它，它负责具体的执行过程，我们后面执行的所有命令基本都是在Master上运行的。Master通常会占据一个独立的服务器（高可用部署建议用3台服务器），主要原因是它太重要了，是整个集群的“首脑”，如果它宕机或者不可用，那么对集群内容器应用的管理都将失效。 在Master上运行着以下关键进程: Kubernetes API Server（kube-apiserver） 提供了HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程。 Kubernetes Controller Manager（kube-controller-manager） Kubernetes里所有资源对象的自动化控制中心，可以将其理解为资源对象的大总管。 Kubernetes Scheduler（kube-scheduler） 负责资源调度（Pod调度）的进程，相当于公交公司的调度室，在Master上通常还需要部署etcd服务，因为Kubernetes里的所有资源对象的数据都被保存在etcd中。 Node除了Master，Kubernetes集群中的其他机器被称为Node，在较早的版本中也被称为Minion。与Master一样，Node可以是一台物理主机，也可以是一台虚拟机。Node是Kubernetes集群中的工作负载节点，每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，其上的工作负载会被Master自动转移到其他节点上。 在每个Node上都运行着以下关键进程: kubelet 负责Pod对应的容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能。 kube-proxy 实现Kubernetes Service的通信与负载均衡机制的重要组件。 Docker Engine（docker） Docker引擎，负责本机的容器创建和管理工作。 Node可以在运行期间动态增加到Kubernetes集群中，前提是在这个节点上已经正确安装、配置和启动了上述关键进程，在默认情况下kubelet会向Master注册自己，这也是Kubernetes推荐的Node管理方式。 一旦Node被纳入集群管理范围，kubelet进程就会定时向Master汇报自身的情报，例如操作系统、Docker版本、机器的CPU和内存情况，以及当前有哪些Pod在运行等，这样Master就可以获知每个Node的资源使用情况，并实现高效均衡的资源调度策略。 而某个Node在超过指定时间不上报信息时，会被Master判定为“失联”，Node的状态被标记为不可用（Not Ready），随后Master会触发“工作负载大转移”的自动流程。 我们可以执行下述命令查看在集群中有多少个Node： 然后可以通过kubectl describe node &lt;node_name&gt;查看某个Node的详细信息: PodPod是Kubernetes最重要的基本概念，下图所示是Pod的组成示意图，我们看到每个Pod都有一个特殊的被称为根容器的Pause容器。Pause容器对应的镜像属于Kubernetes平台的一部分，除了Pause容器，每个Pod还包含一个或多个紧密相关的用户业务容器。 为什么Kubernetes会设计出一个全新的Pod的概念并且Pod有这样特殊的组成结构？ 原因之一：在一组容器作为一个单元的情况下，我们难以简单地对“整体”进行判断及有效地行动。比如，一个容器死亡了，此时算是整体死亡么？是N/M的死亡率么？引入业务无关并且不易死亡的Pause容器作为Pod的根容器，以它的状态代表整个容器组的状态，就简单、巧妙地解决了这个难题。 原因之二：Pod里的多个业务容器共享Pause容器的IP，共享Pause容器挂接的Volume，这样既简化了密切关联的业务容器之间的通信问题，也很好地解决了它们之间的文件共享问题。 Kubernetes为每个Pod都分配了唯一的IP地址，称之为Pod IP，一个Pod里的多个容器共享Pod IP地址。Kubernetes要求底层网络支持集群内任意两个Pod之间的TCP/IP直接通信，这通常采用虚拟二层网络技术来实现，例如Flannel、Open vSwitch等 因此我们需要牢记一点：在Kubernetes里，一个Pod里的容器与另外主机上的Pod容器能够直接通信，同一个Pod里的容器之间仅需通过localhost就能互相通信。 Pod、容器与Node的关系: 一个Pod中的应用容器共享同一组资源： PID命名空间：Pod中的不同应用程序可以看到其他应用程序的进程ID 网络命名空间：Pod中的多个容器能够访问同一个IP和端口范围 IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信 UTS命名空间：Pod中的多个容器共享一个主机名 Volumes（共享存储卷）：Pod中的各个容器可以访问在Pod级别定义的Volumes Pod的生命周期通过Replication Controller来管理；通过模板进行定义，然后分配到一个Node上运行，在Pod所包含容器运行结束后，Pod结束。 Kubernetes为Pod设计了一套独特的网络配置，包括：为每个Pod分配一个IP地址，使用Pod名作为容器间通信的主机名等。 LabelLabel（标签）是Kubernetes系统中另外一个核心概念。一个Label是一个key=value的键值对，其中key与value由用户自己指定。Label可以被附加到各种资源对象上，例如Node、Pod、Service、RC等，一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上。Label通常在资源对象定义时确定，也可以在对象创建后动态添加或者删除。 我们可以通过给指定的资源对象捆绑一个或多个不同的Label来实现多维度的资源分组管理功能，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。 Label相当于我们熟悉的“标签”。给某个资源对象定义一个Label，就相当于给它打了一个标签，随后可以通过Label Selector（标签选择器）查询和筛选拥有某些Label的资源对象，Kubernetes通过这种方式实现了类似SQL的简单又通用的对象查询机制。 Service在Kubernetes的世界里，虽然每个Pod都会被分配一个单独的IP地址，但这个IP地址会随着Pod的销毁而消失，这就引出一个问题：如果有一组Pod组成一个集群来提供服务，那么如何来访问它呢？Service！ 一个Service可以看作一组提供相同服务的Pod的对外访问接口，Service作用于哪些Pod是通过Label Selector来定义的。 拥有一个指定的名字（比如my-mysql-server） 拥有一个虚拟IP（Cluster IP、Service IP或VIP）和端口号，销毁之前不会改变，只能内网访问 能够提供某种远程服务能力 被映射到了提供这种服务能力的一组容器应用上 如果Service要提供外网服务，需指定公共IP和NodePort，或外部负载均衡器 Service可以通过配置NodePort，在Node上打开一个主机的真实端口，这样，能够访问Node的客户端就能通过这个端口访问到内部的Service了 Replication ControllerReplication Controller（简称RC）是Kubernetes系统中的核心概念之一，简单来说，它其实定义了一个期望的场景，即声明某种Pod的副本数量在任意时刻都符合某个预期值 目标Pod的定义 目标Pod需要运行的副本数量 要监控的目标Pod标签（Label） Kubernetes通过RC中定义的Label筛选出对应的Pod实例，并实时监控其状态和数量，如果实例数量少于定义的副本数量（Replicas），则会根据RC中定义的Pod模板来创建一个新的Pod，然后将此Pod调度到合适的Node上启动运行，直到Pod实例数量达到预定目标。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/categories/Kubernetes/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/tags/Kubernetes/"}]},{"title":"'docker（四） 安装私服仓库'","slug":"docker-registry","date":"2020-05-21T13:00:00.000Z","updated":"2020-05-26T03:57:38.966Z","comments":true,"path":"2020/05/21/docker-registry/","link":"","permalink":"https://midkuro.github.io/2020/05/21/docker-registry/","excerpt":"","text":"docker私服仓库docker的私服仓库存储不像maven私服有完整独立的应用，它是通过docker获取私服仓库镜像，并根据镜像创建私服仓库容器 说白了，docker的私服仓库的搭建就是拉取镜像、创建容器、上传镜像的过程 宿主机环境IP：192.168.1.131 私服仓库的搭建1、拉取私服镜像 1docker pull registry:2 2、启动私服 1docker run --name registry -tid --privileged=true --restart=always --net=host -v /home/docker/repository:/var/lib/registry registry 这里使用的是V2版本的私服仓库,/var/lib/registry是私服仓库存储上传镜像的路径，把它挂载到宿主机上避免因为容器坏损丢失私服仓库的镜像存储 3、标记镜像 12命令：docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]例子：docker tag mtex-admin 192.168.1.131:5000/mtex-admin 这里以镜像名：mtex-admin为例，标记镜像将其归入某一仓库,再次查看镜像列表 1docker images 能够看见出现了192.168.1.131:5000/mtex-admin镜像名称，细心点会发现它的镜像ID和mtex-admin是一样的也就是说，两个镜像名称都映射到同一个镜像ID上，如何避免这种情况呢？ 可以执行tag命令之后，删除原来的旧镜像名称，只保留一个名称映射 也可以在创建镜像时，镜像名称以[私服IP:端口/名称]命名,不必在执行tag命令 4、上传私服 1docker push 192.168.1.131:5000/mtex-admin 可以看到上传成功了，使用192.168.1.134试一下拉取镜像 1docker pull 192.168.1.131:5000/mtex-admin 5、配置解析 考虑到记住IP比较麻烦，可以在/etc/hosts中增加本地仓库的域名解析 1echo \"192.168.1.131 docker-registry\" &gt;&gt; /etc/hosts 这时候再执行cat /etc/hosts能够看到，已经增加进去了 6、查看私服镜像 可以通过浏览器打开http://192.168.1.131:5000/v2/_catalog查看 7、删除私服镜像 上面已经将私服的镜像内容挂载到宿主机/home/docker/repository路径中，只需要进入对应路径删除镜像即可路径目录是/home/docker/repository/docker/registry/v2/repositories 常见问题Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交互时可能会出现以下错误 1Get https://192.168.1.131:5000/v2/: http: server gave HTTP response to HTTPS client docker版本1.2以上的，在/etc/docker/daemon.json文件中增加以下内容 12#必须要增加在第一行&#123; \"insecure-registries\":[\"192.168.1.131:5000\"] 然后重启docker，重启registry 1systemctl restart docker.service 查看docker版本的命令docker -v，低于1.2的版本可以升级版本，也可以上网寻找解决方法.","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"}]},{"title":"'docker（三） 执行DockerFile创建镜像'","slug":"docker-dockfile","date":"2020-05-21T12:30:00.000Z","updated":"2020-05-26T09:39:11.800Z","comments":true,"path":"2020/05/21/docker-dockfile/","link":"","permalink":"https://midkuro.github.io/2020/05/21/docker-dockfile/","excerpt":"","text":"DockerFile 文件常用详解 FROM：指定基础镜像，必须为第一个命令 12345678格式： FROM &lt;image&gt; FROM &lt;image&gt;:&lt;tag&gt; FROM &lt;image&gt;@&lt;digest&gt;示例： FROM centos:7.2.1511注： tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像 MAINTAINER：维护者信息 123456格式： MAINTAINER &lt;name&gt;示例： MAINTAINER caijinkun MAINTAINER caijinkun &lt;caijinkun@mastercom.cn&gt; MAINTAINER caijinkun \"caijinkun@mastercom.cn\" RUN：构建镜像时执行的命令 123456789101112131415RUN用于在镜像容器中执行命令，其有以下两种命令执行方式：shell执行格式： RUN &lt;command&gt;exec执行格式： RUN [\"executable\", \"param1\", \"param2\"]示例： RUN [\"executable\", \"param1\", \"param2\"] RUN apk update RUN [\"/etc/execfile\", \"arg1\", \"arg1\"]注： RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像， 可以在构建时指定--no-cache参数,如：docker build --no-cache 每执行Run命令，都会创建一个中间镜像层，使得最终创建的镜像文件变大，建议把命令都在一个Run中执行，用&amp;&amp;分隔. ADD：将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget 12345678910格式： ADD &lt;src&gt;... &lt;dest&gt; ADD [\"&lt;src&gt;\",... \"&lt;dest&gt;\"] 用于支持包含空格的路径示例： ADD hom* /mydir/ # 添加所有以\"hom\"开头的文件 ADD hom?.txt /mydir/ # ? 替代一个单字符,例如：\"home.txt\" ADD test relativeDir/ # 添加 \"test\" 到 `WORKDIR`/relativeDir/ ADD test /absoluteDir/ # 添加 \"test\" 到 /absoluteDir/注： 该命令只能添加Dockerfile路径的下层文件，所以需要事先拷贝文件到该路径下 COPY：功能类似ADD，但是是不会自动解压文件，也不能访问网络资源，建议直接用ADD CMD：构建容器后调用，也就是在容器启动时才进行调用 12345678910格式： CMD [\"executable\",\"param1\",\"param2\"] (执行可执行文件，优先) CMD [\"param1\",\"param2\"] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数) CMD command param1 param2 (执行shell内部命令)示例： CMD echo \"This is a test.\" | wc - CMD [\"/usr/bin/wc\",\"--help\"] CMD [\"java\",\"-jar\",\"mtex-config-0.0.1-SNAPSHOT.jar\"]注： CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令 ENTRYPOINT：配置容器，使其可执行化。配合CMD可省去”application”，只使用参数。 1234567891011格式： ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (可执行文件, 优先) ENTRYPOINT command param1 param2 (shell内部命令)示例： FROM ubuntu ENTRYPOINT [\"top\", \"-b\"] CMD [\"-c\"]注： ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT 而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令。 ENV：设置环境变量 1234567格式： ENV &lt;key&gt; &lt;value&gt; #&lt;key&gt;之后的所有内容均会被视为其&lt;value&gt;的组成部分，因此，一次只能设置一个变量 ENV &lt;key&gt;=&lt;value&gt; ... #可以设置多个变量，每个变量为一个\"&lt;key&gt;=&lt;value&gt;\"的键值对，如果&lt;key&gt;中包含空格，可以使用\\来进行转义，也可以通过\"\"来进行标示；另外，反斜线也可以用于续行示例： ENV myName John Doe ENV myDog Rex The Dog ENV myCat=fluffy EXPOSE：指定于外界交互的端口 12345678910格式： EXPOSE &lt;port&gt; [&lt;port&gt;...]示例： EXPOSE 80 443 EXPOSE 8080 EXPOSE 11211/tcp 11211/udp注： EXPOSE并不会让容器的端口访问到主机。要使其可访问 需要在docker run 运行容器时通过 -p 来发布这些端口 或通过 -P 参数来发布EXPOSE导出的所有端口 VOLUME：用于指定持久化目录 123456789101112格式： VOLUME [\"path\"]示例： VOLUME [\"/data\",\"/home\"]注： 和docker run -v 的区别是无法挂载指定的目录. 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能： 1.卷可以容器间共享和重用 2.容器并不一定要和其它容器共享卷 3.修改卷后会立即生效 4.对卷的修改不会对镜像产生影响 5.卷会一直存在，直到没有任何容器在使用它 WORKDIR：工作目录，类似于cd命令 12345678格式： WORKDIR path示例： WORKDIR /home (这时工作目录为/home) WORKDIR jenkins-running-jar (这时工作目录为/home/jenkins-running-jar)注： 通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY等命令都会在该目录下执行。 在使用docker run运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 docker 执行DockerFile创建镜像基础镜像 docker pull centos:7.2.1511先从仓库中拉取一个centos7.2的系统，来作为最底层的镜像 先下载 jre-8u201-linux-x64.tar.gz 下载地址 以此为基础创建一个具备java环境的基础镜像 这里使用jre而非jdk，主要是为了降低镜像大小。 这里注意需要引入镜像的文件必须与Dockerfile路径同级或下级 在jre-8u201-linux-x64.tar.gz文件路径下 vi Dockerfile 创建镜像，拷贝以下内容 123456789101112131415#使用的基础镜像FROM centos:7.2.1511#作者信息MAINTAINER caijinkun \"caijinkun@mastercom.cn\"#安装中文和zip支持RUN yum -y install kde-l10n-Chinese &amp;&amp; yum -y reinstall glibc-common &amp;&amp; yum -y install unzip zip &amp;&amp; yum clean all &amp;&amp; localedef -c -f UTF-8 -i zh_CN zh_CN.utf8#加入jreADD jre-8u201-linux-x64.tar.gz /usr/local/#设置环境变量ENV JAVA_HOME /usr/local/jre1.8.0_201ENV PATH $JAVA_HOME/bin:$PATHENV LC_ALL zh_CN.utf8ENV TZ Asia/Shanghai 执行Dockfile文件 docker build -t java:jre1.8.0.201 . 并检查镜像创建是否成功docker images java mtex-config镜像基础镜像已经完毕，准备创建程序的DockerFile和程序，这里以mtex-config为例 12345678910111213#使用的基础镜像FROM java:jre1.8.0.201#作者信息MAINTAINER caijinkun \"caijinkun@mastercom.cn\"#加入服务ADD mtex-config-0.0.1-SNAPSHOT.zip tmp.zipRUN mkdir -p /home/jenkins-running-jar/mtex-config/ &amp;&amp; unzip -o tmp.zip -d /home/jenkins-running-jar/mtex-config/ &amp;&amp; rm -f tmp.zip &amp;&amp; rm -rf /home/jenkins-running-jar/mtex-config/properties &amp;&amp;rm -rf /home/jenkins-running-jar/mtex-config/properties_*#工作目录WORKDIR /home/jenkins-running-jar/mtex-config/#启动服务CMD [\"nohup\",\"java\",\"-jar\",\"mtex-config-0.0.1-SNAPSHOT.jar\"] 这里需要引入自身的配置文件夹，所以把压缩包引入镜像后先删除原配置文件夹.待使用docker启动时将自身配置文件挂载进去，也可以使用其他方式. 使用docker启动mtex-config,这里pro-properties是我自身的配置文件夹名称，这里挂载到主机的是linux自带的日志，可自行进行log日志挂载 1docker run --name mtex-config -tid --privileged=true --restart=always --net=host -v /home/jenkins-running-jar/mtex-config/pro-properties:/home/jenkins-running-jar/mtex-config/properties/ -v /home/file/nohupLog/mtex-config.log:/home/jenkins-running-jar/mtex-config/nohup.out mtex-config 启动容器时把自身的配置文件夹挂载到容器中即可.--net=host代表和主机使用同一个网段,即同一个IP和端口. 如果打算通过-p进行端口映射，需要先在启宿主机的防火墙上开启该端口，并对外暴露. mtex-sys镜像程序镜像基本都类似，都是根据业务要求挂载不同的文件即可. 12345678910111213#使用的基础镜像FROM java:jre1.8.0.201#作者信息MAINTAINER caijinkun \"caijinkun@mastercom.cn\"#加入服务ADD mtex-sys-0.0.1-SNAPSHOT.zip tmp.zipRUN mkdir -p /home/jenkins-running-jar/mtex-sys/ &amp;&amp; unzip -o tmp.zip -d /home/jenkins-running-jar/mtex-sys/ &amp;&amp; rm -f tmp.zip#工作目录WORKDIR /home/jenkins-running-jar/mtex-sys/#启动服务CMD [\"nohup\",\"java\",\"-jar\",\"mtex-sys-0.0.1-SNAPSHOT.jar\"] docker启动mtex-sys实例: 1docker run --name mtex-sys -tid --privileged=true --restart=always --net=host -v /home/file/nohupLog/mtex-sys.log:/home/jenkins-running-jar/mtex-sys/nohup.out mtex-sys 这时要注意，sys作为框架需要访问很多个项目的文件夹配置及路径，根据需求进行挂载，或者弄一个项目的共享文件夹即可.","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"}]},{"title":"'docker（二） 安装nginx redis'","slug":"docker-use","date":"2020-05-21T11:30:00.000Z","updated":"2020-09-23T08:23:12.368Z","comments":true,"path":"2020/05/21/docker-use/","link":"","permalink":"https://midkuro.github.io/2020/05/21/docker-use/","excerpt":"","text":"docker 安装 nginxdocker安装镜像，使用的是两个命令docker search xxx 和 docker pull xxx，xxx则为要安装的镜像名称,这里要注意的是创建容器会和主机时间相差8个小时 搜索nginx镜像 docker search nginx 安装nginx镜像 docker pull nginx 查看镜像信息 docker images nginx 建议在nginx.conf中配置使用root启动nginx避免权限不足引起问题 编辑配置文件并设置为root. 重命名镜像名称 docker tag IMAGEID REPOSITORY:TAG IMAGEID是镜像ID，REPOSITORY是镜像新名称，TAG是镜像新标签 创建并启动容器命令 docker run [OPTIONS] IMAGE [COMMAND] [ARG...] docker启动nginx实例： docker run 参数配置 作用 --name xxx 为容器指定一个名称为 xxx -t 为容器重新分配一个伪输入终端，通常与 -i 同时使用； -i 以交互模式运行容器，通常与 -t 同时使用； -d 后台运行容器，并返回容器ID； --privileged=true centos默认关闭SElinux，需要开启特权模式，以root的形式进入容器，否则是普通用户 --restart=always 容器开启自动启动 -p 端口映射，格式为：主机(宿主)端口:容器端口 -v 主机路径:容器路径 把主机的文件挂载到容器中 或 把容器文件同步到主机中 -v /etc/localtime:/etc/localtime:ro 把主机时间同步到容器中，不同步会相差8小时 123456789docker run --name nginx -tid --privileged=true --restart=always -p 8181:8181 -v /home/local/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/file/log/nginx/log:/var/log/nginx -v /home/jenkins-running-jar/static/:/home/jenkins-running-jar/static/ -v /etc/localtime:/etc/localtime:ro docker.io/nginx#分解命令#把容器的日志配置同步到主机中-v /home/file/log/nginx/log:/var/log/nginx #是把主机中的配置文件挂载到容器中-v /home/local/nginx/conf/nginx.conf:/etc/nginx/nginx.conf#挂载nginx配置中需要访问的静态文件-v /home/jenkins-running-jar/static/:/home/jenkins-running-jar/static/ docker.io/nginx为镜像名称 查看容器命令 docker ps -a 停止容器命令 docker stop 容器ID或容器名称 删除容器命令 docker rm 容器ID或者容器名称 进入容器命令 docker exec -it 容器ID /bin/bash 退出容器命令 exit 删除镜像命令 docker rmi 镜像ID docker 安装 Redis安装Redis镜像 docker pull redis:3.2 准备 redis.conf,若无此文件可自行新建同名文件并复制进去如果使用上文配置文件则可不需要执行以下操作，原版的redis.conf需修改以下几点:原文件： 1234bind 127.0.0.1protected-mode yesappendonly no//持久化# requirepass foobared 修改后： 1234#bind 127.0.0.1protected-mode noappendonly yes//持久化requirepass yourpassword //redis密码 docker启动redis实例： 1234567docker run --name redis -tid --privileged=true --restart=always -p 6379:6379 -v /home/local/redis/redis.conf:/etc/redis/redis.conf -v /home/local/redis/data:/data redis redis-server /etc/redis/redis.conf#分解命令#把主机的配置文件挂载到容器中-v /home/local/redis/redis.conf:/etc/redis/redis.conf#映射挂载的数据目录-v /home/local/redis/data:/data","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"}]},{"title":"'docker（一） 安装及存储路径配置'","slug":"docker-install","date":"2020-05-21T11:00:00.000Z","updated":"2020-05-26T03:57:18.936Z","comments":true,"path":"2020/05/21/docker-install/","link":"","permalink":"https://midkuro.github.io/2020/05/21/docker-install/","excerpt":"","text":"docker 安装及存储路径配置docker的安装安装docker yum install docker 启动服务 systemctl start docker.service 设置开机自启 systemctl enable docker.service 查看docker版本 docker version 使用centos7系统的，建议把selinux服务关闭，它会影响docker的启动及一些容器的使用. SELinux一共有3种状态，分别是Enforcing，Permissive和Disabled状态。第一种是默认状态，表示强制启用，第二种是宽容的意思，即大部分规则都放行。第三种是禁用，即不设置任何规则。可以通过命令 getenforce 查看selinux服务的状态，默认一般都是 Enforcing。 修改selinux状态，编辑配置文件 vi /etc/selinux/config 将 SELINUX=enforcing改为SELINUX=disabled，该操作后需要重启机器。 docker存储路径配置docker每次创建一个镜像、容器都会占据大量的内存空间，所以建议在安装的时候就把docker放在大空间的路径下，默认的docker是安装在/var/lib/docker下. 如果docker已经启动，请先关闭它 systemctl stop docker.service . 我打算把它迁移到 /home/docker 路径下，所以先创建文件夹 mkdir /home/docker 然后编辑docker存储路径配置 vi /lib/systemd/system/docker.service,找到ExecStart项 ,把它改成ExecStart=/usr/bin/dockerd --graph /home/docker 保存文件后需要执行命令重新加载配置 systemctl daemon-reload. 然后将原路径文件拷贝到新的路径下 cp -r /var/lib/docker/* /home/docker/ docker中不存在容器的话，可以把原路径下的文件删除 如果docker已经存在容器，需要迁移容器的挂载点 首先输入命令 df -hl 查看挂载点，docker容器会创建名称为overlay和shm的挂载点.这时候可以执行命令cat /proc/mounts|grep docker查看挂载点哪些是属于docker的. 然后执行 umount 挂载点全路径 去掉该容器的挂载，并修改挂载点的路径，改成迁移后的docker路径,重新执行挂载命令 mount 新挂载点路径 再次查看挂载 df -hl 这时候应该看到的都是新的路径，也可以删除原路径下的文件了，如果依旧删除失败，重启机器后可删除，然后尝试运行镜像。 如果运行镜像失败提示:Error response from daemon: shim error: docker-runc not installed on system,执行命令创建软连接cd /usr/libexec/docker/和ln -s docker-runc-current docker-runc 如果运行镜像失败提示:exec: “docker-proxy”: executable file not found in $PATH，执行命令创建软连接 ln -s /usr/libexec/docker/docker-proxy-current /usr/bin/docker-proxy 再次运行镜像，应该就能启动了，个人觉得迁移存储路径，有很大可能会出现上面的运行镜像失败的错误，如果是新装的docker迁移了存储路径，也可以先执行上面创建软连接的命令避免以后发生错误. 常用的docker命令 docker run 参数配置 作用 -v /etc/localtime:/etc/localtime:ro 把主机时间同步到容器中，不同步会相差8小时 --privileged=true centos默认关闭SElinux，需要开启特权模式，以root的形式进入容器，否则是普通用户 --restart=always 容器开启自动启动 --net=host 容器和宿主机的IP同网段 -v 主机路径:容器路径 用户把主机的文件挂载到容器中 /usr/sbin/init 在容器中开启系统命令，能够使用systemctl的命令 -d: 后台运行容器，并返回容器ID； -i: 以交互模式运行容器，通常与 -t 同时使用； -p: 端口映射，格式为：主机(宿主)端口:容器端口 -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； --name=nginx-lb 为容器指定一个名称； 命令大全","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"}]},{"title":"'linux（四） 安装Nodejs'","slug":"linux-nodejs","date":"2020-05-20T13:00:00.000Z","updated":"2020-05-26T04:02:24.954Z","comments":true,"path":"2020/05/20/linux-nodejs/","link":"","permalink":"https://midkuro.github.io/2020/05/20/linux-nodejs/","excerpt":"","text":"node.js安装第一种安装方式1.安装gcc，make，openssl 1yum install -y gcc make gcc-c++ openssl-devel 2.下载安装包下载 node-v9.3.0-linux-x64.tar.gz 下载地址 需要其他版本的请到官网中下载即可 官网地址 3.上传安装包 创建nodejs路径文件夹 1mkdir /var/local/nodejs 进入该路径,并上传安装包到该路径中 1cd /var/local/nodedjs 4.解压安装包 1tar -xf node-v9.3.0-linux-x64.tar.gz 5.编译 进入源代码所在路径 1cd node-v9.3.0-linux-x64 执行配置脚本 1./configure 编译与部署 1make &amp;&amp; make install 6.测试 12node -vnpm -v 这种方式安装，需要安装安装gcc等一些编译环境插件，而且编译比较久，部署完成后nodejs为分别放在好几个文件夹内： 123456#放置nodejs 执行程序/usr/local/bin#放置了node_modules，即nodejs的各种模块/usr/lib#放置了nodejs扩展开发用头文件/usr/include 优点是全局安装nodejs模块，直接使用，而且不受用户访问权限影响，推荐使用这种. 第二种安装方式可以不用执行上面的第一步操作，然后用以下方式替代第五步操作 确认node.js的路径，我这里是/usr/local/nodejs/node-v9.3.0-linux-x64/bin，依次执行 12ln -s /usr/local/nodejs/node-v9.3.0-linux-x64/bin/node /usr/bin/nodeln -s /usr/local/nodejs/node-v9.3.0-linux-x64/bin/npm /usr/bin/npm 注意ln指令用于创建关联（类似与Windows的快捷方式）必须给全路径，否则可能关联错误 该方式需要使用root权限去关联，并且非root用户需要做环境变量配置才能使用node.js node.js卸载1.自带工具删除 1yum remove nodejs npm -y 2.2.手动删除残留 进入 /usr/local/bin 删除 node 的可执行文件node和npm 进入 /usr/local/lib 删除所有 node 和 node_modules文件夹 进入 /usr/local/include 删除所有 node 和 node_modules 文件夹 检查 ~ 文件夹里面的”local”、”lib”、”include”、文件夹，然后删除里面的所有”node” 和”node_modules”文件夹 jenkins中使用node.js 在jenkins界面上 系统管理-全局工具配置 中配置安装的nodejs路径 先搭建一个jenkins前端构建任务，构建一次，作用是为了让jenkins检出SVN上的前端代码 到jenkins项目路径中 cd进入workspace文件夹，再进入前端任务名称的文件夹 确认检出的SVN代码文件夹中是否有package.json文件,进入文件路径中 执行以下命令安装node_modules 123npm install webpack -gnpm install webpack-cli -gnpm install --unsafe-perm=true --allow-root 然后组件安装完成后，即可在jenkins构建任务中编辑shell命令执行npm run dist-p-xxx等操作","categories":[{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.github.io/categories/Nodejs/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.github.io/tags/Nodejs/"}]},{"title":"'linux（三） 安装nginx redis'","slug":"linux-software","date":"2020-05-20T12:35:00.000Z","updated":"2020-05-28T05:27:56.970Z","comments":true,"path":"2020/05/20/linux-software/","link":"","permalink":"https://midkuro.github.io/2020/05/20/linux-software/","excerpt":"","text":"安装nginx1.下载安装包nginx-1.14.1.tar.gz 其他版本请自行下载 官网地址 2.上传并解压安装包 1tar -zxvf nginx-1.14.1.tar.gz 3.设置配置信息 1./configure --prefix=/usr/local/nginx (安装后的文件存放路径） 如果出现以下异常信息 1234./configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option. 则执行命令安装pcre-devel 1yum -y install pcre-devel 安装pcre-devel完成后再次执行命令 1./configure --prefix=/usr/local/nginx 执行完后还有可能会出现这样的问题： 1234567checking for PCRE JIT support ... not foundchecking for system md library ... not foundchecking for system md5 library ... not foundchecking for OpenSSL md5 crypto library ... not foundchecking for sha1 in system md library ... not foundchecking for OpenSSL sha1 crypto library ... not foundchecking for zlib library ... found 若出现上述问题则安装openssl 1yum -y install openssl openssl-devel 安装openssl完成后再次执行命令 1./configure --prefix=/usr/local/nginx 出现下图信息则说明配置成功 4.安装 12makemake install 出现类似这样的就表示安装成功了 123456cp conf/nginx.conf '/usr/local/nginx/conf/nginx.conf.default'test -d '/usr/local/nginx/logs' || mkdir -p '/usr/local/nginx/logs'test -d '/usr/local/nginx/logs' || mkdir -p '/usr/local/nginx/logs'test -d '/usr/local/nginx/html' || cp -R html '/usr/local/nginx'test -d '/usr/local/nginx/logs' || mkdir -p '/usr/local/nginx/logs'make[1]: Leaving directory '/root/setup/nginx/nginx-1.14.1' 安装完后/usr/local/nginx 后出现几个文件夹conf、html、logs、sbin，配置nginx.conf在文件夹conf中 启动nginx 1./usr/nginx/sbin/nginx 部分nginx启动失败解决方法 关闭SELINUX 12vi /etc/selinux/config将SELINUX=enforcing改为SELINUX=disabled 这时候需要注意，开启nginx配置的防火墙端口 开启防火墙端口教程 安装redis1.安装redis 1yum install redis 2.下载fedora的epel仓库 1yum install epel-release 3.安装redis数据库 1yum install redis 4.修改redis.conf配置文件 123456789101112原文件：bind 127.0.0.1protected-mode yesappendonly no//持久化# requirepass foobared修改后：#bind 127.0.0.1protected-mode noappendonly yes//持久化requirepass yourpassword //redis密码 5.使用配置文件启动 redis 1redis-server /etc/redis.conf &amp; 6.启动redis相关命令 12345678# 启动redisservice redis start 或 systemctl start redis.service# 停止redisservice redis stop 或 systemctl stop redis.service# 查看redis运行状态service redis status 或 systemctl status redis.service# 查看redis进程ps -ef | grep redis 7.本机测试访问 12redis-cli -h 127.0.0.1 -p 6379quit 这时候需要注意，非本机访问redis需要开启防火墙端口 开启防火墙端口教程","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.github.io/categories/Nginx/"},{"name":"Redis","slug":"Nginx/Redis","permalink":"https://midkuro.github.io/categories/Nginx/Redis/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.github.io/tags/Linux/"},{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.github.io/tags/Nginx/"},{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/tags/Redis/"}]},{"title":"'linux（二） centos7设置应用程序为系统服务'","slug":"linux-systemctl","date":"2020-05-20T12:30:00.000Z","updated":"2020-05-26T03:58:29.306Z","comments":true,"path":"2020/05/20/linux-systemctl/","link":"","permalink":"https://midkuro.github.io/2020/05/20/linux-systemctl/","excerpt":"","text":"centos7使用systemctl以下的 xxx为服务名称，需根据自身需求修改 1.进入目录 1cd /usr/lib/systemd/system/ 2.创建xxx.service文件 1vi xxx.service 3.赋予xxx.service文件权限 1chmod 754 xxx.service xxx.service文件详解[Unit] 部份 设置参数 参数意义说明 Description 服务名称 After 说明此服务 是在哪个服务启动之后才启动的意思！基本上仅是说明服务启动的顺序而已，并没有强制要求里头的服务一定要启动后此 unit 才能启动。 Before 与 After 的意义相反，是在什么服务启动前最好启动这个服务的意思。不过这仅是规范服务启动的顺序，并非强制要求的意思。 Requires 明确的定义此服务需要在哪个服务启动后才能够启动！就是设置相依服务！如果在此项设置的前导服务没有启动，那么此服务就不会被启动！ Conflicts 代表互斥的服务！亦即这个项目后面接的服务如果有启动，那么我们这个服务本身就不能启动！我们服务有启动，则此项目后的服务就不能启动！ [Service] 部份 设置参数 参数意义说明 Type 说明这个程序启动的方式，会影响到 ExecStart,一般来说，有下面几种类型 simple：默认值，这个程序主要由 ExecStart 接的指令串来启动，启动后常驻于内存中。forking：由 ExecStart 启动的程序通过 spawns 延伸出其他子程序来作为此程序 的主要服务。原生的父程序在启动结束后就会终止运行。 传统的 unit 服务大多属于这种项目.还有oneshot、dbus、idle等类型，请自行了解. EnvironmentFile 可以指定启动脚本的环境配置文件.例如 sshd.service 的配置文件写入到 /etc/sysconfig/sshd 当中！你也可以使用 Environment= 后面接多个不同的 Shell 变量来给予设置 ExecStart 启动应用程序的命令 ExecStop 停止应用程序的命令 ExecReload 重载应用程序的命令 Restart 当设置 Restart=1 时，则当此服务终止后，会再次的启动此服务 [Install] 部份 设置参数 参数意义说明 WantedBy 这个设置后面接的大部分是 *.target unit,意思是这个服务本身是附挂在哪一个target unit下面的,都是附挂在 multi-user.target下面 redis及nginx为例以redis为例，在该路径下 vi redis.service，并复制进去以下内容，进行相应修改. 123456789101112[unit]Description&#x3D;redis - high performance web serverAfter&#x3D;network.target remote-fs.target nss-lookup.target[Service]Type&#x3D;forkingExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis-5.0.2&#x2F;start.shExecReload&#x3D;ExecStop&#x3D;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis-5.0.2&#x2F;stop.sh[Install]WantedBy&#x3D;multi-user.target 以nginx为例，在该路径下 vi nginx.service，并复制进去以下内容，进行相应修改. 123456789101112[unit]Description&#x3D;nginx - high performance web serverAfter&#x3D;network.target remote-fs.target nss-lookup.target[Service]Type&#x3D;forkingExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.confExecReload&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reloadExecStop&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s stop[Install]WantedBy&#x3D;multi-user.target 比如我mtex-auth服务的启动需要依赖mtex-config服务，可以这样配置vi mtex-auth.service 123456789101112[Unit]Description&#x3D;mtex-auth - high performance web serverAfter&#x3D;network.target remote-fs.target nss-lookup.target mtex-configRequires&#x3D;mtex-config[Service]Type&#x3D;forkingExecStart&#x3D;&#x2F;home&#x2F;jenkins-running-shell&#x2F;mtex-auth&#x2F;start.shExecReload&#x3D;ExecStop&#x3D;&#x2F;home&#x2F;jenkins-running-shell&#x2F;mtex-auth&#x2F;stop.sh[Install]WantedBy&#x3D;multi-user.target 服务命令操作以nginx为例，保存nginx.service文件后赋予执行权限 1chmod 754 nginx.service nginx开机自启 1systemctl enable nginx.service 启动nginx 1systemctl start nginx.service 停止nginx 1systemctl stop nginx.service 重启nginx 1systemctl restart nginx.service centos7也可以使用旧版命令 system stop xxx 、system start xxx达到效果.","categories":[{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.github.io/categories/Systemctl/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.github.io/tags/Linux/"},{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.github.io/tags/Systemctl/"}]},{"title":"'linux（一） 开放防火墙端口'","slug":"linux-firewalld","date":"2020-05-20T12:00:00.000Z","updated":"2020-05-26T03:57:49.478Z","comments":true,"path":"2020/05/20/linux-firewalld/","link":"","permalink":"https://midkuro.github.io/2020/05/20/linux-firewalld/","excerpt":"","text":"centos7开放防火墙端口启动防火墙 1systemctl start firewalld 停止防火墙 1systemctl stop firewalld 查看防火墙状态 1firewall-cmd --state 查看防火墙启动状态详情 1systemctl status firewalld 开机禁用 1systemctl disable firewalld 开机启用 1systemctl enable firewalld 查看所有打开的端口 1firewall-cmd --zone=public --list-ports 开启端口 1firewall-cmd --zone=public --add-port=80/tcp --permanent –permanent永久生效，没有此参数重启后失效 重新载入 1firewall-cmd --reload 查看端口状态 1firewall-cmd --zone=public --query-port=80/tcp 删除端口 1firewall-cmd --zone= public --remove-port=80/tcp --permanent","categories":[{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.github.io/categories/Firewall/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.github.io/tags/Linux/"},{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.github.io/tags/Firewall/"}]},{"title":"'jenkins（四） 参数化构建'","slug":"jenkins-param","date":"2020-05-20T07:50:40.000Z","updated":"2020-05-26T03:56:24.453Z","comments":true,"path":"2020/05/20/jenkins-param/","link":"","permalink":"https://midkuro.github.io/2020/05/20/jenkins-param/","excerpt":"","text":"jenkins参数化构建通过输入参数进行构建项目，需要插件build with parameters plugin，正常安装成功的jenkins应该都会自带了的，那么参数可以做什么事呢？如果我想要jenkins构建svn上指定版本号的代码并进行测试，就可以使用参数构建. 首先先了解一下怎么获取svn上指定的版本代码:通过项目路径@版本号进行获取的，版本号为head时，则取最新版本. 打开jenkins的任务配置，在General模块中找到参数化构建工程,勾选并添加自己的参数类型，本文选的是字符参数. 填写完相应的参数配置，需要修改项目svn的路径，将其改成项目路径@$参数名称 的格式.这时候的svn校验将失效，因为是配置了参数. 点击保存，就已经完成了参数化构建的配置了.这时候立即构建的按钮将变成Build with Parameters ,是不是觉得很简单？ 这时候又会发现，上下游均配置了参数化构建，但是触发了上游项目构建，并不能将参数传递到我的下游项目中，这时候会发现下游项目使用的是配置中的默认参数head,怎么做到传递一次参数即可触发构建呢？ 这时候要先安装一款插件Parameterized Trigger Plugin，安装完成后解除项目的上下游关系 然后编辑上游项目的任务配置，找到Post Steps模块,点击Add post-build step,能够看到多了一项选择，选中Trigger/call builds other projects 这里做的是正向配置上下游关系，上文解除了之前上下游关系，目的就是为了在这里通过参数传递进行配置。填入下游项目的工程名称，并点击Add Parameters添加参数，在这里我选择的是Predefined parameters,其他的暂时没有去了解.并填写传参的参数，格式为参数名=${参数名大写},这里我并有去测试小写能不能传递，亲们可以试试看… 这时候构建上游，也能够接收到同样的参数并指定的SVN版本号进行构建了,如果想要在shell命令中使用参数，也可以通过${参数名大写}进行取值. jenkins远程触发项目构建jenkins远程触发项目构建能够实现的功能有很多，本文主要讲解如何通过一个url进行触发构建. 打开任务配置并找到构建触发器模块，勾选触发远程构建并配置一个秘钥，这个秘钥相当于密码，密码错误的话不会触发构建. 如何调度已经说得很清楚了：http://IP:端口号/job/任务名称/build?token=秘钥 也可以使用参数进行远程触发：http://IP:端口号/job/任务名称/buildWithParameters?token=秘钥&amp;&amp;参数名=参数值 也就是说，这时候项目配置了参数构建及远程触发构建，就可以通过http请求的调度促使jenkins进行参数化远程构建… 这个时候会发现，如果我没有登录，它是不让我远程触发构建的，那我如何不需要登录就进行触发构建呢？ 首先先安装一个插件Build Authorization Token Root Plugin,然后登录用户-&gt;点击右上角的登录名-&gt;再点击设置 输入生成token的字符串，并生成一串token秘钥，切记拷贝生成的token秘钥，然后回到项目的构建触发器模块，将生成的token秘钥填入身份验证令牌中即可 这时候请求的url将发生变化: 无参请求:http://IP:端口号/buildByToken/build?job=任务名称&amp;token=秘钥 参数请求:http://IP:端口号/buildByToken/buildWithParameters?job=任务名称&amp;token=秘钥&amp;参数名=参数值","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]},{"title":"'jenkins（三） 上下游与持续集成构建'","slug":"jenkins-upstream","date":"2020-05-20T05:52:40.000Z","updated":"2020-05-26T03:56:59.779Z","comments":true,"path":"2020/05/20/jenkins-upstream/","link":"","permalink":"https://midkuro.github.io/2020/05/20/jenkins-upstream/","excerpt":"","text":"spring boot项目之间的引用触发上下游构建首先上下游关系是可以通过配置实现的，可以通过正向配置或反向配置实现，建议统一使用一种。 先理解一下上游下游的概念，目前我的dao项目作为一个基础类库，然后mtex-auth引入依赖dao，那么dao就是mtex-auth的上游，mtex-auth就是dao的下游。 在这情况下，上游dao主动去建立和下游的mtex-auth的关系，则为正向配置，而下游mtex-auth主动去建立和上游dao的关系，则为反向配置。 正向配置：在dao任务中找到 构建后操作模块增加构建后操作步骤，选择构建其他工程，在该路径填写mtex-auth任务名称,则dao构建成功后会主动触发mtex-auth任务进行构建 反向配置:在mtex任务中找到 构建触发器模块，勾选其他工程构建后触发并填写dao任务名称 在我的理解中，不管正向配置还是反向配置，作用都是一样的，都是建立上下游关系，上游构建成功后触发下游构建,所以建议只使用一种配置，没必要双向关系. 配置好上下游权限后，建议每一个下游任务的配置中增加限制，打开任务进入General模块，点击高级，勾选该项目上游正在构建时阻止该项目构建选项. 设想一下，如果存在项目关系如下： A项目作为B项目的上游 A项目作为C项目的上游 B项目作为C项目的上游 那么在A项目构建成功后，逻辑来讲它是会触发两个下游之间的构建，也就是B项目和C项目同时构建，等B项目构建完会再次触发一次C项目的构建。而通过勾选上游构建时阻止构建下游，就能避免这个问题。 最理想的构建顺序是 A-B-C ,那么在A任务的正向配置中，则不需要配置下游项目C，只需要配置下游项目B，反向配置也一样。 其次，在任务模块构建触发器中，建议关闭 Build whenever a SNAPSHOT dependency is built，因为该配置会根据pom文件的快照项目依赖自动创建上下游关系，导致和正反向配置重复并可能出现多次打包的情况。 jenkins持续集成构建任务关系依赖可能出现这种情况，A、B、C项目都作为D项目的上游，而A、B、C又是单独互不影响的项目，这时候它们是可以进行并发构建的，可是这样就会触发D项目的3次构建，这明显是不合理的，那么怎么做到 A、B、C项目同时构建，然后再触发下游D项目的构建呢？ 首先安装一个串行的插件 Multijob,它支持将任务捆绑构建。我们需要先解除A、B、C项目和D项目的上下游关系，也就是取消正反向配置,并且取消A、B、C任务中General模块的 该项目上游正在构建时阻止该项目构建配置，切记必须取消，否则无法进行构建. 新建任务，选择 Multijob Project,创建一个任务E。 找到构建模块，点击增加构建步骤并选择Multijob Phase,并依次添加A、B、C任务名称 这个时候可以点击每个任务右下角的高级进行详细配置 构建方式可以选择 串行或者并行，串行的话则按照添加任务的顺序进行构建，并行则同时构建。 构建条件可以选择 构建成功触发、构建失败触发、无论结果如何都触发等操作，按需求配置。 配置完成后关联E项目和D项目之间的上下游关系,并配置该项目上游正在构建时阻止该项目构建即可，就能满足触发E项目时， 触发A、B、C项目同时构建，然后再触发下游D项目的构建的操作。 这个时候如果项目是并行的，必须设置jenkins的最大并行执行器的数量,系统管理-&gt;系统设置-&gt;填写执行器数量。","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]},{"title":"'jenkins（二） 搭建简单的构建'","slug":"jenkins-use","date":"2020-05-20T05:51:40.000Z","updated":"2020-05-26T03:57:05.302Z","comments":true,"path":"2020/05/20/jenkins-use/","link":"","permalink":"https://midkuro.github.io/2020/05/20/jenkins-use/","excerpt":"","text":"jenkins插件安装及环境配置在使用jenkins之前，我们先学会配置jenkins的环境以及插件的安装，jenkins的环境配置均支持自动下载安装，但是不建议，也许是个人对环境路径存放位置具有强迫症吧。 首先进入jenkins页面，点击左侧 系统管理 ,然后找到 全局工具配置 然后选中 JDK及Maven的环境进行配置，点击新增将出现配置路径，将已安装的JDK及Maven路径配置上即可,对git有需要的可以自行配置. 配置完成后点击下方的save进行保存，接下来进入插件安装，点击插件管理，并进入可选插件界面 在该界面中，请不要使用右上角的 过滤 功能，由于插件过多，使用jenkins自带的过滤功能会导致浏览器卡死，所以请使用浏览器内容搜索的功能 ctrl + F在浏览器的搜索框中输入 Maven Integration 搜索maven插件，不同的插件版本命名可能略有差异，找到maven插件后在左边文本框中打钩，点击下方直接安装即可 在安装过程中，有一个安装后重启jenkins的设置，建议取消打钩，等待安装完成即可. jenkins基于maven编译简单的java项目在主界面中点击新建任务 进行创建，此时能够看到构建一个maven项目,该选项是需要安装 Maven Integration 才会出现的，选中它并输入项目名称，点击下方的确认按钮 上图的步骤2也可以通过输入一个已存在的任务名称，将任务的所有配置拷贝复制到新建任务当中. General：建议一定要勾选丢弃旧的构建，并配置构建保留天数及数量，可以配置10天、10个，感觉足以，不丢弃旧的构建容易把磁盘空间占满. 源码管理：选中SVN（Git操作也差不多）,并输入项目的svn路径，然后添加svn访问用户，输入账号密码即可，jenkins会自动帮你检测该账号能否访问svn路径并提示。 构建触发器配置： 第一个参数代表的是分钟 minute，取值 0~59； 第二个参数代表的是小时 hour，取值 0~23； 第三个参数代表的是天 day，取值 1~31； 第四个参数代表的是月 month，取值 1~12； 最后一个参数代表的是星期 week，取值 0~7，0 和 7 都是表示星期天。 常用例子: 每小时构建一次： * H/1 * * * 每隔5分钟构建一次： H/5 * * * * 每天8点30分构建一次： 30 8 * * * 每个小时的第10分钟构建一次： 10 * * * * 每周六日的1点10分构建一次： 10 1 * * 6,0 Pre Steps：构建前需要执行的一些操作，可以选择shell脚本、window命令等，这个根据需求去研究如何配置，暂时不细讲 Build： 建议使用clean install 替换 clean package 命令,clean package是把项目打包到target下，它并不会打包到maven的仓库，而clean install会打包进maven的仓库，可以避免一些不必要的问题。 比如我曾经遇见过的一个问题，A项目依赖了B项目，而B项目使用的是clean package命令，导致A项目打包的时候去maven仓库找不到B项目的jar包，所以A项目一直打包失败。 Post Steps：构建后需要执行的一些操作，同Pre Steps，其中构建不稳定指的是最近的5次构建中，曾经出现过构建失败。 构建的邮件发送通知以后再细讲，配置到这后一个简单的构建任务就已经完成了，点击保存，界面会出现新建的构建任务，点击右边的构建即可。 进入项目详情，左下角能够看到一些构建历史，点击构建历史能够查看每一次的构建详情，也能看到触发的构建原因，SVN更新的版本、信息等。","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]},{"title":"'jenkins（一） 安装及卸载'","slug":"jenkins-install","date":"2020-05-20T05:50:40.000Z","updated":"2020-05-26T03:56:56.324Z","comments":true,"path":"2020/05/20/jenkins-install/","link":"","permalink":"https://midkuro.github.io/2020/05/20/jenkins-install/","excerpt":"","text":"安装JDK使用jenkins，需要安装jdk及maven，可以自己安装于本机，也可以通过安装完jenkins后进行自动安装。 jdk-8u201-linux-x64.tar.gz 下载地址 官网地址 apache-maven-3.6.0-bin.tar.gz 下载地址 官网地址 如需更换版本请另行到官网中下载,在linux系统中安装包请选择 linux-x64.tar.gz后缀的安装包进行下载. 下文涉及到JDK及Maven版本相关的命令请自行修改成对应的版本. 在linux终端输入命令 cd /usr/local/ ，并创建java文件夹 mkdir java 执行 cd java 进入java路径中，并将下载的安装包上传至该路径 /usr/local/java下 然后执行命令解压下载的压缩包: tar -zxvf jdk-8u201-linux-x64.tar.gz 若提示错误则请先执行 yum install -y tar 安装压缩包命令再执行解压命令(仅限centos，其他系统请自行百度). 使用vi进入文件编辑模式，配置环境变量:vi /etc/profile 敲击键盘i进入编辑模式，在文件末尾添加以下内容: 12345export JAVA_HOME=/usr/local/java/jdk1.8.0_201export JAVA_BIN=/usr/local/java/jdk1.8.0_201/binexport PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$PATH 敲击键盘:wq 表示退出vi编辑模式并保存修改 执行命令使系统环境变量配置重新加载：source /etc/profile 测试JDK安装是否成功,输入 javac 和java -version 是否安装成功.出现下图类似的信息即安装成功 安装Maven操作与JDK基本相同，Maven环境变量需要配置的内容： 12export MAVEN_HOME=/usr/local/maven/apache-maven-3.6.0export PATH=$PATH:$MAVEN_HOME/bin` 测试Maven安装是否成功，输入 mvn -v 或者 mvn -version 即可. 安装Jenkinsjenkins安装包 jenkins-2.138.3-1.1.noarch.rpm 下载地址 官网地址 不同版本的jenkins安装插件的成功率不一样，推荐使用该jenkins版本，支持中文，并且插件安装的成功率较高。 上传安装包至linux服务器任意路径下，并在该路径下执行 rpm -ivh jenkins-2.138.3-1.1.noarch.rpm 进行安装 安装成功后可查看jenkins默认安装目录： rpm -ql jenkins 可自定义修改jenkins配置文件： vi /etc/sysconfig/jenkins 123456#jenkins端口配置JENKINS_PORT=\"8080\"#启动jenkins的用户，最好使用root，否则会出现权限不够等问题JENKINS_USER=\"jenkins\"#jenkins的项目路径，建议将其改成 `/data/jenkins` 放在大空间的路径下，避免出现空间不足等问题JENKINS_HOME=\"/var/lib/jenkins\" 若修改了JENKINS_HOME 配置，则需执行 cp -r 原路径 目标路径 命令，其中 -r 参数表示若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件. 根据上文将/var/lib/jenkins/路径修改为 /data/jenkins,则执行的命令为 cp -r /var/lib/jenkins/* /data/jenkins/ 退出vi编辑模式并保存 然后设置jenkins服务开机自启动: systemctl enable jenkins.service 启动jenkins: systemtl start jenkins.service ，将start改为restart、stop分别为重启、停止jenkins 如果启动时报错 Starting Jenkins -bash: /usr/bin/java: No such file or directory，则需要编辑文件 vim /etc/init.d/jenkins，将/usr/bin/java改为自己java的地址，自己java地址的查看命令 which java 启动jenkins后，浏览器访问 http://ip:端口 第一次登录Jenkins会要求解锁，复制红色标记中的路径，执行命令 cat 红色标记的路径，将返回的密码填入浏览器页面中，点击continue继续 输入完成后会提示安装自定义插件还是推荐插件，此处我选择左边的推荐插件，安装过程可能由于网络原因导致失败，后续失败的可以在系统设置-插件管理里面卸载或者重新安装即可，也可以在插件安装完成后选择retry重新安装失败的插件，尝试多几次即可。 创建用户并登陆 看到以下界面则代表jenkins已安装成功，到这里linux下安装配置jenkins教程就结束了 卸载Jenkins依次执行以下命令彻底卸载Jenkins 123456service jenkins stopyum clean allyum -y remove jenkinsrm -rf /var/cache/jenkins#请修改为自身机器的jenkins的路径rm -rf /var/lib/jenkins/","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]}],"categories":[{"name":"binary","slug":"binary","permalink":"https://midkuro.github.io/categories/binary/"},{"name":"Synchronized","slug":"Synchronized","permalink":"https://midkuro.github.io/categories/Synchronized/"},{"name":"springMVC","slug":"springMVC","permalink":"https://midkuro.github.io/categories/springMVC/"},{"name":"MySql","slug":"MySql","permalink":"https://midkuro.github.io/categories/MySql/"},{"name":"Netty","slug":"Netty","permalink":"https://midkuro.github.io/categories/Netty/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.github.io/categories/RocketMQ/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://midkuro.github.io/categories/Sentinel/"},{"name":"Stream","slug":"Stream","permalink":"https://midkuro.github.io/categories/Stream/"},{"name":"Nacos","slug":"Nacos","permalink":"https://midkuro.github.io/categories/Nacos/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.github.io/categories/Cryptography/"},{"name":"Cache","slug":"Cache","permalink":"https://midkuro.github.io/categories/Cache/"},{"name":"Source","slug":"Source","permalink":"https://midkuro.github.io/categories/Source/"},{"name":"Druid","slug":"Druid","permalink":"https://midkuro.github.io/categories/Druid/"},{"name":"NIO","slug":"NIO","permalink":"https://midkuro.github.io/categories/NIO/"},{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/categories/Redis/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/categories/ActiveMQ/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.github.io/categories/Thread/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/categories/JVM/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/categories/Kubernetes/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/categories/Docker/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.github.io/categories/Nodejs/"},{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.github.io/categories/Nginx/"},{"name":"Redis","slug":"Nginx/Redis","permalink":"https://midkuro.github.io/categories/Nginx/Redis/"},{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.github.io/categories/Systemctl/"},{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.github.io/categories/Firewall/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/categories/Jenkins/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.github.io/tags/Java/"},{"name":"linux","slug":"linux","permalink":"https://midkuro.github.io/tags/linux/"},{"name":"Synchronized","slug":"Synchronized","permalink":"https://midkuro.github.io/tags/Synchronized/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://midkuro.github.io/tags/SpringMVC/"},{"name":"MySql","slug":"MySql","permalink":"https://midkuro.github.io/tags/MySql/"},{"name":"NIO","slug":"NIO","permalink":"https://midkuro.github.io/tags/NIO/"},{"name":"Netty","slug":"Netty","permalink":"https://midkuro.github.io/tags/Netty/"},{"name":"MQ","slug":"MQ","permalink":"https://midkuro.github.io/tags/MQ/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.github.io/tags/RocketMQ/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.github.io/tags/SpringCloud/"},{"name":"Seata","slug":"Seata","permalink":"https://midkuro.github.io/tags/Seata/"},{"name":"Stream","slug":"Stream","permalink":"https://midkuro.github.io/tags/Stream/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://midkuro.github.io/tags/Sentinel/"},{"name":"Nacos","slug":"Nacos","permalink":"https://midkuro.github.io/tags/Nacos/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.github.io/tags/Cryptography/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.github.io/tags/SpringBoot/"},{"name":"Cache","slug":"Cache","permalink":"https://midkuro.github.io/tags/Cache/"},{"name":"Source","slug":"Source","permalink":"https://midkuro.github.io/tags/Source/"},{"name":"Druid","slug":"Druid","permalink":"https://midkuro.github.io/tags/Druid/"},{"name":"Redis","slug":"Redis","permalink":"https://midkuro.github.io/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://midkuro.github.io/tags/NoSql/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.github.io/tags/ActiveMQ/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.github.io/tags/Thread/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.github.io/tags/JVM/"},{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.github.io/tags/DevOps/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.github.io/tags/Kubernetes/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.github.io/tags/Docker/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.github.io/tags/Nodejs/"},{"name":"Linux","slug":"Linux","permalink":"https://midkuro.github.io/tags/Linux/"},{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.github.io/tags/Nginx/"},{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.github.io/tags/Systemctl/"},{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.github.io/tags/Firewall/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.github.io/tags/Jenkins/"}]}