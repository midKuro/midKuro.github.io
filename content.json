{"meta":{"title":"Kuro's Blog","subtitle":"Kuro","description":"坚持 是一种品格","author":"Kuro","url":"https://midkuro.gitee.io","root":"/"},"pages":[{"title":"about","date":"2020-05-20T09:29:27.000Z","updated":"2020-11-13T05:24:43.788Z","comments":true,"path":"about/index.html","permalink":"https://midkuro.gitee.io/about/index.html","excerpt":"","text":"关于我从事 JAVA 后台开发，熟悉使用 Spring Boot、Spring Cloud 等主流框架；熟悉JVM内存运行区域、类加载机制，熟悉多线程编程，线程安全设计。 对DevOps有一定的了解。编写代码遵循SonarLint检测。 热爱开源项目、热爱新技术、热爱新事物。 关于工作城市：深圳南山区 关于学习正在往终身学习者前进… 关于座右铭 坚持 是一种品格 关于爱好热爱运动，喜爱羽毛球、看小说。 联系我 Blog: midkuro.io GitHub: midkuro Email: 276302007@qq.com"}],"posts":[{"title":"'ELK 之 logstash beats'","slug":"elk-logstash","date":"2020-12-11T08:00:00.000Z","updated":"2020-12-17T05:17:06.631Z","comments":true,"path":"2020/12/11/elk-logstash/","link":"","permalink":"https://midkuro.gitee.io/2020/12/11/elk-logstash/","excerpt":"","text":"ELK Logstash开源的流数据处理、转换（解析）和发送引擎，可以采集来自不同数据源的数据，并对数据进行处理后输出到多种输出源。Logstash是ELK Stash的重要组成部分。 工作原理Logstash的数据处理过程主要包括：Inputs, Filters, Outputs 三部分，如图： Inputs：用于从数据源获取数据，常见的插件如beats、file、kafka、rabbitmq、log4j、redis等。参考 Filters：筛选器是Logstash管道中的数据处理器，input时会触发事件，触发filter对数据进行transport，即转换解析各种格式的数据，常见的过滤器插件如下： 123456789101112grok：解析和构造任意文本。是Logstash过滤器的基础，广泛用于从非结构化数据中导出结构 当前，Grok是Logstash中将非结构化日志数据解析为结构化和可查询内容的最佳方法。 mutate：对事件字段执行常规转换。支持对事件中字段进行重命名，删除，替换和修改。date：把字符串类型的时间字段转换成时间戳类型drop：完全删除事件，例如调试事件。clone：复制事件，可能会添加或删除字段。geoip：添加有关IP地址地理位置的信息。 Outputs：用于数据输出，常见的插件如: 1234567elasticsearch：最高效、方便、易于查询的存储器，最有选择，官方推荐！file：将输出数据以文件的形式写入磁盘。[stupid](javascript:;)graphite：将事件数据发送到graphite，graphite是一种流行的开源工具，用于存储和绘制指标。statsd：将事件数据发送到statsd，该服务“通过UDP侦听统计信息（如计数器和计时器），并将聚合发送到一个或多个可插拔后端服务”。 logstash-sample.yml官方文档：output logstash默认集成了beats，所以默认配置推荐使用beats进行日志采集，logstash进行分析。 1234567# ============================== inputs ===============================#和beats的通讯端口input &#123; beats &#123; port =&gt; 5044 &#125;&#125; 123456789101112131415161718192021# ================================== Outputs ===================================#将输出到es中output &#123; elasticsearch &#123; hosts =&gt; [\"http://192.168.163.129:9200\"] index =&gt; \"%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;\" #user =&gt; \"elastic\" #password =&gt; \"changeme\" &#125; #除了输出到es中，还输出到控制台 stdout &#123;codec =&gt; rubydebug &#125; #根据 beat中输入的数据携带的【tags】进行分类输出 #if \"kuro\" in [tags] &#123; # elasticsearch &#123; # hosts =&gt; [\"http://192.168.163.129:9200\"] # index =&gt; \"%logstash-es-%&#123;+YYYY.MM.dd&#125;\" # &#125; #&#125;&#125; 1234567# ================================== filter ===================================filter &#123; grok &#123; # IP:grok提供的正则 client：提取数据后作为key match =&gt; &#123; \"message\" =&gt; \"%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;\" &#125; &#125;&#125; 123456789//输入 message = 55.3.244.1 GET /index.html 15824 0.043//过滤解析成以下格式：&#123; client: 55.3.244.1 method: GET request: /index.html bytes: 15824 duration: 0.043&#125; 123#通过查看文件，能够看到logstash提供的封装好的正则表达式[root@localhost /]# cd logstash-7.10.1-linux-x86_64/logstash-7.10.1/vendor/bundle/jruby/2.5.0/gems/logstash-patterns-core-4.1.2/patterns[root@localhost /]# cat grok-pattens 1234#运行[root@localhost /]# ./bin/logstash -f config/logstash-sample.conf#使用stdin启动[root@localhost /]# ./bin/logstash -e \"input &#123;stdin &#123;&#125;&#125; output&#123; stdout &#123;&#125;&#125;\" Beats基于golang语言开发，开源的、轻量级的日志收集器的统称。官方文档 特点： 开源：社区中维护了上百个beat，社区地址 轻量级：体积小，功能单一、基于go语言开发，具有先天性能优势，不依赖于Java环境。 高性能：对CPU、内存和IO的资源占用极小。 定位：就功能而言，Beats是弟弟，得益于Java生态优势，Logstash功能明显更加强大。但是Logstash在数据收集上的性能表现饱受诟病，Beats的诞生，其目的就是为了取代Logstash Forwarder 。 官方支持的Beats（下载地址） Filebeat文件日志监控采集 ，主要用于收集日志数据，官方使用手册 由于采集日志需要访问日志文件，意味需要将程序和采集的应用程序部署在同一台机器中，Logstash的Inputs和Filter会十分耗费机器性能，十分不合理，所以有了Beats这种轻量级日志收集器。 通过让Beats进行inputs采集日志，经过Http协议传输到logstash中，这样就能使得logstash无需和应用程序部署在同一台机器中，可以用其他机器来承担Logstash的Filter的性能损耗。 filebeat.yml官方文档： inputs output 123456789101112131415161718192021222324252627282930313233343536373839404142# ============================== Filebeat inputs ===============================filebeat.inputs:#定义输入类型是log- type: log # 开启输入配置 enabled: true #配置输入log的来源路径 paths: - /var/log/*.log - /usr/local/error.log #自定义当前采集的type的标签，可以用于logstash中进行逻辑归类 tags: [\"kuro\"] #排除空行 exclude_lines: ['^$'] #json的所有key都在一个大括号里 #json.keys_under_root: true #当采集错误时增加一个error_key #json.add_error_key: true #当key值和系统key重复时覆盖 #json.overwrite_keys: true #以json的格式输入日志 #json.message_key: log # Multiline options #配置组合 1 multiline: type: pattern #非匹配到的内容往后追加 可选:before match: after #配置组合 1 pattern: '^\\[' # true表示和正则表达式匹配的作为第一行，false表示和正则不匹配的作为第一行 negate: true #配置组合2 #匹配以空格开头的内容 #pattern: '^[[:space:]]' #negate: false 1234//如这个案例，配置组合1 就会把后面的数据追加到第一行，整段作为一个事件[beat-logstash-some-name-832-2015.11.28] IndexNotFoundException[no such index] at org.elasticsearch.cluster.metadata.Exception.resolve(Resolver.java:566) at org.elasticsearch.cluster.metadata.Exception.concreteIndices(Resolver.java:133) 12345//如这个案例，配置组合2 就会把非空格的当做第一行，以空格开头的数据则追加到第一行Exception in thread \"main\" java.lang.NullPointerException at com.example.myproject.Book.getTitle(Book.java:16) at com.example.myproject.Author.getBookTitles(Author.java:25) at com.example.myproject.Bootstrap.main(Bootstrap.java:14) 123456789101112131415161718192021# ================================== Outputs ===================================# ---------------------------- Elasticsearch Output ----------------------------#输出到ES中output.elasticsearch: hosts: [\"192.168.163.129:9200\"] #动态索引名称 index: \"%&#123;[fields.log_type]&#125;-%&#123;[agent.version]&#125;-%&#123;+yyyy.MM.dd&#125;\" #协议 protocol: https # ---------------------------- Elasticsearch Output ----------------------------output.elasticsearch: hosts: [\"http://localhost:9200\"] indices: #按照日志输出的级别归档到不同的index中 - index: \"warning-%&#123;[agent.version]&#125;-%&#123;+yyyy.MM.dd&#125;\" when.contains: message: \"WARN\" - index: \"error-%&#123;[agent.version]&#125;-%&#123;+yyyy.MM.dd&#125;\" when.contains: message: \"ERR\" 12345678# ------------------------------ Logstash Output -------------------------------#输出到logstash中output.logstash: hosts: [\"localhost:5044\", \"localhost:5045\"] #有多节点则开启负载均衡 loadbalance: true #索引名称 index: filebeat 123# ------------------------------ console Output -------------------------------output.console: pretty: true 123456789101112131415161718192021222324252627支持的输入类型: Azure Event Hub Cloud Foundry Container Docker Google Pub&#x2F;Sub HTTP JSON Kafka Log MQTT NetFlow Office 365 Management Activity API Redis S3 Stdin Syslog TCP UDP 支持的输出类型： Console Elasticsearch Logstash Kafka Redis File Elastic Cloud 12#运行：[root@localhost /]# ./filebeat -e -c filebeat.yml Filebeat是读取日志是会记录到读取日志的行号，当重启或者删除es的索引，他依旧会从记录的那一行之后开始读，曾经读取过的数据不会再次读取，若想要重新全量读取，则需要去把data文件夹的数据删除。 Packetbeat通过网络抓包、协议分析，基于协议和端口对一些系统通信进行监控和数据收集。是一个实时网络数据包分析器，可以将其与Elasticsearch一起使用，以提供应用程序监视和性能分析系统。 123456789101112131415支持的协议： ICMP (v4 and v6) DHCP (v4) DNS HTTP AMQP 0.9.1 Cassandra Mysql PostgreSQL Redis Thrift-RPC MongoDB Memcache NFS TLS 12 #执行：[root@localhost /]# sudo ./packetbeat -e -c packetbeat.yml -strict.perms=false","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"}]},{"title":"'Elasticsearch（八） 集群'","slug":"elasticearch-cluster","date":"2020-12-10T09:00:00.000Z","updated":"2020-12-16T02:31:59.182Z","comments":true,"path":"2020/12/10/elasticearch-cluster/","link":"","permalink":"https://midkuro.gitee.io/2020/12/10/elasticearch-cluster/","excerpt":"","text":"Elasticsearch 集群启动用户123[root@localhost elasticsearch]# tar xf elasticsearch-7.10.1-linux-x86_64.tar.gz[root@localhost elasticsearch]# cd elasticsearch-7.10.1/bin[root@rocketmq-nameserver1 bin]# ./elasticsearch 直接通过root启动，将会出现以下异常： 1java.lang.RuntimeException: can not run elasticsearch as root 原因是ES为了安全，不允许直接使用root用户启动，需要创建用户启动： 12345678#创建用户：elasticsearch[root@localhost bin]# adduser elasticsearch#创建用户密码，需要输入两次[root@localhost bin]# passwd elasticsearch#切换到es文件夹上，将对应的文件夹权限赋给该用户[root@localhost elasticsearch]# chown -R elasticsearch elasticsearch-7.10.1#切换至elasticsearch用户[elasticsearch@localhost elasticsearch]# su elasticsearch 集群配置linux下的elasticsearch.yml配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243#---------------------------------- Cluster -----------------------------------#配置文件配置相同的集群名称cluster.name: my-application# ------------------------------------ Node ------------------------------------#各个节点需要有不同的结点名称node.name: node-1# ----------------------------------- Paths ------------------------------------#节点存储数据目录 生产环境不要使用默认目录path.data: /path/to/data#节点存储日志目录 生产环境不要使用默认目录path.logs: /path/to/logs# ----------------------------------- Memory -----------------------------------#开启引导检查的内存锁，关闭使用swapp分区，防止因为内存不足而使用swap分区造成机器性能下降bootstrap.memory_lock: true# ---------------------------------- Network -----------------------------------#把当前节点绑定到以下IP上，如果配置了该项，会触发ES的引导检查network.host: 192.168.163.129 #默认可以不用配置，区间[9200,9300)#服务端口http.port: 9200#通讯端口，用于集群不同节点的通讯transport.port: 9300# --------------------------------- Discovery ----------------------------------#当进行Master时，有哪些节点能参与竞选（node.master: true的节点）discovery.seed_hosts: [\"192.168.163.129:9300\", \"192.168.163.130:9300\"]#设置集群启动时竞选Master的节点列表cluster.initial_master_nodes: [\"node-1\"]#绕过引导检查（生产环境不能配置该项）#discovery.type: single-nodehttp.cors.enabled: true#允许跨域访问 *代表所有http.cors.allow-origin: \"*\"#标记该节点具备竞争master的资格 node.master: true#该节点进行数据存储node.data: false 1234#修改完配置后,关闭防火墙[elasticsearch@localhost bin]# systemctl stop firewalld#进入bin目录启动 -d:表示后台启动[elasticsearch@localhost bin]# ./elasticsearch -d 如果克隆了服务器或者拷贝了多份elasticsearch目录，需要去path.data:配置的路径下删除节点信息，否则会造成ID重复的冲突。 基于Docker 不建议使用ES启动docker，因为很麻烦！！！ 12345[root@localhost /]# docker pull docker.elastic.co/elasticsearch/elasticsearch:7.10.1[root@localhost /]# docker run -d -p 9200:9200 -p 9300:9300 --name es elasticsearch:7.10.1#启动命令参考[root@localhost /]# docker run -d -p 9200:9200 -p 9300:9300 -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" -e discovery.type=single-node --name es elasticsearch:7.10.1 123问题1：error='Cannot allocate memory' 原因：ES 5.x+堆内存大小默认配置为2G ES 7.x+默认4G 解决：-e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" 12345问题2：WARNING: IPv4 forwarding is disabled. Networking will not work.解决： vi &#x2F;etc&#x2F;sysctl.confnet.ipv4.ip_forward&#x3D;1restart network &amp;&amp; systemctl restart dockersysctl net.ipv4.ip_forward 123456789问题3: max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]解释： 5.0以后,ES使用mmapfs作为默认的文件系统存储类型。可以通过配置index.store.type来设置ES默认的文件系统存储类型。Niofs(非阻塞文件系统) mmapfs(内存映射文件系统)配置:index.store.type: niofs解决：sysctl -w vm.max_map_count&#x3D;262144查看是否生效： 或：vi &#x2F;etc&#x2F;sysctl.confvm.max_map_count&#x3D;262144grep vm.max_map_count &#x2F;etc&#x2F;sysctl.conf 1234问题4：max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]解决：vi &#x2F;etc&#x2F;security&#x2F;limits.conf，最后添加以下内容。* soft nofile 65536* hard nofile 65536 12345678910111213141516171819问题5：max number of threads [1024] for user [elasticsearch] is too low, increase to at least [2048]解决：vi &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;90-nproc.conf 修改如下内容（注意星号）：* soft nproc 1024 &#x3D;&gt; * soft nproc 4096当引导检查报未开启内存锁时，需要修改一下配置：vi &#x2F;etc&#x2F;security&#x2F;limits.conf，最后添加以下内容。* soft nofile 65536* hard nofile 65536* soft nproc 32000* hard nproc 32000* hard memlock unlimited* soft memlock unlimitedvi &#x2F;etc&#x2F;systemd&#x2F;system.conf ，分别修改以下内容。DefaultLimitNOFILE&#x3D;65536DefaultLimitNPROC&#x3D;32000DefaultLimitMEMLOCK&#x3D;infinity注意 修改操作系统配置需要重启系统才能生效，如果宿主机内存过小，可能导致容器无法启动。开发模式内存建议4G以上，生产建议32G以上. 12问题6：docker中的es无法加入集群elasticsearch.yml配置中增加 network.publish_host:192.168.1.129 1其他问题：如路径的权限问题、多网卡问题、引导检查问题","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"}]},{"title":"'Elasticsearch（七） JAVA API'","slug":"elasticearch-api","date":"2020-12-10T08:00:00.000Z","updated":"2020-12-16T02:32:27.855Z","comments":true,"path":"2020/12/10/elasticearch-api/","link":"","permalink":"https://midkuro.gitee.io/2020/12/10/elasticearch-api/","excerpt":"","text":"Elasticsearch APIboolean model12345678910111213141516171819202122232425262728GET /product/_search&#123; \"query\": &#123; \"match\": &#123; \"name\": &#123; \"query\": \"my good\", \"operator\": \"or\", //可选：or、and 默认是or \"minimum_should_match\": 2, //最少匹配2个此项 \"boost\"：1 //相关度算法权重 &#125; &#125; &#125;&#125;//所有相关查询，ES底层会转换成bool操作GET /product/_search&#123; \"query\": &#123; \"bool\": &#123; \"should\": [ //and的话，这里就是must, 可选：must/must not/should &#123;\"term\":&#123;\"name\":\"my\"&#125;&#125;, &#123;\"term\":&#123;\"name\":\"good\"&#125;&#125; ], \"boost\": 1, \"minimum_should_match\": 2 &#125; &#125;&#125; JAVA APITransport Client：TransportClient不推荐使用，而推荐使用Java High Level REST Client，并将在Elasticsearch 8.0中删除。Java Low Level REST Client：低级别的REST客户端，通过http与集群交互，用户需自己编组请求JSON串，及解析响应JSON串。兼容所有ES版本Java High Level REST Client：高级别的REST客户端，基于低级别的REST客户端，增加了编组请求JSON串、解析响应JSON串等相关api。使用的版本需要保持和ES服务端的版本一致，否则会有版本问题。 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;7.10.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.10.1&lt;/version&gt;&lt;/dependency&gt; Transport Client1234567891011121314public static void main(String[] args) &#123; //配置集群名称 Settings settings = Settings.builder().put(\"cluster.name\", \"elasticsearch\").build(); //创建连接 //TransportClient client = new PreBuiltTransportClient(Settings.EMPTY) TransportClient client = new PreBuiltTransportClient(settings) .addTransportAddress(new TransportAddress(InetAddress.getByName(\"localhost\"), 9300))//通讯端口 而不是服务端口 .addTransportAddress(new TransportAddress(InetAddress.getByName(\"localhost\"), 9301)); //添加数据 create(client); //关闭连接 client.close();&#125; 123456789101112131415161718private void create(TransportClient client) &#123; //查询数据 List&lt;Product&gt; list = service.list(); for (Product item : list) &#123; //固定语法 IndexResponse response = client.prepareIndex(\"product2\", \"_doc\", item.getId().toString()) .setSource(XContentFactory.jsonBuilder() .startObject() .field(\"name\", item.getName()) .field(\"desc\", item.getDesc()) .field(\"price\", item.getPrice()) .field(\"date\", item.getCreateTime().toLocalDateTime().format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"))) .field(\"tags\", item.getTags().split(\",\")) .endObject()) .get(); System.out.println(response.getResult()); &#125;&#125; 1234567891011//查询一条数据private void get(TransportClient client) &#123; GetResponse response = client.prepareGet(\"product\", \"_doc\", \"1\").get(); String index = response.getIndex();//获取索引名称 String type = response.getType();//获取索引类型 String id = response.getId();//获取索引id System.out.println(\"index:\" + index); System.out.println(\"type:\" + type); System.out.println(\"id:\" + id); System.out.println(response.getSourceAsString());&#125; 1234567891011//批量查询private void getAll(TransportClient client) &#123; SearchResponse response = client.prepareSearch(\"product\") .get(); SearchHits searchHits = response.getHits(); SearchHit[] hits = searchHits.getHits(); for (SearchHit hit : hits) &#123; String res = hit.getSourceAsString(); System.out.println(\"res\" + res); &#125;&#125; 12345678910//增量更新private void update(TransportClient client) &#123; UpdateResponse response = client.prepareUpdate(\"product\", \"_doc\", \"2\") .setDoc(XContentFactory.jsonBuilder() .startObject() .field(\"name\", \"update name\") .endObject()) .get(); System.out.println(response.getResult());&#125; 12345//删除数据private void delete(TransportClient client) &#123; DeleteResponse response = client.prepareDelete(\"product\", \"_doc\", \"2\").get(); System.out.println(response.getResult());&#125; 12345678910111213141516//多条件查询public void multiSearch(TransportClient client) &#123; //SearchResponse：返回的结果集 SearchResponse response = client.prepareSearch(\"product2\") .setQuery(QueryBuilders.termQuery(\"name\", \"xiaomi\")) // Query .setPostFilter(QueryBuilders.rangeQuery(\"price\").from(0).to(4000)) .setFrom(1).setSize(3) .get(); SearchHits searchHits = response.getHits(); SearchHit[] hits = searchHits.getHits(); for (SearchHit hit : hits) &#123; String res = hit.getSourceAsString(); System.out.println(\"res\" + res); &#125; client.close();&#125; 123456789101112131415161718192021222324252627//统计每个月份的tags中每个词项term的平均价格GET /product/_search&#123; \"aggs\": &#123; \"group_by_month\": &#123; \"date_histogram\": &#123; \"field\": \"date\", \"calendar_interval\": \"month\" &#125;, \"aggs\": &#123; \"by_tags\": &#123; \"terms\": &#123; \"field\": \"tags.keyword\" &#125;, \"aggs\": &#123; \"avg_price\": &#123; \"avg\": &#123; \"field\": \"price\" &#125; &#125; &#125; &#125; &#125; &#125; &#125;, \"size\": 0&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//查询结果&#123; \"aggregations\" : &#123; \"group_by_month\" : &#123; \"buckets\" : [ &#123; \"key_as_string\" : \"2020-04-01T00:00:00.000Z\", \"key\" : 1585699200000, \"doc_count\" : 3, \"by_tags\" : &#123; \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ &#123; \"key\" : \"bufangshui\", \"doc_count\" : 1, \"avg_price\" : &#123; \"value\" : 999.0 &#125; &#125;, &#123; \"key\" : \"fashao\", \"doc_count\" : 1, \"avg_price\" : &#123; \"value\" : 2999.0 &#125; &#125; ] &#125; &#125;, &#123; \"key_as_string\" : \"2020-05-01T00:00:00.000Z\", \"key\" : 1588291200000, \"doc_count\" : 2, \"by_tags\" : &#123; \"doc_count_error_upper_bound\" : 0, \"sum_other_doc_count\" : 0, \"buckets\" : [ &#123; \"key\" : \"fashao\", \"doc_count\" : 2, \"avg_price\" : &#123; \"value\" : 4499.0 &#125; &#125;, &#123; \"key\" : \"xingjiabi\", \"doc_count\" : 2, \"avg_price\" : &#123; \"value\" : 4499.0 &#125; &#125; ] &#125; &#125; ] &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//通过Java代码实现上面案例的聚合查询public void aggSearch(TransportClient client) &#123; //region 1-&gt;计算并返回聚合分析response对象 SearchResponse response = client.prepareSearch(\"product\") .addAggregation( AggregationBuilders.dateHistogram(\"group_by_month\") .field(\"date\") .calendarInterval(DateHistogramInterval.MONTH) //.dateHistogramInterval(DateHistogramInterval.MONTH) .subAggregation( AggregationBuilders .terms(\"by_tag\") .field(\"tags.keyword\") .subAggregation( AggregationBuilders .avg(\"avg_price\") .field(\"price\") ) ) ) .execute().actionGet(); //执行查询 //region 2-&gt;输出结果信息 SearchHit[] hits = response.getHits().getHits(); //获取aggregations结果 Map&lt;String, Aggregation&gt; map = response.getAggregations().asMap(); //获取group_by_month结果 Aggregation group_by_month = map.get(\"group_by_month\"); Histogram dates = (Histogram) group_by_month; //转换成分组的桶 Iterator&lt;Histogram.Bucket&gt; buckets = (Iterator&lt;Histogram.Bucket&gt;) dates.getBuckets().iterator(); while (buckets.hasNext()) &#123; //遍历桶中的数据 Histogram.Bucket dateBucket = buckets.next(); System.out.println(\"\\n\\n月份：\" + dateBucket.getKeyAsString() + \"\\n计数：\" + dateBucket.getDocCount()); //获取桶里面的桶by_tag Aggregation group_by_tag = dateBucket.getAggregations().asMap().get(\"by_tag\"); StringTerms terms = (StringTerms) group_by_tag; Iterator&lt;StringTerms.Bucket&gt; tagsBucket = terms.getBuckets().iterator(); while (tagsBucket.hasNext()) &#123; //遍历by_tag桶，获取桶中的平均价格 StringTerms.Bucket tagBucket = tagsBucket.next(); System.out.println(\"\\t标签名称：\" + tagBucket.getKey() + \"\\n\\t数量：\" + tagBucket.getDocCount()); Aggregation avg_price = tagBucket.getAggregations().get(\"avg_price\"); Avg avg = (Avg) avg_price; System.out.println(\"\\t平均价格：\" + avg.getValue() + \"\\n\"); &#125; &#125; //endregion client.close();&#125; High Level REST Client1234常见步骤：1.创建对应的Request对象2.创建对应的Builder对象&#x2F;编写对应操作3.Client执行对应的方法 创建连接1234567//使用 RestHighLevelClientpublic void createConnection &#123; RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\"localhost\", 9200, \"http\"), new HttpHost(\"localhost\", 9201, \"http\"))); //使用的是9200服务端口&#125; 创建索引12345678910111213141516public void createIndex(RestHighLevelClient client) &#123; CreateIndexRequest request = new CreateIndexRequest(\"test_index\"); request.settings(Settings.builder() .put(\"index.number_of_shards\", 3) .put(\"index.number_of_replicas\", 2) ); CreateIndexResponse createIndexResponse = client.indices().create(request, RequestOptions.DEFAULT); if (createIndexResponse.isAcknowledged()) &#123; System.out.println(\"创建index成功!\"); &#125; else &#123; System.out.println(\"创建index失败!\"); &#125; client.close();&#125; 查询索引123456789public void getIndex(RestHighLevelClient client) &#123; GetIndexRequest request = new GetIndexRequest(\"test_index*\"); GetIndexResponse response = client.indices().get(request, RequestOptions.DEFAULT); String[] indices = response.getIndices(); for (String indexName : indices) &#123; System.out.println(\"index name:\" + indexName); &#125; client.close();&#125; 删除索引12345678910public void delIndex(RestHighLevelClient client) &#123; DeleteIndexRequest request = new DeleteIndexRequest(\"test_index\"); AcknowledgedResponse response = client.indices().delete(request, RequestOptions.DEFAULT); if (response.isAcknowledged()) &#123; System.out.println(\"删除index成功!\"); &#125; else &#123; System.out.println(\"删除index失败!\"); &#125; client.close();&#125; 插入数据1234567891011121314public void insertData(RestHighLevelClient client) &#123; List&lt;Product&gt; list = service.list(); //插入数据，index不存在则自动根据匹配到的template创建。index没必要每天创建一个，如果是为了灵活管理，最低建议每月一个 yyyyMM。 IndexRequest request = new IndexRequest(\"test_index\"); //最好不要自定义id 会影响插入速度。 Product product = list.get(0); Gson gson = new Gson(); request.id(product.getId().toString()); request.source(gson.toJson(product), XContentType.JSON); IndexResponse response = client.index(request, RequestOptions.DEFAULT); System.out.println(response); client.close();&#125; 批量插入123456789101112131415public void batchInsertData(RestHighLevelClient client) &#123; //批量插入数据，更新和删除同理 BulkRequest request = new BulkRequest(\"test_index\"); Gson gson = new Gson(); Product product = new Product(); product.setPrice(3999.00); product.setDesc(\"xioami\"); for (int i = 0; i &lt; 10; i++) &#123; product.setName(\"name\" + i); request.add(new IndexRequest().source(gson.toJson(product), XContentType.JSON)); &#125; BulkResponse response = client.bulk(request, RequestOptions.DEFAULT); System.out.println(\"数量:\" + response.getItems().length); client.close();&#125; 查询数据12345678910111213//通过ID查询数据public void getById(RestHighLevelClient client) &#123; //注意 这里查询使用的是别名。 GetRequest request = new GetRequest(\"test_index\", \"PPWhwnIBRwX67j4bTmV1\"); String[] includes = &#123;\"name\", \"price\"&#125;; String[] excludes = &#123;\"desc\"&#125;; FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes); //只查询特定字段。如果需要查询所有字段则不设置该项。 request.fetchSourceContext(fetchSourceContext); GetResponse response = client.get(request, RequestOptions.DEFAULT); System.out.println(response); client.close();&#125; 删除数据1234567//通过ID删除数据public void delById(RestHighLevelClient client) throws IOException &#123; DeleteRequest request = new DeleteRequest(\"test_index\", \"1\"); DeleteResponse response = client.delete(request, RequestOptions.DEFAULT); System.out.println(response); client.close();&#125; 批量查询1234567891011121314public void multiGetById(RestHighLevelClient client) throws IOException &#123; //多个根据id查询 MultiGetRequest request = new MultiGetRequest(); request.add(\"test_index\", \"PPWhwnIBRwX67j4bTmV1\"); //两种写法 request.add(new MultiGetRequest.Item( \"test_index\", \"PfWhwnIBRwX67j4bTmV1\")); MultiGetResponse response = client.mget(request, RequestOptions.DEFAULT); for (MultiGetItemResponse itemResponse : response) &#123; System.out.println(itemResponse.getResponse().getSourceAsString()); &#125; client.close();&#125; 查询更新12345678910111213141516//更新查询public void updateByQuery(RestHighLevelClient client) throws IOException &#123; UpdateByQueryRequest request = new UpdateByQueryRequest(\"test_index\"); //默认情况下，版本冲突会中止 UpdateByQueryRequest 进程，但是你可以用以下命令来代替 //设置版本冲突继续 // request.setConflicts(\"proceed\"); //设置更新条件 request.setQuery(QueryBuilders.matchQuery(\"name\",\"name1 name3\")); // //限制更新条数 // request.setMaxDocs(10); request.setScript( new Script(ScriptType.INLINE, \"painless\", \"ctx._source.desc+='#';\", Collections.emptyMap())); BulkByScrollResponse response = client.updateByQuery(request,RequestOptions.DEFAULT); System.out.println(response); client.close();&#125; 分页查询123456789101112131415public ResultDto carInfo(String keyword,Integer from,Integer size) &#123; SearchRequest searchRequest = new SearchRequest(\"product\"); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchQuery(\"name\", keyword)); searchSourceBuilder.from(from); searchSourceBuilder.size(size); searchRequest.source(searchSourceBuilder); SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT); //ESClient.getInstance().closeClient(); ResultDto res = new ResultDto(); res.setData(searchResponse.getHits().getHits()); return res;&#125; Scroll查询12345678910111213141516171819public ResultDto scroll(String scrollId) &#123; SearchRequest searchRequest = new SearchRequest(\"product\"); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.size(2); //每页两条 searchRequest.source(searchSourceBuilder); searchRequest.scroll(TimeValue.timeValueMinutes(1L)); //scrollID的有效期1分钟 SearchResponse searchResponse = scrollId == null ? client.search(searchRequest, RequestOptions.DEFAULT) : client.scroll(new SearchScrollRequest(scrollId), RequestOptions.DEFAULT); scrollId = searchResponse.getScrollId(); SearchHits hits = searchResponse.getHits(); ResultDto res = new ResultDto(); res.setTag(scrollId); res.setData(hits.getHits()); return res;&#125; 批量操作1234567891011public ResultDto bulk() &#123; SearchRequest searchRequest = new SearchRequest(\"msb_auto\"); BulkRequest request = new BulkRequest(); request.add(new DeleteRequest(\"product\", \"13\")); //删除doc request.add(new UpdateRequest(\"product\", \"22\") .doc(XContentType.JSON, \"name\", \"天籁之音\")); //修改doc一个字段 request.add(new IndexRequest(\"product\").id(\"4\") .source(XContentType.JSON, \"myname\", \"天津一汽\")); //修改整doc BulkResponse bulkResponse = client.bulk(request, RequestOptions.DEFAULT); return null;&#125; 搜索模板12345678910111213141516171819202122232425262728293031323334353637383940414243444546public ResultDto templateSearch() &#123; //region 创建模板并缓存 作用域为整个集群 Request scriptRequest = new Request(\"POST\", \"_scripts/test_template_search\"); scriptRequest.setJsonEntity( \"&#123;\" + \" \\\"script\\\": &#123;\" + \" \\\"lang\\\": \\\"mustache\\\",\" + \" \\\"source\\\": &#123;\" + \" \\\"query\\\": &#123; \\\"match\\\" : &#123; \\\"&#123;&#123;field&#125;&#125;\\\" : \\\"&#123;&#123;value&#125;&#125;\\\" &#125; &#125;,\" + \" \\\"size\\\" : \\\"&#123;&#123;size&#125;&#125;\\\"\" + \" &#125;\" + \" &#125;\" + \"&#125;\"); Response scriptResponse = client.getLowLevelClient().performRequest(scriptRequest); SearchTemplateRequest request = new SearchTemplateRequest(); request.setRequest(new SearchRequest(\"msb_auto\")); //STORED 保存到内存模板 request.setScriptType(ScriptType.STORED); request.setScript(\"test_template_search\"); // 本地模板 //request.setScriptType(ScriptType.INLINE); // request.setScript( // \"&#123;\\n\" + // \" \\\"from\\\": &#123;&#123;from&#125;&#125;,\\n\" + // \" \\\"size\\\": &#123;&#123;size&#125;&#125;,\\n\" + // \" \\\"query\\\": &#123;\\n\" + // \" \\\"match\\\": &#123;\\n\" + // \" \\\"master_brand_name\\\": \\\"&#123;&#123;master_brand_name&#125;&#125;\\\"\\n\" + // \" &#125;\\n\" + // \" &#125;\\n\" + // \"&#125;\"); Map&lt;String, Object&gt; scriptParams = new HashMap&lt;&gt;(); scriptParams.put(\"field\", \"master_brand_name\"); scriptParams.put(\"value\", \"一汽\"); scriptParams.put(\"size\", 5); request.setScriptParams(scriptParams); //查询 SearchTemplateResponse response = client.searchTemplate(request, RequestOptions.DEFAULT); return null;&#125; 模糊查询12345678public SearchHit[] fuzzy(String name) &#123; SearchRequest searchRequest = new SearchRequest(\"product\"); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.fuzzyQuery(\"brand_name.keyword\", name).fuzziness(Fuzziness.AUTO)); searchRequest.source(searchSourceBuilder); SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT); return response.getHits().getHits();&#125; 多语句查询12345678910111213141516171819202122public ResultDto multiSearch() &#123; //1.创建一个空的MultiSearchRequest MultiSearchRequest request = new MultiSearchRequest(); //2.创建SearchRequest,并填充查询条件 SearchRequest firstSearchRequest = new SearchRequest(\"product\"); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchQuery(\"series_name\", \"朗动\")); firstSearchRequest.source(searchSourceBuilder); //3.将SearchRequest装配到MultiSearchRequest中 request.add(firstSearchRequest); //4.创建第二个SearchRequest并重复第三步 SearchRequest secondSearchRequest = new SearchRequest(\"product\"); searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query(QueryBuilders.matchQuery(\"series_name\", \"揽胜运动\")); secondSearchRequest.source(searchSourceBuilder); request.add(secondSearchRequest); MultiSearchResponse response = client.msearch(request, RequestOptions.DEFAULT); return null;&#125; Bool查询1234567891011121314151617public ResultDto boolSearch() &#123; MultiSearchRequest request = new MultiSearchRequest(); SearchRequest searchRequest = new SearchRequest(\"product\"); SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); searchSourceBuilder.query ( QueryBuilders.boolQuery() .must(matchPhraseQuery(\"sale_name\", \"2018款\")) .filter(matchQuery(\"master_brand_name\", \"大众\").analyzer(\"ik_max_word\")) .mustNot(matchQuery(\"series_name\", \"速腾\")) ); searchRequest.source(searchSourceBuilder); request.add(searchRequest); MultiSearchResponse response = client.msearch(request, RequestOptions.DEFAULT); return null;&#125; Sniffer 嗅探器概念：从运行中的Elasticsearch集群自动发现节点并将它们设置为现有RestClient实例（low实例）。 版本：从ES 2.X开始及更高版本支持。 12345678910&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-client-sniffer&lt;/artifactId&gt; &lt;version&gt;7.10.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-client&lt;/artifactId&gt; &lt;version&gt;7.10.1&lt;/version&gt;&lt;/dependency&gt; 12345678910用法：1.创建RestClient：RestClientBuilder2.HTTPS支持：NodesSniffer3.绑定：Sniffer.builder(RestClient)4.监听：SniffOnFailureListener相关设置参数：1.setSniffIntervalMillis：每隔多久触发一次嗅探，单位毫秒，默认30000（5分钟）。2.setSniffAfterFailureDelayMillis：嗅探失败时触发嗅探一次,经过设置的时间（默认1min）之后再次嗅探直至正常。若无绑定监听器则无效。3.setFailureListener：设置用于监听嗅探失败的监听器，当监听到普通嗅探失败，则通知Sniffer实例进行新一轮的嗅探，并更新节点。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class ESClient &#123; private static ESClient ESClient; private String host = \"localhost:9200,localhost:9201\"; private RestClientBuilder builder; private static Sniffer sniffer; private static RestHighLevelClient highClient; private ESClient()&#123; &#125; public static ESClient getInstance() &#123; if (ESClient == null) &#123; synchronized (ESClient.class) &#123; if (ESClient == null) &#123; ESClient = new ESClient(); ESClient.initBuilder(); &#125; &#125; &#125; return ESClient; &#125; public RestClientBuilder initBuilder() &#123; String[] hosts = host.split(\",\"); HttpHost[] httpHosts = new HttpHost[hosts.length]; for (int i = 0; i &lt; hosts.length; i++) &#123; String[] host = hosts[i].split(\":\"); httpHosts[i] = new HttpHost(host[0], Integer.parseInt(host[1]), \"http\"); &#125; builder = RestClient.builder(httpHosts); //region 在Builder中设置请求头 // 1.设置请求头 Header[] defaultHeaders = new Header[]&#123; new BasicHeader(\"Content-Type\", \"application/json\") &#125;; builder.setDefaultHeaders(defaultHeaders); //endregion //RestClient restClient = builder.build(); //启用嗅探器 //SniffOnFailureListener sniffOnFailureListener = new SniffOnFailureListener(); //builder.setFailureListener(sniffOnFailureListener); //sniffer = Sniffer.builder(restClient) // .setSniffIntervalMillis(5000) // .setSniffAfterFailureDelayMillis(10000) // .build(); //sniffOnFailureListener.setSniffer(sniffer); return builder; &#125; public RestHighLevelClient getHighLevelClient() &#123; if (highClient == null) &#123; synchronized (ESClient.class) &#123; if (highClient == null) &#123; //gighClient是通过lowClient包装产生的 highClient = new RestHighLevelClient(builder); //设置嗅探器 //十秒刷新并更新一次节点 sniffer = Sniffer.builder(highClient.getLowLevelClient()) .setSniffIntervalMillis(5000) .setSniffAfterFailureDelayMillis(15000) .build(); &#125; &#125; &#125; return highClient; &#125; /** * * 关闭sniffer client */ public void closeClient() &#123; if (null != highClient) &#123; try &#123; sniffer.close(); //需要在highClient close之前操作 highClient.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 12345678910111213141516public void snifferTest() &#123; RestHighLevelClient client = ESClient.getInstance().getHighLevelClient(); Iterator&lt;Node&gt; nodes = client.getLowLevelClient().getNodes().iterator(); while (nodes.hasNext()) &#123; Node node = nodes.next(); System.out.println(node); &#125; Thread.sleep(5000); System.out.println(\"5秒后:\"); nodes = client.getLowLevelClient().getNodes().iterator(); while (nodes.hasNext()) &#123; Node node = nodes.next(); System.out.println(node); &#125; ESClient.getInstance().closeClient();&#125; 假设有5台机器，IP分别是【9200 - 9204】最后嗅探造成的输出结果是： 123456789先输出:host&#x3D;[http:&#x2F;&#x2F;localhost:9200]host&#x3D;[http:&#x2F;&#x2F;localhost:9201]间隔五秒后输出：host&#x3D;[http:&#x2F;&#x2F;localhost:9200]host&#x3D;[http:&#x2F;&#x2F;localhost:9201]host&#x3D;[http:&#x2F;&#x2F;localhost:9202]host&#x3D;[http:&#x2F;&#x2F;localhost:9203]host&#x3D;[http:&#x2F;&#x2F;localhost:9204] 嗅探器它能够给我们监控动态更新集群的节点数量，避免了程序因节点过多或增加/减少节点造成的切换问题。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"}]},{"title":"'Elasticsearch（六） 搜索'","slug":"elasticearch-query","date":"2020-12-09T09:00:00.000Z","updated":"2020-12-13T16:00:54.234Z","comments":true,"path":"2020/12/09/elasticearch-query/","link":"","permalink":"https://midkuro.gitee.io/2020/12/09/elasticearch-query/","excerpt":"","text":"Elasticsearch 搜索prefix前缀查询：以xx开头的搜索，不计算相关度评分，和filter比，没有bitcache。前缀搜索，尽量把前缀长度设置的更长，性能差，因为它会扫描倒排索引整张表，匹配每个term是否包含xx。 1234567891011121314语法：GET index/_search&#123; \"query\": &#123; \"prefix\": &#123; \"title\": &#123; \"value\": \"text\" &#125; &#125; &#125;&#125;参数：index_prefixes: 默认 \"min_chars\" : 2, \"max_chars\" : 5 1234567891011//类似于SQL的左Like查询GET my_index/_search&#123; \"query\": &#123; \"prefix\": &#123; \"text\": &#123; \"value\": \"myword\" &#125; &#125; &#125;&#125; 使用index_prefixes映射，ES会额外建立一个长度在2和5之间索引，在进行前缀匹配的时候效率会有很大的提高 123456789101112131415//设置默认的 启动索引 加快前缀搜索速度PUT my_index&#123; \"mappings\": &#123; \"properties\": &#123; \"text\": &#123; \"type\": \"text\", \"index_prefixes\": &#123; \"min_chars\":2, \"max_chars\":4 &#125; &#125; &#125; &#125;&#125; wildcard通配符：通配符运算符是匹配一个或多个字符的占位符。例如，*通配符运算符匹配零个或多个字符。可以将通配符运算符与其他字符结合使用以创建通配符模式 123456789101112131415// \"name\" : \"xiaomi nfc phone\"//通配符匹配GET product/_search&#123; \"query\": &#123; \"wildcard\": &#123; \"name\": &#123; //匹配倒排索引表中的term词项 \"value\": \"xia?mi\" &#125; &#125; &#125;&#125;输出结果：能查出 \"name\" : \"xiaomi nfc phone\" 的数据 12345678910111213GET product/_search&#123; \"query\": &#123; \"wildcard\": &#123; \"name.keyword\": &#123; //全量匹配内容 \"value\": \"xia?mi\" &#125; &#125; &#125;&#125;输出结果：不能查出数据 regexp正则：regexp查询的性能可以根据提供的正则表达式而有所不同。为了提高性能，应避免使用通配符模式，如.或 .?+未经前缀或后缀 123456789101112//\"name\" : \"xiaomi nfc phone\" 正则匹配GET product/_search&#123; \"query\": &#123; \"regexp\": &#123; \"name\": &#123; \"value\": \"[\\\\s\\\\S]*nfc[\\\\s\\\\S]*\", // \\\\s\\\\S表示任意字符 \"flags\": \"ALL\" &#125; &#125; &#125;&#125; 123456789101112//\"desc\" : \"xiaomi nfc 2020-05-20 phone\"GET product/_search&#123; \"query\": &#123; \"regexp\": &#123; \"desc\": &#123; \"value\": \".*2020-05-20.*\", \"flags\": \"ALL\" &#125; &#125; &#125;&#125; 无法匹配到上文中的注释数据，原因在于默认使用了standard，会将日期拆成【2020】、【05】、【20】三个词汇，如果想要匹配，需要使用desc.keyword进行全文匹配，但是这样性能十分低下。 而IK分词器很好的对日期进行了分词词项【2020-05-20】，对该索引指定IK分词器（需重建索引），即可查询到结果。 123456789101112PUT product&#123; \"mappings\": &#123; \"properties\": &#123; \"desc\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", //倒排索引分词 \"search_analyzer\": \"ik_max_word\" //搜索分词 &#125; &#125; &#125;&#125; fuzzy混淆字符 (box → fox) 缺少字符 (black → lack) 多出字符 (sic → sick) 颠倒次序 (act → cat) 123456789101112131415语法：GET /_search&#123; \"query\": &#123; \"fuzzy\": &#123; \"desc\": &#123; \"value\": \"keyword\" &#125; &#125; &#125;&#125;参数：value：（必需，字符串）fuzziness：（可选，字符串）最大误差(距离) 并非越大越好, 召回率高 但是结果不准确 距离：两段文本之间的Damerau-Levenshtein距离是指一个字符串需要经过多少次操作之后才能变成另一个字符串。 距离公式：Levenshtein是lucene的，es改进版：Damerau-Levenshtein，axe=&gt;aex Levenshtein=2 ，而Damerau-Levenshtein=1 123456789101112//案例 使用fuzzyGET /product/_search &#123; \"query\": &#123; \"fuzzy\": &#123; \"desc\": &#123; \"value\": \"xioami\", //匹配 xiaomi \"fuzziness\": 5 &#125; &#125; &#125;&#125; 123456789101112//案例 使用matchGET /product/_search&#123; \"query\": &#123; \"match\": &#123; \"desc\": &#123; \"query\": \"quangengneng nfc\", \"fuzziness\": \"AUTO\" &#125; &#125; &#125;&#125; match_phrase_prefixmatch_phrase_prefix与match_phrase相同,但是它多了一个特性,就是它允许在文本的最后一个词项(term)上的前缀匹配。 如果 是一个单词,比如a,它会匹配文档字段所有以a开头的文档,如果是一个短语,比如 “this is ma” ,他会先在倒排索引中做以ma做前缀搜索,然后在匹配到的doc中做match_phrase查询。 1234567891011121314151617语法：GET /index/_search&#123; \"query\": &#123; \"match_phrase_prefix\": &#123; \"fieldName\": &#123; \"query\": \"text\" &#125; &#125; &#125;&#125;参数analyzer 指定何种分析器来对该短语进行分词处理max_expansions 限制匹配到的最大词项，每个分片中匹配的结果达到max_expansions值后停止遍历倒排索引表boost 用于设置该查询的权重slop：允许短语间的词项(term)间隔，指为了让查询和文档匹配需要移动term多少(slop)次 1234567891011//案例 匹配 \"desc\" : \"zhichi nfc\" 注意！无法匹配 \"zhichi aaa nfc\"GET /product/_search&#123; \"query\": &#123; \"match_phrase_prefix\": &#123; \"desc\": &#123; \"query\": \"zhichi nf\", //先进行nf 前缀匹配，再进行match_phrase(zhichi)词项匹配 &#125; &#125; &#125;&#125; 123456789101112131415//案例 可以匹配到：\"zhichi aaa nfc\"GET /product/_search&#123; \"query\": &#123; \"match_phrase_prefix\": &#123; \"desc\": &#123; \"query\": \"zhichi nf\", \"analyzer\": \"whitespace\", \"max_expansions\": 1, \"slop\": 1, //配置slop，允许移动一次term匹配结果 \"boost\": 1 &#125; &#125; &#125;&#125; N-gram：token filter123456edge_ngram：是从第一个字符开始,按照步长,进行分词,适合前缀匹配场景,比如:订单号,手机号,邮政编码的检索ngram：是从每一个字符开始,按照步长,进行分词,适合前缀中缀检索参数：min_gram &#x3D;1 最小步长 默认值 1max_gram &#x3D;1 最大步长 默认值 1 1234567891011【edge_ngram】 拆词： &quot;reba always loves me&quot;min_gram &#x3D;1 max_gram &#x3D;1#r a l mmin_gram &#x3D;1 max_gram &#x3D;2#r a l m#re al lo memin_gram &#x3D;2 max_gram &#x3D;3#re al lo me#reb alw lov me 12345678910111213141516171819202122232425262728293031//创建索引，设置分词器和token filterPUT my_index&#123; \"settings\": &#123; \"analysis\": &#123; \"filter\": &#123; \"2_3_edge_ngram\": &#123; \"type\": \"edge_ngram\", \"min_gram\": 2, \"max_gram\": 3 &#125; &#125;, \"analyzer\": &#123; \"my_edge_ngram\": &#123; \"type\":\"custom\", \"tokenizer\": \"standard\", \"filter\": [ \"2_3_edge_ngram\" ] &#125; &#125; &#125; &#125;, \"mappings\": &#123; \"properties\": &#123; \"text\": &#123; \"type\": \"text\", \"analyzer\":\"my_edge_ngram\", \"search_analyzer\": \"standard\" &#125; &#125; &#125;&#125; 1234567891011GET /my_index/_analyze&#123; \"analyzer\": \"my_edge_ngram\" , \"text\": [\"my english\"]&#125;输出结果：my、en、eng如果分词器把edge_ngram换成ngram，则输出结果如下：my、en、ng、gl、li、is、sh、eng、ngl、gli、lis、ish 123456789//匹配 \"text\": \"my english is good\"GET /my_index/_search&#123; \"query\": &#123; \"match_phrase\": &#123; \"text\": \"my eng is goo\" &#125; &#125;&#125;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"}]},{"title":"'Elasticsearch（五） 分词器'","slug":"elasticearch-analysis","date":"2020-12-09T08:00:00.000Z","updated":"2020-12-13T13:08:35.171Z","comments":true,"path":"2020/12/09/elasticearch-analysis/","link":"","permalink":"https://midkuro.gitee.io/2020/12/09/elasticearch-analysis/","excerpt":"","text":"Elasticsearch 分词器Analysis123456789101112分析器：1.character filter（mapping）：分词之前预处理（过滤无用字符、标签等，转换一些&amp;=&gt;and 《es》=&gt; es HTML Strip Character Filter：html_strip 自动过滤html标签 参数：escaped_tags 需要保留的html标签 Mapping Character Filter：type mapping Pattern Replace Character Filter：type pattern_replace4.tokenizer（分词器）：分词5.token filter：停用词、时态转换、大小写转换、同义词转换、语气词处理等。如：has=&gt;have him=&gt;he apples=&gt;apple normalization character filterHTML Strip Character Filter12345678910111213141516171819202122//HTML Strip Character FilterPUT my_index&#123; \"settings\": &#123; //分析器 \"analysis\": &#123; \"char_filter\": &#123; \"my_char_filter\": &#123; //设置html字符过滤器，并保留&lt;a&gt;标签 \"type\": \"html_strip\", \"escaped_tags\": [\"a\"] &#125; &#125;, //分词器 \"analyzer\": &#123; \"my_analyzer\": &#123; \"tokenizer\": \"keyword\", \"char_filter\": [\"my_char_filter\"] &#125; &#125; &#125; &#125;&#125; 1234567891011//尝试分词POST my_index/_analyze&#123; \"analyzer\": \"my_analyzer\", \"text\": \"&lt;p&gt;I&amp;apos;m so &lt;a&gt;happy&lt;/a&gt;!&lt;/p&gt;\"&#125;输出结果：\"token\" : \"\"\" I'm so &lt;a&gt;happy&lt;/a&gt;!\"\"\" Mapping Character Filter123456789101112131415161718192021222324252627282930313233//Mapping Character FilterPUT my_index&#123; \"settings\": &#123; \"analysis\": &#123; \"analyzer\": &#123; \"my_analyzer\": &#123; \"tokenizer\": \"keyword\", \"char_filter\": [ \"my_char_filter\" ] &#125; &#125;, \"char_filter\": &#123; \"my_char_filter\": &#123; \"type\": \"mapping\", //为指定的字符制定映射规则 \"mappings\": [ \"٠ =&gt; 0\", \"١ =&gt; 1\", \"٢ =&gt; 2\", \"٣ =&gt; 3\", \"٤ =&gt; 4\", \"٥ =&gt; 5\", \"٦ =&gt; 6\", \"٧ =&gt; 7\", \"٨ =&gt; 8\", \"٩ =&gt; 9\" ] &#125; &#125; &#125; &#125;&#125; 12345678POST my_index/_analyze&#123; \"analyzer\": \"my_analyzer\", \"text\": \"My license plate is ٢٥٠١٥\"&#125;输出结果：\"token\" : \"My license plate is 25015\" Pattern Replace Character Filter123456789101112131415161718192021//Pattern Replace Character FilterPUT my_index&#123; \"settings\": &#123; \"analysis\": &#123; \"analyzer\": &#123; \"my_analyzer\": &#123; \"tokenizer\": \"standard\", \"char_filter\": [\"my_char_filter\"] &#125; &#125;, \"char_filter\": &#123; \"my_char_filter\": &#123; \"type\": \"pattern_replace\", //通过正则匹配，把-替换成_ \"pattern\": \"(\\\\d+)-(?=\\\\d)\", \"replacement\": \"$1_\" &#125; &#125; &#125; &#125;&#125; 12345678POST my_index/_analyze&#123; \"analyzer\": \"my_analyzer\", \"text\": \"My credit card is 123-456-789\"&#125;输出结果：\"token\" : \"My credit card is 123_456_789\" token filterlowercase token filter12345678910//大小写 lowercase token filterGET _analyze&#123; \"tokenizer\" : \"standard\", \"filter\" : [\"lowercase\"], \"text\" : \"THE Quick FoX JUMPs\"&#125;输出结果：the、quick、fox、jumps 123456789101112131415161718//当分词后的词项长度满足 &lt; 5 时，执行 filter配置GET /_analyze&#123; \"tokenizer\": \"standard\", \"filter\": [ &#123; \"type\": \"condition\", \"filter\": [ \"lowercase\" ], \"script\": &#123; \"source\": \"token.getTerm().length() &lt; 5\" &#125; &#125; ], \"text\": \"THE QUICK BROWN FOX\"&#125;输出结果：the、QUICK、BROWN、fox stopwords token filter在信息检索中，停用词是为节省存储空间和提高搜索效率，处理文本时自动过滤掉某些字或词，这些字或词即被称为Stop Words（停用词）。 停用词大致分为两类。一类是语言中的功能词，这些词极其普遍而无实际含义，如“the”、“is“、“which“、“on”等。另一类是词汇词，比如’want’等，这些词应用广泛，但搜索引擎无法保证能够给出真正相关的搜索结果，难以缩小搜索范围，还会降低搜索效率。 实践中，通过配置stopwords使得这些词汇不添加进倒排索引中，从而节省索引的存储空间、提高搜索性能。 12345678910111213PUT /my_index&#123; \"settings\": &#123; \"analysis\": &#123; \"analyzer\": &#123; \"my_analyzer\":&#123; \"type\":\"standard\", \"stopwords\":\"_english_\" //启动英语停用词 &#125; &#125; &#125; &#125;&#125; 1234567891011GET my_index/_analyze&#123; \"analyzer\": \"my_analyzer\", \"text\": \"Teacher Ma is in the restroom\"&#125;未启用英语停用词结果：Teacher、Ma、is、in、the、restroom启用英语停用词结果：Teacher、Ma、restroom tokenizer基于ES 7.6版本，支持的内置分词器有15种。官网介绍 123456781.standard analyzer：默认分词器，中文支持的不理想，会逐字拆分。 max_token_length：最大令牌长度。如果看到令牌超过此长度，则将其max_token_length间隔分割。默认为255。 2.Pattern Tokenizer：以正则匹配分隔符，把文本拆分成若干词项。3.Simple Pattern Tokenizer：以正则匹配词项，速度比Pattern Tokenizer快。4.whitespace analyzer：以空白符分隔 Tim_cookie 12345678910111213//配置内置分词器PUT /test_analysis/&#123; \"settings\": &#123; \"analysis\": &#123; \"analyzer\": &#123; \"my_analyzer\": &#123; //自定义分词器名称 \"tokenizer\":\"whitespace\" //指定使用的分词器 standard、pattern、simple &#125; &#125; &#125; &#125;&#125; 123456//验证分词器GET /test_analysis/_analyze&#123; \"analyzer\": \"my_analyzer\", \"text\": \"ooo is bbbb!!\"&#125; 自定义 analysis设置&quot;type&quot;: &quot;custom&quot;告诉Elasticsearch我们正在定义一个定制分析器。将此与配置内置分析器的方式进行比较： type将设置为内置分析器的名称，如 standard或simple 123456789101112131415161718192021222324252627282930313233343536373839PUT /test_analysis&#123; \"settings\": &#123; \"analysis\": &#123; \"char_filter\": &#123; //自定义字符过滤器，设置映射规则 \"test_char_filter\": &#123; \"type\": \"mapping\", \"mappings\": [ \"&amp; =&gt; and\", \"| =&gt; or\" ] &#125; &#125;, \"filter\": &#123; //过滤器，过滤指定字符 \"test_stopwords\": &#123; \"type\": \"stop\", \"stopwords\": [\"is\",\"in\",\"at\",\"the\",\"a\",\"for\"] &#125; &#125;, \"tokenizer\": &#123; //正则分析器 \"punctuation\": &#123; \"type\": \"pattern\", \"pattern\": \"[ .,!?]\" //以正则匹配到的字符做分词 &#125; &#125;, \"analyzer\": &#123; //自定义分词器 \"my_analyzer\": &#123; \"type\": \"custom\", //告诉ES这是一个自定义分词器 \"char_filter\": [ //设置两个字符过滤器 \"html_strip\", \"test_char_filter\" ], \"tokenizer\": \"standard\", //设置内置分词器 \"filter\": [\"lowercase\",\"test_stopwords\"] &#125; &#125; &#125; &#125;&#125; 12345678GET /test_analysis/_analyze&#123; \"text\": \"Teacher ma &amp; zhang also thinks [mother's friends] is good | nice!!!\", \"analyzer\": \"my_analyzer\"&#125;分词结果：teacher、ma、and、zhang、also、thinks、mother's、friends、good、or、nice IK中文分词器IK分词器下载地址 12345IK分词器安装步骤：1.上Github下载IK分词器2.解压分词器，使用maven进行package打包3.从releases中获取打好的zip包，放到es安装目录&#x2F;plugins&#x2F;ik&#x2F; 目录下解压4.重启ES 如果ES版本比IK分词器版本高，启动ES时可能会出现如下错误： 1Plugin [analysis-ik] was built for Elasticsearch version 7.4.0 but version 7.10.1 is running 需要修改IK分词器的配置文件plugin-descriptor.properties： 12#改成自己使用的ES版本号elasticsearch.version=7.10.1 123456789101112131415161718IK分词器提供两种analyzer ik_max_word：细粒度 ik_smart：粗粒度2.IK文件描述 IKAnalyzer.cfg.xml：IK分词配置文件 主词库：main.dic 英文停用词：stopword.dic，不会建立在倒排索引中 特殊词库： quantifier.dic：特殊词库：计量单位等 suffix.dic：特殊词库：后缀名 surname.dic：特殊词库：百家姓 preposition：特殊词库：语气词 自定义词库：比如当下流行词：857、emmm...、996 热更新： 修改ik分词器源码 基于ik分词器原生支持的热更新方案，部署web服务器，提供http接口，通过modified和tag两个http响应头，来提供词语的热更新 12345678GET _analyze&#123; \"text\": \"你的衣服真好看\", \"analyzer\": \"ik_max_word\"&#125;输出结果：你、的、衣服、真好、好看 12345678GET _analyze&#123; \"text\": \"你的衣服真好看\", \"analyzer\": \"ik_smart\"&#125;输出结果：你、的、衣服、真、好看","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"}]},{"title":"'Elasticsearch（四） Painless'","slug":"elasticearch-painless","date":"2020-12-09T07:00:00.000Z","updated":"2020-12-13T12:40:05.460Z","comments":true,"path":"2020/12/09/elasticearch-painless/","link":"","permalink":"https://midkuro.gitee.io/2020/12/09/elasticearch-painless/","excerpt":"","text":"Elasticsearch 之 PainlessPainlessPainless是一种专门用于Elasticsearch的简单,用于内联和存储脚本，类似于Java,也有注释、关键字、类型、变量、函数等，安全的脚本语言。它是Elasticsearch的默认脚本语言，可以安全地用于内联和存储脚本。 1234567891011121314//将price的价格减少1//ctx._source 拿取上下文的source对象，固定写法POST index/_update/id&#123; \"script\": \"ctx._source.price -=1\"&#125;//省略的写法POST index/_update/id&#123; \"script\": &#123; \"source\": \"ctx._source.price -=1\" &#125;&#125; add123456789101112131415161718192021//通过调用方法添加tags里的数据POST product2/_update/3&#123; \"script\": &#123; //标识这是一个painless语言 \"lang\": \"painless\", \"source\": \"ctx._source.tags.add('无线充电')\" &#125;&#125;//传参调用POST product2/_update/3&#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"ctx._source.tags.add(params.tag_name)\", \"params\": &#123; \"tag_name\": \"无线充电\" &#125; &#125;&#125; delete12345678//delete id=15的数据POST product2/_update/15&#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"ctx.op='delete'\" &#125;&#125; upsert12345678910111213141516//如果数据存在,执行script语句进行更新操作,如果数据不存在,那么执行upsert进行插入操作GET /product2/_doc/15POST product2/_update/15&#123; \"script\": &#123; \"source\": \"ctx._source.price += params.param1\", \"lang\": \"painless\", \"params\": &#123; \"param1\": 100 &#125; &#125;, \"upsert\": &#123; \"name\": \"小米10\", \"price\": 1999 &#125;&#125; 查询 Elasticsearch首次执行脚本时，将对其进行编译并将编译后的版本存储在缓存中。编译过程比较消耗性能。如果需要将变量传递到脚本中，则应以命名形式传递变量，params而不是将值硬编码到脚本本身中。例如，如果您希望能够将字段值乘以不同的乘数，请不要将乘数硬编码到脚本中 123456789101112131415161718192021222324252627282930//看took消耗//doc['price'].value 获取doc对象里的price列的值GET product2/_search&#123; //由于是查询字段经过了script计算，返回的结果需要定义一个名称，使用script_fields接收结果 \"script_fields\": &#123; \"test_field\": &#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"doc['price'].value * 9\" &#125; &#125; &#125;&#125;//更换num的值 对比took消耗 GET product2/_search&#123; \"script_fields\": &#123; \"test_field\": &#123; \"script\": &#123; \"lang\": \"expression\", \"source\": \"doc['price'].value * num\", \"params\": &#123; \"num\": 9 &#125; &#125; &#125; &#125;&#125; doc[&#39;price&#39;] * num只编译一次，而doc[&#39;price&#39;] * 9 会随着数字改变而一直编译，效率没有传参的方式高效。ES默认每分钟支持15次编译。 1234567891011121314151617181920212223// 支持查原数据 + 计算数据 ，如原始价格 和 多个打折价格GET product2/_search&#123; \"script_fields\": &#123; \"price\": &#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"doc['price'].value\" &#125; &#125;, \"discount_price\": &#123; \"script\": &#123; \"lang\": \"painless\", //这里要使用数据，因为有多个参数 \"source\": \"[doc['price'].value * params.p1,doc['price'].value * params.p2]\", \"params\": &#123; \"p1\": 0.8, \"p2\": 0.7 &#125; &#125; &#125; &#125;&#125; Stored scriptsStored scripts :可以理解为script模板 缓存在集群的cache中，默认缓存大小是100MB 没有过期时间 可以手工设置过期时间script.cache.expire 通过script.cache.max_size设置缓存大小 脚本最大64MB 通过script.max_size_in_bytes配置 只有发生变更时重新编译。 12345678910111213141516// 语法：/_scripts/&#123;id&#125; 类似存储过程 计算折扣 作用域为整个集群 &#123;id&#125;是scripts的名称//新增POST _scripts/calculate-discount&#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"doc['price'].value * params.discount\" &#125;&#125;//查看GET _scripts/calculate-discount//删除DELETE _scripts/calculate-discount 123456789101112131415//调用GET product2/_search&#123; \"script_fields\": &#123; \"discount_price\": &#123; \"script\": &#123; //调用名称为calculate-discount的srcipt \"id\":\"calculate-discount\", \"params\": &#123; \"discount\": 0.8 &#125; &#125; &#125; &#125;&#125; DatesDates：ZonedDateTime类型，因此它们支持诸如之类的方法getYear，getDayOfWeek 或例如从历元开始到毫秒getMillis。要在脚本中使用它们，请省略get前缀并继续使用小写的方法名其余部分。 12345678910111213141516171819//getYear()//getMonth()//getDayOfMonth()//getDayOfWeek()//getDayOfYear()//getHour()//getMinute()//getSecond()//getNano()GET product2/_search&#123; \"script_fields\": &#123; \"test_year\": &#123; \"script\": &#123; \"source\": \"doc.createtime.value.year\" &#125; &#125; &#125;&#125; Groovy通过两个&quot;&quot;&quot;括起来，在里面能够把它当做java代码进行编写，每个语句分隔使用;，支持使用条件语句。 1234567891011121314POST product2/_update/1&#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"\"\" ctx._source.name += params.name; ctx._source.price -= 1 \"\"\", \"params\": &#123; \"name\": \"无线充电\", \"price\": \"1\" &#125; &#125;&#125; 12345678910111213141516//正则部分匹配phonePOST product2/_update/1&#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"\"\" // =~ 部分匹配 name中包含phone [\\s\\S]表示任意符号 if (ctx._source.name =~ /[\\s\\S]*phone[\\s\\S]*/) &#123; ctx._source.name += \"***|\"; &#125; else &#123; //什么都不做 ctx.op = \"noop\"; &#125; \"\"\" &#125;&#125; 123456789101112131415//正则匹配日期 yyyy-MM-ddPOST product2/_update/1&#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"\"\" // ==~ 全匹配 日期 if (ctx._source.createtime ==~ /[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;/) &#123; ctx._source.name += \"|***\"; &#125; else &#123; ctx.op = \"noop\"; &#125; \"\"\" &#125;&#125; 正则表达式默认情况下处于禁用状态，因为他们绕过了Painless的针对长时间运行和占用内存的脚本保护措施，而且有深度堆栈行为，若想要开启，则需要在elasticsearch.yml增加配置： 1script.painless.regex.enabled: true 聚合操作1234567891011121314151617181920212223242526272829303132333435//计算价格小于1000的tags数量GET /product/_search&#123; \"query\": &#123; \"bool\": &#123; \"filter\": [ &#123; \"range\": &#123; \"price\": &#123; \"lt\": 1000 &#125; &#125; &#125; ] &#125; &#125;, \"aggs\": &#123; \"tag_agg_group\": &#123; \"sum\": &#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"\"\" int total = 0; for (int i = 0; i &lt; doc['tags.keyword'].length; i++) &#123; total++ &#125; return total; \"\"\" &#125; &#125; &#125; &#125;, \"size\": 0&#125; doc[‘field’].value和params[‘_source’] [‘field’] 的区别： 理解之间的区别是很重要的，首先，使用doc关键字，将导致该字段的条件被加载到内存（缓存），这将导致更快的执行，但更多的内存消耗。 此外，doc[…]符号只允许简单类型（不能返回一个复杂类型(JSON对象或者nested类型)），只有在非分析或单个词条的基础上有意义。 但是，doc如果可能，使用仍然是从文档访问值的推荐方式，因为_source每次使用时都必须加载并解析。使用_source非常缓慢。 123456789101112131415161718192021222324//查询一批数据中，字段people：[&#123;\"SF\":男&#125;,&#123;\"SF\":女&#125;]，有多少个男性GET /test_index/_search&#123; \"aggs\": &#123; \"sum_person\": &#123; \"sum\": &#123; \"script\": &#123; \"lang\": \"painless\", \"source\": \"\"\" int total = 0; for (int i = 0; i &lt; params['_source']['people'].length; i++) &#123; if (params['_source']['people'][i]['SF'] == '男') &#123; total += 1; &#125; &#125; return total; \"\"\" &#125; &#125; &#125; &#125;, \"size\": 0&#125; 写入原理 当有写入请求时，数据会先写到内存的Buffer中（Buffer专门用于写入操作），每间隔1S会创建一个index segment的file，然后segment会同步到OS cache中，OS cache会返回一个status = Open，这时候的segment就能对外提供搜索操作。 读写操作进行了异步分离操作，segment对外提供读搜索操作，OS cache后台异步写入数据。 在这种方式下，如果宕机会造成少部分数据的丢失，ES是怎么避免的？ ES在写入索引时，并没有实时落盘到索引文件，而是先双写到内存和translog文件，假如节点挂了，重启节点时就会重放日志，这样相当于把用户的操作模拟了一遍。保证了数据的不丢失。 1234当OS cache中的数据达到一定大小之后或者一定时间后，触发Flush：1.执行 commit操作，把内存中的Buffer、Segment数据同步到OS cache2.把OS cache的数据fsync到 磁盘中3.清空translog Commit Point用于存储可用的segment，每当创建一个segment时，都会往Commit point中做登记，segment文件并不是无限制地创建的，当达到一定的操作/大小时，会执行segment合并操作： 123451.选择一些体积小的segment，然后将其合并成一个更大的segment2.执行flush操作，讲OS cache的数据落地到磁盘中3.创建新的commit point，并且登记新的segment，然后将旧的segment标记成删除状态4.将新的segment搜索状态&#96;status&#x3D;open&#96;打开5.将删除状态的segment文件删除 segment维护了一个.del的文件，当有数据执行删除/更新操作时，它会先将数据在segment中标记成删除的状态，这时候没有物理删除，然后在查询的时候，会将删除状态的数据进行过滤。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"}]},{"title":"'Elasticsearch（三） 倒排索引'","slug":"elasticearch-index","date":"2020-12-09T06:00:00.000Z","updated":"2020-12-13T12:39:57.023Z","comments":true,"path":"2020/12/09/elasticearch-index/","link":"","permalink":"https://midkuro.gitee.io/2020/12/09/elasticearch-index/","excerpt":"","text":"Elasticsearch 倒排索引底层原理 正排索引（doc values ）VS 倒排索引： 概念：从广义来说，doc values 本质上是一个序列化的 列式存储 。列式存储 适用于聚合、排序、脚本等操作，所有的数字、地理坐标、日期、IP 和不分析（ not_analyzed ）字符类型都会默认开启。 特点：倒排索引的优势 在于查找包含某个项的文档，相反，如果用它确定哪些项是否存在单个文档里。 总结：全文搜索需要用倒排索引，而排序和聚合则需要使用 正排索引。 在Mappings中有两个相关配置 12345doc_values：true&#x2F;false 为该字段创建正排索引，默认true，不支持text类型index:true&#x2F;false 为该字段创建倒排索引，默认为true 123456789101112PUT /product&#123; \"mappings\": &#123; \"properties\": &#123; \"tags\": &#123; \"type\": \"text\", \"index\": \"true\" //\"doc_values\": \"true\" text类型不支持 &#125; &#125; &#125;&#125; 1234567891011//当使用es自带的keyword时，它字段值是一个整体的精确匹配，并不会对字段值的内容进行分词GET /product/_search&#123; \"aggs\": &#123; \"tags_group\": &#123; \"terms\": &#123; \"field\": \"tags.keyword\" &#125; &#125; &#125;&#125; 而doc_values正排索引不支持text字段，那text字段怎么进行聚合操作呢？ 1234567891011//当直接使用tags进行聚合操作，想要聚合tags中的分词后的terms词项，会报错GET /product/_search&#123; \"aggs\": &#123; \"tags_group\": &#123; \"terms\": &#123; \"field\": \"tags\" &#125; &#125; &#125;&#125; 1234Text fields are not optimised for operations that require per-document field data like aggregations and sorting, so these operations are disabled by default. Please use a keyword field instead. Alternatively, set fielddata&#x3D;true on [tags] in order to load field data by uninverting the inverted index. Note that this can use significant memory. 大概的意思是，必须要打开fielddata=true，然后将正排索引数据加载到内存中，才可以对分词的field执行聚合操作，而且会消耗很大的内存。 12345678910//修改Mapping结构：开启tags字段 在使用聚合操作时使用 正排索引进行计算PUT /product/_mapping&#123; \"properties\": &#123; \"tags\": &#123; \"type\": \"text\", \"fielddata\": true &#125; &#125;&#125; 这时候再次执行上文的tags的聚合操作，就不会报错了，那么fielddata和doc_values都是开启正排索引，他们之间有什么区别呢？ 维度 doc_values fielddata 创建时间 index时创建 使用时动态创建 创建位置 磁盘 内存(jvm heap) 优点 不占用内存空间 不占用磁盘空间 缺点 索引速度稍低 文档很多时，动态创建开销比较大，而且占内存 默认值 true false doc_values速度稍低这个是相对于fielddata方案的，其实仔细想想也可以理解。拿排序举例，相对于一个在磁盘排序，一个在内存排序。谁的速度快自然不用多说。 与 doc values 不同，fielddata 构建和管理 100% 在内存中，常驻于 JVM 内存堆。这意味着它本质上是不可扩展的。 fielddata可能会消耗大量的堆空间，尤其是在加载高基数（high cardinality）text字段时。一旦fielddata已加载到堆中，它将在该段的生命周期内保留。此外，加载fielddata是一个昂贵的过程，可能会导致用户遇到延迟命中。这就是默认情况下禁用fielddata的原因。 doc_values虽然速度稍慢，但doc_values的优势还是非常明显的。一个很显著的点就是他不会随着文档的增多引起OOM问题。正如前面说的，doc_values在磁盘创建排序和聚合所需的正排索引。这样我们就避免了在生产环境给ES设置一个很大的HEAP_SIZE，也使得JVM的GC更加高效，这个又为其它的操作带来了间接的好处。 12345671.当没有doc value的字段需要聚合时，需要打开fielddata，然后临时在内存中建立正排索引，fielddata的构建和管理发生在JVM heap中。2.Fielddata默认是不启用的，因为text字段比较长，一般只做关键字分词和搜索，很少拿来进行全文匹配和聚合还有排序。3.ES采用了circuit breaker(熔断)机制避免fielddata一次性超过物理内存大小而导致内存溢出，如果发生熔断，查询会被终止并返回异常。4.fielddata使用的是jvm内存，doc value在内存不足时会静静的待在磁盘中，而当内存充足时，会蹦到内存里提升性能。 为什么不可以用倒排索引计算聚合？ 对于聚合部分，我们需要找到匹配的doc里所有唯一的词项（term）。需要遍历每个doc获取所有trem词项，然后再一个个去倒排索引表中进行查找，是一个 n x m 的操作，做这件事情性能很低，很有可能会造成全表遍历。 因此通过正排索引来解决聚合问题。 批量查询123语法：GET /_mgetGET /&lt;index&gt;/_mget 1234567891011121314//批量查询 查询id =2 和id = 3 的数据GET /_mget&#123; \"docs\": [ &#123; \"_index\": \"product\", \"_id\": 2 &#125;, &#123; \"_index\": \"product\", \"_id\": 3 &#125; ]&#125; 123456789101112//封装,把索引名(product提取出来)GET /product/_mget&#123; \"docs\": [ &#123; \"_id\": 2 &#125;, &#123; \"_id\": 3 &#125; ]&#125; 12345//再封装GET /product/_mget&#123; \"ids\":[2,3]&#125; 12345678910111213141516171819202122232425262728//include包含哪些字段 exclude排除哪些字段GET /product/_mget&#123; \"docs\": [ &#123; \"_id\": 2, \"_source\": false //不显示字段数据 &#125;, &#123; \"_id\": 3, \"_source\": [ //指定字段数据 \"name\", \"price\" ] &#125;, &#123; \"_id\": 4, \"_source\": &#123; \"include\": [ \"name\" ], \"exclude\":[ \"price\" ] &#125; &#125; ]&#125; 12345Operate： create：PUT &#x2F;index&#x2F;_create&#x2F;id&#x2F;，强制创建（是否制定id） delete：删除（lazy delete原理） index：可以是创建，也可以是全量替换 update：执行partial update（全量替换，部分替换） 12345//手动指定id和自动生成PUT /test_index/_doc/1/&#123; \"test\":\"123\"&#125; 1234567891011//强制执行创建 如果数据存在则报错PUT /test_index/_doc/1/_create&#123; \"test\":\"123\"&#125;//同上PUT /test_index/_create/1/&#123; \"test\":\"123\"&#125; 12345//自动生产id(guid)POST /test_index/_doc&#123; \"test\":\"123\"&#125; 当使用PUT进行数据覆盖的时候，Version版本号会上升，旧的Version数据会被删除，不会马上删除，会有一个懒删除的机制。 批量操作123456bulk：批量增删改 no-query语法格式：POST /_bulkPOST /&lt;index&gt;/_bulk&#123;\"action\": &#123;\"metadata\"&#125;&#125; //操作和索引&#123;\"data\"&#125; //数据 123456789101112131415161718POST /_bulk&#123; \"delete\": &#123; \"_index\": \"product2\", \"_id\": \"1\" &#125;&#125;&#123; \"create\": &#123; \"_index\": \"product2\", \"_id\": \"2\" &#125;&#125;&#123; \"name\": \"_bulk create 2\" &#125;&#123; \"create\": &#123; \"_index\": \"product2\", \"_id\": \"12\" &#125;&#125;&#123; \"name\": \"_bulk create 12\" &#125;&#123; \"index\": &#123; \"_index\": \"product2\", \"_id\": \"3\" &#125;&#125;&#123; \"name\": \"index product2 \" &#125;&#123; \"index\": &#123; \"_index\": \"product2\", \"_id\": \"13\" &#125;&#125;&#123; \"name\": \"index product2\" &#125;//当出现冲突时尝试三次，三次失败后就放弃&#123; \"update\": &#123; \"_index\": \"product2\", \"_id\": \"4\",\"retry_on_conflict\" : \"3\"&#125; &#125;&#123; \"doc\" : &#123;\"test_field2\" : \"bulk test1\"&#125; &#125; bulk批处理操作要求数据分两行编写，不可以将{}进行换行操作。 1234//加?filter_path=items.*.error 只显示失败的，返回从操作失败的数据信息POST /_bulk?filter_path=items.*.error&#123; \"delete\": &#123; \"_index\": \"product2\", \"_id\": \"1\" &#125;&#125;&#123; \"create\": &#123; \"_index\": \"product2\", \"_id\": \"2\" &#125;&#125; 1234567//version=2&amp;&amp;version_type=external 通过版本更新数据，避免并发覆盖---CASPUT /version_index/_doc/1?version=2&amp;&amp;version_type=external&#123; \"title\": \"窈窕淑女,君子好逑\"&#125;//新版本使用者两个//if_seq_no` and `if_primary_term` ES是通过CAS+Version解决并发的问题！！！","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"}]},{"title":"'Elasticsearch（二） 查询语法'","slug":"elasticearch-dql","date":"2020-12-09T05:00:00.000Z","updated":"2020-12-13T14:17:57.720Z","comments":true,"path":"2020/12/09/elasticearch-dql/","link":"","permalink":"https://midkuro.gitee.io/2020/12/09/elasticearch-dql/","excerpt":"","text":"Elasticsearch 之 DQL查询语法12345678910111213141516171819202122232425262728293031323334353637383940//数据：PUT /product/_doc/1&#123; \"name\" : \"xiaomi phone\", \"desc\" : \"shouji zhong de zhandouji\", \"price\" : 3999, \"tags\": [ \"xingjiabi\", \"fashao\", \"buka\" ]&#125;PUT /product/_doc/2&#123; \"name\" : \"xiaomi nfc phone\", \"desc\" : \"zhichi quangongneng nfc,shouji zhong de jianjiji\", \"price\" : 4999, \"tags\": [ \"xingjiabi\", \"fashao\", \"gongjiaoka\" ]&#125;PUT /product/_doc/3&#123; \"name\" : \"nfc phone\", \"desc\" : \"shouji zhong de hongzhaji\", \"price\" : 2999, \"tags\": [ \"xingjiabi\", \"fashao\", \"menjinka\" ]&#125;PUT /product/_doc/4&#123; \"name\" : \"xiaomi erji\", \"desc\" : \"erji zhong de huangmenji\", \"price\" : 999, \"tags\": [ \"low\", \"bufangshui\", \"yinzhicha\" ]&#125;PUT /product/_doc/5&#123; \"name\" : \"hongmi erji\", \"desc\" : \"erji zhong de kendeji\", \"price\" : 399, \"tags\": [ \"lowbee\", \"xuhangduan\", \"zhiliangx\" ]&#125; 以后语句将忽略type：_doc Query_String12#查询product索引下的所有type/docGET /product/_search 123456789#设置时限查询timeout：(1) 设置：默认没有timeout，如果设置了timeout，那么会执行timeout机制。(2) Timeout机制：假设用户查询结果有1W条数据，但是需要10s才能查询完毕 但是用户设置了1s的timeout，那么不管当前一共查询到了多少数据，都会在1s后ES将停止查询，并返回当前数据。GET /_search?timeout=1s 12#查询doc中包含xiaomi的所有docGET /product/_search?q=xiaomi 12#查询name中包含xiaomi的所有docGET /product/_search?q=name:xiaomi 上面两者的区别： q=xiaomi ：将所有字段拼接成一个长字符串进行匹配 q=name:xiaomi ：直接按照name进行匹配 12#分页查询 每页2条数据 取第一页GET /product/_search?from=0&amp;size=2 12#排序 使用排序的话，相关度分数将_score = nullGET /product/_search?sort=price:asc Query DQL1234567//match_all 查询所有GET /product/_search&#123; \"query\":&#123; \"match_all\": &#123;&#125; &#125;&#125; match 重点掌握语句！！！ 123456789//match 查询 name中包含“nfc” 如果多个单词会进行分词！！！GET /product/_search&#123; \"query\": &#123; \"match\": &#123; \"name\": \"nfc\" &#125; &#125;&#125; 123456789101112131415//sort 搜索名称包含“nfc”并且价格由高到低排序GET /product/_search&#123; \"query\": &#123; \"multi_match\": &#123; \"query\": \"nfc\", \"fields\": [\"name\",\"desc\"] &#125; &#125;, \"sort\": [ &#123; \"price\": \"desc\" &#125; ]&#125; 12345678910//multi_match 据多个字段查询一个关键词，name和desc中包含\"nfc\"GET /product/_search&#123; \"query\": &#123; \"multi_match\": &#123; \"query\": \"nfc\", \"fields\": [\"name\",\"desc\"] &#125; &#125;&#125; 12345678910//_source 元数据：想要查询多个字段，例子中为只查询“name”和“price”字段GET /product/_search&#123; \"query\":&#123; \"match\": &#123; \"name\": \"nfc\" &#125; &#125;, \"_source\": [\"name\",\"price\"]&#125; 1234567891011121314//分页（deep-paging）：查询第一页（每页两条数据）GET /product/_search&#123; \"query\":&#123; \"match_all\": &#123;&#125; &#125;, \"sort\": [ &#123; \"price\": \"asc\" &#125; ], \"from\": 0, \"size\": 2&#125; Full-text queries 全文检索12345678910//query-term：查询条件 \"nfc phone\" 不会被分词，不会分成多个单词//term和match的区别是match 会对查询条件进行分词GET /product/_search&#123; \"query\": &#123; \"term\": &#123; \"name\": \"nfc phone\" &#125; &#125;&#125; 123456789101112//组合查询GET /product/_search&#123; \"query\": &#123; \"bool\": &#123; \"must\": [ &#123;\"term\":&#123;\"name\":\"nfc\"&#125;&#125;, &#123;\"term\":&#123;\"name\":\"phone\"&#125;&#125; ] &#125; &#125;&#125; 123456789//包含查询 类似于 SQL: where xxx in ();GET /product/_search&#123; \"query\": &#123; \"terms\": &#123; \"name\":[\"nfc\",\"phone\"] &#125; &#125;&#125; 1234567891011121314151617//全文检索，一个单词进行分词，常用语句！！！//等价SQL: name in (xiaomi,nfc,zhineng,phone)GET /product/_search&#123; \"query\": &#123; \"match\": &#123; \"name\": \"xiaomi nfc zhineng phone\" &#125; &#125;&#125;//验证这个字符串的分词结果GET /_analyze&#123; \"analyzer\": \"standard\", \"text\":\"xiaomi nfc zhineng phone\"&#125; Phrase search12345678910//短语搜索，和全文检索相反，会将给定的短语（phrase）当成一个完整的查询条件//等价SQL: name contains(\"nfc phone\")GET /product/_search&#123; \"query\": &#123; \"match_phrase\": &#123; \"name\": \"nfc phone\" &#125; &#125;&#125; Query and filter bool：可以组合多个查询条件，bool查询也是采用more_matches_is_better的机制，因此满足must和should子句的文档将会合并起来计算分值。 must：必须满足 ​ 子句（查询）必须出现在匹配的文档中，并将有助于得分。 filter：过滤器 不计算相关度分数，cache☆ ​ 子句（查询）必须出现在匹配的文档中。但是不像 must查询的分数将被忽略。Filter子句在filter上下文中执行，这意味着计分被忽略，并且子句被考虑用于缓存。 should：可能满足 or ​ 子句（查询）应出现在匹配的文档中。 must_not：必须不满足 不计算相关度分数 not ​ 子句（查询）不得出现在匹配的文档中。子句在过滤器上下文中执行，这意味着计分被忽略，并且子句被视为用于缓存。由于忽略计分，0因此将返回所有文档的分数。 minimum_should_match： 12345678910111213141516171819202122//首先筛选name包含“xiaomi phone”并且价格大于1999的数据（不排序） 先执行filter筛选数据//然后搜索name包含“xiaomi”and desc 包含“shouji”GET /product/_search&#123; \"query\": &#123; \"bool\":&#123; \"must\": [ &#123;\"match\": &#123; \"name\": \"xiaomi\"&#125;&#125;, &#123;\"match\": &#123;\"desc\": \"shouji\"&#125;&#125; ], \"filter\": [ &#123;\"match_phrase\":&#123;\"name\":\"xiaomi phone\"&#125;&#125;, &#123;\"range\": &#123; \"price\": &#123; \"gt\": 1999 &#125; &#125;&#125; ] &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031//bool多条件 name包含xiaomi 不包含erji 描述里包不包含nfc都可以，价钱要大于等于4999GET /product/_search&#123; \"query\": &#123; \"bool\":&#123; //name中必须不能包含“erji” \"must\": [ &#123;\"match\": &#123; \"name\": \"xiaomi\"&#125;&#125; ], //name中必须包含“xiaomi” \"must_not\": [ &#123;\"match\": &#123; \"name\": \"erji\"&#125;&#125; ], //should中至少满足0个条件，参见下面的minimum_should_match的解释 \"should\": [ &#123;\"match\": &#123; \"desc\": \"nfc\" &#125;&#125; ], //筛选价格大于4999的doc \"filter\": [ &#123;\"range\": &#123; \"price\": &#123; \"gt\": 4999 &#125; &#125;&#125; ] &#125; &#125;&#125; minimum_should_match：参数指定should返回的文档必须匹配的子句的数量或百分比。如果bool查询包含至少一个should子句，而没有must或 filter子句，则默认值为1。否则，默认值为0 123456789101112131415161718192021//查询 name必须包含 \"nfc\" 且should中必须满足一个条件GET /product/_search&#123; \"query\": &#123; \"bool\":&#123; \"must\": [ &#123;\"match\": &#123; \"name\": \"nfc\"&#125;&#125; ], \"should\": [ &#123;\"range\": &#123; \"price\": &#123;\"gt\":1999&#125; &#125;&#125;, &#123;\"range\": &#123; \"price\": &#123;\"gt\":3999&#125; &#125;&#125; ], //表示should里的条件至少满足一个 \"minimum_should_match\": 1 &#125; &#125;&#125; 1234567891011121314151617181920//这种情况下，should至少满足0个条件GET /product/_search&#123; \"query\": &#123; \"bool\": &#123; \"filter\": &#123; \"bool\": &#123; //价格必须大于1999或者大于3999 \"should\": [ &#123; \"range\": &#123;\"price\": &#123;\"gt\": 1999&#125;&#125;&#125;, &#123; \"range\": &#123;\"price\": &#123;\"gt\": 3999&#125;&#125;&#125; ], \"must\": [ &#123; \"match\": &#123;\"name\": \"nfc\"&#125;&#125; ] &#125; &#125; &#125; &#125;&#125; Compound queries123456789101112131415161718192021222324252627//组合查询//想要一台带NFC功能的 或者 小米的手机 但是不要耳机//等价于SQL:// SELECT * from product // where (`name` like \"%xiaomi%\" or `name` like '%nfc%')// AND `name` not LIKE '%erji%'GET /product/_search&#123; \"query\": &#123; \"constant_score\":&#123; \"filter\": &#123; \"bool\": &#123; \"should\":[ &#123;\"term\":&#123;\"name\":\"xiaomi\"&#125;&#125;, &#123;\"term\":&#123;\"name\":\"nfc\"&#125;&#125; ], \"must_not\":[ &#123;\"term\":&#123;\"name\":\"erji\"&#125;&#125; ] &#125; &#125;, //给他的分数赋值 1.2 没什么 意义 \"boost\": 1.2 &#125; &#125;&#125; 123456789101112131415161718192021222324//搜索一台xiaomi nfc phone或者一台满足 是一台手机 并且 价格小于等于2999//等价于SQL：GET /product/_search&#123; \"query\": &#123; \"constant_score\": &#123; \"filter\": &#123; \"bool\":&#123; \"should\":[ &#123;\"match_phrase\":&#123;\"name\":\"xiaomi nfc phone\"&#125;&#125;, &#123; \"bool\":&#123; \"must\":[ &#123;\"term\":&#123;\"name\":\"phone\"&#125;&#125;, &#123;\"range\":&#123;\"price\":&#123;\"lte\":\"2999\"&#125;&#125;&#125; ] &#125; &#125; ] &#125; &#125; &#125; &#125;&#125; Highlight search1234567891011121314151617181920212223//高亮查询GET /product/_search&#123; \"query\" : &#123; \"match_phrase\" : &#123; \"name\" : \"nfc phone\" &#125; &#125;, \"highlight\":&#123; \"fields\":&#123; \"name\":&#123;&#125; &#125; &#125;&#125;//返回结果：会多返回一段高亮信息\"highlight\" : &#123; \"name\" : [ \"&lt;em&gt;nfc&lt;/em&gt; &lt;em&gt;phone&lt;/em&gt;\" ]&#125; Deep paging问题 假设我要分页获取第5001~5050条数据时，由于数据是无序散落在各个shard分片中的，所以进行分页排序的时候，需要将各个shard分片进行排序，获取每个分片的【0 - 5050】条数据，然后进行合并，最后取出合适的50条数据，然后丢弃其他数据。 这种操作是十分损耗性能的，尽量避免深度分页查询，当你的数据超过1W，不要使用，返回结果不要超过1000个，500以下为宜。 Scroll search通过使用Scroll search来避免部分分页查询，在查询中添加?scroll参数 123456789//其中 1m 表示当前的scroll窗口有效期是1分钟GET /product/_search?scroll=1m&#123; \"query\":&#123; \"match_all\":&#123;&#125; &#125;, \"sort\":[&#123;\"price\":\"asc\"&#125;], \"size\":2&#125; 通过这样查询，返回值会带上一个_scroll_id结果 当进行下一页时，直接通过上一次返回的scroll_id进行查询即可 123456GET /_search/scroll&#123; //给scroll进行续命 \"scroll\" :\"1m\", scroll_id:\"xxxxxxxxxxxx\"&#125; 他的缺点是只能下一页，没办法上一页，不适合实时查询 Filter缓存原理 当使用 term词项去倒排索引表进行搜索时，返回的一条条数据，filter会通过一个Bit数组存储，每个词项term对应一个bit数组，1表示匹配成功，0表示匹配失败。 计算多个filter条件的组合时，直接进行bit数组的与运算就能得出相应的结果，在一定条件下，filter会将查询的bit数组进行缓存。 Mapping概念：mapping就是ES数据字段field的type元数据，ES在创建索引的时候，dynamic mapping会自动为不同的数据指定相应mapping，mapping中包含了字段的类型、搜索方式（exact value或者full text）、分词器等。 12查看mappingGET /product/_mappings 1234567Dynamic mapping“Elasticsearch”：text/keyword 123456 =&gt; long ？为什么不是integer123.123 =&gt; double true false =&gt; boolean2020-05-20 =&gt; date 为啥price是long类型而不是integer？因为es的mapping_type是由JSON分析器检测数据类型，而Json没有隐式类型转换（integer=&gt;long or float=&gt; double）,所以dynamic mapping会选择一个比较宽的数据类型。 123搜索方式：exact value 精确匹配：在倒排索引过程中，分词器会将field作为一个整体创建到索引中，full text全文检索：分词、近义词同义词、混淆词、大小写、词性、过滤、时态转换等（normaliztion） 数据类型12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758【核心类型】：数字类型： long, integer, short, byte, double, float, half_float, scaled_float 在满足需求的情况下，尽可能选择范围小的数据类型。2.字符串：string： 2.1 keyword：适用于索引结构化的字段，可以用于过滤、排序、聚合。 keyword类型的字段只能通过精确值（exact value）搜索到。 Id应该用keyword。 2.2 text： 当一个字段是要被全文搜索的，比如Email内容、产品描述，这些字段应该使用text类型。 设置text类型以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。 text类型的字段不用于排序，很少用于聚合。 （解释一下为啥不会为text创建索引：字段数据会占用大量堆空间，尤其是在加载高基数text字段时。 字段数据一旦加载到堆中，就在该段的生命周期内保持在那里。 同样，加载字段数据是一个昂贵的过程，可能导致用户遇到延迟问题。这就是默认情况下禁用字段数据的原因） 2.3 有时，在同一字段中同时具有全文本（text）和关键字（keyword）版本会很有用：一个用于全文本搜索，另一个用于聚合和排序。 3.date（时间类型）：exact value（精确匹配）4.布尔类型：boolean5.binary（二进制）：binary6.range（区间类型）：integer_range、float_range、long_range、double_range、date_range【复杂类型】：1.Object：用于单个JSON对象2.Nested：用于JSON对象数组【地理位置】：1.Geo-point：纬度&#x2F;经度积分2.Geo-shape：用于多边形等复杂形状【特有类型】：1.IP地址：ip 用于IPv4和IPv6地址2.Completion：提供自动完成建议3.Tocken_count：计算字符串中令牌的数量4.Murmur3：在索引时计算值的哈希并将其存储在索引中5.Annotated-text：索引包含特殊标记的文本（通常用于标识命名实体）6.Percolator：接受来自query-dsl的查询7.Join：为同一索引内的文档定义父&#x2F;子关系8.Rank features：记录数字功能以提高查询时的点击率。9.Dense vector：记录浮点值的密集向量。10.Sparse vector：记录浮点值的稀疏向量。11.Search-as-you-type：针对查询优化的文本字段，以实现按需输入的完成12.Alias：为现有字段定义别名。13.Flattened：允许将整个JSON对象索引为单个字段。14.Shape：shape 对于任意笛卡尔几何。15.Histogram：histogram 用于百分位数聚合的预聚合数值。16.Constant keyword：keyword当所有文档都具有相同值时的情况的 专业化。【Array（数组）】：在Elasticsearch中，数组不需要专用的字段数据类型。默认情况下，任何字段都可以包含零个或多个值，但是，数组中的所有值都必须具有相同的数据类型。【ES 7新增】：1.Date_nanos：date plus 纳秒2.Features：3.Vector：as 1234567891011//手工创建mapping fields的mapping只能创建，无法修改PUT /product&#123; \"mappings\": &#123; \"properties\": &#123; \"field\": &#123; \"mapping_parameter\": \"parameter_value\" &#125; &#125; &#125;&#125; Mapping parametersindex：是否对创建对当前字段创建索引，默认true，如果不创建索引，该字段不会通过索引被搜索到,但是仍然会在source元数据中展示 analyzer:指定分析器（character filter、tokenizer、Token filters）。 boost：对当前字段相关度的评分权重，默认1 coerce：是否允许强制类型转换 true “1”=&gt; 1 false “1”=&lt; 1 copy_to：拷贝字段值 12345678910111213141516171819202122232425262728293031323334//基本案例PUT /product3&#123; \"mappings\": &#123; \"properties\": &#123; \"date\": &#123; \"type\": \"text\" &#125;, \"desc\": &#123; \"type\": \"text\", \"analyzer\": \"english\" &#125;, \"name\": &#123; \"type\": \"text\", \"index\": \"false\", \"boost\": 1 &#125;, \"price\": &#123; \"type\": \"Integer\", \"coerce\": false &#125;, \"tags\": &#123; \"type\": \"text\", \"index\": \"true\" &#125;, \"parts\": &#123; \"type\": \"object\" &#125;, \"partlist\": &#123; \"type\": \"nested\" &#125; &#125; &#125;&#125; 12345678910111213141516171819//copy_to案例PUT copy_to&#123; \"mappings\": &#123; \"properties\": &#123; \"field1\": &#123; \"type\": \"text\", \"copy_to\": \"field_all\" &#125;, \"field2\": &#123; \"type\": \"text\", \"copy_to\": \"field_all\" &#125;, \"field_all\": &#123; \"type\": \"text\" &#125; &#125; &#125;&#125; doc_values：为了提升排序和聚合效率，默认true，如果确定不需要对字段进行排序或聚合，也不需要通过脚本访问字段值，则可以禁用doc值以节省磁盘空间（不支持text和annotated_text） dynamic：控制是否可以动态添加新字段 123456true 新检测到的字段将添加到映射中。（默认）false 新检测到的字段将被忽略。这些字段将不会被索引，因此将无法搜索，但仍会出现在_source返回的匹配项中。这些字段不会添加到映射中，必须显式添加新字段。strict 如果检测到新字段，则会引发异常并拒绝文档。必须将新字段显式添加到映射中 eager_global_ordinals：用于聚合的字段上，优化聚合性能。 Frozen indices（冻结索引）：有些索引使用率很高，会被保存在内存中，有些使用率特别低，宁愿在使用的时候重新创建，在使用完毕后丢弃数据，Frozen indices的数据命中频率小，不适用于高搜索负载，数据不会被保存在内存中，堆空间占用比普通索引少得多，Frozen indices是只读的，请求可能是秒级或者分钟级。eager_global_ordinals不适用于Frozen indices enable：只用于mapping中的object字段类型。当设置为false时，其作用是使es不去解析该字段，并且该字段不能被查询和store，只有在_source中才能看到（即查询结果中会显示的_source数据）。设置enabled为false，可以不设置字段类型，默认为object。 1234567891011121314PUT my_index&#123; \"mappings\": &#123; \"enabled\": false &#125;&#125;PUT my_index&#123; \"mappings\": &#123; \"properties\": &#123; \"session_data\": &#123; \"type\": \"object\", \"enabled\": false &#125; &#125; &#125;&#125; fielddata：查询时内存数据结构，在首次用当前字段聚合、排序或者在脚本中使用时，需要字段为fielddata数据结构，并且创建正排索引保存到堆中。 fields：给field创建多字段，用于不同目的（全文检索或者聚合分析排序） format：格式化 1234\"date\": &#123; \"type\": \"date\", \"format\": \"yyyy-MM-dd\"&#125; ignore_above：text中的keyword长度，超过长度将被截断 ignore_malformed：忽略类型错误 12345678910111213PUT my_index&#123; \"mappings\": &#123; \"properties\": &#123; \"number_one\": &#123; \"type\": \"integer\", \"ignore_malformed\": true &#125;, \"number_two\": &#123; \"type\": \"integer\" &#125; &#125; &#125;&#125; 12345678910111213//虽然有异常 但是不抛出PUT my_index/_doc/1&#123; \"text\": \"Some text value\", \"number_one\":\"foo\" &#125;//数据格式不对PUT my_index/_doc/2&#123; \"text\": \"Some text value\", \"number_two\": \"foo\" &#125; index_options：控制将哪些信息添加到反向索引中以进行搜索和突出显示。仅用于text字段 Index_phrases：提升exact_value查询速度，但是要消耗更多磁盘空间 Index_prefixes：前缀搜索 12min_chars：前缀最小长度，&gt;0，默认2（包含）max_chars：前缀最大长度，&lt;20，默认5（包含） 1234\"index_prefixes\": &#123; \"min_chars\" : 1, \"max_chars\" : 10&#125; meta：附加元数据 norms：是否禁用评分（在filter和聚合字段上应该禁用）。 null_value：为null值设置默认值 1\"null_value\": \"NULL\" proterties：除了mapping还可用于object的属性设置 search_analyzer：设置单独的查询时分析 12345678910111213141516171819202122232425262728293031323334PUT my_index&#123; \"settings\": &#123; \"analysis\": &#123; \"filter\": &#123; \"autocomplete_filter\": &#123; \"type\": \"edge_ngram\", \"min_gram\": 1, \"max_gram\": 20 &#125; &#125;, \"analyzer\": &#123; \"autocomplete\": &#123; \"type\": \"custom\", //倒排索引的分词器 默认 standard \"tokenizer\": \"standard\", \"filter\": [ \"lowercase\", \"autocomplete_filter\" ] &#125; &#125; &#125; &#125;, \"mappings\": &#123; \"properties\": &#123; \"text\": &#123; \"type\": \"text\", \"analyzer\": \"autocomplete\", //搜索时的分词器 默认 standard \"search_analyzer\": \"standard\" &#125; &#125; &#125;&#125; 1234PUT my_index/_doc/1&#123; \"text\": \"Quick Brown Fox\" &#125; 12345678910GET my_index/_search&#123; \"query\": &#123; \"match\": &#123; \"text\": &#123; \"query\": \"Quick Br\", \"operator\": \"and\" &#125; &#125; &#125;&#125; similarity：为字段设置相关度算法，支持BM25、claassic（默认TF-IDF）、boolean store：设置字段是否仅查询 聚合查询语法：&quot;aggs&quot;:{} 12345678910111213//每个tag产品的数量 \"size\":0, 不显示原始结果 //使用text类型.keyword，提高效率GET /product/_search&#123; \"aggs\": &#123; \"your_group_name\": &#123; \"terms\": &#123; \"field\": \"tags.keyword\" &#125; &#125; &#125;, \"size\":0&#125; 1234567891011//text默认不支持聚合，若想要支持，需要修改mapping的key属性：fielddata//text直接做聚合，效率极低，不推荐！！！PUT /product/_mapping&#123; \"properties\": &#123; \"tags\": &#123; \"type\": \"text\", \"fielddata\": true &#125; &#125;&#125; 123456789101112131415161718192021//价格大于1999的每个tag产品的数量GET /product/_search&#123; \"query\": &#123; \"bool\": &#123; \"filter\": [ &#123; \"range\": &#123;\"price\": &#123;\"gt\": 1999&#125;&#125; &#125; ] &#125; &#125;, \"aggs\": &#123; \"tag_agg_group\": &#123; \"terms\": &#123; \"field\": \"tags.keyword\" &#125; &#125; &#125;, \"size\": 0&#125; 1234//平均值语法\"avg\": &#123; \"field\": \"your_avg_key\"&#125; 12345678910111213141516171819202122//价格大于1999的每个tag产品的平均价格GET /product/_search&#123; \"aggs\": &#123; \"tag_agg_avg\": &#123; \"terms\": &#123; \"field\": \"tags.keyword\", \"order\": &#123; \"avg_price\": \"desc\" &#125; &#125;, \"aggs\": &#123; \"avg_price\": &#123; \"avg\": &#123; \"field\": \"price\" &#125; &#125; &#125; &#125; &#125;, \"size\":0&#125; 1234567891011121314151617181920212223242526272829303132//按照千元机 1000以下 中端机[2000-3000) 高端机 [3000,∞）GET /product/_search&#123; \"aggs\": &#123; \"tag_agg_group\": &#123; \"range\": &#123; \"field\": \"price\", \"ranges\": [ &#123; \"from\": 100, \"to\": 1000 &#125;, &#123; \"from\": 1000, \"to\": 3000 &#125;, &#123; \"from\": 3000 &#125; ] &#125;, \"aggs\": &#123; \"price_agg\": &#123; \"avg\": &#123; \"field\": \"price\" &#125; &#125; &#125; &#125; &#125;, \"size\": 0&#125;","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"}]},{"title":"'Elasticsearch（一） 基本概念'","slug":"es-elasticsearch","date":"2020-12-09T04:00:00.000Z","updated":"2020-12-15T05:10:06.740Z","comments":true,"path":"2020/12/09/es-elasticsearch/","link":"","permalink":"https://midkuro.gitee.io/2020/12/09/es-elasticsearch/","excerpt":"","text":"Elasticsearch基本概念ES是基于Lucene分布式搜索服务，可以存储整个对象或文档，分布式的实时文件存储，每个字段都被索引并可被搜索，分布式的实时分析搜索引擎，可以扩展到上百台服务器，处理PB级结构化或非结构化数据。 与传统数据库的对比 索引（index）索引是ES的一个逻辑存储，对应关系型数据库中的库，ES可以把索引数据存放到服务器中，也可以sharding(分片)后存储到多台服务器上。每个索引有一个或多个分片，每个分片可以有多个副本。 类型（type）ES中，一个索引可以存储多个用于不同用途的对象，可以通过类型来区分索引中的不同对象，对应关系型数据库中表的概念。但是在ES6.0开始，类型的概念被废弃，ES7中将它完全删除。删除type的原因： 我们一直认为ES中的“index”类似于关系型数据库的“database”，而“type”相当于一个数据表。ES的开发者们认为这是一个糟糕的认识。例如：关系型数据库中两个数据表示是独立的，即使他们里面有相同名称的列也不影响使用，但ES中不是这样的。 我们都知道elasticsearch是基于Lucene开发的搜索引擎，而ES中不同type下名称相同的filed最终在Lucene中的处理方式是一样的。举个例子，两个不同type下的两个user_name，在ES同一个索引下其实被认为是同一个filed，你必须在两个不同的type中定义相同的filed映射。否则，不同type中的相同字段名称就会在处理中出现冲突的情况，导致Lucene处理效率下降。 去掉type能够使数据存储在独立的index中，这样即使有相同的字段名称也不会出现冲突，就像ElasticSearch出现的第一句话一样“你知道的，为了搜索····”，去掉type就是为了提高ES处理数据的效率。 除此之外，在同一个索引的不同type下存储字段数不一样的实体会导致存储中出现稀疏数据，影响Lucene压缩文档的能力，导致ES查询效率的降低。 文档（document）存储在ES中的主要实体叫文档，可以理解为关系型数据库中表的一行数据记录。每个文档由多个字段（field）组成。区别于关系型数据库的是，ES是一个非结构化的数据库，每个文档可以有不同的字段，并且有一个唯一标识。 映射（mapping）mapping是对索引库中的索引字段及其数据类型进行定义，类似于关系型数据库中的表结构。ES默认动态创建索引和索引类型的mapping，这就像是关系型数据中的，无需定义表机构，更不用指定字段的数据类型。当然也可以手动指定mapping类型。 ES核心概念分片（shard）如果我们的索引数据量很大，超过硬件存放单个文件的限制，就会影响查询请求的速度，Es引入了分片技术。一个分片本身就是一个完成的搜索引擎，文档存储在分片中，而分片会被分配到集群中的各个节点中，随着集群的扩大和缩小，ES会自动的将分片在节点之间进行迁移，以保证集群能保持一种平衡。分片有以下特点： ES的一个索引可以包含多个分片（shard）； 每一个分片（shard）都是一个最小的工作单元，承载部分数据； 每个shard都是一个lucene实例，有完整的简历索引和处理请求的能力； 增减节点时，shard会自动在nodes中负载均衡； 一个文档只能完整的存放在一个shard上（主节点） 一个索引中含有shard的数量，默认值为5，在索引创建后这个值是不能被更改的。 优点：水平分割和扩展我们存放的内容索引；分发和并行跨碎片操作提高性能/吞吐量； 每一个shard关联的副本分片（replica shard）的数量，默认值为1，这个设置在任何时候都可以修改。 Pshard和对应的Rshard不能同时存在于同一个节点，所以最低的可用配置是两个节点，互为主备。 primary shard是可读可写的，而replica shard是只读的。 12345分片的好处：1.当某一台服务器宕机，可以保证其他数据的完整性（非最优方案）2.横向扩容：当数据量增大时，只需要添加一个新的结点，然后创建新的索引，操作非常简单3.看似占用了更多的服务器资源，实际上replica shard带来了性能和集群吞吐量的提升，这点和横向扩容是相同的。不同的是，横向扩容是可以承载更多的数据，而replica shard是单纯的增加数据的副本，带来的是性能和高可用。 副本（replica）副本（replica shard）就是shard的冗余备份，它的主要作用： 冗余备份，防止数据丢失； shard异常时负责容错和负载均衡； ES的特性分布式、高性能、高可用、可伸缩、易维护、速度快、弹性、灵活、操作简单、多语言客户端、X-Pack、hadoop/spark强强联手、开箱即用。 分布式：横向扩展非常灵活 全文检索：基于lucene的强大的全文检索能力； 近实时搜索和分析：数据进入ES，可达到近实时搜索，还可进行聚合分析 高可用：容错机制，自动发现新的或失败的节点，重组和重新平衡数据 模式自由：ES的动态mapping机制可以自动检测数据的结构和类型，创建索引并使数据可搜索。 RESTful API：JSON + HTTP 应用领域： 123451.百度（全文检索、高亮、搜索推荐）2.各大网站的用户行为日志（用户点击、浏览、收藏、评论）3.BI（Business Intelligence商业智能），数据分析：数据挖掘统计。4.Github：代码托管平台，几千亿行代码5.ELK：Elasticsearch（数据存储）、Logstash（日志采集）、Kibana（可视化） 优点12345671.面向开发者友好，屏蔽了Lucene的复杂特性，集群自动发现（cluster discovery）2.自动维护数据在多个节点上的建立3.会帮我做搜索请求的负载均衡4.自动维护冗余副本，保证了部分节点宕机的情况下仍然不会有任何数据丢失5.ES基于Lucene提供了很多高级功能：复合查询、聚合分析、基于地理位置等。6.对于大公司，可以构建几百台服务器的大型分布式集群，处理PB级别数据；对于小公司，开箱即用，门槛低上手简单。7.相遇传统数据库，提供了全文检索，同义词处理（美丽的cls&gt;漂亮的cls），相关度排名。聚合分析以及海量数据的近实时（NTR）处理，这些传统数据库完全做不到。 倒排索引倒排索引（Inverted Index）也叫反向索引，有反向索引必有正向索引。通俗地来讲，正向索引是通过key找value，反向索引则是通过value找key。 1234567数据结构：1、包含这个关键词的document list2、关键词在每个doc中出现的次数 TF term frequency3、关键词在整个索引中出现的次数 IDF inverse doc frequency4、关键词在当前doc中出现的次数5、每个doc的长度，越长相关度越低6、包含这个关键词的所有doc的平均长度 Term（单词）：一段文本经过分析器分析以后就会输出一串单词，这一个一个的就叫做Term（直译为：单词） Term Dictionary（单词字典）：顾名思义，它里面维护的是Term，可以理解为Term的集合 Term Index（单词索引）：为了更快的找到某个单词，我们为单词建立索引 Posting List（倒排列表）：倒排列表记录了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。（PS：实际的倒排列表中并不只是存了文档ID这么简单，还有一些其它的信息，比如：词频（Term出现的次数）、偏移量（offset）等，可以想象成是Python中的元组，或者Java中的对象） （PS：如果类比现代汉语词典的话，那么Term就相当于词语，Term Dictionary相当于汉语词典本身，Term Index相当于词典的目录索引） 每个文档都有一个ID，如果插入的时候没有指定的话，Elasticsearch会自动生成一个。 高可用ES在分配单个索引的分片时会将每个分片尽可能分配到更多的节点上。但是，实际情况取决于集群拥有的分片和索引的数量以及它们的大小，不一定总是能均匀地分布。 ES不允许Primary和它的Replica放在同一个节点中，并且同一个节点不接受完全相同的两个Replica 同一个节点允许多个索引的分片同时存在。 容错机制在局部出错异常的情况下，保证服务正常运行并且有自行恢复能力。 Master节点会尝试重启故障机，故障机启动后将作为Slave节点 数据同步，Master会将宕机期间丢失的数据增量同步到重启机器对应的分片上去。 主节点的Shard分片和副本shard分片不能同时存在于同一个节点，横向扩容新节点时，ES会自动进行分片重新均衡。 如何提高ES分布式系统的可用性以及性能最大化？ （1）每台节点的Shard数量越少，每个shard分配的CPU、内存和IO资源越多，单个Shard的性能越好，当一台机器一个Shard时，单个Shard性能最好。 （2）稳定的Master节点对于群集健康非常重要！理论上讲，应该尽可能的减轻Master节点的压力，分片数量越多，Master节点维护管理shard的任务越重，并且节点可能就要承担更多的数据转发任务，可增加“仅协调”节点来缓解Master节点和Data节点的压力，但是在集群中添加过多的仅协调节点会增加整个集群的负担，因为选择的主节点必须等待每个节点的集群状态更新确认。 （3）反过来说，如果相同资源分配相同的前提下，shard数量越少，单个shard的体积越大，查询性能越低，速度越慢，这个取舍应根据实际集群状况和结合应用场景等因素综合考虑。 （4）数据节点和Master节点一定要分开，集群规模越大，这样做的意义也就越大。 （5）数据节点处理与数据相关的操作，例如CRUD，搜索和聚合。这些操作是I / O，内存和CPU密集型的，所以他们需要更高配置的服务器以及更高的带宽，并且集群的性能冗余非常重要。 （6）由于仅投票节不参与Master竞选，所以和真正的Master节点相比，它需要的内存和CPU较少。但是，所有候选节点以及仅投票节点都可能是数据节点，所以他们都需要快速稳定低延迟的网络。 （7）高可用性（HA）群集至少需要三个主节点，其中至少两个不是仅投票节点。即使其中一个节点发生故障，这样的群集也将能够选举一个主节点。生产环境最好设置3台仅Master候选节点（node.master = true node.data = true） （8）为确保群集仍然可用，集群不能同时停止投票配置中的一半或更多节点。只要有一半以上的投票节点可用，群集仍可以正常工作。这意味着，如果存在三个或四个主节点合格的节点，则群集可以容忍其中一个节点不可用。如果有两个或更少的主机资格节点，则它们必须都保持可用 Master选举每个节点都会不定期的在集群做广播，ping所有节点 如果是偶数节点，Elasticsearch会将其中一个排除在投票配置之外，确保其大小为奇数。 安装elasticsearch下载地址 ES的启动需要JDK环境 12345678window版本启动： elasticsearch.batlinux版本启动： .&#x2F;elasticsearch -d 验证： http:&#x2F;&#x2F;localhost:9200&#x2F; KibanaKibana 是一个免费且开放的用户界面，能够让您对 Elasticsearch 数据进行可视化，可以进行各种操作，从跟踪查询负载，到理解请求如何流经整个应用，都能轻松完成。 下载地址 12345678LINUX启动：.&#x2F;kibanaWINDOW启动kibana.bat验证：http:&#x2F;&#x2F;localhost:5601 Head插件提供可视化的操作页面对ElasticSearch搜索引擎进行各种设置和数据检索功能，可以很直观的查看集群的健康状况，索引分配情况，还可以管理索引和集群以及提供方便快捷的搜索功能等等。 依赖于node 和 grunt管理工具 下载地址 1234安装grunt环境：npm install -g grunt-cli检查：grunt -version 解压下载的压缩包，打开glasticsearch-head-master文件夹，修改Gruntfile.js文件，添加hostname:&#39;*&#39; 在当前目录输入npm install， npm run start启动 验证：http://localhost:9100/ 安装成功 如果无法发现ES节点，尝试在ES配置文件中设置允许跨域 123http.cors.enabled: truehttp.cors.allow-origin: \"*\" ES节点 Master：主节点 每个集群都有且只有一个,尽量避免Master节点 Master节点的主要职责是和集群操作相关的内容，例如创建或删除索引、跟踪哪些节点是集群的一部分，并决定哪些分片分配给相关的节点。 voting：投票节点 需配置 Node.voting_only = true（仅投票节点，即使配置了node.master = true，也不会参选, 但是仍然可以作为数据节点） coordinating：协调节点 每一个节点都隐式的是一个协调节点，如果同时设置了node.master = false和node.data=false，那么此节点将成为仅协调节点，该节点只能处理路由请求，处理搜索，分发索引操作 Master-eligible node：候选节点 设置node.master = true即是候选节点，具备竞选master的资格。 Data node：数据节点 数据节点主要是存储索引数据的节点，主要对文档进行增删改查操作，聚合操作等。 Ingest node：Machine learning node：机器学习节点 1234567891011121.node.master = true node.data = true这是ES节点默认配置，既作为候选节点又作为数据节点，这样的节点一旦被选举为Master，压力是比较大的通常来说Master节点应该只承担较为轻量级的任务，比如创建删除索引，分片均衡等。2.node.master = true node.data = false只作为候选节点，不作为数据节点，可参选Master节点，当选后成为真正的Master节点。3.node.master = false node.data = false既不当候选节点，也不作为数据节点，那就是仅协调节点，负责负载均衡4.node.master=false node.data=true不作为候选节点，但是作为数据节点，这样的节点主要负责数据存储和查询服务。 健康检查123URL: _cat&#x2F;health _cluster&#x2F;health 健康值状态 ① Green：所有Primary和Replica均为active，集群健康 ② Yellow：至少一个Replica不可用，但是所有Primary均为active，数据仍然是可以保证完整性的。 ③ Red：至少有一个Primary为不可用状态，数据不完整，集群不可用。 集群配置elasticearch.yml配置 1234#配置文件配置相同的集群名称cluster.name: my-application#各个节点需要有不同的结点名称node.name: node-1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:#集群名字 同一个集群的节点要设置在同一个集群名称cluster.name: csdemo## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:#节点名字 同一集群的节点名称不能相同node.name: node-1## Add custom attributes to the node:#指定节点的部落属性，这是一个比集群更大的范围。#node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):# 数据存放目录#path.data: /path/to/data## Path to log files:##path.logs: /path/to/logs# ----------------------------------- Memory -----------------------------------## Lock the memory on startup:#锁定物理内存地址，防止elasticsearch内存被交换出去,也就是避免es使用swap交换分区bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.#当系统进行内存交换的时候，es的性能很差# Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#设置ip绑定network.host: 127.0.0.1## Set a custom port for HTTP:#自定义端口号http.port: 9202transport.tcp.port: 9302# 是否启用TCP保持活动状态，默认为truenetwork.tcp.keep_alive: true#是否启用tcp无延迟，true为启用tcp不延迟，默认为false启用tcp延迟network.tcp.no_delay: true#设置是否压缩tcp传输时的数据，默认为false，不压缩。transport.tcp.compress: true## For more information, consult the network module documentation.## --------------------------------- Discovery ----------------------------------#设置成主服务node.master: false# 时候进行数据存贮node.data: true#集群节点列表# Pass an initial list of hosts to perform discovery when this node is started:# The default list of hosts is [\"127.0.0.1\", \"[::1]\"]#当进行Master时，有哪些节点能参与竞选（node.master: true的节点）discovery.seed_hosts: [\"127.0.0.1:9301\", \"127.0.0.1:9302\", \"127.0.0.1:9303\"]## Bootstrap the cluster using an initial set of master-eligible nodes:#设置集群启动时竞选Master的节点列表cluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"] #每个节点在选中的主节点的检查之间等待的时间。默认为1秒cluster.fault_detection.leader_check.interval: 15s #设置主节点等待每个集群状态完全更新后发布到所有节点的时间，默认为30秒cluster.publish.timeout: 90s #集群内同时启动的数据任务个数，默认是2个#cluster.routing.allocation.cluster_concurrent_rebalance: 2##添加或删除节点及负载均衡时并发恢复的线程个数，默认4个#cluster.routing.allocation.node_concurrent_recoveries: 4 ## For more information, consult the discovery and cluster formation module documentation. # ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:#集群中的N个节点启动后,才允许进行数据恢复处理gateway.recover_after_nodes: 3 gateway.expected_nodes: 3#配置限制了单节点上可以开启的ES存储实例的个数node.max_local_storage_nodes: 3gateway.auto_import_dangling_indices: true ## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------## Require explicit names when deleting indices:#删除索引必须要索引名称action.destructive_requires_name: true#是否允许跨域http.cors.enabled: true#允许跨域访问 *代表所有http.cors.allow-origin: \"*\"#master 和 data 的四种组合#1.master=true &amp; data = true 生产环境不推荐使用#2.master=true &amp; data = false 生产环境推荐使用，master不进行数据存储#3.master=false &amp; data = true 备机存储数据#4.master = false &amp; data = false 充当协调节点，类似nginx#标记该节点具备竞争master的资格 node.master: true#该节点进行数据存储node.data: true#标记投票节点Node.voting_only = true 切记，如果拷贝了单点程序做集群节点，一定要把原有的data数据清除，否则多分Master节点数据会导致集群搭建失败。 CRUD1234#创建索引 index是索引名称PUT /index?pretty#案例PUT /product?pretty 12#查询所有索引GET _cat/indices?v 1234#删除索引 index是索引名称DELETE /index?pretty#案例DELETE /product?pretty 1234567891011121314//插入数据 /index/type/id 若无索引会自动创建, type被弱化，统一使用 \"_doc\" PUT /index/type/id&#123; \"key\" : \"value\"&#125;//案例：PUT /product/_doc/1&#123; \"name\" : \"xiaomi phone\", \"desc\" : \"shouji zhong de zhandouji\", \"price\" : 3999, \"tags\": [ \"xingjiabi\", \"fashao\", \"buka\" ]&#125; 123456789101112131415161718192021222324//更新数据---全量更新---再次执行插入数据即可PUT /product/_doc/1&#123; \"name\" : \"xiaomi phone\", \"desc\" : \"shouji zhong de zhandouji\", \"price\" : 13999, \"tags\": [ \"xingjiabi\", \"fashao\", \"buka\" ]&#125;//更新数据---增量更新PUT /index/type/id/_update&#123; \"doc\": &#123; \"key\" : \"value\" &#125;&#125;//增量更新案例PUT /product/_doc/1/_update&#123; \"doc\": &#123; \"price\" : 3999 &#125;&#125; 1234#删除数据DELETE /index/type/id#案例DELETE /product/_doc/1","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"}]},{"title":"' HTTPS 原理'","slug":"https-protocol","date":"2020-11-24T03:00:00.000Z","updated":"2020-11-29T13:20:48.874Z","comments":true,"path":"2020/11/24/https-protocol/","link":"","permalink":"https://midkuro.gitee.io/2020/11/24/https-protocol/","excerpt":"","text":"HTTPS 原理背景 无加密在无加密的情况下，默认是HTTP协议，浏览器向代理服务器发送了请求后，代理服务器能够拦截浏览器的请求，从而达到伪造请求发送给Server、伪造结果发送给浏览器的目的。 加密算法如果采用加密算法对浏览器发送的明文进行加密，将加密请求发送给Server，在这种情况下，是需要浏览器、Server服务器都拥有加密、解密算法逻辑，那么代理服务器可以通过解析浏览器网站，从中获得算法的加密、解逻辑，等同于说密文传输对代理服务器来说，依旧是透明的。 非对称加密算法 公钥加密私钥能解、私钥加密私钥能解、私钥加密公钥能解！公钥加密公钥不能解！！！ 浏览器向Server服务器发起请求公钥的请求，Server返回一个公钥，但是这个公钥被代理服务器拦截了，它伪造一个假的公钥返回给浏览器，浏览器对通过假公钥对请求数据进行加密，代理服务器拦截后，使用假私钥解密数据，然后伪造请求到Server服务器中，依旧是不安全的。 非对称算法最主要的问题是浏览器无法识别公钥的真假。 对称加密算法浏览器通过对数据进行对称加密，这个密钥如果是由浏览器随机生成的，再经过一种某种渠道传递给Server服务器，代理服务器如果无法获得这个密钥，那么加密的请求和结果代理服务器将无法进行识别。 那么最关键的问题在于如何将随机生成的密钥安全的传送给Server服务器呢？ 加密，将随机生成的密钥采用非对称算法加密传送给Server，假设浏览器拥有一个正确的Server返回的公钥，简称Server.公钥，通过非对称加密算法（Server公钥+密钥） 生成密文发送，就算代理服务器拦截到了Server公钥，它也无法解密这串密文，因为公钥无法解密公钥加密的数据。 那么第二个关键问题在于如何让浏览器拥有一个正确的Server返回的公钥呢？换句话问，Server如何正确得将公钥发送给浏览器而不被串改？ 先声明一个概念，只要让浏览器得到一个正确的Server.公钥，而不是一个伪造的假公钥，即使代理服务器拦截到Server.公钥也无任何意义，因为无法解密公钥加密的数据。 证书 引入一个第三方CA机构，通过非对称算法，利用Server.私钥生成Server.公钥，再将Server.公钥交付给CA机构进行加密，CA机构通过CA.私钥对Server.公钥加密，最后生成证书，下发到浏览器中。 合法的CA机构会和操作系统打交道，将CA公钥内置在操作系统中，浏览器获得证书后通过CA.公钥进行解密证书获得Server.公钥，这个步骤代理服务器没有CA.私钥，它没办法伪造一个不合格的证书。 也就是说，通过CA机构下发的合格证书，就能保证浏览器获得一个正确的Server.公钥。 HTTPS 证书生成以及自签名证书12345678910111213141516相关概念：#SSL/TLS：TLS(Transport Layer Security) 是 SSL(Secure Socket Layer) 的后续版本#查看系统已存证书certmgr.msc#CSR证书签名请求文件#CRT证书#key私钥 OPenSSL 自签名下载http://slproweb.com/products/Win32OpenSSL.html 证书中的信息 Country Name (2 letter code) [XX]:CN #请求签署人的信息 State or Province Name (full name) []: #请求签署人的省份名字 Locality Name (eg, city) [Default City]:# 请求签署人的城市名字 Organization Name (eg, company) [Default Company Ltd]:#请求签署人的公司名字 Organizational Unit Name (eg, section) []:#请求签署人的部门名字 Common Name (eg, your name or your server’s hostname) []:#这里一般填写请求人的的服务器域名， 服务器端证书1.生成私钥找到OpenSSL安装目录下的/bin目录中的OpenSSL.exe 执行命令 openssl genrsa -des3 -out c:/dev/server.key 生成私钥，需要提供一个至少4位，最多1023位的密码 2.由私钥创建待签名证书1openssl.exe req -new -key c:&#x2F;dev&#x2F;server.key -out c:&#x2F;dev&#x2F;pub.csr 需要依次输入国家，地区，城市，组织，组织单位，Common Name和Email。其中Common Name，可以写自己的名字或者域名，如果要支持https，Common Name应该与域名保持一致，否则会引起浏览器警告。 3.查看证书中的内容openssl.exe req -text -in c:/dev/pub.csr -noout 自建CA我们用的操作系统（windows, linux, unix ,android, ios等）都预置了很多信任的根证书，比如我的windows中就包含VeriSign的根证书，那么浏览器访问服务器比如支付宝www.alipay.com时，SSL协议握手时服务器就会把它的服务器证书发给用户浏览器，而这本服务器证书又是比如VeriSign颁发的，自然就验证通过了。 1.创建CA私钥openssl.exe genrsa -out c:/dev/myca.key 2048 2.生成CA待签名证书openssl.exe req -new -key c:/dev/myca.key -out c:/dev/myca.csr 3.生成CA根证书openssl.exe x509 -req -in c:/dev/myca.csr -extensions v3_ca -signkey c:/dev/myca.key -out myca.crt 4.对服务器证书签名openssl x509 -days 365 -req -in c:/dev/pub.csr -extensions v3_req -CAkey c:/dev/myca.key -CA c:/dev/myca.crt -CAcreateserial -out c:/dev/server.crt Nginx配置12345678server &#123; listen 443 ssl; server_name aa.abc.com; ssl_certificate /data/cert/server.crt; ssl_certificate_key /data/cert/server.key;&#125; 随后在系统中安装证书，并且申请免费签名 SS安装服务器端 123wget --no-check-certificate https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;teddysun&#x2F;shadowsocks_install&#x2F;master&#x2F;shadowsocksR.shchmod +x shadowsocksR.sh.&#x2F;shadowsocksR.sh 2&gt;&amp;1 | tee shadowsocksR.log 卸载 1.&#x2F;shadowsocksR.sh uninstall 运行状态 1&#x2F;etc&#x2F;init.d&#x2F;shadowsocks status","categories":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://midkuro.gitee.io/categories/HTTPS/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://midkuro.gitee.io/tags/HTTPS/"}]},{"title":"'Linux 虚拟服务器 LVS'","slug":"lvs-keepalived","date":"2020-11-23T03:00:00.000Z","updated":"2020-11-24T13:42:32.220Z","comments":true,"path":"2020/11/23/lvs-keepalived/","link":"","permalink":"https://midkuro.gitee.io/2020/11/23/lvs-keepalived/","excerpt":"","text":"Linux 虚拟服务器网络协议原理 12345cd /proc/$$/fdexec 8&lt;&gt; /dev/tcp/www.baidu.com/80echo -e 'GET / HTTP/1.0\\n' &gt;&amp; 8cat &lt;&amp; 8exec 8&lt;&amp;- 123[root@localhost /]# ping www.baidu.comPING www.a.shifen.com (14.215.177.39) 56(84) bytes of data.64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=54 time=6.07 ms 通过PING百度的网络，能够看到百度的IP地址：14.215.177.39，那么我们的路由器是如何找到这个请求该往哪里发呢？ 通过将百度的地址与路由表中的子网掩码（Genmask）进行按位与运算，计算出来的结果如果和目标地址（Destination）匹配，就会找到下一跳的路由地址（Gateway）。 最后匹配上的条目是 14.215.177.39 &amp; 0.0.0.0 = 0.0.0.0 -&gt; 192.168.8.2 通过计算得知，数据包想出局域网，最终它将会经过Gateway = 192.168.8.2 LVS 如Nginx，他是一个7层的反向代理服务器，它需要在中间层建立三次握手，效率会有损耗，而LVS是一个四层代理服务器，它将请求穿透到后台服务器。 D-NAT DR TUN 隐藏IP 1234567891011121314隐藏VIP方法：对外隐藏，对内可见 ：kernel parameter:目标mac地址为全F，交换机触发广播 /proc/sys/net/ipv4/conf/*IF*/arp_ignore: 定义接收到ARP请求时的响应级别； 0：只要本地配置的有相应地址，就给予响应； **1：仅在请求的目标(MAC)地址配置请求** 到达的接口上的时候，才给予响应；arp_announce：定义将自己地址向外通告时的通告级别； 0：将本地任何接口上的任何地址向外通告； 1：试图仅向目标网络通告与其网络匹配的地址； **2：仅向与本地接口上地址匹配的网络进行通告；** 使用1234567891011121314四种静态： rr:轮循wrr:dh: sh:动态调度方法：lc: 最少连接wlc: 加权最少连接sed: 最短期望延迟nq: never queueLBLC: 基于本地的最少连接DH: LBLCR: 基于本地的带复制功能的最少连接 LVS怎么知道每一台Server有多少连接呢？ 偷窥策略，每一个Client通过LVS发起TCP的三次握手，LVS最少能收到两次Client发送的ACK确认，这时候认为连接数+1，当TCP四次分手时收到FIN和ACK之后，认为连接数-1。 1234567891011121314ipvs内核模块yum install ipvsadm -y管理集群服务添加：-A -t|u|f service-address [-s scheduler]-t: TCP协议的集群 -u: UDP协议的集群service-address: IP:PORT-f: FWM: 防火墙标记 service-address: Mark Number修改：-E删除：-D -t|u|f service-addressipvsadm -A -t 192.168.9.100:80 -s rr 12345678910111213141516171819202122232425262728管理集群服务中的RS添加：-a -t|u|f service-address -r server-address [-g|i|m] [-w weight] -t|u|f service-address：事先定义好的某集群服务 -r server-address: 某RS的地址，在NAT模型中，可使用IP：PORT实现端口映射； [-g|i|m]: LVS类型 -g: DR -i: TUN -m: NAT [-w weight]: 定义服务器权重修改：-e删除：-d -t|u|f service-address -r server-address# ipvsadm -a -t 172.16.100.1:80 -r 192.168.10.8 –g# ipvsadm -a -t 172.16.100.1:80 -r 192.168.10.9 -g查看 -L|l -n: 数字格式显示主机地址和端口 --stats：统计数据 --rate: 速率 --timeout: 显示tcp、tcpfin和udp的会话超时时长 -:c 显示当前的ipvs连接状况删除所有集群服务 -C：清空ipvs规则保存规则 -S # ipvsadm -S &gt; /path/to/somefile载入此前的规则： -R# ipvsadm -R &lt; /path/form/somefile 12345678910111213141516171819202122232425262728293031323334353637383940414243LVS：node01: #创建对外提供的VIP地址 网卡eth0:8 ifconfig eth0:8 192.168.150.100/24node02~node03: 1)修改内核： echo 1 &gt; /proc/sys/net/ipv4/conf/eth0/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/eth0/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce 2）设置隐藏的vip： ifconfig lo:3 192.168.150.100 netmask 255.255.255.255 RealServer中的服务：node02~node03: #部署一个简单版本的webServer yum install httpd -y service httpd start vi /var/www/html/index.html from 192.168.150.1xLVS服务配置node01: yum install ipvsadm # —A 设置他的负载均衡模式 ipvsadm -A -t 192.168.150.100:80 -s rr # -a 设置VIP的下一跳路由规则和权重 ipvsadm -a -t 192.168.150.100:80 -r 192.168.150.12 -g -w 1 ipvsadm -a -t 192.168.150.100:80 -r 192.168.150.13 -g -w 1 ipvsadm -ln验证： 浏览器访问 192.168.150.100 看到负载 疯狂F5 node01： netstat -natp 结论看不到socket连接 node02~node03: netstat -natp 结论看到很多的socket连接 node01: ipvsadm -lnc 查看偷窥记录本 TCP 00:57 FIN_WAIT 192.168.150.1:51587 192.168.150.100:80 192.168.150.12:80 FIN_WAIT： 连接过，偷窥了所有的包 SYN_RECV： 基本上lvs都记录了，证明lvs没事，一定是后边网络层出问题 Keepalived 通过配置主备Keepalived，当主机Master挂了后，Keepalived会通过IP漂移技术，将192.168.150.100漂移到node04结点备机BackUp机器上，确保了LVS的单点故障问题。 并且在LVS中配置了健康检查，校验Real Server的健康状态，确保故障时LVS能够及时得把他从负载均衡列表中移除。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970keepalived实验：主机： node01~node04node01: ipvsadm -C ifconfig eth0:8 down----------------------------node01,node04: yum install keepalived ipvsadm -y 配置： cd /etc/keepalived/ cp keepalived.conf keepalived.conf.bak vi keepalived.conf node01: vrrp：虚拟路由冗余协议！ vrrp_instance VI_1 &#123; state MASTER // node04 BACKUP interface eth0 virtual_router_id 51 priority 100 // node04 50 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.150.100/24 dev eth0 label eth0:8 #等同于LVS的：ifconfig eth0:8 192.168.150.100/24 &#125; &#125; #vip配置 virtual_server 192.168.150.100 80 &#123; delay_loop 6 #轮训 lb_algo rr #模式 lb_kind DR nat_mask 255.255.255.0 #在多少秒内发送同一台RealServer persistence_timeout 0 protocol TCP real_server 192.168.150.12 80 &#123; weight 1 HTTP_GET &#123; url &#123; #健康检查URL path / status_code 200 &#125; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 &#125; &#125; real_server 192.168.150.13 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 &#125; &#125; scp ./keepalived.conf root@node04:`pwd` 1234567891011121314#node1、node4 启动keepAlivedservice keepalived start验证： #查看LVS的负载均衡配置 ipvsadm -ln #查看主机和备机的偷窥记事本请求情况 ipvsadm -lnc #node01 主动挂掉网卡,再查看node4的网卡配置，IP是否漂移，偷窥记事本是否有请求 ifconfig eth0 down #node01 启动网卡，查看IP和请求是否漂移回主机 ifconfig eth0 up 如果Nnode01的KeepAlived挂了，就会导致导致Node04的KeepAlived无法接收到Node01的健康通知，就会抢过它的IP，这时候就会导致有两台机器有两个对外暴露的相同IP，会导致客户端发送的数据造成混乱。 通过ZooKeeper集群进行保证KeepAlived的存活。","categories":[{"name":"LVS","slug":"LVS","permalink":"https://midkuro.gitee.io/categories/LVS/"}],"tags":[{"name":"LVS","slug":"LVS","permalink":"https://midkuro.gitee.io/tags/LVS/"}]},{"title":"'SSM 框架整合'","slug":"ssm-frame","date":"2020-11-10T14:33:00.000Z","updated":"2020-11-12T04:23:24.718Z","comments":true,"path":"2020/11/10/ssm-frame/","link":"","permalink":"https://midkuro.gitee.io/2020/11/10/ssm-frame/","excerpt":"","text":"SSM 框架整合配置整合1234567891011121314步骤： 1.引入各个框架相关依赖 2.创建web.xml配置文件 2.1 添加spring相关配置 2.2 添加springMvc相关配置 3.创建springmvc.xml配置文件 3.1 定义扫描的包 include:@Controller 3.2 定义静态资源、动态资源、视图解析器 4.创建spring.xml配置文件 4.1 定义扫描的包 exclude:@Controller 4.2 配置数据源 DruidSource 4.3 配置事务管理器、开启事务控制 5 添加并编写映射文件Mapper配置 6.spring.xml中整合mybatis、定义mybatis扫描器 pom.xmlspring依赖12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/cglib/cglib --&gt;&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver --&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/aopalliance/aopalliance --&gt;&lt;dependency&gt; &lt;groupId&gt;aopalliance&lt;/groupId&gt; &lt;artifactId&gt;aopalliance&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-aspects --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt;&lt;/dependency&gt; springmvc依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;!-- 移除了和 spring 重叠的 spring-context --&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-web --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-webmvc --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-core --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.10.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-databind --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.10.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-annotations --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.10.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/commons-io/commons-io --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/commons-fileupload/commons-fileupload --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/javax.servlet/jstl --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; mybatis依赖12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.19&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/log4j/log4j --&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt; &lt;artifactId&gt;mybatis-ehcache&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-api --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;2.0.0-alpha1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-log4j12 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;2.0.0-alpha1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; spring和mybatis整合依赖123456&lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis-spring --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.4&lt;/version&gt;&lt;/dependency&gt; web.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"&gt; &lt;!--spring相关配置--&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!--springMVC相关配置--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--配置编码过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncoding&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--配置REST过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;rest&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;rest&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; springmvc.xml123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;!--定义扫描的包 use-default-filters:默认的扫描会包含@Controller,@Service,@Component,@Repository,我们再进行配置的时候需要扫描这么多组件 只扫描@Controller这个注解 --&gt; &lt;context:component-scan base-package=\"com.kuro\" use-default-filters=\"false\"&gt; &lt;context:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; &lt;!--请求静态资源--&gt; &lt;mvc:default-servlet-handler&gt;&lt;/mvc:default-servlet-handler&gt; &lt;!--请求动态资源--&gt; &lt;mvc:annotation-driven&gt;&lt;/mvc:annotation-driven&gt; &lt;!--设置视图管理器--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/page/\"&gt;&lt;/property&gt; &lt;property name=\"suffix\" value=\".jsp\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; spring.xml1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--定义扫描的包--&gt; &lt;context:component-scan base-package=\"com.kuro\" use-default-filters=\"false\"&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; &lt;!--定义外部配置文件--&gt; &lt;context:property-placeholder location=\"classpath:db.properties\"&gt;&lt;/context:property-placeholder&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;driver&#125;\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"$&#123;url&#125;\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"$&#123;username&#125;\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置事务管理器--&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--开启事务控制--&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\"&gt;&lt;/tx:annotation-driven&gt; &lt;!--整合mybatis 用以替代 mybatis-config.xml 相关配置 --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;property name=\"mapperLocations\" value=\"classpath:com/kuro/dao/*.xml\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--定义mybatis扫描器，扫描映射文件--&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.kuro.dao\"&gt;&lt;/property&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;/beans&gt; db.properties1234driver=com.mysql.cj.jdbc.Driverurl=jdbc:mysql://192.168.85.111:3306/demo?serverTimezone=UTCusername=rootpassword=123456 EmpDao.xml12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.kuro.dao.EmpDao\"&gt; &lt;select id=\"findEmpByEmpno\" resultType=\"com.kuro.bean.Emp\"&gt; select * from emp where empno = #&#123;empno&#125; &lt;/select&gt;&lt;/mapper&gt; Emp.java12345public class Emp &#123; private Integer empno; private String ename; private String job;&#125; EmpDao.java123public interface EmpDao &#123; public Emp findEmpByEmpno(Integer empno);&#125; SSMController.java123456789101112131415@Controllerpublic class SSMController &#123; @Autowired EmpDao empDao; @RequestMapping(\"/test\") public String test(Model model)&#123; System.out.println(\"test\"); Emp emp = empDao.selectEmpByEmpno(7369); System.out.println(emp); model.addAttribute(\"emp\",emp.getEname()); return \"success\"; &#125;&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/categories/Spring/"},{"name":"Mybatis","slug":"Spring/Mybatis","permalink":"https://midkuro.gitee.io/categories/Spring/Mybatis/"},{"name":"SpringMVC","slug":"Spring/Mybatis/SpringMVC","permalink":"https://midkuro.gitee.io/categories/Spring/Mybatis/SpringMVC/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"}]},{"title":"'Mybatis plus的使用'","slug":"mybatis-plus","date":"2020-11-09T14:33:00.000Z","updated":"2020-11-12T01:55:33.476Z","comments":true,"path":"2020/11/09/mybatis-plus/","link":"","permalink":"https://midkuro.gitee.io/2020/11/09/mybatis-plus/","excerpt":"","text":"Mybatis Plus的使用环境搭建pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/log4j/log4j --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.19&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-orm --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; spring.xml 在这里注入的sqlSessionFactoryBean需要使用Mybatis Plus的com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx https://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--引入外部配置文件--&gt; &lt;context:property-placeholder location=\"classpath:db.properties\"&gt;&lt;/context:property-placeholder&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;driverClassName&#125;\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"$&#123;url&#125;\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"$&#123;username&#125;\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--添加事务管理器--&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--添加事务注解配置--&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\"/&gt; &lt;!--整合spring和mybatis--&gt; &lt;bean id=\"sqlSessionFactoryBean\" class=\"com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"&gt;&lt;/property&gt; &lt;!-- &lt;property name=\"mapperLocations\" value=\"classpath:com/mashibing/dao/*.xml\"&gt;&lt;/property&gt;--&gt; &lt;/bean&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.mashibing.dao\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; EmpDao.java 通过继承Mybatis Plus提供的BaseMapper来实现接口映射，默认会提供多种API接口调用，不需要再编写EmpDao.xml 123public interface EmpDao extends BaseMapper&lt;Emp&gt; &#123; public List&lt;Emp&gt; selectEmpByCondition();&#125; Test.java12345678public class Test &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"spring.xml\"); @Test public void test02()&#123; EmpDao empDao = context.getBean(\"empDao\", EmpDao.class); &#125;&#125; 增删改查插入操作12345678910111213/** 在mybatis-plus中，插入数据的sql语句会伴随你插入的对象的属性值数量进行更改，不需要传参所有列，比较灵活*/@Testpublic void testInsert()&#123; Emp emp = new Emp(); emp.seteName(\"zhangsan\"); emp.setJob(\"Teacher\"); emp.setDeptno(10); int insert = empDao.insert(emp); System.out.println(insert);&#125; ​ 当运行上述代码的时候，发现报错了，原因在于你写的实体类的名称跟表的名称不匹配，因此在实现的是需要添加@TableName注解，指定具体的表的名称。 运行通过之后，大家会发现结果能够正常的进行插入，但是在控制台会打印一个警告信息，说没有@TableId的注解，原因就在于定义实体类的时候并没有声明其中的主键是哪个列，以及使用什么样的主键生成策略，因此，可以在类的属性上添加如下注解，来消除此警告。 12345678910@TableName(\"tbl_emp\")public class Emp &#123; /** * 在 mybatis-plus2.x版本的时候，如果设置了表自增，那么id必须制定为auto类型，否则插入不成功，3.x不存在此问题 */ @TableId(value = \"empno\",type = IdType.AUTO) private Integer empno; //省略其他属性&#125; MyBatis plus在插入操作的过程中，会动态调整SQL语句，根据输入的对象的字段的个数来动态的调整SQL语句插入的字段。 修改操作123456Emp emp = new Emp();emp.setEmpno(6);emp.seteName(\"lisi\");emp.setJob(\"Teacher\");emp.setMgr(100);int insert = empDao.updateById(emp); 删除操作123456789101112131415//根据id删除数据 int i = empDao.deleteById(6);//根据id集合批量删除int i = empDao.deleteBatchIds(Arrays.asList(1, 2, 3));//根据map类型的数据进行删除，但是要注意，key为列的名称。value是具体的值Map&lt;String,Object&gt; map = new HashMap&lt;String,Object&gt;();map.put(\"empno\",4);int i = empDao.deleteByMap(map);//使用呢QueryWapper进行删除QueryWrapper wrapper = new QueryWrapper();wrapper.eq(\"empno\",7);int delete = empDao.delete(wrapper); 查询操作1234567891011121314151617181920212223242526/* 查询单条语句，需要添加对应的查询条件，封装在QueryWrapper中 * 注意使用selectOne的时候有且仅能返回一条语句，如果是多条结果的话，会报错 */QueryWrapper wrapper = new QueryWrapper();wrapper.eq(\"empno\",\"8\");wrapper.eq(\"e_name\",\"zhangsan\");Emp emp = empdao.selectOne(wrapper);//查询某一个结果集的数据List&lt;Emp&gt; list = empdao.selectList(null);System.out.println(list);//根据id的集合返回数据List&lt;Emp&gt; list = empdao.selectBatchIds(Arrays.asList(8, 9));System.out.println(list);//根据id进行查询Emp emp = empdao.selectById(8);//查询结果集合封装成一个list里面的对象是mapList&lt;Map&lt;String, Object&gt;&gt; maps = empdao.selectMaps(null);//返回满足查询条件的所有行总数Integer integer = empdao.selectCount(null);System.out.println(integer); 分页操作1234567891011&lt;!--分页查询,需要在mybatis-config.xml的配置文件中添加--&gt;&lt;plugins&gt; &lt;plugin interceptor=\"com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor\"&gt;&lt;/plugin&gt;&lt;/plugins&gt;&lt;!--或者在spring.xml中整合的mybatis配置中添加--&gt;&lt;property name=\"plugins\"&gt; &lt;array&gt; &lt;bean class=\"com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor\"&gt;&lt;/bean&gt; &lt;/array&gt;&lt;/property&gt; 12Page&lt;Emp&gt; empPage = empDao.selectPage(new Page&lt;&gt;(2, 5), null);List&lt;Emp&gt; records = empPage.getRecords(); 相关配置官网 在此链接中包含了非常多的配置项，用户可以按照自己的需求添加需要的配置，配置方式如下： spring.xml 123456789101112131415161718&lt;bean id=\"sqlSessionFactory\" class=\"com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean\"&gt; &lt;property name=\"configuration\" ref=\"configuration\"/&gt; &lt;!-- 非必须 --&gt; &lt;property name=\"globalConfig\" ref=\"globalConfig\"/&gt; &lt;!-- 非必须 --&gt; ......&lt;/bean&gt;&lt;bean id=\"configuration\" class=\"com.baomidou.mybatisplus.core.MybatisConfiguration\"&gt; ......&lt;/bean&gt;&lt;bean id=\"globalConfig\" class=\"com.baomidou.mybatisplus.core.config.GlobalConfig\"&gt; &lt;property name=\"dbConfig\" ref=\"dbConfig\"/&gt; &lt;!-- 非必须 --&gt; ......&lt;/bean&gt;&lt;bean id=\"dbConfig\" class=\"com.baomidou.mybatisplus.core.config.GlobalConfig.DbConfig\"&gt; ......&lt;/bean&gt; ​ 通过这个配置文件的配置，大家可以进行回想上述问题的出现，mybatis-plus是如何解决这个问题的呢？ ​ 在mybatis-plus中会引入写默认的配置，这个选项的默认配置为true，因此可以完成对应的实现。 我们可以通过如下配置来禁用驼峰标识的操作，如下所示： 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;context:property-placeholder location=\"classpath:db.properties\"&gt;&lt;/context:property-placeholder&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;driverClassname&#125;\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"$&#123;url&#125;\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"$&#123;username&#125;\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;tx:annotation-driven transaction-manager=\"transactionManager\"&gt;&lt;/tx:annotation-driven&gt; &lt;bean id=\"sqlSessionFactoryBean\" class=\"com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean\"&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"&gt;&lt;/property&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt; &lt;property name=\"typeAliasesPackage\" value=\"com.mashibing.bean\"&gt;&lt;/property&gt; &lt;property name=\"globalConfig\" ref=\"globalConfig\"&gt;&lt;/property&gt; &lt;property name=\"configuration\" ref=\"configuration\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.mashibing.dao\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"configuration\" class=\"com.baomidou.mybatisplus.core.MybatisConfiguration\"&gt; &lt;property name=\"mapUnderscoreToCamelCase\" value=\"false\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"globalConfig\" class=\"com.baomidou.mybatisplus.core.config.GlobalConfig\"&gt; &lt;property name=\"dbConfig\" ref=\"dbConfig\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"dbConfig\" class=\"com.baomidou.mybatisplus.core.config.GlobalConfig.DbConfig\"&gt; &lt;/bean&gt;&lt;/beans&gt; 1、当添加上述配置之后，大家发现运行过程中报错， ​ Property ‘configuration’ and ‘configLocation’ can not specified with together ​ 表示这两个标签无法同时使用，因此我们可以选择将configLocation给禁用掉，就是不使用mybatis的配置，此时就能够正常使用了，但是放置属性的时候又报错了，原因就在于我们把驼峰标识给禁用了，重新开启即可。除此之外，我们还可以在属性的上面添加@TableField属性 12@TableField(value = \"e_name\")private String eName; 2、此时发现日志功能又无法使用了，只需要添加如下配置即可 1234&lt;bean id=\"configuration\" class=\"com.baomidou.mybatisplus.core.MybatisConfiguration\"&gt; &lt;property name=\"mapUnderscoreToCamelCase\" value=\"true\"&gt;&lt;/property&gt; &lt;property name=\"logImpl\" value=\"org.apache.ibatis.logging.log4j.Log4jImpl\"&gt;&lt;/property&gt;&lt;/bean&gt; 3、我们在刚刚插入数据的时候发现每个类可能都需要写主键生成策略，这是比较麻烦的，因此可以选择将主键配置策略设置到全局配置中。 1234&lt;bean id=\"dbConfig\" class=\"com.baomidou.mybatisplus.core.config.GlobalConfig.DbConfig\"&gt; &lt;property name=\"idType\" ref=\"idType\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;util:constant id=\"idType\" static-field=\"com.baomidou.mybatisplus.annotation.IdType.AUTO\"&gt;&lt;/util:constant&gt; 4、如果你的表的名字都具备相同的前缀，那么可以设置默认的前缀配置策略，此时的话可以将实体类上的@TableName标签省略不写 12345&lt;bean id=\"dbConfig\" class=\"com.baomidou.mybatisplus.core.config.GlobalConfig.DbConfig\"&gt; &lt;property name=\"idType\" ref=\"idType\"&gt;&lt;/property&gt; &lt;property name=\"tablePrefix\" value=\"tbl_\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;util:constant id=\"idType\" static-field=\"com.baomidou.mybatisplus.annotation.IdType.AUTO\"&gt;&lt;/util:constant&gt; 5、在mybatis-plus中如果需要获取插入的数据的主键的值，那么直接获取即可，原因就在于配置文件中指定了默认的属性为true 代码生成器12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;3.3.1.tmp&lt;/version&gt;&lt;/dependency&gt; 添加 模板引擎 依赖，MyBatis-Plus 支持 Velocity（默认）、Freemarker、Beetl，用户可以选择自己熟悉的模板引擎，如果都不满足您的要求，可以采用自定义模板引擎。 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.30&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.ibeetl&lt;/groupId&gt; &lt;artifactId&gt;beetl&lt;/artifactId&gt; &lt;version&gt;3.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import com.baomidou.mybatisplus.annotation.IdType;import com.baomidou.mybatisplus.generator.AutoGenerator;import com.baomidou.mybatisplus.generator.config.DataSourceConfig;import com.baomidou.mybatisplus.generator.config.GlobalConfig;import com.baomidou.mybatisplus.generator.config.PackageConfig;import com.baomidou.mybatisplus.generator.config.StrategyConfig;import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy;import org.junit.Test;public class MyTest &#123; @Test public void testGenerator()&#123; //此处默认有两个对应的实现类，大家不要导错包 GlobalConfig globalConfig = new GlobalConfig(); //设置全局的配置 globalConfig.setActiveRecord(true)//是否支持AR模式 .setAuthor(\"lian\")//设置作者 .setOutputDir(\"e:\\\\self_project\\\\mybatisplus_generatorcode\\\\src\\\\main\\\\java\")//设置生成路径 .setFileOverride(true)//设置文件覆盖 .setIdType(IdType.AUTO) //设置主键生成策略 .setServiceName(\"%sService\")//设置生成的serivce接口的名字 .setBaseResultMap(true) //设置基本的结果集映射 .setBaseColumnList(true);//设置基本的列集合 //设置数据源的配置 DataSourceConfig dataSourceConfig = new DataSourceConfig(); dataSourceConfig.setDriverName(\"com.mysql.cj.jdbc.Driver\") .setUrl(\"jdbc:mysql://192.168.85.111:3306/mp?serverTimezone=UTC\") .setUsername(\"root\").setPassword(\"123456\"); // 进行策略配置 StrategyConfig strategyConfig = new StrategyConfig(); strategyConfig.setCapitalMode(true)//设置全局大写命名 .setNaming(NamingStrategy.underline_to_camel)//数据库表映射到实体的命名策略 .setTablePrefix(\"tbl_\")//设置表名前缀 .setInclude(\"tbl_emp\");//生成的表 // 进行包名的策略配置 PackageConfig packageConfig = new PackageConfig(); packageConfig.setParent(\"com.mashibing\") .setMapper(\"mapper\") .setService(\"service\") .setController(\"controller\") .setEntity(\"bean\") .setXml(\"mapper\"); //整合配置 AutoGenerator autoGenerator = new AutoGenerator(); autoGenerator.setGlobalConfig(globalConfig).setDataSource(dataSourceConfig).setStrategy(strategyConfig) .setPackageInfo(packageConfig); autoGenerator.execute(); &#125;&#125; 乐观锁插件当要更新一条记录的时候，希望这条记录没有被别人更新，通过比列中的版本字段来判断是否更新，需要对该字段添加@Version注解 取出记录时，获取当前version，更新时，带上这个version，执行更新时， set version = newVersion where version = oldVersion，如果version不对，就更新失败 添加配置： 1&lt;bean class=\"com.baomidou.mybatisplus.extension.plugins.OptimisticLockerInterceptor\"&gt;&lt;/bean&gt; 12&lt;bean class=\"com.baomidou.mybatisplus.extension.plugins.IllegalSQLInterceptor\"&gt;&lt;/bean&gt; 123456789@Testpublic void testSqlIllegal()&#123; QueryWrapper&lt;Emp&gt; queryWrapper = new QueryWrapper&lt;&gt;(); queryWrapper.or(); List&lt;Emp&gt; list = empDao.selectList(queryWrapper); for (Emp emp : list) &#123; System.out.println(emp); &#125;&#125;","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://midkuro.gitee.io/categories/Mybatis/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://midkuro.gitee.io/tags/Mybatis/"}]},{"title":"'Mybatis SQL映射文件详解'","slug":"mybatis-mapper","date":"2020-11-09T14:32:00.000Z","updated":"2020-11-12T01:50:55.810Z","comments":true,"path":"2020/11/09/mybatis-mapper/","link":"","permalink":"https://midkuro.gitee.io/2020/11/09/mybatis-mapper/","excerpt":"","text":"Mybatis SQL映射文件详解12345678910**映射文件中，可以编写以下的顶级元素标签**：cache – 该命名空间的缓存配置。cache-ref – 引用其它命名空间的缓存配置。resultMap – 描述如何从数据库结果集中加载对象，是最复杂也是最强大的元素。parameterMap – 老式风格的参数映射。此元素已被废弃，并可能在将来被移除！请使用行内参数映射。文档中不会介绍此元素。sql – 可被其它语句引用的可重用语句块。insert – 映射插入语句。update – 映射更新语句。delete – 映射删除语句。select – 映射查询语句。 增删改1234567891011121314151617181920&lt;!--insert delete update分别用来标识不同类型的sql语句 id:用来标识跟dao接口中匹配的方法，必须与方法的名字一一对应上 flushCache：用来标识当前sql语句的结果是否进入二级缓存 statementType：用来选择执行sql语句的方式 statement：最基本的jdbc的操作，用来表示一个sql语句，不能防止sql注入 PREPARED: preareStatement：采用预编译的方式，能够防止sql注入，设置参数的时候需要该对象来进行设置 CALLABLE：调用存储过程 useGeneratedKeys：放完成插入操作的时候，可以将自增生成的主键值返回到具体的对象 keyProperty：指定返回的主键要赋值到哪个属性中 在编写sql语句的过程中，无论你是否配置了驼峰标识的识别setting，都需要在sql语句中写具体的表的属性名，不能写对象名称 --&gt;&lt;insert id=\"save\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt; insert into emp(empno,ename) values(#&#123;empno&#125;,#&#123;ename&#125;)&lt;/insert&gt;&lt;update id=\"update\"&gt; update emp set sal=#&#123;sal&#125; where empno = #&#123;empno&#125;&lt;/update&gt;&lt;delete id=\"delete\"&gt; delete from emp where empno = #&#123;empno&#125;&lt;/delete&gt; 123public Integer save(Emp emp);public Integer update(Emp emp);public Integer delete(Integer empno); select基本语法123456&lt;!--在mybatis中，会包含非常多的查询操作，因此查询的参数比较麻烦 id:用来设置当前sql语句匹配的dao接口的方法，必须要跟方法的名字统一 resultType:表示返回的结果的类型,一般使用的并不多，此类型只能返回单一的对象，而我们在查询的时候特别是关联查询的时候，需要自定义结果集 当返回的结果是一个集合的时候，并不需要resultmap，只需要使用resulttype指定集合中的元素类型即可 resultMap:当进行关联查询的时候，在返回结果的对象中还包含另一个对象的引用时，此时需要自定义结果集合，使用resultmap --&gt; 参数传递1234567891011&lt;!--参数的获取值的方式： 每次在向sql语句中设置结果值的时候，可以使用#&#123;&#125;，还可以使用$&#123;&#125;这样的方式，那么哪种比较好？ #&#123;&#125;：select * from emp where empno = ? $&#123;&#125;: select * from emp where empno = 7369 通过sql语句可以得出结论： #&#123;&#125;的处理方式是使用了参数预编译的方式，不会引起sql注入的问题 $&#123;&#125;的处理方式是直接拼接sql语句，得到对应的sql语句，会有sql注入的危险 因此，我们推荐大家使用#&#123;&#125;的方式 但是要注意，$&#123;&#125;也是有自己的使用场景的？ 当需要传入动态的表名，列名的时候就需要使用$&#123;&#125;,就是最直接的拼接字符串的行为 --&gt; 12345678910111213141516171819202122232425&lt;!--当查询语句中包含多个参数的时候，我们应该如何获取需要的参数 1、如果是单个参数， 基本数据类型：那么可以使用#&#123;&#125;随便获取 引用数据类型:使用#&#123;&#125;获取值的是必须要使用对象的属性名 2、如果是多个参数： 我们在获取参数值的时候，就不能简单的通过#&#123;&#125;来获取了,只能通过arg0,arg1,param1,param2...这样的方式来获取参数的值 原因在于，mybatis在传入多个参数的时候，会讲这些参数的结果封装到map结构中，在map中key值就是(arg0,arg1,...) (param1,param2...),这种方式非常不友好，没有办法根据属性名来获取具体的参数值 如果想要使用参数的话，可以进行如下的设置： public List&lt;Emp&gt; selectEmpByEmpnoAndSal2(@Param(\"empno\") Integer empno, @Param(\"sal\") Double sal); 这样的方式其实是根据@Param来进行参数的获取 3、自定义map结构 --&gt;&lt;select id=\"selectEmpByEmpnoAndSal\" resultType=\"com.kuro.bean.Emp\"&gt; select * from emp where empno = #&#123;emono&#125;&lt;/select&gt;&lt;select id=\"selectEmpByEmpnoAndSal2\" resultType=\"com.kuro.bean.Emp\"&gt; select * from emp where empno = #&#123;empno&#125; and sal &gt;#&#123;sal&#125;&lt;/select&gt;&lt;select id=\"selectEmpByEmpnoAndSal3\" resultType=\"com.kuro.bean.Emp\"&gt; select * from emp where empno = #&#123;empno&#125; and sal &gt;#&#123;sal&#125;&lt;/select&gt; 123public List&lt;Emp&gt; selectEmpByEmpnoAndSal(Emp emp);public List&lt;Emp&gt; selectEmpByEmpnoAndSal2(@Param(\"empno\") Integer empno, @Param(\"sal\") Double sal);public List&lt;Emp&gt; selectEmpByEmpnoAndSal3(Map&lt;String,Object&gt; map); 返回集合1234567891011121314&lt;!--当返回值的结果是集合的时候，返回值的类型依然写的是集合中具体的类型--&gt;&lt;select id=\"selectAll\" resultType=\"Emp\"&gt; select * from emp&lt;/select&gt;&lt;!--当需要返回的结果是一个map的集合的时候，同时map中包含多个对象，那么此时必须要在dao的方法上添加@MapKey注解，来标识到底是哪一个属性值作为key--&gt;&lt;select id=\"selectAll2\" resultType=\"Emp\"&gt; select * from emp&lt;/select&gt;&lt;!--当返回值是map结构的时候，会把查询结构的字段值作为key，结果作为value--&gt;&lt;select id=\"selectEmpByEmpnoReturnMap\" resultType=\"map\"&gt; select * from emp where empno = #&#123;empno&#125;&lt;/select&gt; 1234public List&lt;Emp&gt; selectAll();@MapKey(\"ename\")public Map&lt;String,Emp&gt; selectAll2();public Map&lt;Object,Object&gt; selectEmpByEmpnoReturnMap(Integer empno); 12345678910111213141516171819202122232425262728&lt;!--在使用mybatis的时候，有些情况下需要我们封装结果集，一般情况下mybatis会帮我们自动封装（字段名跟属性值必须一一对应），但是如果字段的值和类中的值不匹配的时候，怎么处理？ 1、可以在sql语句中添加别名字段，来保证赋值成功，但是太麻烦了，而且不可重用 2、resultMap：--&gt;&lt;mapper namespace=\"com.kuro.dao.DogDao\"&gt; &lt;!--自定义结果集 id:表示当前结果集的唯一标识 type:表示当前结果集的类型 --&gt; &lt;resultMap id=\"myDog\" type=\"com.kuro.bean.Dog\"&gt; &lt;!-- id:表示指定对应的主键 property:实体类中对应的属性值 column：表中字段的名称 --&gt; &lt;id property=\"id\" column=\"id\"&gt;&lt;/id&gt; &lt;!--除主键外的其他字段映射--&gt; &lt;result property=\"name\" column=\"dname\"&gt;&lt;/result&gt; &lt;result property=\"age\" column=\"dage\"&gt;&lt;/result&gt; &lt;result property=\"gender\" column=\"dgender\"&gt;&lt;/result&gt; &lt;/resultMap&gt; &lt;select id=\"selectDogById\" resultMap=\"myDog\"&gt; select * from dog where id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 联合查询123456789101112131415161718192021222324252627&lt;!--将每一个属性值都映射成对象中的数据，如果有实体类对象，就写成对象.属性的方式--&gt;&lt;!-- &lt;resultMap id=\"myEmp\" type=\"com.kuro.bean.Emp\"&gt;--&gt;&lt;!-- &lt;id column=\"empno\" property=\"empno\"&gt;&lt;/id&gt;--&gt;&lt;!-- &lt;result column=\"ename\" property=\"ename\"&gt;&lt;/result&gt;--&gt;&lt;!-- &lt;result column=\"job\" property=\"job\"&gt;&lt;/result&gt;--&gt;&lt;!-- &lt;result column=\"mgr\" property=\"mgr\"&gt;&lt;/result&gt;--&gt;&lt;!-- &lt;result column=\"hiredate\" property=\"hiredate\"&gt;&lt;/result&gt;--&gt;&lt;!-- &lt;result column=\"sal\" property=\"sal\"&gt;&lt;/result&gt;--&gt;&lt;!-- &lt;result column=\"comm\" property=\"comm\"&gt;&lt;/result&gt;--&gt;&lt;!-- &lt;result column=\"deptno\" property=\"dept.deptno\"&gt;&lt;/result&gt;--&gt;&lt;!-- &lt;result column=\"dname\" property=\"dept.dname\"&gt;&lt;/result&gt;--&gt;&lt;!-- &lt;result column=\"loc\" property=\"dept.loc\"&gt;&lt;/result&gt;--&gt;&lt;!-- &lt;/resultMap&gt;--&gt;&lt;!--使用第二种方式--&gt;&lt;resultMap id=\"myEmp\" type=\"com.kuro.bean.Emp\"&gt; &lt;id column=\"empno\" property=\"empno\"&gt;&lt;/id&gt; &lt;!--数据是一对多的情况时，使用 association --&gt; &lt;association property=\"dept\" javaType=\"com.kuro.bean.Dept\"&gt; &lt;id property=\"deptno\" column=\"deptno\"&gt;&lt;/id&gt; &lt;result property=\"dname\" column=\"dname\"&gt;&lt;/result&gt; &lt;result property=\"loc\" column=\"loc\"&gt;&lt;/result&gt; &lt;/association&gt;&lt;/resultMap&gt;&lt;select id=\"selectEmpByEmpno\" resultMap=\"myEmp\"&gt; select * from emp left join dept on emp.deptno = dept.deptno where empno = #&#123;empno&#125;&lt;/select&gt; 123456789101112131415161718&lt;resultMap id=\"myDept\" type=\"com.kuro.bean.Dept\"&gt; &lt;id column=\"deptno\" property=\"deptno\"&gt;&lt;/id&gt; &lt;result property=\"dname\" column=\"dname\"&gt;&lt;/result&gt; &lt;result property=\"loc\" column=\"loc\"&gt;&lt;/result&gt; &lt;!--数据是多对一的情况时，使用 collection--&gt; &lt;collection property=\"emps\" ofType=\"com.kuro.bean.Emp\"&gt; &lt;id column=\"empno\" property=\"empno\"&gt;&lt;/id&gt; &lt;result column=\"ename\" property=\"ename\"&gt;&lt;/result&gt; &lt;result column=\"job\" property=\"job\"&gt;&lt;/result&gt; &lt;result column=\"mgr\" property=\"mgr\"&gt;&lt;/result&gt; &lt;result column=\"hiredate\" property=\"hiredate\"&gt;&lt;/result&gt; &lt;result column=\"sal\" property=\"sal\"&gt;&lt;/result&gt; &lt;result column=\"comm\" property=\"comm\"&gt;&lt;/result&gt; &lt;/collection&gt;&lt;/resultMap&gt;&lt;select id=\"selectDeptByDeptno\" resultMap=\"myDept\"&gt; select * from dept left join emp on dept.deptno = emp.deptno where dept.deptno = #&#123;deptno&#125;&lt;/select&gt; 1234567891011public class Emp &#123; private Integer empno; private Dept dept;&#125;public class Dept &#123; private Integer deptno; private String dname; private String loc; private List&lt;Emp&gt; emps;&#125; 分步查询1234567891011&lt;select id=\"selectDeptByStemp2\" resultMap=\"deptEmp\"&gt; select * from dept where deptno = #&#123;deptno&#125;&lt;/select&gt;&lt;resultMap id=\"deptEmp\" type=\"com.kuro.bean.Dept\"&gt; &lt;id column=\"deptno\" property=\"deptno\"&gt;&lt;/id&gt; &lt;result property=\"dname\" column=\"dname\"&gt;&lt;/result&gt; &lt;result property=\"loc\" column=\"loc\"&gt;&lt;/result&gt; &lt;collection property=\"emps\" ofType=\"com.kuro.bean.Emp\" select=\"com.kuro.dao.EmpDao.selectEmpByStep2\" column=\"deptno\" fetchType=\"lazy\"&gt; &lt;/collection&gt;&lt;/resultMap&gt; 123public Dept selectDeptByStemp2(Integer deptno);public Emp selectEmpByStep2(Integer deptno); 延迟查询当我们在进行表关联的时候，有可能在查询结果的时候不需要关联对象的属性值，那么此时可以通过延迟加载来实现功能。在全局配置文件mybatis-config.xml中添加如下属性 1234&lt;settings&gt; &lt;!--开启延时加载--&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/&gt;&lt;/settings&gt; 如果设置了全局加载，但是希望在某一个sql语句查询的时候不适用延时策略，可以添加如下属性： 1&lt;association property=\"dept\" select=\"com.kuro.dao.DeptDao.getDeptAndEmpsBySimple\" column=\"deptno\" fetchType=\"eager\"/&gt; 动态SQLif使用动态 SQL 最常见情景是根据条件包含 where 子句的一部分。 where 元素只会在子元素返回任何内容的情况下才插入 “WHERE” 子句。而且，若子句的开头为 “AND” 或 “OR”，where 元素也会将它们去除。 123456789101112&lt;select id=\"selectEmpByCondition\" resultType=\"com.kuro.bean.Emp\"&gt; select * from emp &lt;where&gt; &lt;if test=\"empno!=null\"&gt; empno &gt; #&#123;empno&#125; &lt;/if&gt; &lt;if test=\"ename!=null\"&gt; and ename=#&#123;ename&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 1public Emp selectEmpByCondition(Emp emp); choose有时候，我们不想使用所有的条件，而只是想从多个条件中选择一个使用。针对这种情况，MyBatis 提供了 choose 元素，它有点像 Java 中的 switch 语句。 12345678910111213141516&lt;select id=\"selectEmpByCondition\" resultType=\"com.kuro.bean.Emp\"&gt; select * from emp &lt;where&gt; &lt;choose&gt; &lt;when test=\"empno!=null\"&gt; empno = #&#123;empno&#125; &lt;/when&gt; &lt;when test=\"ename!=null\"&gt; ename=#&#123;ename&#125; &lt;/when&gt; &lt;otherwise&gt; 1=1 &lt;/otherwise&gt; &lt;/choose&gt; &lt;/where&gt;&lt;/select&gt; trim1234567891011121314151617&lt;!-- trim:截取字符串，可以自定义where的格式 prefix：为sql语句整体添加一个前缀 prefixOverrides:去除整体sql语句前面多余的字符串 suffixOverriede:去除整体sql语句后面多余的字符串 --&gt;&lt;select id=\"selectEmpByCondition\" resultType=\"com.kuro.bean.Emp\"&gt; select * from emp &lt;trim prefix=\"where\" prefixOverrides=\"and\" suffixOverrides=\"and|or\"&gt; &lt;if test=\"empno!=null\"&gt; empno = #&#123;empno&#125; and &lt;/if&gt; &lt;if test=\"ename!=null\"&gt; ename=#&#123;ename&#125; or &lt;/if&gt; &lt;/trim&gt;&lt;/select&gt; foreach123456789101112131415&lt;!-- foreach:遍历集合中的元素 collection:指定要遍历的集合 separator:分隔符 open:以什么开始 close：以什么结束 item:遍历过程中的每一个元素值 index:表示索引 --&gt;&lt;select id=\"selectEmpByDeptnos\" resultType=\"com.kuro.bean.Emp\"&gt; select * from emp where deptno in &lt;foreach collection=\"deptnos\" separator=\",\" open=\"(\" item=\"deptno\" index=\"idx\" close=\")\"&gt; #&#123;deptno&#125; &lt;/foreach&gt;&lt;/select&gt; 1public List&lt;Emp&gt; selectEmpByDeptnos(@Param(\"deptnos\") List&lt;Integer&gt; deptnos); 缓存机制12345678如果没有缓存，那么每次查询的时候都需要从数据库中加载数据，这回造成io的性能问题，所以，在很多情况下如果连续执行两条相同的sql语句，可以直接从缓存中获取，如果获取不到，那么再去查询数据库，这意味着查询完成的结果需要放到缓存中。缓存分类： 1、一级缓存：表示sqlSession级别的缓存，每次查询的时候会开启一个会话，此会话相当于一次连接，关闭之后自动失效 2、二级缓存：全局范围内的缓存，sqlsession关闭之后才会生效 3、第三方缓存：继承第三方的组件，来充当缓存的作用 一级缓存1234567一级缓存：表示将数据存储在sqlsession中，关闭之后自动失效，默认情况下是开启的 在同一个会话之内，如果执行了多个相同的sql语句，那么除了第一个之外，所有的数据都是从缓存中进行查询的 在某些情况下，一级缓存可能会失效？ 1、在同一个方法中，可能会开启多个会话，此时需要注意，会话跟方法没有关系，不是一个方法就只能由一个会话，所以严格记住,缓存的数据是保存在sqlsession中的 2、当传递对象的时候，如果对象中的属性值不同，也不会走缓存 3、在同一个连接中，如果修改了数据，那么缓存会失效，不同连接中，相互不受影响 4、如果在一个会话过程中，手动清空了缓存，那么缓存也会失效 1234567891011121314@Testpublic void test() throws IOException &#123; SqlSession sqlSession = sqlSessionFactory.openSession(); EmpDao mapper = sqlSession.getMapper(EmpDao.class); Emp emp = mapper.selectEmpByEmpno(7369); System.out.println(emp); //同一个SqlSession中，走缓存获取 EmpDao mapper2 = sqlSession2.getMapper(EmpDao.class); Emp emp2 = mapper2.selectEmpByEmpno(7369); System.out.println(emp2); sqlSession.close();&#125; 二级缓存1234567891011121314151617181920212223二级缓存：表示的是全局缓存，必须要等到sqlsession关闭之后才会生效 默认是不开启的，如果需要开启的话，需要进行如下设置 1、修改全局配置文件，在settings中添加配置 &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; 2、指定在哪个映射文件中使用缓存的配置 &lt;cache&gt;&lt;/cache&gt; 3、对应的java实体类必须要实现序列化的接口 在使用二级缓存的时候，可以包含多个属性值： eviction：缓存淘汰机制： LRU： 最近最少使用 FIFO:先进先出，按照添加缓存的顺序执行 SOFT – 软引用：基于垃圾回收器状态和软引用规则移除对象。 WEAK – 弱引用：更积极地基于垃圾收集器状态和弱引用规则移除对象。 flushInterval：设置间隔多长时间进行缓存刷新 size:引用的条数，是一个正整数，缓存中可以存储多少个对象，一般不设置，如果设置的话不要太大，会导致内存溢出 readonly:只读属性： true:只读缓存，会给所有的调用的方法返回该对象的实例，不安全 false:读写缓存，只是返回缓存对象的拷贝，比较安全 一级缓存跟二级缓存有没有可能同时存在数据？ 不会同时存在，因为二级缓存生效的时候，是在sqlsession关闭的时候 当查询数据的时候，我们是先查询一级缓存还是先查询二级缓存？ **先查询二级缓存，然后再查询一级缓存** 1234567891011121314151617@Testpublic void test() throws IOException &#123; //第一个SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); EmpDao mapper = sqlSession.getMapper(EmpDao.class); Emp emp = mapper.selectEmpByEmpno(7369); System.out.println(emp); //第二个SqlSession，走缓存 SqlSession sqlSession2 = sqlSessionFactory.openSession(); EmpDao mapper2 = sqlSession2.getMapper(EmpDao.class); Emp emp2 = mapper2.selectEmpByEmpno(7369); System.out.println(emp2); sqlSession.close(); sqlSession2.close();&#125; 第三方缓存12345可以使用第三方缓存，如`Ehcache` 1.新增`maven`依赖 1.在映射文件中使用缓存的配置 &lt;cache type=\"org.mybatis.caches.ehcache.EhcacheCache\"&gt;&lt;/cache&gt; 2.新建配置文件`ehcache.xml`并配置相关属性 12345678910111213141516171819202122232425&lt;!-- https://mvnrepository.com/artifact/org.ehcache/ehcache --&gt;&lt;dependency&gt; &lt;groupId&gt;org.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.mybatis.caches/mybatis-ehcache --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt; &lt;artifactId&gt;mybatis-ehcache&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-api --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;2.0.0-alpha1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-log4j12 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;2.0.0-alpha1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 123456789101112131415161718&lt;!-- ehcache.xml --&gt;&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;ehcache xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"http://ehcache.org/ehcache.xsd\"&gt; &lt;!-- 磁盘保存路径 --&gt; &lt;diskStore path=\"D:\\ehcache\" /&gt; &lt;defaultCache maxElementsInMemory=\"1\" maxElementsOnDisk=\"10000000\" eternal=\"false\" overflowToDisk=\"true\" timeToIdleSeconds=\"120\" timeToLiveSeconds=\"120\" diskExpiryThreadIntervalSeconds=\"120\" memoryStoreEvictionPolicy=\"LRU\"&gt; &lt;/defaultCache&gt;&lt;/ehcache&gt; 1234567891011121314151617属性说明： diskStore：指定数据在磁盘中的存储位置。 defaultCache：当借助CacheManager.add(&quot;demoCache&quot;)创建Cache时，EhCache便会采用&lt;defalutCache&#x2F;&gt;指定的的管理策略 以下属性是必须的： maxElementsInMemory - 在内存中缓存的element的最大数目 maxElementsOnDisk - 在磁盘上缓存的element的最大数目，若是0表示无穷大 eternal - 设定缓存的elements是否永远不过期。如果为true，则缓存的数据始终有效，如果为false那么还要根据timeToIdleSeconds，timeToLiveSeconds判断 overflowToDisk - 设定当内存缓存溢出的时候是否将过期的element缓存到磁盘上 以下属性是可选的： timeToIdleSeconds - 当缓存在EhCache中的数据前后两次访问的时间超过timeToIdleSeconds的属性取值时，这些数据便会删除，默认值是0,也就是可闲置时间无穷大 timeToLiveSeconds - 缓存element的有效生命期，默认是0.,也就是element存活时间无穷大 diskSpoolBufferSizeMB 这个参数设置DiskStore(磁盘缓存)的缓存区大小.默认是30MB.每个Cache都应该有自己的一个缓冲区. diskPersistent - 在VM重启的时候是否启用磁盘保存EhCache中的数据，默认是false。 diskExpiryThreadIntervalSeconds - 磁盘缓存的清理线程运行间隔，默认是120秒。每个120s，相应的线程会进行一次EhCache中数据的清理工作 memoryStoreEvictionPolicy - 当内存缓存达到最大，有新的element加入的时候， 移除缓存中element的策略。默认是LRU（最近最少使用），可选的有LFU（最不常使用）和FIFO（先进先出） 代码生成器1234可以通过generator反向从数据库表动态生成实体类和一些基础的查询API： 1.引入依赖 2.编写`mybatis-generator.xml`配置 3.运行代码生成映射 12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233&lt;!-- mybatis-generator.xml --&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\"&gt;&lt;!--总配置标签--&gt;&lt;generatorConfiguration&gt; &lt;!--具体配置的上下文环境--&gt; &lt;!-- &lt;context id=\"simple\" targetRuntime=\"MyBatis3DynamicSql\"&gt;--&gt; &lt;context id=\"simple\" targetRuntime=\"MyBatis3Simple\"&gt; &lt;!--指向我们需要连接的数据库--&gt; &lt;jdbcConnection driverClass=\"com.mysql.cj.jdbc.Driver\" connectionURL=\"jdbc:mysql://192.168.85.111:3306/demo?serverTimezone=UTC\" userId=\"root\" password=\"123456\"/&gt; &lt;!--生成对应的实体类 targetPackage:指定存放的包 targetProject：指定当前工程的目录 --&gt; &lt;javaModelGenerator targetPackage=\"com.kuro.bean\" targetProject=\"src/main/java\"/&gt; &lt;!--生成对应的SQL映射文件--&gt; &lt;!--MyBatis3DynamicSql的话，就不需要这个--&gt; &lt;sqlMapGenerator targetPackage=\"com.kuro.dao\" targetProject=\"src/main/resources\"/&gt; &lt;!--生成对应的DAO接口--&gt; &lt;javaClientGenerator type=\"XMLMAPPER\" targetPackage=\"com.kuro.dao\" targetProject=\"src/main/java\"/&gt; &lt;!-- &lt;javaClientGenerator targetPackage=\"com.kuro.dao\" targetProject=\"src/main/java\"/&gt;--&gt; &lt;!--指定需要反向生成的表--&gt; &lt;table tableName=\"emp\" /&gt; &lt;table tableName=\"dept\" /&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 123456789101112public class MyTest &#123; public static void main(String[] args) throws Exception &#123; List&lt;String&gt; warnings = new ArrayList&lt;String&gt;(); boolean overwrite = true; File configFile = new File(\"mybatis-generator.xml\"); ConfigurationParser cp = new ConfigurationParser(warnings); Configuration config = cp.parseConfiguration(configFile); DefaultShellCallback callback = new DefaultShellCallback(overwrite); MyBatisGenerator myBatisGenerator = new MyBatisGenerator(config, callback, warnings); myBatisGenerator.generate(null); &#125;&#125;","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://midkuro.gitee.io/categories/Mybatis/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://midkuro.gitee.io/tags/Mybatis/"}]},{"title":"'Mybatis的介绍和基本使用'","slug":"mybatis-config","date":"2020-11-09T14:31:00.000Z","updated":"2020-11-12T01:50:36.092Z","comments":true,"path":"2020/11/09/mybatis-config/","link":"","permalink":"https://midkuro.gitee.io/2020/11/09/mybatis-config/","excerpt":"","text":"Mybatis的基本使用基本使用pom.xml123456789101112&lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.4&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.19&lt;/version&gt;&lt;/dependency&gt; Emp.java1234567891011121314package com.kuro.bean;import java.util.Date;public class Emp &#123; private Integer empno; private String ename; private String job; private Integer mgr; private Date hiredate; private Double sal; private Double common; private Integer deptno; //省略构造、toString、getter、Setter方法&#125; EmpDao.java123456package com.kuro.dao;import com.kuro.bean.Emp;public interface EmpDao &#123; public Emp findEmpByEmpno(Integer empno);&#125; mybatis-config.xml12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--配置数据库连接--&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.cj.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/demo?serverTimezone=UTC\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--引入每一个接口对应点xml文件--&gt; &lt;mappers&gt; &lt;mapper resource=\"EmpDao.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; EmpDao.xml12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!--namespace:编写接口的全类名，就是告诉要实现该配置文件是哪个接口的具体实现--&gt;&lt;mapper namespace=\"com.kuro.dao.EmpDao\"&gt; &lt;!-- select:表示这个操作是一个查询操作 id表示的是要匹配的方法的名称 resultType:表示返回值的类型，查询操作必须要包含返回值的类型 #&#123;属性名&#125;：表示要传递的参数的名称 --&gt; &lt;select id=\"findEmpByEmpno\" resultType=\"com.kuro.bean.Emp\"&gt; select * from emp where empno = #&#123;empno&#125; &lt;/select&gt;&lt;/mapper&gt; Test.java123456789101112131415161718192021222324252627282930313233package com.kuro.test;import com.kuro.bean.Emp;import com.kuro.dao.EmpDao;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.junit.Test;import java.io.IOException;import java.io.InputStream;public class MyTest &#123; @Test public void test01() throws IOException&#123; // 根据全局配置文件创建出SqlSessionFactory String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); // SqlSessionFactory:负责创建SqlSession对象的工厂 sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); //获取与数据库相关的会话 SqlSession sqlSession = sqlSessionFactory.openSession(); //获取对应的映射接口对象 EmpDao mapper = sqlSession.getMapper(EmpDao.class); //执行具体的sql语句 Emp emp = mapper.selectEmpByEmpno(7369); System.out.println(emp); //关闭会话 sqlSession.close(); &#125;&#125; mybatis-config.xml详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107s&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;!--在填写标签的时候一定要注意相关配置的顺序--&gt;&lt;configuration&gt; &lt;!-- 当需要引入外部的配置文件的时候，可以使用这样的方式 类似于&lt;context:property-placeholder location&gt; resource:表示从当前项目的类路径中进行加载，如果用的是idea指的是resource资源目录下的配置文件 url:可以从当前文件系统的磁盘目录查找配置，也可以从网络上的资源进行引入 --&gt; &lt;properties resource=\"db.properties\" &gt;&lt;/properties&gt; &lt;!--可以影响mybatis运行时的行为，包含N多个属性，需要什么引入什么--&gt; &lt;settings&gt; &lt;!--开启驼峰标识验证--&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/&gt; &lt;!--配置懒加载开关--&gt; &lt;setting name=\"lazyLoadingEnabled\" value=\"true\"/&gt; &lt;!--配置缓存开关--&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt; &lt;!--typeAliases:表示在引入实体类的名称时候，可以使用别名，而不需要写完全限定名--&gt; &lt;typeAliases&gt; &lt;!--每一个具体的类都需要单独来写，如果有100个类呢？--&gt; &lt;!-- &lt;typeAlias type=\"com.kuro.bean.Emp\" alias=\"aaa\"&gt;&lt;/typeAlias&gt;--&gt; &lt;!--可以指定具体的包来保证实体类不需要写完全限定名--&gt; &lt;package name=\"com.kuro.bean\"/&gt; &lt;/typeAliases&gt; &lt;!--设置定义自己的类型处理器，mybatis中默认内置了很多类型处理器，一般不需要自己来实现--&gt; &lt;!-- &lt;typeHandlers&gt;--&gt; &lt;!-- &lt;typeHandler handler=\"\" &gt;&lt;/typeHandler&gt;--&gt; &lt;!-- &lt;package name=\"\"/&gt;--&gt; &lt;!-- &lt;/typeHandlers&gt;--&gt; &lt;!--当需要自定义对象工厂的时候实现此标签，完成结果集到java对象实例化的过程--&gt; &lt;!-- &lt;objectFactory type=\"\"&gt;&lt;/objectFactory&gt;--&gt; &lt;!--在项目开发过程中，会包含开发环境，测试环境，生产环境，有可能会使用不同的数据源进行连接操作， 在此配置文件中可以指定多个环境 default:表示选择哪个环境作为运行时环境 --&gt; &lt;environments default=\"development\"&gt; &lt;!--配置具体的环境属性 id:表示当前环境的名称 --&gt; &lt;environment id=\"development\"&gt; &lt;!--事务管理器，每一种数据源都需要配置具体的事务管理器 type:表示事务管理器的类型 jdbc:使用jdbc原生的事务控制 managed:什么都没做 --&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!--配置具体的数据源的类型 type:表示数据源的类型 pooled:使用数据库连接池 unpooled：每次都打开和关闭一个链接 --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;!--链接数据的时候需要添加的必备的参数，一般是四个，如果是连接池的话，可以设置连接最大个数等相关信息--&gt; &lt;property name=\"driver\" value=\"$&#123;driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!--提供了不同的数据库厂商的标识，当有数据库移植的需求的时候，可以根据不同的数据库来执行不同的sql语句用来扩展数据库的移植性--&gt; &lt;databaseIdProvider type=\"DB_VENDOR\"&gt; &lt;property name=\"MySQL\" value=\"mysql\"/&gt; &lt;property name=\"SQL Server\" value=\"sqlserver\"/&gt; &lt;property name=\"Oracle\" value=\"oracle\"/&gt; &lt;/databaseIdProvider&gt; &lt;!--是来将mapper映射文件引入到配置文件中，方便程序启动的时候进行加载 每次在进行填写的时候需要注意，写完xml映射之后一定要添加到mybatis-config文件中 resource:从项目的类路径下加载对应的映射文件 url:从本地磁盘目录或者网络中引入映射文件 class:可以直接引入类的完全限定名，可以使用注解的方式进行使用, 如果不想以注解的方式引入呢？ 如果想要class的方式引入配置文件，可以将xml文件添加到具体的类的同级目录下 1、 如果是maven的项目的话，需要添加如下配置，因为maven默认只会编译java文件，需要把xml文件也添加到指定目录中 &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; 2、在resource资源目录下，创建跟dao层一样的同级目录即可，将配置文件放到指定的目录 --&gt; &lt;mappers&gt; &lt;!-- &lt;mapper resource=\"EmpDao.xml\" /&gt;--&gt; &lt;!-- &lt;mapper resource=\"UserDao.xml\"/&gt;--&gt; &lt;!-- &lt;mapper class=\"com.kuro.dao.UserDaoAnnotation\"&gt;&lt;/mapper&gt;--&gt; &lt;!-- &lt;mapper class=\"com.kuro.dao.UserDao\"&gt;&lt;/mapper&gt;--&gt; &lt;!--如果需要引入多个配置文件，可以直接定义包的名称 resource目录下配置的映射文件必须要具体相同的目录 --&gt; &lt;package name=\"com.kuro.dao\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; db.properties1234driver=com.mysql.cj.jdbc.Driverurl=jdbc:mysql://192.168.85.111:3306/demo?serverTimezone=UTCusername=rootpassword=123456","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://midkuro.gitee.io/categories/Mybatis/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://midkuro.gitee.io/tags/Mybatis/"}]},{"title":"'数据结构与算法 训练营二期'","slug":"algorithm-trainingcamp2","date":"2020-10-30T14:33:00.000Z","updated":"2020-12-23T05:16:20.165Z","comments":true,"path":"2020/10/30/algorithm-trainingcamp2/","link":"","permalink":"https://midkuro.gitee.io/2020/10/30/algorithm-trainingcamp2/","excerpt":"","text":"训练营二期脑图大纲 打表法123456789打表法：1）问题如果返回值不太多，可以用hardcode的方式列出，作为程序的一部分2）一个大问题解决时底层频繁使用规模不大的小问题的解，如果小问题的返回值满足条件1），可以把小问题的解列成一张表，作为程序的一部分3）打表找规律打表找规律：1）某个题，输入参数类型简单，并且只有一个实际参数2）要求的返回值类型也简单，并且只有一个3）用暴力方法，把输入参数对应的返回值，打印出来看看，进而优化code 123456题目一：小虎去买苹果，商店只提供两种类型的塑料袋，每种类型都有任意数量。1）能装下6个苹果的袋子2）能装下8个苹果的袋子小虎可以自由使用两种袋子来装苹果，但是小虎有强迫症，他要求自己使用的袋子数量必须最少，且使用的每个袋子必须装满。给定一个正整数N，返回至少使用多少袋子。如果N无法让使用的每个袋子必须装满，返回-1 123456789101112131415161718192021222324252627282930//打表找规律public static int minBags(int apple) &#123; if (apple &lt; 0) &#123; return -1; &#125; int bag6 = -1; int bag8 = apple / 8; int rest = apple - 8 * bag8; while (bag8 &gt;= 0 &amp;&amp; rest &lt; 24) &#123; int restUse6 = minBagBase6(rest); if (restUse6 != -1) &#123; bag6 = restUse6; break; &#125; rest = apple - 8 * (--bag8); &#125; return bag6 == -1 ? -1 : bag6 + bag8;&#125;// 如果剩余苹果rest可以被装6个苹果的袋子搞定，返回袋子数量// 不能搞定返回-1public static int minBagBase6(int rest) &#123; return rest % 6 == 0 ? (rest / 6) : -1;&#125;public static void main(String[] args) &#123; for(int apple = 1; apple &lt; 100;apple++) &#123; System.out.println(apple + \" : \"+ minBags(apple)); &#125;&#125; 1234567891011//整合规律public static int minBagAwesome(int apple) &#123; if ((apple &amp; 1) != 0) &#123; // 如果是奇数，返回-1 return -1; &#125; if (apple &lt; 18) &#123; return apple == 0 ? 0 : (apple == 6 || apple == 8) ? 1 : (apple == 12 || apple == 14 || apple == 16) ? 2 : -1; &#125; return (apple - 18) / 8 + 3;&#125; 12345678题目二：给定一个正整数N，表示有N份青草统一堆放在仓库里有一只牛和一只羊，牛先吃，羊后吃，它俩轮流吃草不管是牛还是羊，每一轮能吃的草量必须是：1，4，16，64…(4的某次方)谁最先把草吃完，谁获胜假设牛和羊都绝顶聪明，都想赢，都会做出理性的决定根据唯一的参数N，返回谁会赢 1234567891011121314151617181920212223242526272829303132// n份青草放在一堆// 先手后手都绝顶聪明// string \"先手\" \"后手\"//暴力递归测试打表规律public static String winner1(int n) &#123; // 0 1 2 3 4 // 后 先 后 先 先 if (n &lt; 5) &#123; // base case return (n == 0 || n == 2) ? \"后手\" : \"先手\"; &#125; // n &gt;= 5 时 int base = 1; // 当前先手决定吃的草数 // 当前是先手在选 while (base &lt;= n) &#123; // 当前一共n份草，先手吃掉的是base份，n - base 是留给后手的草 // 母过程 先手 在子过程里是 后手 if (winner1(n - base).equals(\"后手\")) &#123; return \"先手\"; &#125; if (base &gt; n / 4) &#123; // 防止base*4之后溢出 break; &#125; base *= 4; &#125; return \"后手\";&#125;public static void main(String[] args) &#123; for (int i = 0; i &lt;= 50; i++) &#123; System.out.println(i + \" : \" + winner1(i)); &#125;&#125; 12345678//打表规律public static String winner2(int n) &#123; if (n % 5 == 0 || n % 5 == 2) &#123; return \"后手\"; &#125; else &#123; return \"先手\"; &#125;&#125; 12345678题目三：定义一种数：可以表示成若干（数量&gt;1）连续正数和的数比如:5 &#x3D; 2+3，5就是这样的数12 &#x3D; 3+4+5，12就是这样的数1不是这样的数，因为要求数量大于1个、连续正数和2 &#x3D; 1 + 1，2也不是，因为等号右边不是连续正数给定一个参数N，返回是不是可以表示成若干连续正数和的数 1234567891011121314151617181920212223242526272829//打表public static boolean isMSum1(int num) &#123; for (int i = 1; i &lt;= num; i++) &#123; int sum = i; for (int j = i + 1; j &lt;= num; j++) &#123; if (sum + j &gt; num) &#123; break; &#125; if (sum + j == num) &#123; return true; &#125; sum += j; &#125; &#125; return false;&#125;public static void main(String[] args) &#123; for (int num = 1; num &lt; 200; num++) &#123; System.out.println(num + \" : \" + isMSum1(num)); &#125; System.out.println(\"test begin\"); for (int num = 1; num &lt; 5000; num++) &#123; if (isMSum1(num) != isMSum2(num)) &#123; System.out.println(\"Oops!\"); &#125; &#125; System.out.println(\"test end\");&#125; 12345678//打表规律 1 2 4 8 16，2的次幂是false//(num &amp; (num - 1)) == 0; 表示这个数是2的次幂 ，否则不是public static boolean isMSum2(int num) &#123; if (num &lt; 3) &#123; return false; &#125; return (num &amp; (num - 1)) != 0;&#125; 矩阵技巧12345矩阵处理技巧1）zigzag打印矩阵2）转圈打印矩阵3）原地旋转正方形矩阵核心技巧：找到coding上的宏观调度 1234567891011zigzag打印矩阵:|a b c d||e f g h||i j k l|要求输出顺序是： abeijfcdgklh思想：两个点A、B都是从坐标[0,0]上出发A每次往右走，走到不能往右了，就往下走B每次往下走，走到不能往下了，就往右走这样A和B始终能连成一条贯穿矩阵内容的斜线，输出处于斜线上的内容即可 12345678910111213141516171819202122232425262728293031323334public static void printMatrixZigZag(int[][] matrix) &#123; //A坐标点 int tR = 0; int tC = 0; //B坐标点 int dR = 0; int dC = 0; int endR = matrix.length - 1; int endC = matrix[0].length - 1; //输出方向 从下到上，还是从上到下 boolean fromUp = false; while (tR != endR + 1) &#123; printLevel(matrix, tR, tC, dR, dC, fromUp); tR = tC == endC ? tR + 1 : tR; tC = tC == endC ? tC : tC + 1; dC = dR == endR ? dC + 1 : dC; dR = dR == endR ? dR : dR + 1; fromUp = !fromUp; &#125; System.out.println();&#125;public static void printLevel(int[][] m, int tR, int tC, int dR, int dC, boolean f) &#123; if (f) &#123; while (tR != dR + 1) &#123; System.out.print(m[tR++][tC--] + \" \"); &#125; &#125; else &#123; while (dR != tR - 1) &#123; System.out.print(m[dR--][dC++] + \" \"); &#125; &#125;&#125; 1234567891011121314转圈打印矩阵:|a b c d||e f g h||i j k l|要求输出顺序是： abcdhlkjiefg思想：分解矩阵，每次输出一个框： abcdhlkjie fg以a,l点的(x,y)坐标为点:从a点出发，输出横列，它的a.y++，直到a.y + 1 &#x3D; l.y停下从d点出发，输出竖列，它的a.x++，直到a.x + 1 &#x3D; l.x停下从l点出发，输出横列，它的l.y--，直到l.y - 1 &#x3D; a.x停下从i点出发，输出竖列，它的l.x--，直到l.x - 1 &#x3D; a.y停下切割成四部分，先输出外围框，然后a和l分别向左下，右上移动，再次输出框 1234567891011121314151617181920212223242526272829303132333435363738394041public static void spiralOrderPrint(int[][] matrix) &#123; int tR = 0; int tC = 0; int dR = matrix.length - 1; int dC = matrix[0].length - 1; while (tR &lt;= dR &amp;&amp; tC &lt;= dC) &#123; printEdge(matrix, tR++, tC++, dR--, dC--); &#125;&#125;public static void printEdge(int[][] m, int tR, int tC, int dR, int dC) &#123; //兼容a点和l点处于同一条直线的情况 if (tR == dR) &#123; for (int i = tC; i &lt;= dC; i++) &#123; System.out.print(m[tR][i] + \" \"); &#125; &#125; else if (tC == dC) &#123; for (int i = tR; i &lt;= dR; i++) &#123; System.out.print(m[i][tC] + \" \"); &#125; &#125; else &#123; int curC = tC; int curR = tR; while (curC != dC) &#123; System.out.print(m[tR][curC] + \" \"); curC++; &#125; while (curR != dR) &#123; System.out.print(m[curR][dC] + \" \"); curR++; &#125; while (curC != tC) &#123; System.out.print(m[dR][curC] + \" \"); curC--; &#125; while (curR != tR) &#123; System.out.print(m[curR][tC] + \" \"); curR--; &#125; &#125;&#125; 12345678原地旋转正方形矩阵|a b c| |i e a||e f g| 向左旋转90度 -&gt; |j f b||i j k| |k g c|思想：取四个点坐标 a、c、k、i,分组，a向右移动的数据，对应变化到c向下移动的数据，依次等于每次每组都是在互相交换数据。a -&gt; c c-&gt;k k-i&gt; i-&gt;a，然后各自移动，重复操作，外圈交换完就交换内圈 1234567891011121314151617181920public static void rotate(int[][] matrix) &#123; int a = 0; int b = 0; int c = matrix.length - 1; int d = matrix[0].length - 1; while (a &lt; c) &#123; rotateEdge(matrix, a++, b++, c--, d--); &#125;&#125;public static void rotateEdge(int[][] m, int a, int b, int c, int d) &#123; int tmp = 0; for (int i = 0; i &lt; d - b; i++) &#123; tmp = m[a][b + i]; m[a][b + i] = m[c - i][b]; m[c - i][b] = m[c][d - i]; m[c][d - i] = m[a + i][d]; m[a + i][d] = tmp; &#125;&#125; 数组累加和1234题目一:给定一个正整数组成的无序数组arr，给定一个正整数值K找到arr的所有子数组里，哪个子数组的累加和等于K，并且是长度最大的返回其长度 12思路：滑动窗口 [L..R]，划到等于K，则记录长度，并且L&#x2F;R继续滑动右移，大于K时，L右移，R越界，则窗口内无结果。 123456789101112131415161718192021222324252627public static int getMaxLength(int[] arr, int K) &#123; if (arr == null || arr.length == 0 || K &lt;= 0) &#123; return 0; &#125; int L = 0; int R = 0; int sum = arr[0]; int len = 0; while (R &lt; arr.length) &#123; //窗口内的值相等则记录长度，并且L向右滑动，并且sum要减去arr[L]值 if (sum == K) &#123; len = Math.max(len, R - L + 1); sum -= arr[L++]; &#125; else if (sum &lt; K) &#123; R++; //先自增判断是否越界，越界则break if (R == arr.length) &#123; break; &#125; sum += arr[R]; &#125; else &#123; //如果大于K，L也向右滑动，并且sum要减去arr[L]值 sum -= arr[L++]; &#125; &#125; return len;&#125; 12345题目二:给定一个整数组成的无序数组arr，值可能正、可能负、可能0给定一个整数值K找到arr的所有子数组里，哪个子数组的累加和等于K，并且是长度最大的返回其长度 12345678思想：用Map存储最早出现的累加和信息&lt;sum,index&gt;，sum是从Index &#x3D; 0累加到当前index的值依次遍历数组，当前遍历的i的sum - K &#x3D; V，V去Map中寻找是否有值若有值，V对应最早出现的[index + 1,i]，这段长度就是以i结尾，最长的子数组累加和注意：map中需要实现补充&lt;0,-1&gt;的记录，因为在还没开始时数组累加和就应该等于0否则将会出现以下反例：[3,-3,7] K &#x3D; 7, 当i &#x3D; 2时， sum &#x3D; 7, V &#x3D; sum - K &#x3D; 0,映射Map&lt;0,1&gt;的数据,这时length &#x3D; i - V.value &#x3D; 1若最开始Map中就已存在&lt;0,-1&gt;，则有length &#x3D; i - (-1) &#x3D; 3 123456789101112131415161718192021public static int maxLength(int[] arr, int k) &#123; if (arr == null || arr.length == 0) &#123; return 0; &#125; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); map.put(0, -1); // important int len = 0; int sum = 0; for (int i = 0; i &lt; arr.length; i++) &#123; sum += arr[i]; //判断Map是否存在出现累加和的值 if (map.containsKey(sum - k)) &#123; len = Math.max(i - map.get(sum - k), len); &#125; //记录第一次出现当前累加和的值的index if (!map.containsKey(sum)) &#123; map.put(sum, i); &#125; &#125; return len;&#125; 1234567题目三:有一个包含正数、负数、零的整数数组，要求得到同时包含相等数量的1、2的最长子数组长度例子：[1,3,-2,2,4,1,2]思路：遍历，遇到1就把值变成1，遇到2把值变成-1，遇到其他值，都变成0 --&gt; [1,0,0,-1,0,1,-1]转换成了数组累加和的问题，最长子串中累加和等于0的问题。 12345题目四:给定一个整数组成的无序数组arr，值可能正、可能负、可能0给定一个整数值K找到arr的所有子数组里，哪个子数组的累加和&lt;&#x3D;K，并且是长度最大的返回其长度 1234567891011思路：用两个数组来记录信息，minSum数组存储以当前index为L和R，R向右边扩的最小累加和minSumRIndex存储以index为L，R扩到的最小累加和下标如例子(arr从右往左遍历)：arr &#x3D; [3,-2,0,7,-3,2]minSum &#x3D; [1,-2,0,4,-3,2]minSumRIndex &#x3D; [2,2,2,4,4,5] 以i &#x3D; 0开始，sum +&#x3D; [0,2]，然后看看sum是否小于K，小于则继续扩 sum+&#x3D; [3,4]，扩到不能扩为止若出现不能扩，这里有个优化点：sum &#x3D; [0,R]的累加值，则[1,R]的sum1 &#x3D; sum - [0,0]接着以 i &#x3D; 1开始,看看[R+1,..]能否被扩进去，若不能，则跳过i &#x3D; 1的累加 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//O(N)public static int maxLengthAwesome(int[] arr, int k) &#123; if (arr == null || arr.length == 0) &#123; return 0; &#125; int[] minSums = new int[arr.length]; int[] minSumRIndex = new int[arr.length]; //末尾的肯定是自己，没办法扩 minSums[arr.length - 1] = arr[arr.length - 1]; minSumRIndex[arr.length - 1] = arr.length - 1; //从右往左计算 for (int i = arr.length - 2; i &gt;= 0; i--) &#123; if (minSums[i + 1] &lt;= 0) &#123; minSums[i] = arr[i] + minSums[i + 1]; minSumRIndex[i] = minSumRIndex[i + 1]; &#125; else &#123; minSums[i] = arr[i]; minSumRIndex[i] = i; &#125; &#125; //扩到第一个超的index int end = 0; //已经扩出来整体累加和的值 int sum = 0; //全局最大长度 int res = 0; // i是窗口的最左的位置，end扩出来的最右有效块儿的最后一个位置的，再下一个位置 // end也是下一块儿的开始位置 // 窗口：[i~end) for (int i = 0; i &lt; arr.length; i++) &#123; // while循环结束之后： // 1) 如果以i开头的情况下，累加和&lt;=k的最长子数组是arr[i..end-1]，看看这个子数组长度能不能更新res； // 2) 如果以i开头的情况下，累加和&lt;=k的最长子数组比arr[i..end-1]短，更新还是不更新res都不会影响最终结果； while (end &lt; arr.length &amp;&amp; sum + minSums[end] &lt;= k) &#123; sum += minSums[end]; end = minSumRIndex[end] + 1; &#125; res = Math.max(res, end - i); if (end &gt; i) &#123; // 窗口内还有数 [i~end) [4,4) sum -= arr[i]; &#125; else &#123; // 窗口内已经没有数了，说明从i开头的所有子数组累加和都不可能&lt;=k end = i + 1; &#125; &#125; return res;&#125; 哈希函数1234561）输入参数data，假设是in类型，特征：可能性无穷大，比如str类型的参数2）输出参数类型out，特征：可能性可以很大，但一定是有穷尽的3）哈希函数没有任何随机的机制，固定的输入一定是固定的输出4）输入无穷多但输出值有限，所以不同输入也可能输出相同（哈希碰撞）5）再相似的不同输入，得到的输出值，会几乎均匀的分布在out域上重点：第5条！ 123456假设链表长度大于1需要扩容，初始化数组大小为1，等于每次插入hashMap都需要扩容假设最简单的扩容是：1-&gt;2-&gt;4-&gt;8-&gt;...-&gt;N 那么样本量N时，它的扩容次数是logN每次扩容的时候，扩容的数据量是当时的数量被，不是最后的N来估计，扩容总代价为：假设每次扩容都需要遍历整个数据大小，则：1+2+4+8+...+N&#x2F;4+N&#x2F;2，等比数列收敛于O(N)加N个数的总打低价为O(N)，均摊下来为O(1) 1234567891011121314题目：32位无符号整数的范围是0~4,294,967,295，现在有一个正好包含40亿个无符号整数的文件，可以使用最多1GB的内存，怎么找到出现次数最多的数？分析：最简单的是通过HashMap&lt;整数,出现次数&gt;进行词频统计，但是把40亿个整数放进HashMap一定超过1G内存不妨假设忽略hashMap自身属性所占用的字节量，一个int占4字节，一对&lt;key,value&gt; 8个字节如果40亿个整数都不同，那么内存将有40亿 * 8 &#x3D; 320亿字节，而一个1G&#x3D;10亿字节多，必然超思想：将40亿个整数进行hash % 40放入文件中，将40亿数据打散到40个文件中，根据哈希函数的特性，会几乎均匀的分布而且同一个数字计算相同hash，所以必定在同一个文件中，在这种情况下,1G内存计算每个文件的Top并比较即使40亿个整数全部落在同一个文件中，也可以照样进行HashMap词频统计，因为都是同一个数字的话，必定不会超1G 布隆过滤器布隆过滤器图解 1231）利用哈希函数的性质2）每一条数据提取特征3）加入描黑库 12341，假设数据量为n，预期的失误率为p（布隆过滤器大小和每个样本的大小无关）2，根据n和p，算出Bloom Filter一共需要多少个bit位，向上取整，记为m3，根据m和n，算出Bloom Filter需要多少个哈希函数，向上取整，记为k4，根据修正公式，算出真实的失误率p_true 12345678问题：如何找出多个Hash函数把值打散在多个bit中？思想：可以找两个Hash函数，分别是F()和G()，对两个Hash函数算出来的值进行加工即可得出多个互相独立的Hash函数第一个Hash函数 &#x3D; F() + 1 * G()第二个Hash函数 &#x3D; F() + 2 * G()第三个Hash函数 &#x3D; F() + 3 * G()... 一致性Hash一致性Hash图解 123分布式存储结构最常见的结构1）哈希域变成环的设计2）虚拟节点技术 并行算法1234567岛问题：一个只有0和1两种数字的二维矩阵中，上下左右能连成一片的1，算一个岛，返回矩阵中，一共有几个岛如：|0 1 0 1 1 1||1 1 0 0 1 0||1 0 0 0 1 1||1 1 1 0 0 0| 答案：两个岛 12思想：写一个感染函数，自身是1的点，改成2，递归将上下左右相邻是1的点都感染成2 1234567891011121314151617181920212223242526272829public static int countIslands1(int[][] m) &#123; if (m == null || m[0] == null) &#123; return 0; &#125; int N = m.length; int M = m[0].length; int res = 0; for (int i = 0; i &lt; N; i++) &#123; for (int j = 0; j &lt; M; j++) &#123; //找到一个为1的，则岛数量++，感染岛相连的片区 if (m[i][j] == 1) &#123; res++; infect(m, i, j, N, M); &#125; &#125; &#125; return res;&#125;public static void infect(int[][] m, int i, int j, int N, int M) &#123; if (i &lt; 0 || i &gt;= N || j &lt; 0 || j &gt;= M || m[i][j] != 1) &#123; return; &#125; m[i][j] = 2; infect(m, i + 1, j, N, M); infect(m, i - 1, j, N, M); infect(m, i, j + 1, N, M); infect(m, i, j - 1, N, M);&#125; 12345678并行算法：岛问题数据量庞大时，上述解法是单线程解法，可以将岛进行切割，划分各个区域，每个区域统计岛的数量由于划分区域算出来的岛数势必大于等于真实解，因为区域切割会将原本属于同一座岛屿的切割成两座。|1 1 1 1 1 1||1 0 0 0 1 0||1 0 0 0 1 1||1 1 1 1 1 0|如果将上图例子切割成两片区域进行计算，最终结果需要进行，可以通过并查集。 12345678思想：切割成两片区域并行计算，计算的时候记录和切割线附近的点，如坐标A[2,0]、B[2,3]、C[3,0]、D[3,3]最后通过并查集合并A点和B点(res--),然后再判断C点和D点是否是一个并查集由于A和C是处于同一个并查集，B和D也处于同一个并查集，而且A和B并查集经过合并，所以C和D本身就处于同一个并查集左区域res &#x3D; 1, 右区域res &#x3D; 1, sum &#x3D; 2 - mergeA&amp;B &#x3D; 1最终岛屿数：1扩展：可以不止切割成两片区域，可以切割成多块，最后使用并查集进行合并。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public static class UnionFindSet&lt;V&gt; &#123; // a -&gt; a 生成的点 public HashMap&lt;V, Element&lt;V&gt;&gt; elementMap; public HashMap&lt;Element&lt;V&gt;, Element&lt;V&gt;&gt; fatherMap; // sizeMap中的key，每一个key都一定是集合的头节点（代表节点） public HashMap&lt;Element&lt;V&gt;, Integer&gt; sizeMap; public UnionFindSet(List&lt;V&gt; list) &#123; elementMap = new HashMap&lt;&gt;(); fatherMap = new HashMap&lt;&gt;(); sizeMap = new HashMap&lt;&gt;(); for (V value : list) &#123; Element&lt;V&gt; element = new Element&lt;V&gt;(value); elementMap.put(value, element); fatherMap.put(element, element); sizeMap.put(element, 1); &#125; &#125; // 从输入参数element出发，往上一直找，找到不能再往上的头节点，返回 private Element&lt;V&gt; findHead(Element&lt;V&gt; element) &#123; // 把往上找的过程中，沿途的点都记录在path里 Stack&lt;Element&lt;V&gt;&gt; path = new Stack&lt;&gt;(); while (element != fatherMap.get(element)) &#123; path.push(element); element = fatherMap.get(element); &#125; while (!path.isEmpty()) &#123; fatherMap.put(path.pop(), element); &#125; return element; &#125; public boolean isSameSet(V a, V b) &#123; if (elementMap.containsKey(a) &amp;&amp; elementMap.containsKey(b)) &#123; return findHead(elementMap.get(a)) == findHead(elementMap.get(b)); &#125; return false; &#125; public void union(V a, V b) &#123; if (elementMap.containsKey(a) &amp;&amp; elementMap.containsKey(b)) &#123; Element&lt;V&gt; aF = findHead(elementMap.get(a)); Element&lt;V&gt; bF = findHead(elementMap.get(b)); if (aF != bF) &#123; Element&lt;V&gt; big = sizeMap.get(aF) &gt;= sizeMap.get(bF) ? aF : bF; Element&lt;V&gt; small = big == aF ? bF : aF; fatherMap.put(small, big); sizeMap.put(big, sizeMap.get(aF) + sizeMap.get(bF)); sizeMap.remove(small); &#125; &#125; &#125; public int getSetNum() &#123; return sizeMap.size(); &#125;&#125;public static int countIslands2(int[][] m) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int row = 0; row &lt; m.length; row++) &#123; for (int col = 0; col &lt; m[0].length; col++) &#123; if (m[row][col] == 1) &#123; String position = String.valueOf(row) + \"_\" + String.valueOf(col); list.add(position); &#125; &#125; &#125; UnionFindSet&lt;String&gt; unionSet = new UnionFindSet&lt;&gt;(list); for (int row = 0; row &lt; m.length; row++) &#123; for (int col = 0; col &lt; m[0].length; col++) &#123; if (m[row][col] == 1) &#123; // row,col 5, 3 -&gt; 5_3 String position = String.valueOf(row) + \"_\" + String.valueOf(col); if (row - 1 &gt;= 0 &amp;&amp; m[row - 1][col] == 1) &#123; String up = String.valueOf(row - 1) + \"_\" + String.valueOf(col); unionSet.union(up, position); &#125; if (col - 1 &gt;= 0 &amp;&amp; m[row][col - 1] == 1) &#123; String left = String.valueOf(row) + \"_\" + String.valueOf(col - 1); unionSet.union(left, position); &#125; &#125; &#125; &#125; return unionSet.getSetNum();&#125; 资源限制12345671）布隆过滤器用于集合的建立与查询，并可以节省大量空间（已讲）2）一致性哈希解决数据服务器的负载管理问题（已讲）3）利用并查集结构做岛问题的并行计算（已讲）4）哈希函数可以把数据按照种类均匀分流5）位图解决某一范围上数字的出现情况，并可以节省大量空间6）利用分段统计思想、并进一步节省大量空间7）利用堆、外排序来做多个处理单元的结果合并 1234567891011题目一：32位无符号整数的范围是0~4,294,967,295，现在有一个正好包含40亿个无符号整数的文件，所以在整个范围中必然存在没出现过的数。可以使用最多1GB的内存，怎么找到所有未出现过的数？思想：int占4字节，弄成二维数组的话，一个下标存储一个值，没出现的数据上存储的就是0，出现过就存储1最终内存变成4 * 40亿 &#x3D; 160亿字节，而1GB内存&#x3D;10亿多字节若把这些数据放在bit中，原本4字节(32bit)存储一个数，现在一个bit标识处没出现过，等于缩小了32倍也就是 160亿&#x2F;32 ≈ 500MB 123456789进阶：题目一基础上，内存限制为 3KB，但是只用找到一个没出现过的数即可思想：通过3KB&#x2F;4 算出他最多能存储的数组长度&#x3D;750，取小于该长度临近的2的某次方的数：512根据无符号长度大小 2^32 &#x2F; 512 &#x3D; 8388609，等于把整个无符号整数范围划分成512份取40亿数据进行区域划分，只需要统计40亿每个数字属于哪个区域(512份中的一份)，count++因为只有40亿的数据，最终必定有一个区域count是小于 8388609，该区域必有未出现的数根据区域的范围L..R继续划分，直到数据量能够让3KB大小进行bit词频统计 12345进阶：题目一基础上，内存限制为五个变量，但是只用找到一个没出现过的数即可思想：二分L、M、R，一直二分统计区域出现的词频，重复二分未占满的区域，最多二分32次 123456789题目二：32位无符号整数的范围是0~4294967295，现在有40亿个无符号整数，可以使用最多1GB的内存，找出所有出现了两次的数。思想：基于题目一的思想，用两个bit表示一个数出现的频率，出现1次则[01]、2次则[10]、3次及以上则[11]也就是用了500MB * 2 &#x3D; 1G内存，把所有bit是[10]的取出来则是答案 123456789101112131415题目三：有一个包含100亿个URL的大文件，假设每个URL占用64B，请找出其中所有重复的URL【补充】某搜索公司一天的用户搜索词汇是海量的(百亿数据量)，请设计一种求出每天热门Top100词汇的可行办法思想：要确认有多少台机器可用，可以有一台皇帝机通过hash函数%机器数量，把url分散到各个机器上如果一个机器还不够处理，则用第二个hash函数进行分文件处理。第一次分机器，第二次分文件，机器怕的是种类过多导致爆内存，而不是重复数据量大爆补充：分机器、分文件，每个文件的Top100进行PK，可以根据外排,每个文件的Top100中的Top1进行比较也可以用二维堆进行比较，假设三个文件三个堆，再取每个堆的堆顶再构建成一个堆 1234567题目四：32位无符号整数的范围是0~4294967295，现在有40亿个无符号整数可以使用最多3K的内存，怎么找到这40亿个整数的中位数？思路：可以基于题目一的进阶思路，切割成512份，把前面的count累加，能够定位到第20亿小的值处于其中的某一份中如0~16份的count加起来等于19亿，第17份有4亿，那么，第20亿小的值，一定在第17份中的第1亿小的值，分而治之 1234567891011题目五：32位无符号整数的范围是0~4294967295，有一个10G大小的文件，每一行都装着这种类型的数字，整个文件是无序的，给你5G的内存空间，请你输出一个10G大小的文件，就是原文件所有数字排序的结果思路：用一个Map&lt;Integer,Index&gt;和一个小根堆&lt;val,Count&gt;实现，小根堆中是有限个数K，Map的size和K相同遍历一遍，大于堆顶的元素则放入堆中替换堆顶，重排序，小于堆顶的忽略，等于堆顶的Count++这样一轮之后能够得到K个Integer的排序，放入文件中，下次遍历时忽略大于等于上次堆顶的数值一个Map的KeyValue占8个字节，小根堆一个节点也占8个字节，那么K的大小取舍等于5G&#x2F;16字节 搜索二叉树12345搜索二叉树：左树的所有节点都比当前节点小，右树的所有节点都比当前节点大搜索二叉树一定要说明以什么标准来排序经典的搜索二叉树，树上没有重复的用来排序的key值如果有重复节点的需求，可以在一个节点内部增加数据项 123456789101112131415搜索二叉树查询key（查询某个key存在还是不存在）1）如果当前节点的value&#x3D;&#x3D;key，返回true2）如果当前节点的value&lt;key，当前节点向左移动3）如果当前节点的value&gt;key，当前节点向右移动4）如果当前节点变成null，返回false搜索二叉树插入新的key和查询过程一样，但当前节点滑到空的时候，就插入在这里搜索二叉树删除key0）先找到key所在的节点1）如果该节点没有左孩子、没有右孩子，直接删除即可2）如果该节点有左孩子、没有右孩子，直接用左孩子顶替该节点3）如果该节点没有左孩子、有右孩子，直接用右孩子顶替该节点4）如果该节点有左孩子、有右孩子，用该节点后继节点(右树上的最左节点)顶替该节点 1234搜索二叉树特别不讲究1）基础的搜索二叉树，添加、删除时候不照顾平衡性2）数据状况很差时，性能就很差给搜索二叉树引入两个动作：左旋、右旋 123456789101112//遍历查询public Node search(int element) &#123; Node node = root; while (node != null &amp;&amp; node.value != null &amp;&amp; node.value != element) &#123; if (element &lt; node.value) &#123; node = node.left; &#125; else &#123; node = node.right; &#125; &#125; return node;&#125; 12345678910111213141516171819202122232425262728293031//插入public Node insert(int element) &#123; if (root == null) &#123; root = createNode(element, null, null, null); size++; return root; &#125; Node insertParentNode = null; Node searchTempNode = root; //查询新节点应该挂载在哪个父节点中 while (searchTempNode != null &amp;&amp; searchTempNode.value != null) &#123; insertParentNode = searchTempNode; if (element &lt; searchTempNode.value) &#123; searchTempNode = searchTempNode.left; &#125; else &#123; searchTempNode = searchTempNode.right; &#125; &#125; //挂节点 Node newNode = createNode(element, insertParentNode, null, null); if (insertParentNode.value &gt; newNode.value) &#123; insertParentNode.left = newNode; &#125; else &#123; insertParentNode.right = newNode; &#125; size++; return newNode;&#125; 12345678910111213141516171819202122232425262728293031323334//删除节点protected Node delete(Node deleteNode) &#123; if (deleteNode != null) &#123; Node nodeToReturn = null; if (deleteNode != null) &#123; if (deleteNode.left == null) &#123; // 如果该节点没有左孩子、有右孩子，直接用右孩子顶替该节点 // transplant(a,b) b去替换a的环境，a断连掉，把b返回：(返回受影响的节点) nodeToReturn = transplant(deleteNode, deleteNode.right); &#125; else if (deleteNode.right == null) &#123; //如果该节点有左孩子、没有右孩子，直接用左孩子顶替该节点 nodeToReturn = transplant(deleteNode, deleteNode.left); &#125; else &#123; //如果该节点有左孩子、有右孩子，查找该节点的后继节点(右树上的最左节点) Node successorNode = getMinimum(deleteNode.right); //如果后继节点的父节点不是删除的节点，则用后继节点顶替删除节点的位置 if (successorNode.parent != deleteNode) &#123; //把后继节点的右子树驳接到原父节点上 transplant(successorNode, successorNode.right); successorNode.right = deleteNode.right; successorNode.right.parent = successorNode; &#125; //把后继节点驳接到到删除节点的父节点下 transplant(deleteNode, successorNode); successorNode.left = deleteNode.left; successorNode.left.parent = successorNode; nodeToReturn = successorNode; &#125; size--; &#125; return nodeToReturn; &#125; return null;&#125; AVL树123456789AVL树:平衡二叉树1）最严格的平衡性，任何节点左树高度和右树高度差不超过12）往上沿途检查每个节点时，都去检查四种违规情况：LL、RR、LR、RL3）不同情况虽然看起来复杂，但是核心点是：LL（做一次右旋）、RR（做一次左旋）LR和RL（利用旋转让底层那个上到顶部）查询时间复杂度O(logN)单次增&#x2F;删&#x2F;旋转的时间复杂度都是O(1) 12345678910111213 1 2 3 4 5 6上图数字代表添加顺序，当没有添加节点6时，它是平衡的，添加节点6时，节点1的左树高度是3，右树高度是1，所以不平衡节点1是因为 左边（节点2）的左侧（节点4）不平衡的，这种违规情况被称作：LL也就是说，四种违规情况：LL：来源于左树+左树的左侧RR：来源于右树+右树的右侧LR：来源于左树+左树的右侧RL：来源于右树+右树的左侧 123456789101112LL和RR的违规情况很好处理，只要对不平衡的节点(X)进行一次旋转即可LL（做一次右旋）、RR（做一次左旋）而LR和RL需要做两次旋转，但是核心是相同的：LR：找到左树的右侧节点(X.L.R)，利用旋转让这个节点到达不平衡节点(X)的位置即可RL：找到右树的左侧节点(X.R.L)，利用旋转让这个节点到达不平衡节点(X)的位置即可 1 2 3 4 5 67 8在这种情况下删除节点6，会造成X节点个数：X.L&#x3D;3，X.R &#x3D; 1，满足同时违规LL和LR型，只能使用LL型方案解决！！！ 12345678910111213141516171819202122232425//四种违规场景判断：//获取X节点的L和R高度int leftHeight = (X.L == null) ? -1 : X.L.height;int rightHeight = (X.R == null) ? -1 : X.R.height;int nodeBalance = rightHeight - leftHeight;//等于2表示需要做调整， 右树 &gt; 左树if (nodeBalance == 2) &#123; //高度：X.R.R = X.L + 1 表示是RR类型 if (X.R.R != null &amp;&amp; X.R.R.height == leftHeight + 1) &#123; //X进行左旋 然后更新旋转的节点高度 &#125; else &#123; //否则是 RL类型，X.R右旋，然后X左旋，更新旋转节点高度 &#125;&#125; else if (nodeBalance == -2) &#123; //高度：X.L.L = X.R + 1，表示是LL型 if (X.L.L != null &amp;&amp; X.L.L.height == rightHeight + 1) &#123; //X进行右旋，然后更新旋转的节点高度 &#125; else &#123; //否则是LR类型，X.L左旋，然后X右旋，更新旋转节点高度 &#125;&#125; else &#123; //不需要调整&#125; 1234567891011121314151617181920212223242526//左旋protected Node rotateLeft(Node node) &#123; Node temp = node.right; temp.parent = node.parent; node.right = temp.left; if (node.right != null) &#123; node.right.parent = node; &#125; temp.left = node; node.parent = temp; // temp took over node's place so now its parent should point to temp if (temp.parent != null) &#123; if (node == temp.parent.left) &#123; temp.parent.left = temp; &#125; else &#123; temp.parent.right = temp; &#125; &#125; else &#123; root = temp; &#125; return temp;&#125; 1234567891011121314151617181920212223242526//右旋protected Node rotateRight(Node node) &#123; Node temp = node.left; temp.parent = node.parent; node.left = temp.right; if (node.left != null) &#123; node.left.parent = node; &#125; temp.right = node; node.parent = temp; // temp took over node's place so now its parent should point to temp if (temp.parent != null) &#123; if (node == temp.parent.left) &#123; temp.parent.left = temp; &#125; else &#123; temp.parent.right = temp; &#125; &#125; else &#123; root = temp; &#125; return temp;&#125; SB树12345678910Size Balanced Tree：平衡二叉搜索树1）让每一个叔叔节点为头的数，节点个数都不少于其任何一个侄子节点 保证了左右子树的规模不会相差 N+1个节点以上2）也是从底层被影响节点开始向上做路径每个节点检查3）与AVL树非常像，也是四种违规类型：LL、RR、LR、RL4）与AVL树非常像，核心点是：LL（做一次右旋）、RR（做一次左旋）LR和RL（利用旋转让底层那个上到顶部）5）与AVL树不同的是，每轮经过调整后，谁的孩子发生变化了，谁就再查单次增&#x2F;删&#x2F;旋转的时间复杂度都是O(1) 12345SB树在使用时候的改进1）删除时候可以不用检查2）就把平衡性的调整放在插入的时候3）因为这种只要变就递归的特性，别的树没有4）可以在节点上封装别的数据项，来增加功能 12345678910111213假设有函数M(X)，其含义表示查询X节点是否有违规情况： LL: X.L.L(侄子节点) &gt; X.R(叔叔节点) 操作：X节点右旋， 原X.L接替X节点位置，需要递归M(X)和M(原X.L)判断旋转改变位置后是否违规RR: X.R.R(侄子节点) &gt; X.L(叔叔节点)操作：X节点左旋， 原X.R接替X节点位置，需要递归M(X)和M(原X.R)判断旋转改变位置后是否违规LR: X.L.R(侄子节点) &gt; X.R(叔叔节点)操作：X.L.R旋转上来替代X，则需要递归原X节点的M(X)、M(X.L)、M(X.L.R)RL: X.R.L(侄子节点) &gt; X.L(叔叔节点)操作：X.R.L旋转上来替代X，则需要递归原X节点的M(X)、M(X.R)、M(X.R.L) 1234567891011121314//自定义的SB数结构public static class SBTNode&lt;K extends Comparable&lt;K&gt;, V&gt; &#123; public K key; public V value; public SBTNode&lt;K, V&gt; l; //左孩子节点 public SBTNode&lt;K, V&gt; r; //右孩子节点 public int size; // 当前节点有多少个节点(子树节点 + 自身) public SBTNode(K key, V value) &#123; this.key = key; this.value = value; size = 1; //创建时默认是1，只有自己一个 &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279public static class SizeBalancedTreeMap&lt;K extends Comparable&lt;K&gt;, V&gt; &#123; //只要个根节点 private SBTNode&lt;K, V&gt; root; //右旋，返回旋转后的顶部节点 private SBTNode&lt;K, V&gt; rightRotate(SBTNode&lt;K, V&gt; cur) &#123; SBTNode&lt;K, V&gt; leftNode = cur.l; cur.l = leftNode.r; leftNode.r = cur; //cur.l节点直接继承cur的size leftNode.size = cur.size; //cur的旋转后的size需要重新计算 cur.size = (cur.l != null ? cur.l.size : 0) + (cur.r != null ? cur.r.size : 0) + 1; return leftNode; &#125; private SBTNode&lt;K, V&gt; leftRotate(SBTNode&lt;K, V&gt; cur) &#123; SBTNode&lt;K, V&gt; rightNode = cur.r; cur.r = rightNode.l; rightNode.l = cur; rightNode.size = cur.size; cur.size = (cur.l != null ? cur.l.size : 0) + (cur.r != null ? cur.r.size : 0) + 1; return rightNode; &#125; //递归检查平衡 private SBTNode&lt;K, V&gt; maintain(SBTNode&lt;K, V&gt; cur) &#123; if (cur == null) &#123; return null; &#125; //LL if (cur.l != null &amp;&amp; cur.l.l != null &amp;&amp; cur.r != null &amp;&amp; cur.l.l.size &gt; cur.r.size) &#123; //cur节点右旋，原cur.L接替cur节点位置，需要递归M(cur)和M(原cur.L)是否违规 cur = rightRotate(cur); cur.r = maintain(cur.r); cur = maintain(cur); &#125; else if (cur.l != null &amp;&amp; cur.l.r != null &amp;&amp; cur.r != null &amp;&amp; cur.l.r.size &gt; cur.r.size) &#123; //LR类型 左旋+右旋 ，检查cur.l cur.r cur cur.l = leftRotate(cur.l); cur = rightRotate(cur); cur.l = maintain(cur.l); cur.r = maintain(cur.r); cur = maintain(cur); &#125; else if (cur.r != null &amp;&amp; cur.r.r != null &amp;&amp; cur.l != null &amp;&amp; cur.r.r.size &gt; cur.l.size) &#123; //RR cur = leftRotate(cur); cur.l = maintain(cur.l); cur = maintain(cur); &#125; else if (cur.r != null &amp;&amp; cur.r.l != null &amp;&amp; cur.l != null &amp;&amp; cur.r.l.size &gt; cur.l.size) &#123; //RL cur.r = rightRotate(cur.r); cur = leftRotate(cur); cur.l = maintain(cur.l); cur.r = maintain(cur.r); cur = maintain(cur); &#125; return cur; &#125; //查询节点 private SBTNode&lt;K, V&gt; findLastIndex(K key) &#123; //用一个字段缓存最接近这个key的节点，如果查不到这个key，就返回最接近的节点 SBTNode&lt;K, V&gt; pre = root; SBTNode&lt;K, V&gt; cur = root; while (cur != null) &#123; pre = cur; if (key.compareTo(cur.key) == 0) &#123; break; &#125; else if (key.compareTo(cur.key) &lt; 0) &#123; cur = cur.l; &#125; else &#123; cur = cur.r; &#125; &#125; return pre; &#125; private SBTNode&lt;K, V&gt; findLastNoSmallIndex(K key) &#123; SBTNode&lt;K, V&gt; ans = null; SBTNode&lt;K, V&gt; cur = root; while (cur != null) &#123; if (key.compareTo(cur.key) == 0) &#123; ans = cur; break; &#125; else if (key.compareTo(cur.key) &lt; 0) &#123; ans = cur; cur = cur.l; &#125; else &#123; cur = cur.r; &#125; &#125; return ans; &#125; private SBTNode&lt;K, V&gt; findLastNoBigIndex(K key) &#123; SBTNode&lt;K, V&gt; ans = null; SBTNode&lt;K, V&gt; cur = root; while (cur != null) &#123; if (key.compareTo(cur.key) == 0) &#123; ans = cur; break; &#125; else if (key.compareTo(cur.key) &lt; 0) &#123; cur = cur.l; &#125; else &#123; ans = cur; cur = cur.r; &#125; &#125; return ans; &#125; // 现在，以cur为头的树上，加(key, value)这样的记录 // 加完之后，会对cur做检查，该调整调整 // 返回，调整完之后，整棵树的新头部 private SBTNode&lt;K, V&gt; add(SBTNode&lt;K, V&gt; cur, K key, V value) &#123; if (cur == null) &#123; return new SBTNode&lt;K, V&gt;(key, value); &#125; else &#123; cur.size++; if (key.compareTo(cur.key) &lt; 0) &#123; cur.l = add(cur.l, key, value); &#125; else &#123; cur.r = add(cur.r, key, value); &#125; return maintain(cur); &#125; &#125; // 在cur这棵树上，删掉key所代表的节点 // 返回cur这棵树的新头部 // 删除不调整平衡性 private SBTNode&lt;K, V&gt; delete(SBTNode&lt;K, V&gt; cur, K key) &#123; cur.size--; if (key.compareTo(cur.key) &gt; 0) &#123; cur.r = delete(cur.r, key); &#125; else if (key.compareTo(cur.key) &lt; 0) &#123; cur.l = delete(cur.l, key); &#125; else &#123; // 当前要删掉cur if (cur.l == null &amp;&amp; cur.r == null) &#123; // free cur memory -&gt; C++ cur = null; &#125; else if (cur.l == null &amp;&amp; cur.r != null) &#123; // free cur memory -&gt; C++ cur = cur.r; &#125; else if (cur.l != null &amp;&amp; cur.r == null) &#123; // free cur memory -&gt; C++ cur = cur.l; &#125; else &#123; // 有左有右 SBTNode&lt;K, V&gt; pre = null; SBTNode&lt;K, V&gt; des = cur.r; des.size--; while (des.l != null) &#123; pre = des; des = des.l; des.size--; &#125; if (pre != null) &#123; pre.l = des.r; des.r = cur.r; &#125; des.l = cur.l; des.size = des.l.size + (des.r == null ? 0 : des.r.size) + 1; // free cur memory -&gt; C++ cur = des; &#125; &#125; //如果删除SB树在删除的时候要调整平衡性，则在这里加 //cur = maintain(cur); return cur; &#125; private SBTNode&lt;K, V&gt; getIndex(SBTNode&lt;K, V&gt; cur, int kth) &#123; if (kth == (cur.l != null ? cur.l.size : 0) + 1) &#123; return cur; &#125; else if (kth &lt;= (cur.l != null ? cur.l.size : 0)) &#123; return getIndex(cur.l, kth); &#125; else &#123; return getIndex(cur.r, kth - (cur.l != null ? cur.l.size : 0) - 1); &#125; &#125; public int size() &#123; return root == null ? 0 : root.size; &#125; public boolean containsKey(K key) &#123; if (key == null) &#123; throw new RuntimeException(\"invalid parameter.\"); &#125; SBTNode&lt;K, V&gt; lastNode = findLastIndex(key); return lastNode != null &amp;&amp; key.compareTo(lastNode.key) == 0 ? true : false; &#125; public void put(K key, V value) &#123; if (key == null) &#123; throw new RuntimeException(\"invalid parameter.\"); &#125; SBTNode&lt;K, V&gt; lastNode = findLastIndex(key); if (lastNode != null &amp;&amp; key.compareTo(lastNode.key) == 0) &#123; lastNode.value = value; &#125; else &#123; //添加节点进二叉树中，需要重新遍历，调整后返回调整之后的root root = add(root, key, value); &#125; &#125; public void remove(K key) &#123; if (key == null) &#123; throw new RuntimeException(\"invalid parameter.\"); &#125; if (containsKey(key)) &#123; root = delete(root, key); &#125; &#125; public K getIndexKey(int index) &#123; if (index &lt; 0 || index &gt;= this.size()) &#123; throw new RuntimeException(\"invalid parameter.\"); &#125; return getIndex(root, index + 1).key; &#125; public V getIndexValue(int index) &#123; if (index &lt; 0 || index &gt;= this.size()) &#123; throw new RuntimeException(\"invalid parameter.\"); &#125; return getIndex(root, index + 1).value; &#125; public V get(K key) &#123; if (key == null) &#123; throw new RuntimeException(\"invalid parameter.\"); &#125; SBTNode&lt;K, V&gt; lastNode = findLastIndex(key); if (lastNode != null &amp;&amp; key.compareTo(lastNode.key) == 0) &#123; return lastNode.value; &#125; else &#123; return null; &#125; &#125; public K firstKey() &#123; if (root == null) &#123; return null; &#125; SBTNode&lt;K, V&gt; cur = root; while (cur.l != null) &#123; cur = cur.l; &#125; return cur.key; &#125; public K lastKey() &#123; if (root == null) &#123; return null; &#125; SBTNode&lt;K, V&gt; cur = root; while (cur.r != null) &#123; cur = cur.r; &#125; return cur.key; &#125; public K floorKey(K key) &#123; if (key == null) &#123; throw new RuntimeException(\"invalid parameter.\"); &#125; SBTNode&lt;K, V&gt; lastNoBigNode = findLastNoBigIndex(key); return lastNoBigNode == null ? null : lastNoBigNode.key; &#125; public K ceilingKey(K key) &#123; if (key == null) &#123; throw new RuntimeException(\"invalid parameter.\"); &#125; SBTNode&lt;K, V&gt; lastNoSmallNode = findLastNoSmallIndex(key); return lastNoSmallNode == null ? null : lastNoSmallNode.key; &#125;&#125; 跳表12345跳表（skiplist）1）结构上根本和搜索二叉树无关2）利用随机概率分布来使得高层索引可以无视数据规律，做到整体性能优良3）思想是所有有序表中最先进的4）结构简单就是多级单链表 123456789101.以KEY&#x3D;NULL作为最左节点且链表中最小的节点2.每个节点的索引指针数量是利用随机概率分布得到的3.KEY&#x3D;NULL的索引指针数量会根据其他节点的指针数量做扩大4.每次索引节点时，索引到无结果时，会进行指针下跳的操作如上述图中，黄色节点表示当前链表，蓝色节点表示是当前链表准备新增的节点1.步骤一中添加nextNodes.size&#x3D;3的节点3， NULL节点会先对自身的nextNodes进行扩大 1 -&gt; 32.NULL节点中寻找小于且最接近节点3的节点，然后改变索引指针指向3.步骤二中添加nextNodes.size&#x3D;2的节点5，NULL无需扩容，找到了最接近节点5的节点34.由于节点5无高层索引指针，所以进行索引指针下跳，到第二条索引指针，进行连接 1234567在理想情况下，层数应该是这样的：...4: N&#x2F;8个节点3: N&#x2F;4个节点2: N&#x2F;2个节点1: N个节点查询的时间复杂度是O(logN) 123456789101112131415161718192021222324252627282930// 跳表的节点定义public static class SkipListNode&lt;K extends Comparable&lt;K&gt;, V&gt; &#123; public K key; public V val; //当前节点有多条指向外部的指针 //跳表中认为 key:null 是链表中的最小节点 //经典的跳表的nextNodes的size是根据随机数随机产生的 //头节点key:null 的nextNodes如果发现有其他节点size比他大，就会扩充得和他一样大 public ArrayList&lt;SkipListNode&lt;K, V&gt;&gt; nextNodes; public SkipListNode(K k, V v) &#123; key = k; val = v; nextNodes = new ArrayList&lt;SkipListNode&lt;K, V&gt;&gt;(); &#125; // 遍历的时候，如果是往右遍历到的null(next == null), 遍历结束 // 头(null), 头节点的null，认为最小 // node -&gt; 头，node(null, \"\") node.isKeyLess(!null) true // node里面的key是否比otherKey小，true，不是false public boolean isKeyLess(K otherKey) &#123; // otherKey == null -&gt; false return otherKey != null &amp;&amp; (key == null || key.compareTo(otherKey) &lt; 0); &#125; public boolean isKeyEqual(K otherKey) &#123; return (key == null &amp;&amp; otherKey == null) || (key != null &amp;&amp; otherKey != null &amp;&amp; key.compareTo(otherKey) == 0); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189public static class SkipListMap&lt;K extends Comparable&lt;K&gt;, V&gt; &#123; //随机指针的概率 55开 private static final double PROBABILITY = 0.5; // &lt; 0.5 继续做，&gt;=0.5 停 private SkipListNode&lt;K, V&gt; head; //不同Key的数量 private int size; //目前最大索引指针高度， 从0层开始 private int maxLevel; public SkipListMap() &#123; //初始化跳表时默认加入 Key：null 节点 head = new SkipListNode&lt;K, V&gt;(null, null); head.nextNodes.add(null); size = 0; maxLevel = 0; &#125; // 从最高层开始，一路找下去， // 最终，找到第0层的&lt;key的最右的节点 private SkipListNode&lt;K, V&gt; mostRightLessNodeInTree(K key) &#123; if (key == null) &#123; return null; &#125; //从最高层开始遍历 int level = maxLevel; SkipListNode&lt;K, V&gt; cur = head; // 从上层跳下层 while (level &gt;= 0) &#123; // cur level -&gt; level-1 //从左往右走 cur = mostRightLessNodeInLevel(key, cur, level--); &#125; return cur; &#125; // 在level层里，如何往右移动 // 现在来到的节点是cur，来到了cur的level层，在level层上，找到&lt;key最后一个节点并返回 private SkipListNode&lt;K, V&gt; mostRightLessNodeInLevel(K key, SkipListNode&lt;K, V&gt; cur, int level) &#123; SkipListNode&lt;K, V&gt; next = cur.nextNodes.get(level); while (next != null &amp;&amp; next.isKeyLess(key)) &#123; cur = next; next = cur.nextNodes.get(level); &#125; return cur; &#125; public boolean containsKey(K key) &#123; if (key == null) &#123; return false; &#125; SkipListNode&lt;K, V&gt; less = mostRightLessNodeInTree(key); SkipListNode&lt;K, V&gt; next = less.nextNodes.get(0); return next != null &amp;&amp; next.isKeyEqual(key); &#125; public void put(K key, V value) &#123; if (key == null) &#123; return; &#125; //找到0层上，最右一个，&lt; Key的Node SkipListNode&lt;K, V&gt; less = mostRightLessNodeInTree(key); //基于这个节点在第0层取右边的节点 SkipListNode&lt;K, V&gt; find = less.nextNodes.get(0); //右边的节点如果不为空，必定要么大于Key，要么等于Key if (find != null &amp;&amp; find.isKeyEqual(key)) &#123; find.val = value; &#125; else &#123; //find == null || find.key &gt; key //新增节点，因为找不到匹配他的节点，在当前定位的less节点后面做节点插入操作 //节点数量++ size++; //随机random出新增节点的层数，随机数小于0.5则层数++ int newNodeLevel = 0; while (Math.random() &lt; PROBABILITY) &#123; newNodeLevel++; &#125; //比较新节点层数和头节点层数，如果比头节点层数大，头节点扩张层数 while (newNodeLevel &gt; maxLevel) &#123; //在未加入节点时，头节点扩张的层数的next指针指向NULL head.nextNodes.add(null); maxLevel++; &#125; SkipListNode&lt;K, V&gt; newNode = new SkipListNode&lt;K, V&gt;(key, value); //创建节点后默认节点的层数指向NULL for (int i = 0; i &lt;= newNodeLevel; i++) &#123; newNode.nextNodes.add(null); &#125; int level = maxLevel; SkipListNode&lt;K, V&gt; pre = head; //例子： //head: -&gt;null(新增层) newNode: -&gt;null // : -&gt;oldNode-&gt;null : -&gt;null //head: -&gt;newNode -&gt;null // : -&gt;newNode -&gt;oldNode -&gt; null //while循环Level下跳 while (level &gt;= 0) &#123; //返回第Level层中最靠右且小于Key的节点 pre = mostRightLessNodeInLevel(key, pre, level); //如果当前节点的层数小于等于新增节点的层数，则插入当前层 if (level &lt;= newNodeLevel) &#123; //把新增结点的next指针指向上一个节点第Level层的next指针 newNode.nextNodes.set(level, pre.nextNodes.get(level)); //上一个节点的next指针指向当前节点 pre.nextNodes.set(level, newNode); &#125; level--; &#125; &#125; &#125; public V get(K key) &#123; if (key == null) &#123; return null; &#125; SkipListNode&lt;K, V&gt; less = mostRightLessNodeInTree(key); SkipListNode&lt;K, V&gt; next = less.nextNodes.get(0); return next != null &amp;&amp; next.isKeyEqual(key) ? next.val : null; &#125; public void remove(K key) &#123; if (containsKey(key)) &#123; size--; int level = maxLevel; SkipListNode&lt;K, V&gt; pre = head; while (level &gt;= 0) &#123; pre = mostRightLessNodeInLevel(key, pre, level); SkipListNode&lt;K, V&gt; next = pre.nextNodes.get(level); // 1）在这一层中，pre下一个就是key // 2）在这一层中，pre的下一个key是&gt;要删除key if (next != null &amp;&amp; next.isKeyEqual(key)) &#123; //删除 pre -&gt; 删除的Key - &gt;pre.next.next 指向到下下个节点 pre.nextNodes.set(level, next.nextNodes.get(level)); &#125; //缩层，刚好删除了最高层唯一的节点 // 在level层只有一个节点了，就是默认节点head if (level != 0 &amp;&amp; pre == head &amp;&amp; pre.nextNodes.get(level) == null) &#123; head.nextNodes.remove(level); maxLevel--; &#125; level--; &#125; &#125; &#125; public K firstKey() &#123; return head.nextNodes.get(0) != null ? head.nextNodes.get(0).key : null; &#125; public K lastKey() &#123; int level = maxLevel; SkipListNode&lt;K, V&gt; cur = head; while (level &gt;= 0) &#123; SkipListNode&lt;K, V&gt; next = cur.nextNodes.get(level); while (next != null) &#123; cur = next; next = cur.nextNodes.get(level); &#125; level--; &#125; return cur.key; &#125; //向上取 &gt;= key 的节点 public K ceillingKey(K key) &#123; if (key == null) &#123; return null; &#125; SkipListNode&lt;K, V&gt; less = mostRightLessNodeInTree(key); SkipListNode&lt;K, V&gt; next = less.nextNodes.get(0); return next != null ? next.key : null; &#125; public K floorKey(K key) &#123; if (key == null) &#123; return null; &#125; SkipListNode&lt;K, V&gt; less = mostRightLessNodeInTree(key); SkipListNode&lt;K, V&gt; next = less.nextNodes.get(0); return next != null &amp;&amp; next.isKeyEqual(key) ? next.key : less.key; &#125; public int size() &#123; return size; &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://midkuro.gitee.io/categories/algorithm/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"algorithm","slug":"algorithm","permalink":"https://midkuro.gitee.io/tags/algorithm/"}]},{"title":"'数据结构与算法 训练营一期'","slug":"algorithm-trainingcamp1","date":"2020-10-30T14:32:00.000Z","updated":"2020-12-20T14:36:25.308Z","comments":true,"path":"2020/10/30/algorithm-trainingcamp1/","link":"","permalink":"https://midkuro.gitee.io/2020/10/30/algorithm-trainingcamp1/","excerpt":"","text":"训练营一期窗口滑动12345678910滑动窗口是什么？滑动窗口是一种想象出来的数据结构：滑动窗口有左边界L和有边界R在数组或者字符串或者一个序列上，记为S，窗口就是S[L..R]这一部分L往右滑意味着一个样本出了窗口，R往右滑意味着一个样本进了窗口L和R都只能往右滑滑动窗口能做什么？滑动窗口、首尾指针等技巧，说白了是一种求解问题的流程设计。 12345滑动内最大值和最小值的更新结构:窗口不管L还是R滑动之后，都会让窗口呈现新状况，如何能够更快的得到窗口当前状况下的最大值和最小值？最好平均下来复杂度能做到O(1)利用单调双端队列！ 123456思想：使用单调双端队列（头部由大到小）(队列里存储的是数组下标)当R新增的值V比队列尾部的最小值X大，则弹出X，再次比较，直到队列的尾部数据比V大，或者队列为空，压入V值。当L移动时，比较当前下标和队列下标，若相等，则弹出。获取滑动窗口内当前最大值：peek队列头部总代价：O(N) 每次平均：O(1) 12345题目一:假设一个固定大小为W的窗口，依次划过arr，返回每一次滑出状况的最大值例如，arr &#x3D; [4,3,5,4,3,3,6,7], W &#x3D; 3返回：[5,5,5,4,6,7] 12345678910111213141516171819202122232425262728public static int[] getMaxWindow(int[] arr, int w) &#123; if (arr == null || w &lt; 1 || arr.length &lt; w) &#123; return null; &#125; // 其中放的是位置，头代表 （大-&gt;小）尾 LinkedList&lt;Integer&gt; qmax = new LinkedList&lt;Integer&gt;(); int[] res = new int[arr.length - w + 1]; int index = 0; // L...R // i for (int R = 0; R &lt; arr.length; R++) &#123; // 当前让 i -&gt; [i] 进窗口 ， i 就是 r // R -&gt; 值 可以放在比他大的数后，或者空 while (!qmax.isEmpty() &amp;&amp; arr[qmax.peekLast()] &lt;= arr[R]) &#123; qmax.pollLast(); &#125; qmax.addLast(R); // 数进来了 // 如果窗口没有形成W的长度之前，不弹出数字的 if (qmax.peekFirst() == R - w) &#123; qmax.pollFirst(); &#125; // 以上窗口更新做完了 if (R &gt;= w - 1) &#123; res[index++] = arr[qmax.peekFirst()]; &#125; &#125; return res;&#125; 12345题目二:给定一个整型数组arr，和一个整数num某个arr中的子数组sub，如果想达标，必须满足：sub中最大值 – sub中最小值 &lt;&#x3D; num，返回arr中达标子数组的数量 12345678思路：一个[L ~ R]窗口内，如果他达标，那么在[L ~ R]缩小范围内的子数组必定达标。一个[L ~ R]窗口内，如果他不达标，那么在[L ~ R]扩大范围内的数组必定不达标。两个滑动窗口，一个存储MAX，一个存储MIN，MAX - MIN &lt;&#x3D; num,一直滑动 (R &#x3D; R +1)当左闭右开区间：[L ~ R) 的 MAX-MIN&gt;num 时停下来（R 进队列）当前滑动的R - L就是当前以L开头达标的子数组数量然后L + 1，再次判断 当前 L ~ R + 1的 Max-MIN &gt; num ? 周而复始 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static int getNum(int[] arr, int num) &#123; if (arr == null || arr.length == 0) &#123; return 0; &#125; LinkedList&lt;Integer&gt; qmin = new LinkedList&lt;Integer&gt;(); LinkedList&lt;Integer&gt; qmax = new LinkedList&lt;Integer&gt;(); int L = 0; int R = 0; // [L..R) -&gt; [0,0) 窗口内无数 [1,1) // [0,1) -&gt; [0~0] int res = 0; while (L &lt; arr.length) &#123; // L是开头位置，尝试每一个开头 // 如果此时窗口的开头是L,下面的while工作:R向右扩到违规为止 while (R &lt; arr.length) &#123; // R是最后一个达标位置的再下一个 while (!qmin.isEmpty() &amp;&amp; arr[qmin.peekLast()] &gt;= arr[R]) &#123; qmin.pollLast(); &#125; qmin.addLast(R); // R -&gt; arr[R], while (!qmax.isEmpty() &amp;&amp; arr[qmax.peekLast()] &lt;= arr[R]) &#123; qmax.pollLast(); &#125; qmax.addLast(R); //当不达标时break，结算达标的数据 if (arr[qmax.getFirst()] - arr[qmin.getFirst()] &gt; num) &#123; break; &#125; R++; &#125; // R是最后一个达标位置的再下一个，第一个违规的位置 res += R - L; //L要向右移动，判断窗口内的数据index是否过期 if (qmin.peekFirst() == L) &#123; qmin.pollFirst(); &#125; if (qmax.peekFirst() == L) &#123; qmax.pollFirst(); &#125; L++; &#125; return res;&#125; 单调栈12345678910单调栈是什么？一种特别设计的栈结构，为了解决如下的问题：给定一个可能含有重复值的数组arr，i位置的数一定存在如下两个信息1）arr[i]的左侧离i最近并且小于(或者大于)arr[i]的数在哪？2）arr[i]的右侧离i最近并且小于(或者大于)arr[i]的数在哪？如果想得到arr中所有位置的两个信息，怎么能让得到信息的过程尽量快。那么到底怎么设计呢？ 12345思想：一个栈，从栈底到栈顶由小到大，如果压入的值V比栈顶的X小，则弹出X， X左侧最近最小值则是栈中X下的值，X右侧最近最小值则是压入的V值栈中可以通过存储一个数组（存储重复值的index）的形式（解决数据相等的问题）时间复杂度：O(N) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// arr [3, 2, 1, 4, 5] // 0 1 2 3 4 // [ // 0 : [-1, 1 ] // 1 : [-1, 2 ] // ... // ] // public static int[][] getNearLess(int[] arr) &#123; int[][] res = new int[arr.length][2]; // List&lt;Integer&gt; -&gt; 放的是位置，同样值的东西，位置压在一起 // 代表值 底 -&gt; 顶 小 -&gt; 大 Stack&lt;List&lt;Integer&gt;&gt; stack = new Stack&lt;&gt;(); for (int i = 0; i &lt; arr.length; i++) &#123; // i -&gt; arr[i] 进栈 // 底 -&gt; 顶， 小 -&gt; 大 //当栈中为空或者栈顶元素大于压入栈的元素时，弹出栈顶元素进行结算 while (!stack.isEmpty() &amp;&amp; arr[stack.peek().get(0)] &gt; arr[i]) &#123; List&lt;Integer&gt; popIs = stack.pop(); // 取位于下面位置的列表中，最晚加入的那个的数组index int leftLessIndex = stack.isEmpty() ? -1 : stack.peek().get(stack.peek().size() - 1); //栈中相同值，不同index的数据，他们的答案都是一样的 for (Integer popi : popIs) &#123; res[popi][0] = leftLessIndex; res[popi][1] = i; &#125; &#125; // 如果压入的值和栈顶中的值相等的、加到栈顶的数组index列表中 if (!stack.isEmpty() &amp;&amp; arr[stack.peek().get(0)] == arr[i]) &#123; stack.peek().add(Integer.valueOf(i)); &#125; else &#123; //如果压入的值比栈顶的值小，新开辟一个数组，压入栈 ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(i); stack.push(list); &#125; &#125; //遍历结束，栈中还有元素，弹出结算 while (!stack.isEmpty()) &#123; List&lt;Integer&gt; popIs = stack.pop(); // 取位于下面位置的列表中，最晚加入的那个 int leftLessIndex = stack.isEmpty() ? -1 : stack.peek().get(stack.peek().size() - 1); for (Integer popi : popIs) &#123; res[popi][0] = leftLessIndex; res[popi][1] = -1; &#125; &#125; return res; &#125; 1234题目三：给定一个只包含正整数的数组arr，arr中任何一个子数组sub，一定都可以算出(sub累加和 )* (sub中的最小值)是什么，那么所有子数组中，这个值最大是多少？ 123456789101112131415161718192021222324public static int max(int[] arr) &#123; int size = arr.length; int[] sums = new int[size]; sums[0] = arr[0]; for (int i = 1; i &lt; size; i++) &#123; sums[i] = sums[i - 1] + arr[i]; &#125; int max = Integer.MIN_VALUE; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); for (int i = 0; i &lt; size; i++) &#123; //当arr[i]小于 栈顶元素时，结算栈中大于i的值，每次弹出一个值 while (!stack.isEmpty() &amp;&amp; arr[stack.peek()] &gt;= arr[i]) &#123; int j = stack.pop(); //以j下标的元素做最小值，计算[peck().... j ....i] 区间的结果 max = Math.max(max, (stack.isEmpty() ? sums[i - 1] : (sums[i - 1] - sums[stack.peek()])) * arr[j]); &#125; stack.push(i); &#125; while (!stack.isEmpty()) &#123; int j = stack.pop(); max = Math.max(max, (stack.isEmpty() ? sums[size - 1] : (sums[size - 1] - sums[stack.peek()])) * arr[j]); &#125; return max;&#125; 斐波那契数列12345610^75次方怎么计算最快？75 &#x3D; 64 + 8 + 2 + 1 &#x3D; 1001011 定义t &#x3D; 10^1 ，每次循环，t &#x3D; t * t， 二进制 1001011 位上为1，则result * t所以10^75 &#x3D; 10^64 * 10^8 * 10^2 * 10^1 其中 t自乘了6次O(log75) 12341）斐波那契数列的线性求解（O(N)）的方式非常好理解2）同时利用线性代数，也可以改写出另一种表示 | F(N) , F(N-1) | &#x3D; | F(2), F(1) | * 某个二阶矩阵的N-2次方3）求出这个二阶矩阵，进而最快求出这个二阶矩阵的N-2次方 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public static int f3(int n) &#123; if (n &lt; 1) &#123; return 0; &#125; if (n == 1 || n == 2) &#123; return 1; &#125; // [ 1 ,1 ] // [ 1, 0 ] int[][] base = &#123; &#123; 1, 1 &#125;, &#123; 1, 0 &#125; &#125;; int[][] res = matrixPower(base, n - 2); return res[0][0] + res[1][0];&#125;//求某个矩阵的 p次方public static int[][] matrixPower(int[][] m, int p) &#123; int[][] res = new int[m.length][m[0].length]; for (int i = 0; i &lt; res.length; i++) &#123; res[i][i] = 1; &#125; // res = 矩阵中的1 单位矩阵 int[][] tmp = m;// 矩阵1次方 for (; p != 0; p &gt;&gt;= 1) &#123; if ((p &amp; 1) != 0) &#123; res = muliMatrix(res, tmp); &#125; tmp = muliMatrix(tmp, tmp); &#125; return res;&#125;// 两个矩阵乘完之后的结果返回public static int[][] muliMatrix(int[][] m1, int[][] m2) &#123; int[][] res = new int[m1.length][m2[0].length]; for (int i = 0; i &lt; m1.length; i++) &#123; for (int j = 0; j &lt; m2[0].length; j++) &#123; for (int k = 0; k &lt; m2.length; k++) &#123; res[i][j] += m1[i][k] * m2[k][j]; &#125; &#125; &#125; return res;&#125; 12345678910111213类似斐波那契数列的递归优化如果某个递归，除了初始项之外，具有如下的形式F(N) &#x3D; C1 * F(N) + C2 * F(N-1) + … + Ck * F(N-k) ( C1…Ck 和k都是常数)并且这个递归的表达式是严格的、不随条件转移的那么都存在类似斐波那契数列的优化，时间复杂度都能优化成O(logN) F(N) &#x3D; F(N-1) + F(N-1) 是一个二阶系数问题公式：|F(N),F(N- K + 1)| &#x3D; |F(1),F(2)...F(K)| * 某个K阶矩阵的N-K次方 123456题目二：第一年农场有1只成熟的母牛A，往后的每年：1）每一只成熟的母牛都会生一只母牛2）每一只新出生的母牛都在出生的第三年成熟3）每一只母牛永远不会死返回N年后牛的数量 1234567891011121314151617public static int c3(int n) &#123; if (n &lt; 1) &#123; return 0; &#125; if (n == 1 || n == 2 || n == 3) &#123; return n; &#125; int[][] base = &#123; &#123; 1, 1, 0 &#125;, &#123; 0, 0, 1 &#125;, &#123; 1, 0, 0 &#125; &#125;; int[][] res = matrixPower(base, n - 3); // &#123;|x1,x2,x3| //|3,2,1| * |y1,y2,y3| = 3 * x1 + 2 * y1 + 1 * z1 // |z1,z2,z3|&#125; return 3 * res[0][0] + 2 * res[1][0] + res[2][0];&#125; 1234567题目三一个人可以一次往上迈1个台阶，也可以迈2个台阶返回这个人迈上N级台阶的方法数思路：最后一次迈台阶，分迈1个台阶和2个台阶，所以f(n) &#x3D; f(n - 1) + f(n - 2)和斐波那契数列唯一不同的，就是基数[1,1] 和 [1,2]的区别，其他矩阵计算均相同 123给定一个数N，想象只由0和1两种字符，组成的所有长度为N的字符串如果某个字符串,任何0字符的左边都有1紧挨着,认为这个字符串达标返回有多少达标的字符串 123456思路：如果f(n)第一个字符是0，[0.....]，那么不管后续怎么变化，都不满足结果所以f(n) &#x3D; [1 [n-1....]]n - 1 位置 &#x3D; 0 的话，第三个位置只能是1，也就是f(n - 2) 的结果n - 1 位置 &#x3D; 1 的话，第三个位置可以是0，可以是1，也就是f(n - 1)的结果所以f(n) &#x3D; f(n - 1) + f(n - 2) 1234给定一个黑盒函数f(),等概率返回1~7，请问怎么封装该函数返回等概率1~10？思路：把1~3的值当做0,4~6的值当做1，摇到7则重新摇，然后组装二进制[0000] 摇4次填入二进制值，大于10则重新摇 1234给定一个黑盒函数f()，P概率返回0,1-P的概率返回1，请问怎么封装成等概率返回0和1？思路：二进制[00]，把摇到的结果塞进二进制，若出现[00]或者[11]则重新摇，出现[01]或者[10]的概率都是p * (1 - p) 蓄水池算法12345解决的问题：假设有一个源源吐出不同球的机器，只有装下10个球的袋子，每一个吐出的球，要么放入袋子，要么永远扔掉如何做到机器吐出每一个球之后，所有吐出的球都等概率被放进袋子里 123456思想：前十个球直接丢到袋子中，当11号球未吐出之前，入袋子的概率是100%，当第N个球吐出后，设定他入袋的概率是10&#x2F;N假设1号球被扔掉，那么它的概率被扔掉的概率是(10&#x2F;N) * (1&#x2F;10) &#x3D; 1&#x2F;N，那么1号球还在袋子的概率就是 1 * (1 - 1&#x2F;N) &#x3D; 10&#x2F;N假设13号球以10&#x2F;13的概率入袋了，当吐出14号球时，13号球还在袋的概率是：10&#x2F;13 * (1 - (10&#x2F;14 * 1&#x2F;10)) &#x3D; 10&#x2F;14以此类推，当吐出N个球时，前面的球在袋子中的概率都是10&#x2F;N，概率均等。 1234567891011121314151617181920212223242526272829303132333435public static class RandomBox &#123; private int[] bag; private int N; private int count; public RandomBox(int capacity) &#123; bag = new int[capacity]; N = capacity; count = 0; &#125; private int rand(int max) &#123; return (int) (Math.random() * max) + 1; &#125; public void add(int num) &#123; count++; if (count &lt;= N) &#123; bag[count - 1] = num; &#125; else &#123; if (rand(count) &lt;= N) &#123; bag[rand(N) - 1] = num; &#125; &#125; &#125; public int[] choices() &#123; int[] ans = new int[N]; for (int i = 0; i &lt; N; i++) &#123; ans[i] = bag[i]; &#125; return ans; &#125;&#125; KMP算法123KMP算法核心1）如何理解next数组2）如何利用next数组加速匹配过程，优化时的两个实质！ 123假设字符串str长度为N，字符串match长度为M，M &lt;&#x3D; N想确定str中是否有某个子串是等于match的。时间复杂度O(N) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// O(N)public static int getIndexOf(String s, String m) &#123; if (s == null || m == null || m.length() &lt; 1 || s.length() &lt; m.length()) &#123; return -1; &#125; char[] str = s.toCharArray(); char[] match = m.toCharArray(); int x = 0; // str中当前比对到的位置 int y = 0; // match中当前比对到的位置 // M M &lt;= N O(M) int[] next = getNextArray(match); // next[i] match中i之前的字符串match[0..i-1] // O(N) while (x &lt; str.length &amp;&amp; y &lt; match.length) &#123; if (str[x] == match[y]) &#123; x++; y++; &#125; else if (next[y] == -1) &#123; // y == 0 x++; &#125; else &#123; y = next[y]; &#125; &#125; //当x 越界 若 y不越界，则表示当前y索引不等于match长度，返回-1 //当x 越界 若 y也越界，表示y等于x的末尾串 //当y 越界 则返回 y在x的中的index return y == match.length ? x - y : -1;&#125;// M O(M)//获取match字符中，每i个字符的 [0 ~ i-1]位置，头部和尾部相等得到字符长度public static int[] getNextArray(char[] match) &#123; if (match.length == 1) &#123; return new int[] &#123; -1 &#125;; &#125; int[] next = new int[match.length]; next[0] = -1; //默认第一个字符是-1 next[1] = 0; //默认第二个字符是0，因为前面只有一个字符 int i = 2; // cn代表，cn位置的字符，是当前和i-1位置比较的字符 等价：cn = next[i - 1] int cn = 0; while (i &lt; next.length) &#123; if (match[i - 1] == match[cn]) &#123; // 跳出来的时候 next[i++] = ++cn; //等同于以下三句： //next[i] = cn + 1 当匹配到等长的字符时 // i++; 移动指针 // cn++; 由于cn = next[i - 1]，而cn也要向右移动一步 &#125; else if (cn &gt; 0) &#123; //如果不相等，则跳到next[i - 1]上继续对比 cn = next[cn]; &#125; else &#123; next[i++] = 0; &#125; &#125; return next;&#125; 1234567有一个字符串X,判断另一个字符串V是否是该字符串的这种结构：x &#x3D; &quot;123456&quot; V &#x3D; &quot;234561&quot; 结果：truex &#x3D; &quot;123456&quot; V &#x3D; &quot;345612&quot; 结果：truex &#x3D; &quot;123456&quot; V &#x3D; &quot;456123&quot; 结果：truex &#x3D; &quot;123456&quot; V &#x3D; &quot;234516&quot; 结果: false思路：把&quot;123456&quot;自身头尾拼接，变成 “123456123456”，只要该字符串包含V，则正确 123给定两棵二叉树的头节点head1和head2想知道head1中是否有某个子树的结构和head2完全一样 123456789101112131415161718192021222324252627282930313233343536// 暴力递归// big做头节点的树，其中是否有某棵子树的结构，是和small为头的树，完全一样的// 时间复杂度：O(big.size * small.size)public static boolean containsTree1(Node big, Node small) &#123; if (small == null) &#123; return true; &#125; // small != null if (big == null) &#123; return false; &#125; // big！=null small!=null if (isSameValueStructure(big, small)) &#123; return true; &#125; return containsTree1(big.left, small) || containsTree1(big.right, small);&#125;// head1为头的树，是否在结构对应上，完全和head2一样public static boolean isSameValueStructure(Node head1, Node head2) &#123; if (head1 == null &amp;&amp; head2 != null) &#123; return false; &#125; if (head1 != null &amp;&amp; head2 == null) &#123; return false; &#125; if (head1 == null &amp;&amp; head2 == null) &#123; return true; &#125; if (head1.value != head2.value) &#123; return false; &#125; // head1.value == head2.value return isSameValueStructure(head1.left, head2.left) &amp;&amp; isSameValueStructure(head1.right, head2.right);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394//KMP算法//思想：对big和small做先序遍历，用KMP比较生成的两个数组public static boolean containsTree2(Node big, Node small) &#123; if (small == null) &#123; return true; &#125; if (big == null) &#123; return false; &#125; ArrayList&lt;String&gt; b = preSerial(big); ArrayList&lt;String&gt; s = preSerial(small); String[] str = new String[b.size()]; for (int i = 0; i &lt; str.length; i++) &#123; str[i] = b.get(i); &#125; String[] match = new String[s.size()]; for (int i = 0; i &lt; match.length; i++) &#123; match[i] = s.get(i); &#125; return getIndexOf(str, match) != -1;&#125;//先序遍历public static ArrayList&lt;String&gt; preSerial(Node head) &#123; ArrayList&lt;String&gt; ans = new ArrayList&lt;&gt;(); pres(head, ans); return ans;&#125;public static void pres(Node head, ArrayList&lt;String&gt; ans) &#123; if (head == null) &#123; ans.add(null); &#125; else &#123; ans.add(String.valueOf(head.value)); pres(head.left, ans); pres(head.right, ans); &#125;&#125;//这里为什么用两个数组？如果拼接成两个字符串会有什么后果？//原因：123_1_n_n_n 和 23_1_n_n_n 会造成子串匹配，但这不是我们想要的结果。public static int getIndexOf(String[] str1, String[] str2) &#123; if (str1 == null || str2 == null || str1.length &lt; 1 || str1.length &lt; str2.length) &#123; return -1; &#125; int x = 0; int y = 0; int[] next = getNextArray(str2); while (x &lt; str1.length &amp;&amp; y &lt; str2.length) &#123; if (isEqual(str1[x], str2[y])) &#123; x++; y++; &#125; else if (next[y] == -1) &#123; x++; &#125; else &#123; y = next[y]; &#125; &#125; return y == str2.length ? x - y : -1;&#125;public static int[] getNextArray(String[] ms) &#123; if (ms.length == 1) &#123; return new int[] &#123; -1 &#125;; &#125; int[] next = new int[ms.length]; next[0] = -1; next[1] = 0; int i = 2; int cn = 0; while (i &lt; next.length) &#123; if (isEqual(ms[i - 1], ms[cn])) &#123; next[i++] = ++cn; &#125; else if (cn &gt; 0) &#123; cn = next[cn]; &#125; else &#123; next[i++] = 0; &#125; &#125; return next;&#125;public static boolean isEqual(String a, String b) &#123; if (a == null &amp;&amp; b == null) &#123; return true; &#125; else &#123; if (a == null || b == null) &#123; return false; &#125; else &#123; return a.equals(b); &#125; &#125;&#125; bfprt算法1234题目：在无序数组中求第K小的数1）改写快排的方法2）bfprt算法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// 改写快排，时间复杂度O(N)public static int minKth2(int[] array, int k) &#123; int[] arr = copyArray(array); return process2(arr, 0, arr.length - 1, k - 1);&#125;public static int[] copyArray(int[] arr) &#123; int[] ans = new int[arr.length]; for (int i = 0; i != ans.length; i++) &#123; ans[i] = arr[i]; &#125; return ans;&#125;// arr 第k小的数// process2(arr, 0, N-1, k-1)// arr[L..R] 范围上，如果排序的话(不是真的去排序)，找位于index的数// index [L..R]public static int process2(int[] arr, int L, int R, int index) &#123; if (L == R) &#123; // L = =R ==INDEX return arr[L]; &#125; // 不止一个数 L + [0, R -L] int pivot = arr[L + (int) (Math.random() * (R - L + 1))]; // range[0] range[1] // L ..... R pivot // 0 1000 70...800 int[] range = partition(arr, L, R, pivot); if (index &gt;= range[0] &amp;&amp; index &lt;= range[1]) &#123; return arr[index]; &#125; else if (index &lt; range[0]) &#123; return process2(arr, L, range[0] - 1, index); &#125; else &#123; return process2(arr, range[1] + 1, R, index); &#125;&#125;public static int[] partition(int[] arr, int L, int R, int pivot) &#123; int less = L - 1; int more = R + 1; int cur = L; while (cur &lt; more) &#123; if (arr[cur] &lt; pivot) &#123; swap(arr, ++less, cur++); &#125; else if (arr[cur] &gt; pivot) &#123; swap(arr, cur, --more); &#125; else &#123; cur++; &#125; &#125; return new int[] &#123; less + 1, more - 1 &#125;;&#125;public static void swap(int[] arr, int i1, int i2) &#123; int tmp = arr[i1]; arr[i1] = arr[i2]; arr[i2] = tmp;&#125; 12345思想：bfprt算法的后续步骤和快排是相同的，唯一不同的是，它要精挑细选出第一次的pivot（快排是用随机生成）数组长度为N，bfprt(arr, k)通过对数据进行分组，每5个一组，然后每个组内自行排序:O(1)，N&#x2F;5个小组，则是O(N)取每个小组的中位数组成新数组marr，再对marr取第marr.length&#x2F;2小的值bfprt(marr, marr.length&#x2F;2)这样对挑出的值进行partition，能够保证左右分组最少有(3&#x2F;10)N个数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// 利用bfprt算法，时间复杂度O(N)public static int minKth3(int[] array, int k) &#123; int[] arr = copyArray(array); return bfprt(arr, 0, arr.length - 1, k - 1);&#125;// arr[L..R] 如果排序的话，位于index位置的数，是什么，返回public static int bfprt(int[] arr, int L, int R, int index) &#123; if (L == R) &#123; return arr[L]; &#125; //计算partition合适的值做划分 int pivot = medianOfMedians(arr, L, R); int[] range = partition(arr, L, R, pivot); //如果k落在partition的区间上，则命中，否则继续bfprt左右其中一个分区 if (index &gt;= range[0] &amp;&amp; index &lt;= range[1]) &#123; return arr[index]; &#125; else if (index &lt; range[0]) &#123; return bfprt(arr, L, range[0] - 1, index); &#125; else &#123; return bfprt(arr, range[1] + 1, R, index); &#125;&#125;// arr[L...R] 五个数一组// 每个小组内部排序// 每个小组中位数领出来，组成marr// marr中的中位数，返回public static int medianOfMedians(int[] arr, int L, int R) &#123; int size = R - L + 1; int offset = size % 5 == 0 ? 0 : 1; int[] mArr = new int[size / 5 + offset]; for (int team = 0; team &lt; mArr.length; team++) &#123; int teamFirst = L + team * 5; // L ... L + 4 // L +5 ... L +9 // L +10....L+14 //取5个一组的数组的排序后的中位数 mArr[team] = getMedian(arr, teamFirst, Math.min(R, teamFirst + 4)); &#125; // marr中，找到中位数 // marr(0, marr.len - 1, mArr.length / 2 ) return bfprt(mArr, 0, mArr.length - 1, mArr.length / 2);&#125;public static int getMedian(int[] arr, int L, int R) &#123; insertionSort(arr, L, R); return arr[(L + R) / 2];&#125;public static void insertionSort(int[] arr, int L, int R) &#123; for (int i = L + 1; i &lt;= R; i++) &#123; for (int j = i - 1; j &gt;= L &amp;&amp; arr[j] &gt; arr[j + 1]; j--) &#123; swap(arr, j, j + 1); &#125; &#125;&#125;// for testpublic static int[] generateRandomArray(int maxSize, int maxValue) &#123; int[] arr = new int[(int) (Math.random() * maxSize) + 1]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = (int) (Math.random() * (maxValue + 1)); &#125; return arr;&#125; Manacher算法123456Manacher算法核心1）理解回文半径数组2）理解所有中心的回文最右边界R，和取得R时的中心点C3）理解 L…(i&#96;)…C…(i)…R 的结构，以及根据i’回文长度进行的状况划分4）每一种情况划分，都可以加速求解i回文半径的过程 123假设字符串str长度为N，想返回最长回文子串的长度时间复杂度O(N) 1234567891011思想：字符串中间穿插&#39;#&#39;字符，可以解决虚拟中心的问题，如【abba】-&gt;【#a#b#b#a#】，这时候能够定位到中心Index&#x3D;4回文半径数组：每个字符当中心，中心到左&#x2F;右回文边界的长度，生成一个数组边界R：中心扩到最右边回文边界的距离index，当R被更新时，更新中心点C当遍历的index落在区间[C,R]外，也就是index &gt; R,只能暴力递归判断 index - 1 ?&#x3D; index + 1 ...当index落在区间[C,R]内，则index以C为中点，找到index&#96;的之前计算的答案1.当index&#96;的答案区间落在[C,R]内，则index 答案 &#x3D; index&#96;答案 ，因为是基于C中点做的对称2.当index&#96;的答案区间落在[C,R]外，则以index为中心的回文边界 等于[C,R]中的R3.当Index&#96;回文区域左边界和[C,R]的左边界L相等，则接着暴力：R + 1 ?&#x3D; 2(index) - R - 1... 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public static int manacher(String s) &#123; if (s == null || s.length() == 0) &#123; return 0; &#125; // \"12132\" -&gt; \"#1#2#1#3#2#\" char[] str = manacherString(s); // 回文半径的大小 int[] pArr = new int[str.length]; int C = -1; // 思想中：R代表最右的扩成功的位置。coding：最右的扩成功位置的，再下一个位置 int R = -1; int max = Integer.MIN_VALUE; for (int i = 0; i &lt; str.length; i++) &#123; // R第一个违规的位置，i&gt;= R pArr[i] = 1 // i位置扩出来的答案，i位置扩的区域，至少是多大。 // 1）i对称点压线L --&gt;i位置至少不用验证 R - i个区域 // 2）i对称点在[L-R]内 --&gt; i位置至少不用验证i对称点的区域（其实就是结果相等） // 3）i对称点在[L-R]外 --&gt; i位置至少不用验证R - i个区域（其实结果就是R-i） //最终解释：把i位置不需要验证的区域设置到pArr[i]中 pArr[i] = R &gt; i ? Math.min(pArr[2 * C - i], R - i) : 1; //在不越界的情况下，接着往外扩，扩到了就pArr[i]++ while (i + pArr[i] &lt; str.length &amp;&amp; i - pArr[i] &gt; -1) &#123; if (str[i + pArr[i]] == str[i - pArr[i]]) pArr[i]++; else &#123; break; &#125; &#125; //判断是否刷新R，刷新则更新，并且更新中心点 if (i + pArr[i] &gt; R) &#123; R = i + pArr[i]; C = i; &#125; max = Math.max(max, pArr[i]); &#125; //#1#2#1# 回文半径=4, 4 - 1 = 3 = 原始字符串长度 return max - 1;&#125;public static char[] manacherString(String str) &#123; char[] charArr = str.toCharArray(); char[] res = new char[str.length() * 2 + 1]; int index = 0; for (int i = 0; i != res.length; i++) &#123; res[i] = (i &amp; 1) == 0 ? '#' : charArr[index++]; &#125; return res;&#125; 123456题目：给一个字符串，请问怎么拼接最短的情况下让这个字符串构成一个回文字符串？思路：找到C在最左侧，第一个R边界等于最后一个字符的位置，然后把左边不是回文的数据逆序拼接如：abc12321 --&gt; abc12321cba Morris遍历1234567一种遍历二叉树的方式，并且时间复杂度O(N)，额外空间复杂度O(1) 通过利用原树中大量空闲指针的方式，达到节省空间的目的什么时候能用Morris遍历？当一个节点它需要收集左树的信息和右树的信息做整合，则无法使用当一个节点它收集完左树的信息之后，使用完便丢弃，再收集右树的信息时，则可以使用 12345678910Morris遍历细节假设来到当前节点cur，开始时cur来到头节点位置1）如果cur没有左孩子，cur向右移动(cur &#x3D; cur.right)2）如果cur有左孩子，找到左子树上最右的节点mostRight： a.如果mostRight的右指针指向空，让其指向cur， 然后cur向左移动(cur &#x3D; cur.left) b.如果mostRight的右指针指向cur，让其指向null， 然后cur向右移动(cur &#x3D; cur.right)3）cur为空时遍历停止 12345678910111213141516171819202122232425262728293031// 1// 2 3// 4 5 6 7 morris输出：1242513637//规律：所有有左子树的节点，都会经过两次public static void morris(Node head) &#123; if (head == null) &#123; return; &#125; Node cur = head; Node mostRight = null; while (cur != null) &#123; // cur有没有左树 mostRight = cur.left; if (mostRight != null) &#123; // 有左树的情况下 // 找到cur左树上，真实的最右 while (mostRight.right != null &amp;&amp; mostRight.right != cur) &#123; mostRight = mostRight.right; &#125; // 从while中出来，mostRight一定是cur左树上的最右节点 // mostRight if (mostRight.right == null) &#123; mostRight.right = cur; cur = cur.left; continue; &#125; else &#123; // mostRight.right != null -&gt; mostRight.right == cur mostRight.right = null; &#125; &#125; cur = cur.right; &#125;&#125; 1234morris遍历： 1242513637先序：第二次经过节点时不打印第二次的节点 1245367中序：第一次经过节点时不打印第一次的节点 4251637后序：能经过两次，且第二次经过的节点，逆序打印他的左子树的右边界，之后单独打印整棵树的右边界 4256371 123456789101112131415161718192021222324252627282930//morris先序输出public static void morrisPre(Node head) &#123; if (head == null) &#123; return; &#125; Node cur = head; Node mostRight = null; while (cur != null) &#123; mostRight = cur.left; if (mostRight != null) &#123; while (mostRight.right != null &amp;&amp; mostRight.right != cur) &#123; mostRight = mostRight.right; &#125; //第一次到达这个节点,打印 if (mostRight.right == null) &#123; mostRight.right = cur; System.out.print(cur.value + \" \"); cur = cur.left; continue; &#125; else &#123; mostRight.right = null; &#125; &#125; else &#123; //只到达一次的节点,打印 System.out.print(cur.value + \" \"); &#125; cur = cur.right; &#125; System.out.println();&#125; 123456789101112131415161718192021222324252627282930//morris中序遍历//第一次到该节点，他是会cur = cur.left，第二次时cur = cur.right//只会到达一次的节点也是cur = cur.right//总结：当cur = cur.right时打印public static void morrisIn(Node head) &#123; if (head == null) &#123; return; &#125; Node cur = head; Node mostRight = null; while (cur != null) &#123; mostRight = cur.left; if (mostRight != null) &#123; while (mostRight.right != null &amp;&amp; mostRight.right != cur) &#123; mostRight = mostRight.right; &#125; //第一次到达该节点时，会continue if (mostRight.right == null) &#123; mostRight.right = cur; cur = cur.left; continue; &#125; else &#123; mostRight.right = null; &#125; &#125; System.out.print(cur.value + \" \"); cur = cur.right; &#125; System.out.println();&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//morris后序遍历 public static void morrisPos(Node head) &#123; if (head == null) &#123; return; &#125; Node cur = head; Node mostRight = null; while (cur != null) &#123; mostRight = cur.left; if (mostRight != null) &#123; while (mostRight.right != null &amp;&amp; mostRight.right != cur) &#123; mostRight = mostRight.right; &#125; if (mostRight.right == null) &#123; mostRight.right = cur; cur = cur.left; continue; &#125; else &#123; //第二次经过该节点时逆序输出左子树的右边界 mostRight.right = null; printEdge(cur.left); &#125; &#125; cur = cur.right; &#125; //单独输出整棵树的右边界 printEdge(head); System.out.println();&#125;//反转链表，输出后再反转回来public static void printEdge(Node head) &#123; Node tail = reverseEdge(head); Node cur = tail; while (cur != null) &#123; System.out.print(cur.value + \" \"); cur = cur.right; &#125; reverseEdge(tail);&#125;public static Node reverseEdge(Node from) &#123; Node pre = null; Node next = null; while (from != null) &#123; next = from.right; from.right = pre; pre = from; from = next; &#125; return pre;&#125; 1234567891011121314151617181920212223242526272829303132//判断是否是搜索二叉树//中序遍历，值如果不是递增，则不是public static boolean isBST(Node head) &#123; if (head == null) &#123; return true; &#125; Node cur = head; Node mostRight = null; Integer pre = null; while (cur != null) &#123; mostRight = cur.left; if (mostRight != null) &#123; while (mostRight.right != null &amp;&amp; mostRight.right != cur) &#123; mostRight = mostRight.right; &#125; if (mostRight.right == null) &#123; mostRight.right = cur; cur = cur.left; continue; &#125; else &#123; mostRight.right = null; &#125; &#125; if(pre != null &amp;&amp; pre &gt;= cur.value) &#123; return false; &#125; pre = cur.value; cur = cur.right; &#125; return true;&#125; 123给定一棵二叉树的头节点head求以head为头的树中，最小深度是多少？ 1234567891011121314151617181920212223//暴力递归public static int minHeight1(Node head) &#123; if (head == null) &#123; return 0; &#125; return p(head);&#125;public static int p(Node x) &#123; if (x.left == null &amp;&amp; x.right == null) &#123; return 1; &#125; // 左右子树起码有一个不为空 int leftH = Integer.MAX_VALUE; if (x.left != null) &#123; leftH = p(x.left); &#125; int rightH = Integer.MAX_VALUE; if (x.right != null) &#123; rightH = p(x.right); &#125; return 1 + Math.min(leftH, rightH);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 根据morris遍历改写public static int minHeight2(Node head) &#123; if (head == null) &#123; return 0; &#125; Node cur = head; Node mostRight = null; //cur当前高度 int curLevel = 0; //最小的层数 int minHeight = Integer.MAX_VALUE; while (cur != null) &#123; mostRight = cur.left; if (mostRight != null) //cur遍历的左子树(mostRight)的右边界节点的个数 int rightBoardSize = 1; while (mostRight.right != null &amp;&amp; mostRight.right != cur) &#123; rightBoardSize++; mostRight = mostRight.right; &#125; if (mostRight.right == null) &#123; // 第一次到达，cur必定往下走，当前层数++， curLevel++; mostRight.right = cur; cur = cur.left; continue; &#125; else &#123; // 第二次到达，重新捕获到了mostRight：cur左子树的右边界节点 //当mostRight的左子树是否为空，若是，则为叶子节点，计算该叶子节点的高度 if (mostRight.left == null) &#123; //curLevel是MostRight叶子节点的高度，在它串回去之前计算最小高度 minHeight = Math.min(minHeight, curLevel); &#125; //往回串，curLevel需要回退，减去左子树的右边界节点个数 curLevel -= rightBoardSize; mostRight.right = null; &#125; &#125; else &#123; // 只有一次到达 curLevel++; &#125; cur = cur.right; &#125; //最后要遍历一下根节点的右边界高度 int finalRight = 1; cur = head; while (cur.right != null) &#123; finalRight++; cur = cur.right; &#125; if (cur.left == null &amp;&amp; cur.right == null) &#123; minHeight = Math.min(minHeight, finalRight); &#125; return minHeight;&#125; 线段树1234567891011121314151617181920212223242526271，一种支持范围整体修改和范围整体查询的数据结构2，解决的问题范畴：大范围信息可以只由左、右两侧信息加工出，而不必遍历左右两个子范围的具体状况思路：1.将整个数组[0,length - 1]，舍弃index&#x3D;0，从1开始[1,length], 即新长度N &#x3D; length + 1;2.对数组进行二分[1,N&#x2F;2] [newLength&#x2F;2+1,N]...一直二分到[L,R]--&gt;L&#x3D;&#x3D;R3.将之index看作一个完整二叉树，头节点headIndex &#x3D; 14.它的左树index &#x3D; 2 * headIndex, 右树index &#x3D; 2 * headIndex + 15.舍弃index&#x3D;0是为了进行位运算:快 左index &#x3D; headIndex &lt;&lt; 1; 右index &#x3D; (headIndex &lt;&lt; 1)|16.二分成index二叉树，数组长度N &#x3D; 8时，节点数 &#x3D; 2 * N - 1,当N &#x3D; 9时，多一倍数量7.所以新二分数组sum的长度时定义成4N， (N &lt;&lt; 2)，为了完整的存储整个二分之后的二叉树8.新数组中，index &#x3D; 1存储原数组[1,length]的sum信息，index &#x3D; 2存储 [1,length&#x2F;2]，如下：arr &#x3D; &#123;1,3,4,7&#125;; sum &#x3D; &#123;15,4,11,1,3,4,7,0...&#125; sum.length &#x3D; 4(N + 1) [1-4] [1-2] [3-4] [1] [2] [3] [4]9.创建lazy数组，length &#x3D; 4(N + 1)，用以缓存操作值，如 区间[1,4]的值 + 1，则lazy[1] &#x3D; 110.再操作[1,2] + 2,[1,2]无法完全覆盖[1,4],则lazy下发缓存，lazy[2]&#x3D;1,lazy[3]&#x3D;1,清空lazy[1]&#x3D;011.清空完lazy[1]，然后接着处理[1,2] + 2的操作，区间[1-4]和[1-2]不匹配，把操作分散下发到子树上[1-2]12.[1-2]区间对应lazy[2] &#x3D; 1的值，处理[1,2] + 2操作,则lazy[2] +&#x3D; 213.最终lazy&#x3D;&#123;0,2,3,0...&#125;14.而当lazy有懒住数据时，sum需要根据区间大小进行累加计算15.如当区间[1,4] + 1 时lazy[1] &#x3D; 1,[1,4]对应index&#x3D;1,所以sum[1] +&#x3D; 1 * (4 - 1 + 1)15.对应公式：sum[i] +&#x3D; C * (R - L + 1)，V时增加的值，R - L + 1是区间长度 123456线段树实例一：给定一个数组arr，用户希望你实现如下三个方法1）void add(int L, int R, int V) : 让数组arr[L…R]上每个数都加上V2）void update(int L, int R, int V) : 让数组arr[L…R]上每个数都变成V3）int sum(int L, int R) :让返回arr[L…R]这个范围整体的累加和怎么让这三个方法，时间复杂度都是O(logN) 1234567891011121314151617181920212223242526272829303132//暴力递归public static class Right &#123; public int[] arr; public Right(int[] origin) &#123; arr = new int[origin.length + 1]; for (int i = 0; i &lt; origin.length; i++) &#123; arr[i + 1] = origin[i]; &#125; &#125; public void update(int L, int R, int C) &#123; for (int i = L; i &lt;= R; i++) &#123; arr[i] = C; &#125; &#125; public void add(int L, int R, int C) &#123; for (int i = L; i &lt;= R; i++) &#123; arr[i] += C; &#125; &#125; public long query(int L, int R) &#123; long ans = 0; for (int i = L; i &lt;= R; i++) &#123; ans += arr[i]; &#125; return ans; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161public static class SegmentTree &#123; // arr[]为原序列的信息从0开始，但在arr里是从1开始的 // sum[]模拟线段树维护区间和 // lazy[]为累加懒惰标记 // change[]为更新的值 // update[]为更新慵懒标记 private int MAXN; private int[] arr; private int[] sum; private int[] lazy; private int[] change; private boolean[] update; public SegmentTree(int[] origin) &#123; MAXN = origin.length + 1; arr = new int[MAXN]; // arr[0] 不用 从1开始使用 for (int i = 1; i &lt; MAXN; i++) &#123; arr[i] = origin[i - 1]; &#125; sum = new int[MAXN &lt;&lt; 2]; // 用来支持脑补概念中，某一个范围的累加和信息 lazy = new int[MAXN &lt;&lt; 2]; // 用来支持脑补概念中，某一个范围沒有往下傳遞的纍加任務 change = new int[MAXN &lt;&lt; 2]; // 用来支持脑补概念中，某一个范围有没有更新操作的任务 update = new boolean[MAXN &lt;&lt; 2]; // 用来支持脑补概念中，某一个范围更新任务，更新成了什么 &#125; //累加左右树的数据到节点中 private void pushUp(int rt) &#123; sum[rt] = sum[rt &lt;&lt; 1] + sum[rt &lt;&lt; 1 | 1]; &#125; // 之前的，所有懒增加，和懒更新，从父范围，发给左右两个子范围 // 分发策略是什么 // ln表示左子树元素结点个数，rn表示右子树结点个数 private void pushDown(int rt, int ln, int rn) &#123; //如果有update方法，先下发update懒住的内容，再下发lazy懒住的内容 //因为update操作后，它的所有子树都是无效的，所以子树的update、lazy、sum全都清空 if (update[rt]) &#123; //设置左子树update懒住 update[rt &lt;&lt; 1] = true; //把左子树update懒住的值直接改成父节点之前懒住的值 change[rt &lt;&lt; 1] = change[rt]; //清空左子树的Lazy缓存，因为没用了 lazy[rt &lt;&lt; 1] = 0; //左子树的sum = 底值 * 区间长度 sum[rt &lt;&lt; 1] = change[rt] * ln; //右子树也如此 update[rt &lt;&lt; 1 | 1] = true; change[rt &lt;&lt; 1 | 1] = change[rt]; lazy[rt &lt;&lt; 1 | 1] = 0; sum[rt &lt;&lt; 1 | 1] = change[rt] * rn; //清除父节点状态 update[rt] = false; &#125; //把自身的懒信息下发到左右子树上 if (lazy[rt] != 0) &#123; //左树加上父节点懒的信息 lazy[rt &lt;&lt; 1] += lazy[rt]; //左树累加和值加上父节点懒住的值 * 区间长度 sum[rt &lt;&lt; 1] += lazy[rt] * ln; //右树也是 lazy[rt &lt;&lt; 1 | 1] += lazy[rt]; sum[rt &lt;&lt; 1 | 1] += lazy[rt] * rn; //清除父节点的 lazy[rt] = 0; &#125; &#125; // 在初始化阶段，先把sum数组，填好 // 在arr[l~r]范围上，去build，1~N， // rt : 这个范围在sum中的下标 public void build(int l, int r, int rt) &#123; if (l == r) &#123; sum[rt] = arr[l]; return; &#125; int mid = (l + r) &gt;&gt; 1; //先填左右树，然后收集答案 build(l, mid, rt &lt;&lt; 1); build(mid + 1, r, rt &lt;&lt; 1 | 1); pushUp(rt); &#125; // L..R -&gt; 任务范围 ,所有的值累加上C // l,r -&gt; 表达的范围 // rt 去哪找l，r范围上的信息 //假设：arr = &#123;1,3,4,7&#125; //[L..R] -&gt; [1..3] [l,r] -&gt; [1..4] rt -&gt; 1 public void add( int L, int R, int C, int l, int r, int rt) &#123; // 任务的范围彻底覆盖了，当前表达的范围 if (L &lt;= l &amp;&amp; r &lt;= R) &#123; sum[rt] += C * (r - l + 1); lazy[rt] += C; return; &#125; // 任务并没有把l...r全包住 // 要把当前任务往下发 // 任务 L, R 没有把本身表达范围 l,r 彻底包住 int mid = (l + r) &gt;&gt; 1; // l..mid (rt &lt;&lt; 1) mid+1...r(rt &lt;&lt; 1 | 1) // 下发之前所有攒的懒任务 pushDown(rt, mid - l + 1, r - mid); // 左孩子是否需要接到任务 if (L &lt;= mid) &#123; add(L, R, C, l, mid, rt &lt;&lt; 1); &#125; // 右孩子是否需要接到任务 if (R &gt; mid) &#123; add(L, R, C, mid + 1, r, rt &lt;&lt; 1 | 1); &#125; // 左右孩子做完任务后，我更新我的sum信息 pushUp(rt); &#125; public void update(int L, int R, int C, int l, int r, int rt) &#123; if (L &lt;= l &amp;&amp; r &lt;= R) &#123; update[rt] = true; change[rt] = C; sum[rt] = C * (r - l + 1); lazy[rt] = 0; return; &#125; // 当前任务躲不掉，无法懒更新，要往下发 int mid = (l + r) &gt;&gt; 1; pushDown(rt, mid - l + 1, r - mid); if (L &lt;= mid) &#123; update(L, R, C, l, mid, rt &lt;&lt; 1); &#125; if (R &gt; mid) &#123; update(L, R, C, mid + 1, r, rt &lt;&lt; 1 | 1); &#125; pushUp(rt); &#125; // 1~6 累加和是多少？ 1~8 rt public long query(int L, int R, int l, int r, int rt) &#123; //如果L-R包含l，r 返回返回内的值 if (L &lt;= l &amp;&amp; r &lt;= R) &#123; return sum[rt]; &#125; int mid = (l + r) &gt;&gt; 1; //下发之前攒的任务 pushDown(rt, mid - l + 1, r - mid); long ans = 0; //查询和累加子树结果，并返回 if (L &lt;= mid) &#123; ans += query(L, R, l, mid, rt &lt;&lt; 1); &#125; if (R &gt; mid) &#123; ans += query(L, R, mid + 1, r, rt &lt;&lt; 1 | 1); &#125; return ans; &#125;&#125; 12345678910线段树实例二：想象一下标准的俄罗斯方块游戏，X轴是积木最终下落到底的轴线下面是这个游戏的简化版：1）只会下落正方形积木2）[a,b] -&gt; 代表一个边长为b的正方形积木，积木左边缘沿着X &#x3D; a这条线从上方掉落3）认为整个X轴都可能接住积木，也就是说简化版游戏是没有整体的左右边界的4）没有整体的左右边界，所以简化版游戏不会消除积木，因为不会有哪一层被填满。给定一个N*2的二维数组matrix，可以代表N个积木依次掉落，返回每一次掉落之后的最大高度 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112public static class SegmentTree &#123; private int[] max; private int[] change; private boolean[] update; public SegmentTree(int size) &#123; int N = size + 1; max = new int[N &lt;&lt; 2]; change = new int[N &lt;&lt; 2]; update = new boolean[N &lt;&lt; 2]; &#125; //左右树的最大高度就是父节点的最大高度 private void pushUp(int rt) &#123; max[rt] = Math.max(max[rt &lt;&lt; 1], max[rt &lt;&lt; 1 | 1]); &#125; // ln表示左子树元素结点个数，rn表示右子树结点个数 private void pushDown(int rt, int ln, int rn) &#123; if (update[rt]) &#123; update[rt &lt;&lt; 1] = true; update[rt &lt;&lt; 1 | 1] = true; change[rt &lt;&lt; 1] = change[rt]; change[rt &lt;&lt; 1 | 1] = change[rt]; max[rt &lt;&lt; 1] = change[rt]; max[rt &lt;&lt; 1 | 1] = change[rt]; update[rt] = false; &#125; &#125; public void update(int L, int R, int C, int l, int r, int rt) &#123; if (L &lt;= l &amp;&amp; r &lt;= R) &#123; update[rt] = true; change[rt] = C; max[rt] = C; return; &#125; int mid = (l + r) &gt;&gt; 1; pushDown(rt, mid - l + 1, r - mid); if (L &lt;= mid) &#123; update(L, R, C, l, mid, rt &lt;&lt; 1); &#125; if (R &gt; mid) &#123; update(L, R, C, mid + 1, r, rt &lt;&lt; 1 | 1); &#125; pushUp(rt); &#125; public int query(int L, int R, int l, int r, int rt) &#123; if (L &lt;= l &amp;&amp; r &lt;= R) &#123; return max[rt]; &#125; int mid = (l + r) &gt;&gt; 1; pushDown(rt, mid - l + 1, r - mid); int left = 0; int right = 0; if (L &lt;= mid) &#123; left = query(L, R, l, mid, rt &lt;&lt; 1); &#125; if (R &gt; mid) &#123; right = query(L, R, mid + 1, r, rt &lt;&lt; 1 | 1); &#125; return Math.max(left, right); &#125;&#125;//正方形起始下标离线化 把大值映射到数组的index小值中，从1开始// positions[起始index][方块长度]// [2,7] -&gt; [2 , 8） 左开右闭 -&gt; [2,7]// [3, 10] -&gt; 3, 12////public HashMap&lt;Integer, Integer&gt; index(int[][] positions) &#123; TreeSet&lt;Integer&gt; pos = new TreeSet&lt;&gt;(); for (int[] arr : positions) &#123; pos.add(arr[0]); //起始长度 + 正方形长度 -1 pos.add(arr[0] + arr[1] - 1); &#125; //TreeSet排序之后存储下表映射 HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int count = 0; for (Integer index : pos) &#123; map.put(index, ++count); &#125; return map;&#125;public List&lt;Integer&gt; fallingSquares(int[][] positions) &#123; HashMap&lt;Integer, Integer&gt; map = index(positions); // 100 -&gt; 1 306 -&gt; 2 403 -&gt; 3 // [100,403] 1~3 int N = map.size(); // 1 ~ N SegmentTree segmentTree = new SegmentTree(N); int max = 0; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); // 每落一个正方形，收集一下，所有东西组成的图像，最高高度是什么 for (int[] arr : positions) &#123; int L = map.get(arr[0]); int R = map.get(arr[0] + arr[1] - 1); //查询出原有高度 + 正方形高度 int height = segmentTree.query(L, R, 1, N, 1) + arr[1]; //比较最大高度 max = Math.max(max, height); //收集截至到此时，图形的最大高度 res.add(max); //更新该区间的高度【直接更新[1,N],index = 1】 segmentTree.update(L, R, height, 1, N, 1); &#125; return res;&#125; 123线段覆盖问题：假设现在有很多线段长度，如[1,2] [2,4] [1,4]，请问最多盖住的线段有几段?如上问题：[1,4]盖住三段 1234567891011121314151617181920//暴力递归public static int maxCover1(int[][] lines) &#123; int min = Integer.MAX_VALUE; int max = Integer.MIN_VALUE; for (int i = 0; i &lt; lines.length; i++) &#123; min = Math.min(min, lines[i][0]); max = Math.max(max, lines[i][1]); &#125; int cover = 0; for (double p = min + 0.5; p &lt; max; p += 1) &#123; int cur = 0; for (int i = 0; i &lt; lines.length; i++) &#123; if (lines[i][0] &lt; p &amp;&amp; lines[i][1] &gt; p) &#123; cur++; &#125; &#125; cover = Math.max(cover, cur); &#125; return cover;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//小根堆解决public static int maxCover2(int[][] m) &#123; Line[] lines = new Line[m.length]; for (int i = 0; i &lt; m.length; i++) &#123; lines[i] = new Line(m[i][0], m[i][1]); &#125; //以线段的起始坐标排序，小的先画 Arrays.sort(lines, new StartComparator()); PriorityQueue&lt;Line&gt; heap = new PriorityQueue&lt;&gt;(new EndComparator()); int max = 0; //遍历，当新的L &gt; 小根堆中的R,弹出所有小于L的值，把L放进去 for (int i = 0; i &lt; lines.length; i++) &#123; while (!heap.isEmpty() &amp;&amp; heap.peek().end &lt;= lines[i].start) &#123; heap.poll(); &#125; heap.add(lines[i]); //这时候堆中的数量就是盖住的数量 max = Math.max(max, heap.size()); &#125; return max;&#125;public static class Line &#123; public int start; public int end; public Line(int s, int e) &#123; start = s; end = e; &#125;&#125;public static class StartComparator implements Comparator&lt;Line&gt; &#123; @Override public int compare(Line o1, Line o2) &#123; return o1.start - o2.start; &#125;&#125;public static class EndComparator implements Comparator&lt;Line&gt; &#123; @Override public int compare(Line o1, Line o2) &#123; return o1.end - o2.end; &#125;&#125; 1给个二维数组，里面包含了矩形的两个对角点，通过两个对角点(x1,y1)(x2,y2)能够画出用一个矩形，返回哪个区域盖住的矩形最多 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public static class Rectangle &#123; public int up; public int down; public int left; public int right; public Rectangle(int up, int down, int left, int right) &#123; this.up = up; this.down = down; this.left = left; this.right = right; &#125;&#125;public static class DownComparator implements Comparator&lt;Rectangle&gt; &#123; @Override public int compare(Rectangle o1, Rectangle o2) &#123; return o1.down - o2.down; &#125;&#125;public static class LeftComparator implements Comparator&lt;Rectangle&gt; &#123; @Override public int compare(Rectangle o1, Rectangle o2) &#123; return o1.left - o2.left; &#125;&#125;public static class RightComparator implements Comparator&lt;Rectangle&gt; &#123; @Override public int compare(Rectangle o1, Rectangle o2) &#123; return o1.right - o2.right; &#125;&#125;// 矩形数量是N// O(N*LogN)// +// O(N) * [ O(N) + O(N *LogN) ]public static int maxCover(Rectangle[] recs) &#123; if (recs == null || recs.length == 0) &#123; return 0; &#125; // 根据down（底）排序 Arrays.sort(recs, new DownComparator()); // 可能会对当前底边的公共局域，产生影响的矩形 // list -&gt; treeSet(有序表表达) TreeSet&lt;Rectangle&gt; leftOrdered = new TreeSet&lt;&gt;(new LeftComparator()); int ans = 0; // O(N) for (int i = 0; i &lt; recs.length; i++) &#123; // 依次考察每一个矩形的底边 int curDown = recs[i].down; // 当前的底边值取出来 int index = i; while (recs[index].down == curDown) &#123; leftOrdered.add(recs[index]); // O(logN) index++; &#125; i = index; // O(N) list是不是有一些顶&lt;=底的矩形 removeLowerOnCurDown(leftOrdered, curDown); // 维持了右边界排序的容器,演变成了线段覆盖问题 TreeSet&lt;Rectangle&gt; rightOrdered = new TreeSet&lt;&gt;(new RightComparator()); for (Rectangle rec : leftOrdered) &#123; // O(N) removeLeftOnCurLeft(rightOrdered, rec.left); rightOrdered.add(rec);// O(logN) ans = Math.max(ans, rightOrdered.size()); &#125; &#125; return ans;&#125;public static void removeLowerOnCurDown(TreeSet&lt;Rectangle&gt; set, int curDown) &#123; List&lt;Rectangle&gt; removes = new ArrayList&lt;&gt;(); for (Rectangle rec : set) &#123; if (rec.up &lt;= curDown) &#123; removes.add(rec); &#125; &#125; for (Rectangle rec : removes) &#123; set.remove(rec); &#125;&#125;public static void removeLeftOnCurLeft(TreeSet&lt;Rectangle&gt; rightOrdered, int curLeft) &#123; List&lt;Rectangle&gt; removes = new ArrayList&lt;&gt;(); for (Rectangle rec : rightOrdered) &#123; if (rec.right &gt; curLeft) &#123; break; &#125; removes.add(rec); &#125; for (Rectangle rec : removes) &#123; rightOrdered.remove(rec); &#125;&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://midkuro.gitee.io/categories/algorithm/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"algorithm","slug":"algorithm","permalink":"https://midkuro.gitee.io/tags/algorithm/"}]},{"title":"'数据结构与算法'","slug":"algorithm-base","date":"2020-10-29T14:32:00.000Z","updated":"2020-12-22T12:34:49.049Z","comments":true,"path":"2020/10/29/algorithm-base/","link":"","permalink":"https://midkuro.gitee.io/2020/10/29/algorithm-base/","excerpt":"","text":"基础算法脑图大纲 1234评估算法优劣的核心指标是什么？时间复杂度（流程决定）额外空间复杂度（流程决定）常数项时间（实现细节决定） 时间复杂度12345678910如何确定算法流程的时间复杂度？当完成了表达式的建立，只要把最高阶项留下即可。低阶项都去掉，高阶项的系数也去掉。记为：O(忽略掉系数的高阶项)时间复杂度的意义在于：当我们要处理的样本量很大很大时，我们会发现低阶项是什么不是最重要的；每一项的系数是什么，不是最重要的。真正重要的就是最高阶项是什么。这就是时间复杂度的意义，它是衡量算法流程的复杂程度的一种指标，该指标只与数据量有关，与过程之外的优化无关。 选择排序123456789101112过程：arr[0～N-1]范围上，找到最小值所在的位置，然后把最小值交换到0位置。arr[1～N-1]范围上，找到最小值所在的位置，然后把最小值交换到1位置。arr[2～N-1]范围上，找到最小值所在的位置，然后把最小值交换到2位置。…arr[N-1～N-1]范围上，找到最小值位置，然后把最小值交换到N-1位置。估算：很明显，如果arr长度为N，每一步常数操作的数量，如等差数列一般所以，总的常数操作数量 &#x3D; a*(N^2) + b*N + c (a、b、c都是常数)所以选择排序的时间复杂度为O(N^2)。 123456789101112//核心思想：//i ~ N-1 中最小的值放在 i 上for (int i = 0; i &lt; arr.length - 1; i++) &#123; // i ~ N-1 // 最小值在哪个位置上 i～n-1 int minIndex = i; for (int j = i + 1; j &lt; arr.length; j++) &#123; // i ~ N-1 上找最小值的下标 minIndex = arr[j] &lt; arr[minIndex] ? j : minIndex; &#125; //交换 swap(arr, i, minIndex);&#125; 冒泡排序123456789101112131415过程：在arr[0～N-1]范围上：arr[0]和arr[1]，谁大谁来到1位置；arr[1]和arr[2]，谁大谁来到2位置…arr[N-2]和arr[N-1]，谁大谁来到N-1位置在arr[0～N-2]范围上，重复上面的过程，但最后一步是arr[N-3]和arr[N-2]，谁大谁来到N-2位置在arr[0～N-3]范围上，重复上面的过程，但最后一步是arr[N-4]和arr[N-3]，谁大谁来到N-3位置…最后在arr[0～1]范围上，重复上面的过程，但最后一步是arr[0]和arr[1]，谁大谁来到1位置估算：很明显，如果arr长度为N，每一步常数操作的数量，依然如等差数列一般所以，总的常数操作数量 &#x3D; a*(N^2) + b*N + c (a、b、c都是常数)所以冒泡排序的时间复杂度为O(N^2)。 1234567891011// 0 ~ N-1// 0 ~ N-2// 0 ~ N-3for (int e = arr.length - 1; e &gt; 0; e--) &#123; // 0 ~ e for (int i = 0; i &lt; e; i++) &#123; //重点在于i 和 i+1 比较交换 if (arr[i] &gt; arr[i + 1]) &#123; swap(arr, i, i + 1); &#125; &#125;&#125; 插入排序12345678过程：想让arr[0~0]上有序，这个范围只有一个数，当然是有序的。想让arr[0~1]上有序，所以从arr[1]开始往前看，如果arr[1]&lt;arr[0]，就交换。否则什么也不做。…想让arr[0~i]上有序，所以从arr[i]开始往前看，arr[i]这个数不停向左移动，一直移动到左边的数字不再比自己大，停止移动。最后一步，想让arr[0~N-1]上有序， arr[N-1]这个数不停向左移动，一直移动到左边的数字不再比自己大，停止移动。估算时发现这个算法流程的复杂程度，会因为数据状况的不同而不同。 1234567// 0~0 有序的// 0~i 想有序for (int i = 1; i &lt; arr.length; i++) &#123; // 0 ~ i 做到有序 for (int j = i - 1; j &gt;= 0 &amp;&amp; arr[j] &gt; arr[j + 1]; j--) &#123; swap(arr, j, j + 1); &#125;&#125; 1234567如果某个算法流程的复杂程度会根据数据状况的不同而不同，那么你必须要按照最差情况来估计。很明显，在最差情况下，如果arr长度为N，插入排序的每一步常数操作的数量，还是如等差数列一般所以，总的常数操作数量 &#x3D; a*(N^2) + b*N + c (a、b、c都是常数)所以插入排序排序的时间复杂度为O(N^2)。 额外空间复杂度12345678910你要实现一个算法流程，在实现算法流程的过程中，你需要开辟一些空间来支持你的算法流程。作为输入参数的空间，不算额外空间。作为输出结果的空间，也不算额外空间。因为这些都是必要的、和现实目标有关的。所以都不算。但除此之外，你的流程如果还需要开辟空间才能让你的流程继续下去。这部分空间就是额外空间。如果你的流程只需要开辟有限几个变量，额外空间复杂度就是O(1)。 1234567我们会发现，时间复杂度这个指标，是忽略低阶项和所有常数系数的。难道同样时间复杂度的流程，在实际运行时候就一样的好吗？当然不是。时间复杂度只是一个很重要的指标而已。如果两个时间复杂度一样的算法，你还要去在时间上拼优劣，就进入到拼常数时间的阶段，简称拼常数项。 算法流程的常数项123456789放弃理论分析，生成随机数据直接测。为什么不去理论分析？不是不能纯分析，而是没必要。因为不同常数时间的操作，虽然都是固定时间，但还是有快慢之分的。比如，位运算的常数时间原小于算术运算的常数时间，这两个运算的常数时间又远小于数组寻址的时间。所以如果纯理论分析，往往会需要非常多的分析过程。都已经到了具体细节的程度，莫不如交给实验数据好了。 二分法123456789101112131415161718192021//在一个有序数组中，找某个数是否存在 public static boolean exist(int[] sortedArr, int num) &#123; if (sortedArr == null || sortedArr.length == 0) &#123; return false; &#125; int L = 0; int R = sortedArr.length - 1; int mid = 0; // L..R while (L &lt; R) &#123; mid = L + ((R - L) &gt;&gt; 1); // mid = (L + R) / 2 if (sortedArr[mid] == num) &#123; return true; &#125; else if (sortedArr[mid] &gt; num) &#123; R = mid - 1; &#125; else &#123; L = mid + 1; &#125; &#125; return sortedArr[L] == num;&#125; 12345678910111213141516//在一个有序数组中，找&gt;=value最左侧的位置 public static int nearestIndex(int[] arr, int value) &#123; int L = 0; int R = arr.length - 1; int index = -1; // 记录最左的对号 while (L &lt;= R) &#123; int mid = L + ((R - L) &gt;&gt; 1); if (arr[mid] &gt;= value) &#123; index = mid; R = mid - 1; &#125; else &#123; L = mid + 1; &#125; &#125; return index;&#125; 1234567891011121314151617181920212223242526//局部最小值问题(等于找数据的曲线变化转折点，数值连续下降再上升，就算是一个局部最小值)public static int getLessIndex(int[] arr) &#123; if (arr == null || arr.length == 0) &#123; return -1; // no exist &#125; if (arr.length == 1 || arr[0] &lt; arr[1]) &#123; return 0; &#125; if (arr[arr.length - 1] &lt; arr[arr.length - 2]) &#123; return arr.length - 1; &#125; int left = 1; int right = arr.length - 2; int mid = 0; while (left &lt; right) &#123; mid = (left + right) / 2; if (arr[mid] &gt; arr[mid - 1]) &#123; right = mid - 1; &#125; else if (arr[mid] &gt; arr[mid + 1]) &#123; left = mid + 1; &#125; else &#123; return mid; &#125; &#125; return left;&#125; 异或运算1234//如何不用额外变量交换两个数a = a ^ bb = a ^ ba = a ^ b 1234567//注意：a 和 b 不能指向同一个地址空间，否则怎么交换都是0// 比如i和j是一个位置的话，会出错public static void swap(int[] arr, int i, int j) &#123; arr[i] = arr[i] ^ arr[j]; arr[j] = arr[i] ^ arr[j]; arr[i] = arr[i] ^ arr[j];&#125; 12345678//一个数组中有一种数出现了奇数次，其他数都出现了偶数次，怎么找到并打印这种数 public static void printOddTimesNum1(int[] arr) &#123; int eor = 0; for (int i = 0; i &lt; arr.length; i++) &#123; eor ^= arr[i]; &#125; System.out.println(eor);&#125; 123456//怎么把一个int类型的数，提取出最右侧的1来n &amp; (~n + 1);// n : 001100100// ~n : 110011011// ~n+1 : 110011100// : 000000100 1234567891011121314151617181920212223//一个数组中有两种数出现了奇数次，其他数都出现了偶数次，怎么找到并打印这两种数public static void printOddTimesNum2(int[] arr) &#123; int eor = 0; for (int i = 0; i &lt; arr.length; i++) &#123; eor ^= arr[i]; &#125; // eor = a ^ b // eor != 0 // eor必然有一个位置上是1（必然这两个数在这位上一个是0一个是1） // 0110010000 // 0000010000 int rightOne = eor &amp; (~eor + 1); // 提取出最右的1 int onlyOne = 0; // eor' for (int i = 0 ; i &lt; arr.length;i++) &#123; // arr[1] = 111100011110000 // rightOne= 000000000010000 //只异或最右边有1的值，偶数的过滤完，剩下奇数的那个数 if ((arr[i] &amp; rightOne) != 0) &#123; onlyOne ^= arr[i]; &#125; &#125; System.out.println(onlyOne + \" \" + (eor ^ onlyOne));&#125; 123456789//提取整数n转换成二进制之后，他的中1的数量public static int bit1counts(int N) &#123; int count = 0; while(n != 0) &#123; int rightOne = n &amp; (~n + 1); count++; n = n ^ rightOne; &#125;&#125; 栈和队列123456789101112131415161718192021222324252627282930313233343536373839404142434445//用数组实现队列public static class MyQueue &#123; private int[] arr; private int pushi; private int polli; private int size; private final int limit; public MyQueue(int limit) &#123; arr = new int[limit]; pushi = 0; polli = 0; size = 0; this.limit = limit; &#125; public void push(int value) &#123; if (size == limit) &#123; throw new RuntimeException(\"栈满了，不能再加了\"); &#125; size++; arr[pushi] = value; pushi = nextIndex(pushi); &#125; public int pop() &#123; if (size == 0) &#123; throw new RuntimeException(\"栈空了，不能再拿了\"); &#125; size--; int ans = arr[polli]; polli = nextIndex(polli); return ans; &#125; public boolean isEmpty() &#123; return size == 0; &#125; // 如果现在的下标是i，返回下一个位置 private int nextIndex(int i) &#123; return i &lt; limit - 1 ? i + 1 : 0; &#125;&#125; 123实现一个特殊的栈，在基本功能的基础上，再实现返回栈中最小元素的功能pop、push、getMin操作的时间复杂度都是 O(1)。 设计的栈类型可以使用现成的栈结构。 123思想：用两个Stack，一个存储数据，一个存储最小值解法一：小于等于栈顶元素时才push，等于栈顶元素时才pop解法二：push的时候压入min和push之中的最小值，弹出则都弹出 12345678910111213141516171819202122232425262728293031323334353637//开多个栈，push的时候压入min和push之中的最小值，弹出则都弹出public static class MyStack2 &#123; private Stack&lt;Integer&gt; stackData; private Stack&lt;Integer&gt; stackMin; public MyStack2() &#123; this.stackData = new Stack&lt;Integer&gt;(); this.stackMin = new Stack&lt;Integer&gt;(); &#125; public void push(int newNum) &#123; if (this.stackMin.isEmpty()) &#123; this.stackMin.push(newNum); &#125; else if (newNum &lt; this.getmin()) &#123; this.stackMin.push(newNum); &#125; else &#123; int newMin = this.stackMin.peek(); this.stackMin.push(newMin); &#125; this.stackData.push(newNum); &#125; public int pop() &#123; if (this.stackData.isEmpty()) &#123; throw new RuntimeException(\"Your stack is empty.\"); &#125; this.stackMin.pop(); return this.stackData.pop(); &#125; public int getmin() &#123; if (this.stackMin.isEmpty()) &#123; throw new RuntimeException(\"Your stack is empty.\"); &#125; return this.stackMin.peek(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041//如何用栈结构实现队列结构//两个栈，一个push、一个pop，把push推到pop栈再弹出pop栈顶public static class TwoStacksQueue &#123; public Stack&lt;Integer&gt; stackPush; public Stack&lt;Integer&gt; stackPop; public TwoStacksQueue() &#123; stackPush = new Stack&lt;Integer&gt;(); stackPop = new Stack&lt;Integer&gt;(); &#125; //只要pop空了再移过去,每次移过去要移动所有push栈的数据 // push栈向pop栈倒入数据 private void pushToPop() &#123; if (stackPop.empty()) &#123; while (!stackPush.empty()) &#123; stackPop.push(stackPush.pop()); &#125; &#125; &#125; public void add(int pushInt) &#123; stackPush.push(pushInt); pushToPop(); &#125; public int poll() &#123; if (stackPop.empty() &amp;&amp; stackPush.empty()) &#123; throw new RuntimeException(\"Queue is empty!\"); &#125; pushToPop(); return stackPop.pop(); &#125; public int peek() &#123; if (stackPop.empty() &amp;&amp; stackPush.empty()) &#123; throw new RuntimeException(\"Queue is empty!\"); &#125; pushToPop(); return stackPop.peek(); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243//如何用队列结构实现栈结构//两个队列，一个存，取，当取的时候把存的队列都塞到取的队列中，一直塞到存的队列剩下一个，把那个数据返回，并且设置取队列等于存队列，存队列等于取队列public static class TwoQueueStack&lt;T&gt; &#123; public Queue&lt;T&gt; queue; public Queue&lt;T&gt; help; public TwoQueueStack() &#123; queue = new LinkedList&lt;&gt;(); help = new LinkedList&lt;&gt;(); &#125; public void push(T value) &#123; queue.offer(value); &#125; public T poll() &#123; while (queue.size() &gt; 1) &#123; help.offer(queue.poll()); &#125; T ans = queue.poll(); Queue&lt;T&gt; tmp = queue; queue = help; help = tmp; return ans; &#125; public T peek() &#123; while (queue.size() &gt; 1) &#123; help.offer(queue.poll()); &#125; T ans = queue.poll(); help.offer(ans); Queue&lt;T&gt; tmp = queue; queue = help; help = tmp; return ans; &#125; public boolean isEmpty() &#123; return queue.isEmpty(); &#125;&#125; 递归12345递归公式T(N) &#x3D; a * T(N&#x2F;b) + O(N^d)(其中的a、b、d都是常数)的递归函数，可以直接通过Master公式来确定时间复杂度如果 log(b,a) &lt; d，复杂度为O(N^d)如果 log(b,a) &gt; d，复杂度为O(N^log(b,a))如果 log(b,a) &#x3D;&#x3D; d，复杂度为O(N^d * logN) 1234567891011121314// arr[L..R]范围上求最大值 L ... R Npublic static int process(int[] arr, int L, int R) &#123; if (L == R) &#123; // arr[L..R]范围上只有一个数，直接返回，base case return arr[L]; &#125; int mid = L + ((R - L) &gt;&gt; 1); // 中点 1 int leftMax = process(arr, L, mid); int rightMax = process(arr, mid + 1, R); return Math.max(leftMax, rightMax);&#125;//时间复杂度://T（N） = 2 * T（N/2） + O(N^0)//log(2,2) = 1 &gt; 0，复杂度为O(N) 哈希表123456789101)哈希表在使用层面上可以理解为一种集合结构2)如果只有key，没有伴随数据value，可以使用HashSet结构3)如果既有key，又有伴随数据value，可以使用HashMap结构4)有无伴随数据，是HashMap和HashSet唯一的区别，实际结构是一回事 5)使用哈希表增(put)、删(remove)、改(put)和查(get)的操作，可以认为时间复杂度为 O(1)，但是常数时间比较大 6)放入哈希表的东西，如果是基础类型，内部按值传递，内存占用是这个东西的大小 7)放入哈希表的东西，如果不是基础类型，内部按引用传递，内存占用是8字节哈希表在使用时，增删改查时间复杂度都是O(1)有序表在使用时，比哈希表功能多，时间复杂度都是O(logN) 归并排序12341）整体是递归，左边排好序+右边排好序+merge让整体有序2）让其整体有序的过程里用了排外序方法3）利用master公式来求解时间复杂度4）当然可以用非递归实现 12345678910111213141516171819202122232425262728293031323334// arr[L...R]范围上，变成有序的//二分，开辟新数组，遍历二分的左右数组比较大小塞进去，然后拷贝回去//O(N * log N)//选择排序O(N^2)大量在浪费比较行为public static void process(int[] arr, int L, int R) &#123; if (L == R) &#123; // base case return; &#125; int mid = L + ((R - L) &gt;&gt; 1); process(arr, L, mid); process(arr, mid + 1, R); merge(arr, L, mid, R);&#125;public static void merge(int[] arr, int L, int M, int R) &#123; int[] help = new int[R - L + 1]; int i = 0; int p1 = L; int p2 = M + 1; //下标遍历两个数组，赋值新数组 while (p1 &lt;= M &amp;&amp; p2 &lt;= R) &#123; help[i++] = arr[p1] &lt;= arr[p2] ? arr[p1++] : arr[p2++]; &#125; // 要么p1越界了，要么p2越界了 while (p1 &lt;= M) &#123; help[i++] = arr[p1++]; &#125; while (p2 &lt;= R) &#123; help[i++] = arr[p2++]; &#125; for (i = 0; i &lt; help.length; i++) &#123; arr[L + i] = help[i]; &#125;&#125; 1234567891011121314151617181920212223242526272829303132// 非递归方法实现//通过把相邻的MergeSize个数据有序，分段，每次合并两段，再重复//O(N * log N)public static void mergeSort2(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; int N = arr.length; int mergeSize = 1;// 当前有序的，左组长度 while (mergeSize &lt; N) &#123; // log N //当前组的下标 int L = 0; // 0.... while (L &lt; N) &#123; // L...M 左组（mergeSize） int M = L + mergeSize - 1; if (M &gt;= N) &#123; break; &#125; // L...M M+1...R(mergeSize) int R = Math.min(M + mergeSize, N - 1); merge(arr, L, M, R); L = R + 1; &#125; //防止双倍数组长度逸出int最大值 if (mergeSize &gt; N / 2) &#123; break; &#125; //双倍扩大 mergeSize &lt;&lt;= 1; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940// arr[L..R]既要排好序，也要求小和返回//在一个数组中，每一个数左边比当前数小的数累加起来，叫做这个数组的小和。public static int process(int[] arr, int l, int r) &#123; if (l == r) &#123; return 0; &#125; // l &lt; r int mid = l + ((r - l) &gt;&gt; 1); //左组 和右组 迭代过程中产生的小和 + 自己调用merge产生的小和 return process(arr, l, mid) + process(arr, mid + 1, r) + merge(arr, l, mid, r);&#125;public static int merge(int[] arr, int L, int m, int r) &#123; int[] help = new int[r - L + 1]; int i = 0; int p1 = L; int p2 = m + 1; int res = 0; while (p1 &lt;= m &amp;&amp; p2 &lt;= r) &#123; //右边的比左边的大时，计算右边还剩下多少个数 * 左边的值，累加到res上 res += arr[p1] &lt; arr[p2] ? (r - p2 + 1) * arr[p1] : 0; //当左右组数相同时，先拷贝右数 help[i++] = arr[p1] &lt; arr[p2] ? arr[p1++] : arr[p2++]; &#125; while (p1 &lt;= m) &#123; help[i++] = arr[p1++]; &#125; while (p2 &lt;= r) &#123; help[i++] = arr[p2++]; &#125; for (i = 0; i &lt; help.length; i++) &#123; arr[L + i] = help[i]; &#125; return res;&#125; 快速排序12345678//把所有非0的数放左边//设定一个index，遇到非0的都和index交换，index++int index = -1;for(int i = 0;i &lt; arr.length; i++) &#123; if (arr[i] &gt; 0) &#123; swap(arr, i, ++index); &#125;&#125; 123荷兰国旗问题给定一个数组arr，和一个整数num。请把小于num的数放在数组的左边，等于num的数放在中间，大于num的数放在数组的右边。返回等于num的下标 12345678910111213141516171819202122// arr[L..R]上，以arr[R]位置的数做划分值// &lt;= X &gt; X// &lt;= X Xpublic static int partition(int[] arr, int L, int R) &#123; if (L &gt; R) &#123; return -1; &#125; if (L == R) &#123; return L; &#125; int lessEqual = L - 1; int index = L; while (index &lt; R) &#123; //由于这里用了&lt;=，所以有多个num时，会返回最右边的下标 if (arr[index] &lt;= arr[R]) &#123; swap(arr, index, ++lessEqual); &#125; index++; &#125; swap(arr, ++lessEqual, R); return lessEqual;&#125; 123456789快速排序1.0在arr[L..R]范围上，进行快速排序的过程：1）用arr[R]对该范围做partition，&lt;&#x3D; arr[R]的数在左部分并且保证arr[R]最后来到左部分的最后一个位置，记为M； &lt;&#x3D; arr[R]的数在右部分（arr[M+1..R]）2）对arr[L..M-1]进行快速排序(递归)3）对arr[M+1..R]进行快速排序(递归)因为每一次partition都会搞定一个数的位置且不会再变动，所以排序能完成时间复杂度O(N^2) 12345678910//V1.0public static void process1(int[] arr, int L, int R) &#123; if (L &gt;= R) &#123; return; &#125; // L..R partition arr[R] [ &lt;=arr[R] arr[R] &gt;arr[R] ] int M = partition(arr, L, R); process1(arr, L, M - 1); process1(arr, M + 1, R);&#125; 123456789快速排序2.0在arr[L..R]范围上，进行快速排序的过程：1）用arr[R]对该范围做partition，&lt; arr[R]的数在左部分，&#x3D;&#x3D; arr[R]的数中间，&gt;arr[R]的数在右部分。假设&#x3D;&#x3D; arr[R]的数所在范围是[a,b]2）对arr[L..a-1]进行快速排序(递归)3）对arr[b+1..R]进行快速排序(递归)因为每一次partition都会搞定一批数的位置且不会再变动，所以排序能完成时间复杂度O(N^2) 12345678910//V2.0public static void process2(int[] arr, int L, int R) &#123; if (L &gt;= R) &#123; return; &#125; //返回arr[R]的下标范围 int[] equalArea = netherlandsFlag(arr, L, R); process2(arr, L, equalArea[0] - 1); process2(arr, equalArea[1] + 1, R);&#125; 1234567891011121314151617181920212223// arr[L...R] 玩荷兰国旗问题的划分，以arr[R]做为num的值public static int[] netherlandsFlag(int[] arr, int L, int R) &#123; // &lt;arr[R] ==arr[R] &gt; arr[R] //返回 中间等于 arr[R]的区间 int less = L - 1; // &lt; 区 右边界 int more = R; // &gt; 区 左边界 最右边的R不动 int index = L; //遍历的区间在于 [L--- R-1] while (index &lt; more) &#123; if (arr[index] == arr[R]) &#123; index++; &#125; else if (arr[index] &lt; arr[R]) &#123; swap(arr, index++, ++less); &#125; else &#123; // &gt; swap(arr, index, --more); &#125; &#125; //最后再把index=R的数据插到more的左侧 // L...Less less+1...more-1 more...R-1 R // L...Less less+1........more more+1...R swap(arr, more, R); return new int[] &#123; less + 1, more &#125;;&#125; 12345678快速排序3.0(随机快排+荷兰国旗技巧优化)在arr[L..R]范围上，进行快速排序的过程：1）在这个范围上，随机选一个数记为num，1）用num对该范围做partition，&lt; num的数在左部分，&#x3D;&#x3D; num的数中间，&gt;num的数在右部分。假设&#x3D;&#x3D; num的数所在范围是[a,b]2）对arr[L..a-1]进行快速排序(递归)3）对arr[b+1..R]进行快速排序(递归)因为每一次partition都会搞定一批数的位置且不会再变动，所以排序能完成 123456789101112131415161718192021222324252627282930313233//V3.0public static void process3(int[] arr, int L, int R) &#123; if (L &gt;= R) &#123; return; &#125; swap(arr, L + (int) (Math.random() * (R - L + 1)), R); int[] equalArea = netherlandsFlag(arr, L, R); process3(arr, L, equalArea[0] - 1); process3(arr, equalArea[1] + 1, R);&#125;public static int[] netherlandsFlag(int[] arr, int L, int R) &#123; if (L &gt; R) &#123; return new int[] &#123; -1, -1 &#125;; &#125; if (L == R) &#123; return new int[] &#123; L, R &#125;; &#125; int less = L - 1; // &lt; 区 右边界 int more = R; // &gt; 区 左边界 int index = L; while (index &lt; more) &#123; if (arr[index] == arr[R]) &#123; index++; &#125; else if (arr[index] &lt; arr[R]) &#123; swap(arr, index++, ++less); &#125; else &#123; // &gt; swap(arr, index, --more); &#125; &#125; swap(arr, more, R); return new int[] &#123; less + 1, more &#125;;&#125; 1234561）通过分析知道，划分值越靠近中间，性能越好；越靠近两边，性能越差2）随机选一个数进行划分的目的就是让好情况和差情况都变成概率事件3）把每一种情况都列出来，会有每种情况下的时间复杂度，但概率都是1&#x2F;N4）那么所有情况都考虑，时间复杂度就是这种概率模型下的长期期望！时间复杂度O(N*logN)，额外空间复杂度O(logN)都是这么来的。 堆结构12345678910111213141516171）堆结构就是用数组实现的完全二叉树结构2）完全二叉树中如果每棵子树的最大值都在顶部就是大根堆3）完全二叉树中如果每棵子树的最小值都在顶部就是小根堆4）堆结构的heapInsert与heapify操作5）堆结构的增大和减少 6）优先级队列结构，就是堆结构N个元素，树的高度： logN父节点:(index - 1)&#x2F;2左子节点：2 * index + 1右子节点： 2 * index + 2注：有些算法不算第0个下标的数据，而是从1开始，因为计算节点将变成：父节点：index&#x2F;2 (index &gt;&gt; 1)左子节点： 2 * index (index &lt;&lt; 1)右子节点： 2 * index + 1 ((index &lt;&lt; 1) | 1) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//把第0个位置当做根节点，1~2位置当做根节点的左右节点public static class MyMaxHeap &#123; private int[] heap; private final int limit; //当前heap中保持着大根堆结构的数量 private int heapSize; public void push(int value) &#123; if (heapSize == limit) &#123; throw new RuntimeException(\"heap is full\"); &#125; heap[heapSize] = value; // value heapSize heapInsert(heap, heapSize++); &#125; // 用户此时，让你返回最大值，并且在大根堆中，把最大值删掉 // 剩下的数，依然保持大根堆组织 public int pop() &#123; int ans = heap[0]; //最后的heapSize和根节点交换 swap(heap, 0, --heapSize); heapify(heap, 0, heapSize); return ans; &#125; private void heapInsert(int[] arr, int index) &#123; // arr[index] // arr[index] 不比 arr[index父]大了 ， 停 // index = 0; while (arr[index] &gt; arr[(index - 1) / 2]) &#123; swap(arr, index, (index - 1) / 2); index = (index - 1) / 2; &#125; &#125; // 从index位置，往下看，不断的下沉， // 停：我的孩子都不再比我大；已经没孩子了 // arr[index]位置的数，能否往下移动 public static void heapify(int[] arr, int index, int heapSize) &#123; int left = index * 2 + 1; // 左孩子的下标 while (left &lt; heapSize) &#123; // 下方还有孩子的时候 // 两个孩子中，谁的值大，把下标给largest // 1）只有左孩子，left -&gt; largest // 2) 同时有左孩子和右孩子，右孩子的值&lt;= 左孩子的值，left -&gt; largest // 3) 同时有左孩子和右孩子并且右孩子的值&gt; 左孩子的值， right -&gt; largest int largest = left + 1 &lt; heapSize &amp;&amp; arr[left + 1] &gt; arr[left] ? left + 1 : left; // 父和较大的孩子之间，谁的值大，把下标给largest largest = arr[largest] &gt; arr[index] ? largest : index; if (largest == index) &#123; break; &#125; swap(arr, largest, index); index = largest; left = index * 2 + 1; &#125; &#125;&#125; 123456堆排序1，先让整个数组都变成大根堆结构，建立堆的过程: 1)从上到下的方法，时间复杂度为O(N*logN) 2)从下到上的方法，时间复杂度为O(N) 2，把堆的最大值和堆末尾的值交换，然后减少堆的大小之后，再去调整堆，一直周而复始，时间复杂度为O(N*logN) 3，堆的大小减小成0之后，排序完成 12345678910111213141516171819202122232425262728// 堆排序额外空间复杂度O(1)// 堆排序的逻辑：先排一次大根堆，第0个位置肯定是最大的 O(N*logN)// 把第0个位置和大根堆最后一个数交换，大根堆范围缩小1 O(N*logN)// 接着循环一直排大根堆，直到heapSize等于0//第一次创建大根堆的逻辑可以优化成O(N)，要逆序从最后一个往上比较，父节点小的调用heapify下沉public static void heapSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; // O(N*logN)写法 // for (int i = 0; i &lt; arr.length; i++) &#123; // O(N) // heapInsert(arr, i); // O(logN) // &#125; //O(N)写法 for (int i = arr.length - 1; i &gt;= 0; i--) &#123; heapify(arr, i, arr.length); &#125; int heapSize = arr.length; swap(arr, 0, --heapSize); // O(N*logN) while (heapSize &gt; 0) &#123; // O(N) heapify(arr, 0, heapSize); // O(logN) swap(arr, 0, --heapSize); // O(1) &#125;&#125; 123已知一个几乎有序的数组。几乎有序是指，如果把数组排好顺序的话，每个元素移动的距离一定不超过k，并且k相对于数组长度来说是比较小的。请选择一个合适的排序策略，对这个数组进行排序。 1234567891011121314151617181920212223//时间复杂度O(N * logK)//在K个范围排序小根堆，然后弹出根节点，再加入下一个结点public static void sortedArrDistanceLessK(int[] arr, int k) &#123; if (k == 0) &#123; return; &#125; // 默认小根堆 PriorityQueue&lt;Integer&gt; heap = new PriorityQueue&lt;&gt;(); int index = 0; // 0...K-1 for (; index &lt;= Math.min(arr.length - 1, k - 1); index++) &#123; heap.add(arr[index]); &#125; int i = 0; for (; index &lt; arr.length; i++, index++) &#123; heap.add(arr[index]); arr[i] = heap.poll(); &#125; //当小根堆无法继续扩容时，以此弹出小根堆中最小的值 while (!heap.isEmpty()) &#123; arr[i++] = heap.poll(); &#125;&#125; 前缀树1234561）单个字符串中，字符从前到后的加到一棵多叉树上2）字符放在路上，节点上有专属的数据项（常见的是pass和end值）3）所有样本都这样添加，如果没有路就新建，如有路就复用4）沿途节点的pass值增加1，每个字符串结束时来到的节点end值增加1可以完成前缀相关的查询 123456例子：设计一种结构。用户可以：1）void insert(String str) 添加某个字符串，可以重复添加，每次算1个2）int search(String str) 查询某个字符串在结构中还有几个3) void delete(String str) 删掉某个字符串，可以重复删除，每次算1个4）int prefixNumber(String str) 查询有多少个字符串，是以str做前缀的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293//通过链表记录链路，index记录字母public static class Node1 &#123; public int pass; public int end; public Node1[] nexts; public Node1() &#123; pass = 0; end = 0; nexts = new Node1[26]; &#125;&#125;public static class Trie1 &#123; private Node1 root; public Trie1() &#123; root = new Node1(); &#125; public void insert(String word) &#123; if (word == null) &#123; return; &#125; char[] chs = word.toCharArray(); Node1 node = root; node.pass++; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; // 从左往右遍历字符 index = chs[i] - 'a'; // 由字符，对应成走向哪条路 if (node.nexts[index] == null) &#123; node.nexts[index] = new Node1(); &#125; node = node.nexts[index]; node.pass++; &#125; node.end++; &#125; public void delete(String word) &#123; if (search(word) != 0) &#123; char[] chs = word.toCharArray(); Node1 node = root; node.pass--; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; index = chs[i] - 'a'; if (--node.nexts[index].pass == 0) &#123; node.nexts[index] = null; return; &#125; node = node.nexts[index]; &#125; node.end--; &#125; &#125; // word这个单词之前加入过几次 public int search(String word) &#123; if (word == null) &#123; return 0; &#125; char[] chs = word.toCharArray(); Node1 node = root; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; index = chs[i] - 'a'; if (node.nexts[index] == null) &#123; return 0; &#125; node = node.nexts[index]; &#125; return node.end; &#125; // 所有加入的字符串中，有几个是以pre这个字符串作为前缀的 public int prefixNumber(String pre) &#123; if (pre == null) &#123; return 0; &#125; char[] chs = pre.toCharArray(); Node1 node = root; int index = 0; for (int i = 0; i &lt; chs.length; i++) &#123; index = chs[i] - 'a'; if (node.nexts[index] == null) &#123; return 0; &#125; node = node.nexts[index]; &#125; return node.pass; &#125;&#125; 桶排序1234567891011桶排序思想下的排序：计数排序 &amp; 基数排序 1)桶排序思想下的排序都是不基于比较的排序2)时间复杂度为O(N)，额外空间负载度O(M)3)应用范围有限，需要样本的数据状况满足桶的划分 一般来讲，计数排序要求，样本是整数，且范围比较窄一般来讲，基数排序要求，样本是10进制的正整数一旦要求稍有升级，改写代价增加是显而易见的 12345计数排序:如年龄0~200，设定一个下标为0~200的数组，遍历并数组中的值++，适用范围有限且和样本数据强关联基数排序：建立十个桶队列，低位数据补齐至和高位相同位数，如 100,001按照个十百位顺序入队列，再依次取出十个桶队列的所有元素，最后有序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//排序非负数的十进制// only for no-negative valuepublic static void radixSort(int[] arr) &#123; if (arr == null || arr.length &lt; 2) &#123; return; &#125; radixSort(arr, 0, arr.length - 1, maxbits(arr));&#125;//获取最大值的位数 如 100 ---&gt; 3位public static int maxbits(int[] arr) &#123; int max = Integer.MIN_VALUE; for (int i = 0; i &lt; arr.length; i++) &#123; max = Math.max(max, arr[i]); &#125; int res = 0; while (max != 0) &#123; res++; max /= 10; &#125; return res;&#125;// arr[l..r]排序 , digit// l..r 3 56 17 100 3public static void radixSort(int[] arr, int L, int R, int digit) &#123; final int radix = 10; int i = 0, j = 0; // 有多少个数准备多少个辅助空间 int[] help = new int[R - L + 1]; //d表示当前要取出的位数下标，1表示个位，2表示十位 for (int d = 1; d &lt;= digit; d++) &#123; // 有多少位就进出几次 // 10个空间 // count[0] 当前位(d位)是0的数字有多少个 // count[1] 当前位(d位)是(0和1)的数字有多少个 // count[2] 当前位(d位)是(0、1和2)的数字有多少个 // count[i] 当前位(d位)是(0~i)的数字有多少个 int[] count = new int[radix]; // count[0..9] //这时候的count[]存储的个位数等于当前下标的数量 for (i = L; i &lt;= R; i++) &#123; // 103 d=1 3 // 209 d=1 9 j = getDigit(arr[i], d); count[j]++; &#125; //count做累加和，i - 1的数据做累加，count[]存储的是个位数小于等于当前下标的数量 for (i = 1; i &lt; radix; i++) &#123; count[i] = count[i] + count[i - 1]; &#125; //倒序遍历数组，把数据放在第count[j]个位置上，j-- //通过这种方式实现队列排序 for (i = R; i &gt;= L; i--) &#123; j = getDigit(arr[i], d); help[count[j] - 1] = arr[i]; count[j]--; &#125; for (i = L, j = 0; i &lt;= R; i++, j++) &#123; arr[i] = help[j]; &#125; &#125;&#125;public static int getDigit(int x, int d) &#123; return ((x / ((int) Math.pow(10, d - 1))) % 10);&#125; 总结1234567稳定性是指同样大小的样本再排序之后不会改变相对次序对基础类型来说，稳定性毫无意义对非基础类型来说，稳定性有重要意义有些排序算法可以实现成稳定的，而有些排序算法无论如何都实现不成稳定的 12345678910 时间复杂度 额外空间复杂度 稳定性选择排序 O(N^2) O(1) 无冒泡排序 O(N^2) O(1) 有插入排序 O(N^2) O(1) 有归并排序 O(N*logN) O(N) 有随机快排 O(N*logN) O(logN) 无堆排序 O(N*logN) O(1) 无&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;计数排序 O(N) O(M) 有基数排序 O(N) O(N) 有 追求稳定性的话，可以选择归并排序，追求额外空间复杂度低的，选择堆排序，两者都不追求时，快排的效率最高。 123451）不基于比较的排序，对样本数据有严格要求，不易改写2）基于比较的排序，只要规定好两个样本怎么比大小就可以直接复用3）基于比较的排序，时间复杂度的极限是O(N*logN)4）时间复杂度O(N*logN)、额外空间复杂度低于O(N)、且稳定的基于比较的排序是不存在的。5）为了绝对的速度选快排、为了省空间选堆排、为了稳定性选归并 链表12345快慢指针：快指针走的步数是慢指针的两倍1）输入链表头节点，奇数长度返回中点，偶数长度返回上中点2）输入链表头节点，奇数长度返回中点，偶数长度返回下中点3）输入链表头节点，奇数长度返回中点前一个，偶数长度返回上中点前一个4）输入链表头节点，奇数长度返回中点前一个，偶数长度返回下中点前一个 12345678public static class Node &#123; public int value; public Node next; public Node(int v) &#123; value = v; &#125;&#125; 123456789101112131415// head 头//1）输入链表头节点，奇数长度返回中点，偶数长度返回上中点public static Node midOrUpMidNode(Node head) &#123; if (head == null || head.next == null || head.next.next == null) &#123; return head; &#125; // 链表有3个点或以上 Node slow = head.next; Node fast = head.next.next; while (fast.next != null &amp;&amp; fast.next.next != null) &#123; slow = slow.next; fast = fast.next.next; &#125; return slow;&#125; 12345678910111213//2）输入链表头节点，奇数长度返回中点，偶数长度返回下中点public static Node midOrDownMidNode(Node head) &#123; if (head == null || head.next == null) &#123; return head; &#125; Node slow = head.next; Node fast = head.next; while (fast.next != null &amp;&amp; fast.next.next != null) &#123; slow = slow.next; fast = fast.next.next; &#125; return slow; &#125; 12345678910111213//3）输入链表头节点，奇数长度返回中点前一个，偶数长度返回上中点前一个public static Node midOrUpMidPreNode(Node head) &#123; if (head == null || head.next == null || head.next.next == null) &#123; return null; &#125; Node slow = head; Node fast = head.next.next; while (fast.next != null &amp;&amp; fast.next.next != null) &#123; slow = slow.next; fast = fast.next.next; &#125; return slow; &#125; 12345678910111213141516//4）输入链表头节点，奇数长度返回中点前一个，偶数长度返回下中点前一个public static Node midOrDownMidPreNode(Node head) &#123; if (head == null || head.next == null) &#123; return null; &#125; if (head.next.next == null) &#123; return head; &#125; Node slow = head; Node fast = head.next; while (fast.next != null &amp;&amp; fast.next.next != null) &#123; slow = slow.next; fast = fast.next.next; &#125; return slow; &#125; 123456给定一个单链表的头节点head，请判断该链表是否为回文结构。 笔试做法：1.创建栈，全都丢到栈里，弹出来和原来的链表做比较，空间复杂度O（N）2.快慢指针找到中点，中点后的链表压入栈中，空间复杂度O（N&#x2F;2）面试做法：快慢指针找到中点，reverse中点后的链表，然后头尾两个指针遍历比较，最后要还原reverse的链表 1234567891011121314151617// need n extra space//时间复杂度O（N），空间复杂度O（N）public static boolean isPalindrome1(Node head) &#123; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); Node cur = head; while (cur != null) &#123; stack.push(cur); cur = cur.next; &#125; while (head != null) &#123; if (head.value != stack.pop().value) &#123; return false; &#125; head = head.next; &#125; return true;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344// need O(1) extra spacepublic static boolean isPalindrome3(Node head) &#123; if (head == null || head.next == null) &#123; return true; &#125; Node n1 = head; Node n2 = head; while (n2.next != null &amp;&amp; n2.next.next != null) &#123; // find mid node n1 = n1.next; // n1 -&gt; mid n2 = n2.next.next; // n2 -&gt; end &#125; // n1 中点 n2 = n1.next; // n2 -&gt; right part first node n1.next = null; // mid.next -&gt; null Node n3 = null; while (n2 != null) &#123; // right part convert n3 = n2.next; // n3 -&gt; save next node n2.next = n1; // next of right node convert n1 = n2; // n1 move n2 = n3; // n2 move &#125; n3 = n1; // n3 -&gt; save last node n2 = head;// n2 -&gt; left first node boolean res = true; while (n1 != null &amp;&amp; n2 != null) &#123; // check palindrome if (n1.value != n2.value) &#123; res = false; break; &#125; n1 = n1.next; // left to mid n2 = n2.next; // right to mid &#125; n1 = n3.next; n3.next = null; while (n1 != null) &#123; // recover list n2 = n1.next; n1.next = n3; n3 = n1; n1 = n2; &#125; return res;&#125; 12345将单向链表按某值划分成左边小、中间相等、右边大的形式1）把链表放入数组里，在数组上做partition（笔试用）2）分成小、中、大三部分，再把各个部分之间串起来（面试用） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//用6个指针，生成三条链表，最后连起来public static Node listPartition2(Node head, int pivot) &#123; Node sH = null; // small head Node sT = null; // small tail Node eH = null; // equal head Node eT = null; // equal tail Node mH = null; // big head Node mT = null; // big tail Node next = null; // save next node // every node distributed to three lists while (head != null) &#123; next = head.next; head.next = null; if (head.value &lt; pivot) &#123; if (sH == null) &#123; sH = head; sT = head; &#125; else &#123; sT.next = head; sT = head; &#125; &#125; else if (head.value == pivot) &#123; if (eH == null) &#123; eH = head; eT = head; &#125; else &#123; eT.next = head; eT = head; &#125; &#125; else &#123; if (mH == null) &#123; mH = head; mT = head; &#125; else &#123; mT.next = head; mT = head; &#125; &#125; head = next; &#125; // 小于区域的尾巴，连等于区域的头，等于区域的尾巴连大于区域的头 if (sT != null) &#123; // 如果有小于区域 sT.next = eH; eT = eT == null ? sT : eT; // 下一步，谁去连大于区域的头，谁就变成eT &#125; // 上面的if，不管跑了没有，et // all reconnect if (eT != null) &#123; // 如果小于区域和等于区域，不是都没有 eT.next = mH; &#125; return sH != null ? sH : (eH != null ? eH : mH);&#125; 1234567891011一种特殊的单链表节点类描述如下 class Node &#123; int value; Node next; Node rand; Node(int val) &#123; value = val; &#125; &#125; rand指针是单链表节点结构中新增的指针，rand可能指向链表中的任意一个节点，也可能指向null。给定一个由Node节点类型组成的无环单链表的头节点 head，请实现一个函数完成这个链表的复制，并返回复制的新链表的头节点。 【要求】时间复杂度O(N)，额外空间复杂度O(1) 123456789101112131415161718//hash表做法 空间复杂度O（N）public static Node copyListWithRand1(Node head) &#123; HashMap&lt;Node, Node&gt; map = new HashMap&lt;Node, Node&gt;(); Node cur = head; while (cur != null) &#123; map.put(cur, new Node(cur.value)); cur = cur.next; &#125; cur = head; while (cur != null) &#123; // cur 老 // map.get(cur) 新 map.get(cur).next = map.get(cur.next); map.get(cur).rand = map.get(cur.rand); cur = cur.next; &#125; return map.get(head);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142//拷贝链表结点，并插入到链表中，然后按对获取结点，设置rand值，再分离next指针，返回链表public static Node copyListWithRand2(Node head) &#123; if (head == null) &#123; return null; &#125; Node cur = head; Node next = null; // copy node and link to every node // 1 -&gt; 2 // 1 -&gt; 1' -&gt; 2 while (cur != null) &#123; // cur 老 next 老的下一个 next = cur.next; cur.next = new Node(cur.value); cur.next.next = next; cur = next; &#125; cur = head; Node curCopy = null; // set copy node rand // 1 -&gt; 1' -&gt; 2 -&gt; 2' while (cur != null) &#123; // cur 老 // cur.next 新 copy next = cur.next.next; curCopy = cur.next; curCopy.rand = cur.rand != null ? cur.rand.next : null; cur = next; &#125; // head head.next Node res = head.next; cur = head; // split while (cur != null) &#123; next = cur.next.next; curCopy = cur.next; cur.next = next; curCopy.next = next != null ? next.next : null; cur = next; &#125; return res;&#125; 123给定两个可能有环也可能无环的单链表，头节点head1和head2。请实现一个函数，如果两个链表相交，请返回相交的 第一个节点。如果不相交，返回null 【要求】如果两个链表长度之和为N，时间复杂度请达到O(N)，额外空间复杂度 请达到O(1)。 1234567891011121314151617181920212223// 找到链表第一个入环节点，如果无环，返回null//当有环时，快指针和慢指针相遇后，慢指针接着往下走，快指针回到头结点，每次走一步，他们再次相遇的点就是第一个入环节点public static Node getLoopNode(Node head) &#123; if (head == null || head.next == null || head.next.next == null) &#123; return null; &#125; // n1 慢 n2 快 Node n1 = head.next; // n1 -&gt; slow Node n2 = head.next.next; // n2 -&gt; fast while (n1 != n2) &#123; if (n2.next == null || n2.next.next == null) &#123; return null; &#125; n2 = n2.next.next; n1 = n1.next; &#125; n2 = head; // n2 -&gt; walk again from head while (n1 != n2) &#123; n1 = n1.next; n2 = n2.next; &#125; return n1;&#125; 123456789101112131415161718192021222324252627282930313233343536// 如果两个链表都无环，返回第一个相交节点，如果不想交，返回null//记录链表长度，如果最后一个结点不同，则不相交//相交的话，减去长链表的和短链表的差值，同长之后一起遍历，判断结点是否相同public static Node noLoop(Node head1, Node head2) &#123; if (head1 == null || head2 == null) &#123; return null; &#125; Node cur1 = head1; Node cur2 = head2; int n = 0; while (cur1.next != null) &#123; n++; cur1 = cur1.next; &#125; while (cur2.next != null) &#123; n--; cur2 = cur2.next; &#125; if (cur1 != cur2) &#123; return null; &#125; // n : 链表1长度减去链表2长度的值 cur1 = n &gt; 0 ? head1 : head2; // 谁长，谁的头变成cur1 cur2 = cur1 == head1 ? head2 : head1; // 谁短，谁的头变成cur2 //长链表先走差值步 n = Math.abs(n); while (n != 0) &#123; n--; cur1 = cur1.next; &#125; while (cur1 != cur2) &#123; cur1 = cur1.next; cur2 = cur2.next; &#125; return cur1;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445// 两个有环链表，返回第一个相交节点，如果不想交返回null//两个有环链表的三种情况：//1.相交于入环节点或环外，loop1 == loop2，和环没有任何关系或者入环节点相交，直接当做无环相交//2.不相交//3.环内相交，loop走一圈，如果遇到了loop2，则环内相交，否则不相交public static Node bothLoop(Node head1, Node loop1, Node head2, Node loop2) &#123; Node cur1 = null; Node cur2 = null; //相交入环节点或环外 if (loop1 == loop2) &#123; cur1 = head1; cur2 = head2; int n = 0; while (cur1 != loop1) &#123; n++; cur1 = cur1.next; &#125; while (cur2 != loop2) &#123; n--; cur2 = cur2.next; &#125; cur1 = n &gt; 0 ? head1 : head2; cur2 = cur1 == head1 ? head2 : head1; n = Math.abs(n); while (n != 0) &#123; n--; cur1 = cur1.next; &#125; while (cur1 != cur2) &#123; cur1 = cur1.next; cur2 = cur2.next; &#125; return cur1; &#125; else &#123; cur1 = loop1.next; while (cur1 != loop1) &#123; // if (cur1 == loop2) &#123; return loop1; &#125; cur1 = cur1.next; &#125; return null; &#125;&#125; 二叉树1234567891011先序：任何子树的处理顺序都是，先头节点、再左子树、然后右子树中序：任何子树的处理顺序都是，先左子树、再头节点、然后右子树后序：任何子树的处理顺序都是，先左子树、再右子树、然后头节点1）理解递归序2）先序、中序、后序都可以在递归序的基础上加工出来3）第一次到达一个节点就打印就是先序、第二次打印即中序、第三次即后序 123456789101112131415161718192021222324252627282930// 实际上就是递归序// 先序打印所有节点public static void pre(Node head) &#123; if (head == null) &#123; return; &#125; System.out.println(head.value); pre(head.left); pre(head.right);&#125;// 中序打印所有节点public static void in(Node head) &#123; if (head == null) &#123; return; &#125; in(head.left); System.out.println(head.value); in(head.right);&#125;// 后序打印所有节点public static void pos(Node head) &#123; if (head == null) &#123; return; &#125; pos(head.left); pos(head.right); System.out.println(head.value);&#125; 12345678910111213141516171819202122//用非递归的方式实现//先序//头结点压入栈，然后对栈实现pop弹出并打印，然后依次压入弹出的右、左结点//入栈顺序：头-右-左 出栈顺序：头-左-右public static void pre(Node head) &#123; System.out.print(\"pre-order: \"); if (head != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); stack.add(head); while (!stack.isEmpty()) &#123; head = stack.pop(); System.out.print(head.value + \" \"); if (head.right != null) &#123; stack.push(head.right); &#125; if (head.left != null) &#123; stack.push(head.left); &#125; &#125; &#125; System.out.println();&#125; 1234567891011121314151617181920//非递归的中序遍历//压入每个结点的左结点，压完时弹出栈，并打印，然后压入它的右结点，继续遍历右结点的左树//入栈顺序：头-左-左 出栈顺序：左-左-头public static void in(Node head) &#123; System.out.print(\"in-order: \"); if (head != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); while (!stack.isEmpty() || head != null) &#123; if (head != null) &#123; stack.push(head); head = head.left; &#125; else &#123; head = stack.pop(); System.out.print(head.value + \" \"); head = head.right; &#125; &#125; &#125; System.out.println();&#125; 1234567891011121314151617181920212223242526//非递归的后序遍历//头结点压入栈，然后对栈实现pop弹出并打印，然后依次压入弹出的左、右结点（如果是这种情况，则会出现后序遍历的相反输出操作）//所以只需要弄两个栈，一个栈弹出的内容压到第二个栈中，最后输出第二个栈的内容//入栈顺序 头-左-右 出栈顺序：头-右-左 -&gt;入第二个栈后顺序：左右头public static void pos1(Node head) &#123; System.out.print(\"pos-order: \"); if (head != null) &#123; Stack&lt;Node&gt; s1 = new Stack&lt;Node&gt;(); Stack&lt;Node&gt; s2 = new Stack&lt;Node&gt;(); s1.push(head); while (!s1.isEmpty()) &#123; head = s1.pop(); s2.push(head); if (head.left != null) &#123; s1.push(head.left); &#125; if (head.right != null) &#123; s1.push(head.right); &#125; &#125; while (!s2.isEmpty()) &#123; System.out.print(s2.pop().value + \" \"); &#125; &#125; System.out.println();&#125; 12345678910111213141516171819202122232425//只用一个栈实现非递归的后序遍历public static void pos2(Node h) &#123; System.out.print(\"pos-order: \"); if (h != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;(); //h用于记录上一个打印的节点 stack.push(h); Node c = null; while (!stack.isEmpty()) &#123; c = stack.peek(); //如果h不是c的左右节点，代表c的左右节点没处理过，那么先压入左树处理 if (c.left != null &amp;&amp; h != c.left &amp;&amp; h != c.right) &#123; stack.push(c.left); //如果h处于c的左节点，并且c的右节点不为空，压入右树处理 &#125; else if (c.right != null &amp;&amp; h != c.right) &#123; stack.push(c.right); &#125; else &#123; //c的左右节点已经处理过了，打印c节点 System.out.print(stack.pop().value + \" \"); h = c; &#125; &#125; &#125; System.out.println();&#125; 123456789101112131415161718//实现二叉树的按层遍历public static void level(Node head) &#123; if (head == null) &#123; return; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.add(head); while (!queue.isEmpty()) &#123; Node cur = queue.poll(); System.out.println(cur.value); if (cur.left != null) &#123; queue.add(cur.left); &#125; if (cur.right != null) &#123; queue.add(cur.right); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637//求二叉树最宽的层有多少个节点//思路：map中存储&lt;Node,层数&gt;,用一个变量来存储当前的层数，当队列中取出来的节点层数与当前层数不同时，则代表上一层遍历结束，计算上一层的层数//宽度都是需要进入下一层时才开始计算，所以最后一层要单独计算public static int maxWidthUseMap(Node head) &#123; if (head == null) &#123; return 0; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.add(head); // key 在 哪一层，value HashMap&lt;Node, Integer&gt; levelMap = new HashMap&lt;&gt;(); levelMap.put(head, 1); int curLevel = 1; // 当前你正在统计哪一层的宽度 int curLevelNodes = 0; // 当前层curLevel层，宽度目前是多少 int max = 0; while (!queue.isEmpty()) &#123; Node cur = queue.poll(); int curNodeLevel = levelMap.get(cur); if (cur.left != null) &#123; levelMap.put(cur.left, curNodeLevel + 1); queue.add(cur.left); &#125; if (cur.right != null) &#123; levelMap.put(cur.right, curNodeLevel + 1); queue.add(cur.right); &#125; if (curNodeLevel == curLevel) &#123; curLevelNodes++; &#125; else &#123; max = Math.max(max, curLevelNodes); curLevel++; curLevelNodes = 1; &#125; &#125; max = Math.max(max, curLevelNodes); return max;&#125; 12345678910111213141516171819202122232425262728293031//不使用hashMap计算二叉树最大宽度//遍历，并且记录每次遍历的最右边的子节点，它就是下一层的最右边的节点，每次遍历一层，比较对象是否相等，相等则到达当前层最右边位置public static int maxWidthNoMap(Node head) &#123; if (head == null) &#123; return 0; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); queue.add(head); Node curEnd = head; // 当前层，最右节点是谁 Node nextEnd = null; // 下一层，最右节点是谁 int max = 0; int curLevelNodes = 0; // 当前层的节点数 while (!queue.isEmpty()) &#123; Node cur = queue.poll(); if (cur.left != null) &#123; queue.add(cur.left); nextEnd = cur.left; &#125; if (cur.right != null) &#123; queue.add(cur.right); nextEnd = cur.right; &#125; curLevelNodes++; if (cur == curEnd) &#123; max = Math.max(max, curLevelNodes); curLevelNodes = 0; curEnd = nextEnd; &#125; &#125; return max;&#125; 12345二叉树的序列化和反序列化1）可以用先序或者中序或者后序或者按层遍历，来实现二叉树的序列化2）用了什么方式序列化，就用什么样的方式反序列化 12345678910//先序-序列化 不要忽略空，每个节点都有左右两个NULL值public static void pres(Node head, Queue&lt;String&gt; ans) &#123; if (head == null) &#123; ans.add(null); &#125; else &#123; ans.add(String.valueOf(head.value)); pres(head.left, ans); pres(head.right, ans); &#125;&#125; 1234567891011//先序--反序列化public static Node preb(Queue&lt;String&gt; prelist) &#123; String value = prelist.poll(); if (value == null) &#123; return null; &#125; Node head = new Node(Integer.valueOf(value)); head.left = preb(prelist); head.right = preb(prelist); return head;&#125; 123456789101112131415161718192021222324252627282930//按层遍历序列化public static Queue&lt;String&gt; levelSerial(Node head) &#123; Queue&lt;String&gt; ans = new LinkedList&lt;&gt;(); if (head == null) &#123; ans.add(null); &#125; else &#123; //加入队列时序列化 ans.add(String.valueOf(head.value)); Queue&lt;Node&gt; queue = new LinkedList&lt;Node&gt;(); queue.add(head); while (!queue.isEmpty()) &#123; head = queue.poll(); if (head.left != null) &#123; ans.add(String.valueOf(head.left.value)); queue.add(head.left); &#125; else &#123; //左节点等于空，加序列化，不加队列 ans.add(null); &#125; if (head.right != null) &#123; ans.add(String.valueOf(head.right.value)); queue.add(head.right); &#125; else &#123; //右节点等于空，加序列化，不加队列 ans.add(null); &#125; &#125; &#125; return ans;&#125; 12345678910111213二叉树结构如下定义：Class Node &#123; V value; Node left; Node right; Node parent;&#125;给你二叉树中的某个节点，返回该节点的中序遍历的后继节点 1 2 34 5 6 7中序遍历：4-&gt;2-&gt;5-&gt;1-&gt;6-&gt;3-&gt;74的后继节点是2 1234567891011121314151617181920212223242526public static Node getSuccessorNode(Node node) &#123; if (node == null) &#123; return node; &#125; if (node.right != null) &#123; //如果有右树，找到它右树的最左节点 return getLeftMost(node.right); &#125; else &#123; // 无右子树，循环找到node节点是父...节点的左侧时，返回 Node parent = node.parent; while (parent != null &amp;&amp; parent.right == node) &#123; // 当前节点是其父亲节点右孩子 node = parent; parent = node.parent; &#125; return parent; &#125;&#125;public static Node getLeftMost(Node node) &#123; if (node == null) &#123; return node; &#125; while (node.left != null) &#123; node = node.left; &#125; return node; &#125; 12345请把一段纸条竖着放在桌子上，然后从纸条的下边向上方对折1次，压出折痕后展开。此时折痕是凹下去的，即折痕突起的方向指向纸条的背面。 如果从纸条的下边向上方连续对折2次，压出折痕后展开，此时有三条折痕，从上到下依次是下折痕、下折痕和上折痕。 给定一个输入参数N，代表纸条都从下边向上方连续对折N次。 请从上到下打印所有折痕的方向。 例如:N&#x3D;1时，打印: down N&#x3D;2时，打印: down down up 思路：等于一个二叉树，头结点down、左树全是down、右树全是up 12345678910111213// 递归过程，来到了某一个节点，// i是节点的层数，N一共的层数，down == true 凹 down == false 凸//printProcess(1, N, true);public static void printProcess(int i, int N, boolean down) &#123; //通过层数进行递归 if (i &gt; N) &#123; return; &#125; printProcess(i + 1, N, true); //递归的中序遍历 System.out.println(down ? \"凹 \" : \"凸 \"); printProcess(i + 1, N, false);&#125; 二叉树的递归套路1234561）假设以X节点为头，假设可以向X左树和X右树要任何信息2）在上一步的假设下，讨论以X为头节点的树，得到答案的可能性（最重要）3）列出所有可能性后，确定到底需要向左树和右树要什么样的信息4）把左树信息和右树信息求全集，就是任何一棵子树都需要返回的信息S5）递归函数都返回S，每一棵子树都这么要求6）写代码，在代码中考虑如何把左树的信息和右树信息整合出整棵树的信息 1判断是否是一颗完全二叉树 12345678910111213141516171819202122232425262728293031/*思路： 1.左/右树是否平衡 2.左/右树的高度是否超过1*/// 左、右要求一样，Info 信息返回的结构体public static class Info &#123; public boolean isBalaced; public int height; public Info(boolean b, int h) &#123; isBalaced = b; height = h; &#125;&#125;//判断是否是一颗完全二叉树//左树平衡、右树平衡、左右树高度相差不超过1public static Info process2(Node X) &#123; if (X == null) &#123; return new Info(true, 0); &#125; Info leftInfo = process2(X.left); Info rightInfo = process2(X.right); int height = Math.max(leftInfo.height, rightInfo.height) + 1; boolean isBalanced = true; if (!leftInfo.isBalaced || !rightInfo.isBalaced || Math.abs(leftInfo.height - rightInfo.height) &gt; 1) &#123; isBalanced = false; &#125; return new Info(isBalanced, height);&#125; 1给定一棵二叉树的头节点head，任何两个节点之间都存在距离,返回整棵二叉树的最大距离 1234567891011121314151617181920212223242526272829303132333435/* 思路： 1.与X无关： 左树/右树的最大距离 2.与X有关： 左树的高度 + 右树的高度 + 1 3.从左/右树要得到的信息： 左/右树的高度、最大距离。*/public static class Info &#123; public int maxDistance; public int height; public Info(int dis, int h) &#123; maxDistance = dis; height = h; &#125;&#125;//当前树的最大高度 = Max(左树,右树)高度 + 1//当前树最大距离 = Max ( Max(左树,右树)距离, 左树高度+右树高度+1)public static Info process(Node X) &#123; if (X == null) &#123; return new Info(0, 0); &#125; Info leftInfo = process(X.left); Info rightInfo = process(X.right); //左右树最大高度+1 int height = Math.max(leftInfo.height, rightInfo.height) + 1; //左右数高度+1 || 左树最大距离 || 右树最大距离 三者求max int maxDistance = Math.max( Math.max(leftInfo.maxDistance, rightInfo.maxDistance), leftInfo.height + rightInfo.height + 1); return new Info(maxDistance, height);&#125; 12给定一棵二叉树的头节点head，返回这颗二叉树中最大的二叉搜索子树的节点数量 1234567891011121314151617181920212223/* 思路： 1.与X无关： 1.1 左/右树是否是二叉搜索树 1.2 左/右树的子树有多少个二叉搜索树节点 2.与X相关： 2.1 左树的最大值是否小于X 2.2 右树的最小值是否大于X*/public static class Info &#123; public boolean isAllBST; //最大的搜索二叉树节点数量 public int maxSubBSTSize; public int min; public int max; public Info(boolean is, int size, int mi, int ma) &#123; isAllBST = is; maxSubBSTSize = size; min = mi; max = ma; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static Info process(Node X) &#123; if(X == null) &#123; return null; &#125; Info leftInfo = process(X.left); Info rightInfo = process(X.right); //先赋值当前节点的最大值和最小值 int min = X.value; int max = X.value; //如果左树不为空 if(leftInfo != null) &#123; //取X和左树的min、max的最大值，最小值 min = Math.min(min, leftInfo.min); max = Math.max(max, leftInfo.max); &#125; //如果右树不为空 if(rightInfo != null) &#123; //同样 min = Math.min(min, rightInfo.min); max = Math.max(max, rightInfo.max); &#125; //先赋默认值 int maxSubBSTSize = 0; //先赋值左、右的最大二叉搜索子树的节点数量 if(leftInfo != null) &#123; maxSubBSTSize = leftInfo.maxSubBSTSize; &#125; if(rightInfo !=null) &#123; maxSubBSTSize = Math.max(maxSubBSTSize, rightInfo.maxSubBSTSize); &#125; boolean isAllBST = false; //结点也是搜索二叉树的一部分 if( // 左树整体需要是搜索二叉树 ( leftInfo == null ? true : leftInfo.isAllBST ) &amp;&amp; ( rightInfo == null ? true : rightInfo.isAllBST ) &amp;&amp; // 左树最大值&lt;x (leftInfo == null ? true : leftInfo.max &lt; X.value) &amp;&amp; (rightInfo == null ? true : rightInfo.min &gt; X.value) ) &#123; //取左树的max + 右树的max + 1 maxSubBSTSize = (leftInfo == null ? 0 : leftInfo.maxSubBSTSize) + (rightInfo == null ? 0 : rightInfo.maxSubBSTSize) + 1; //设置该节点及子树都是搜索二叉树 isAllBST = true; &#125; 123456派对的最大快乐值这个公司现在要办party，你可以决定哪些员工来，哪些员工不来，规则：1.如果某个员工来了，那么这个员工的所有直接下级都不能来2.派对的整体快乐值是所有到场员工快乐值的累加3.你的目标是让派对的整体快乐值尽量大给定一棵多叉树的头节点boss，请返回派对的最大快乐值。 123456789/*思路：1.X不发请柬： 1.1 X/happy = 0 1.2 累加各个max(下层员工来的maxHappy, 不来的maxHappy)2.X发请柬： 2.1 X的快乐值 x.happy 2.2 每个直接下层员工不来，累加他们的最大快乐值*/ 1234567891011121314151617181920public static class Employee &#123; public int happy; public List&lt;Employee&gt; nexts; public Employee(int h) &#123; happy = h; nexts = new ArrayList&lt;&gt;(); &#125;&#125;public static class Info &#123; //来的最大快乐值 public int yes; //不来的最大快乐值 public int no; public Info(int y, int n) &#123; yes = y; no = n; &#125;&#125; 123456789101112131415161718public static Info process2(Employee x) //基层员工，最底层，没有下级节点 if (x.nexts.isEmpty()) &#123; return new Info(x.happy, 0); &#125; //X来的当前快乐值 int yes = x.happy; //不来为0 int no = 0; for (Employee next : x.nexts) &#123; Info nextInfo = process2(next); //当X来，则累加它子树不来的max最大快乐值 yes += nextInfo.no; //当X不来，则累加子树Max(来/不来)的最大快乐值 no += Math.max(nextInfo.yes, nextInfo.no); &#125; return new Info(yes, no);&#125; 12345678910给定一棵二叉树的头节点head，返回这颗二叉树中最大的二叉搜索子树的头节点思路：1.与X无关： 1.1 Max（左树的答案，右树的答案） 1.2 左右树最搜索二叉树头结点 1.3 搜索二叉树的结点数量2.与X有关： 2.1 左树的Max&lt;X&lt;右树的Min 2.2 左右树的Max、Min 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 每一棵子树public static class Info &#123; //最大搜二叉树结点 public Node maxSubBSTHead; //结点数量 public int maxSubBSTSize; public int min; public int max; public Info(Node h, int size, int mi, int ma) &#123; maxSubBSTHead = h; maxSubBSTSize = size; min = mi; max = ma; &#125;&#125;public static Info process(Node X) &#123; if (X == null) &#123; return null; &#125; Info leftInfo = process(X.left); Info rightInfo = process(X.right); int min = X.value; int max = X.value; Node maxSubBSTHead = null; int maxSubBSTSize = 0; if (leftInfo != null) &#123; min = Math.min(min, leftInfo.min); max = Math.max(max, leftInfo.max); maxSubBSTHead = leftInfo.maxSubBSTHead; maxSubBSTSize = leftInfo.maxSubBSTSize; &#125; if (rightInfo != null) &#123; min = Math.min(min, rightInfo.min); max = Math.max(max, rightInfo.max); if (rightInfo.maxSubBSTSize &gt; maxSubBSTSize) &#123; maxSubBSTHead = rightInfo.maxSubBSTHead; maxSubBSTSize = rightInfo.maxSubBSTSize; &#125; &#125; //左树整体是否是搜索二叉树 if ((leftInfo == null ? true : (leftInfo.maxSubBSTHead == X.left &amp;&amp; leftInfo.max &lt; X.value)) &amp;&amp; (rightInfo == null ? true : (rightInfo.maxSubBSTHead == X.right &amp;&amp; rightInfo.min &gt; X.value))) &#123; maxSubBSTHead = X; maxSubBSTSize = (leftInfo == null ? 0 : leftInfo.maxSubBSTSize) + (rightInfo == null ? 0 : rightInfo.maxSubBSTSize) + 1; &#125; return new Info(maxSubBSTHead, maxSubBSTSize, min, max);&#125; 1234567891011给定一棵二叉树的头节点head，返回这颗二叉树中是不是完全二叉树思路：1.X是否是满二叉树 1.1 左树的高度&#x3D;右树的高度，并且都是满二叉树2.X的最后一层没有越过左树 2.1 左树是完全二叉树，右树是满二叉树，并且左树高度比右树高度大13.X的最后一层刚好填满左树 3.1 左&#x2F;右树都是满二叉树，并且左树高度比右树高度大14.X的最后一层越过左树，来到右树 4.1 左树是完全二叉树，右树是满二叉树，并且左树高度比右树高度大1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 对每一棵子树，是否是满二叉树、是否是完全二叉树、高度public static class Info &#123; //是否是满二叉树 public boolean isFull; //是否是完全二叉树 public boolean isCBT; //高度 public int height; public Info(boolean full, boolean cbt, int h) &#123; isFull = full; isCBT = cbt; height = h; &#125;&#125;public static Info process(Node X) &#123; if (X == null) &#123; //空树-满二叉树-完全二叉树-高度0 return new Info(true, true, 0); &#125; Info leftInfo = process(X.left); Info rightInfo = process(X.right); int height = Math.max(leftInfo.height, rightInfo.height) + 1; //左树满、右树满、并且高度相同 boolean isFull = leftInfo.isFull &amp;&amp; rightInfo.isFull &amp;&amp; leftInfo.height == rightInfo.height; boolean isCBT = false; if (isFull) &#123; isCBT = true; &#125; else &#123; // 以x为头整棵树，不满 //左右树都是完全二叉树才进行判断逻辑 if (leftInfo.isCBT &amp;&amp; rightInfo.isCBT) &#123; //左树是完全二叉树、右树是满的、并且高度大1 if (leftInfo.isCBT &amp;&amp; rightInfo.isFull &amp;&amp; leftInfo.height == rightInfo.height + 1) &#123; isCBT = true; &#125; //左树是满的、右树也是满的，并且高度大1 if (leftInfo.isFull &amp;&amp; rightInfo.isFull &amp;&amp; leftInfo.height == rightInfo.height + 1) &#123; isCBT = true; &#125; //左树是满的，右树是完全二叉树，并且高度相同 if (leftInfo.isFull &amp;&amp; rightInfo.isCBT &amp;&amp; leftInfo.height == rightInfo.height) &#123; isCBT = true; &#125; &#125; &#125; return new Info(isFull, isCBT, height);&#125; 贪心算法12345671）最自然智慧的算法2）用一种局部最功利的标准，总是做出在当前看来是最好的选择3）难点在于证明局部最功利的标准可以得到全局最优解4）对于贪心算法的学习主要以增加阅历和经验为主 123给定一个由字符串组成的数组strs，必须把所有的字符串拼接起来，返回所有可能的拼接结果中，字典序最小的结果 12345678910111213141516171819//暴力递归// strs里放着所有的字符串// 已经使用过的字符串的下标，在use里登记了，不要再使用了// 之前使用过的字符串，拼接成了-&gt; path// 用all收集所有可能的拼接结果public static void process(String[] strs, HashSet&lt;Integer&gt; use, String path, ArrayList&lt;String&gt; all) &#123; if (use.size() == strs.length) &#123; all.add(path); &#125; else &#123; for (int i = 0; i &lt; strs.length; i++) &#123; if (!use.contains(i)) &#123; //深度优先遍历，加完使用完还原现场删掉它 use.add(i); process(strs, use, path + strs[i], all); use.remove(i); &#125; &#125; &#125;&#125; 12345678910111213141516171819//贪心算法public static class MyComparator implements Comparator&lt;String&gt; &#123; @Override public int compare(String a, String b) &#123; return (a + b).compareTo(b + a); &#125;&#125;public static String lowestString2(String[] strs) &#123; if (strs == null || strs.length == 0) &#123; return \"\"; &#125; Arrays.sort(strs, new MyComparator()); String res = \"\"; for (int i = 0; i &lt; strs.length; i++) &#123; res += strs[i]; &#125; return res;&#125; 1234一些项目要占用一个会议室宣讲，会议室不能同时容纳两个项目的宣讲。给你每一个项目开始的时间和结束的时间你来安排宣讲的日程，要求会议室进行的宣讲的场次最多。返回最多的宣讲场次。 1234567891011121314151617181920212223//暴力递归// 还剩什么会议都放在programs里// done 之前已经安排了多少会议，数量// timeLine目前来到的时间点是什么// 目前来到timeLine的时间点，已经安排了done多的会议，剩下的会议programs可以自由安排// 返回能安排的最多会议数量public static int process(Program[] programs, int done, int timeLine) &#123; if (programs.length == 0) &#123; return done; &#125; // 还有会议可以选择 int max = done; // 当前安排的会议是什么会，每一个都枚举 for (int i = 0; i &lt; programs.length; i++) &#123; if (programs[i].start &gt;= timeLine) &#123; //移除i位置上的元素，拷贝新数组，所以不需要还原现场 Program[] next = copyButExcept(programs, i); max = Math.max(max, process(next, done + 1, programs[i].end)); &#125; &#125; return max;&#125; 1234567891011121314//贪心算法//按照结束时间排序，结束时间最早的，添加进安排public static int bestArrange2(Program[] programs) &#123; Arrays.sort(programs, new ProgramComparator()); int timeLine = 0; int result = 0; for (int i = 0; i &lt; programs.length; i++) &#123; if (timeLine &lt;= programs[i].start) &#123; result++; timeLine = programs[i].end; &#125; &#125; return result; &#125; 12345给定一个字符串str，只由‘X’和‘.’两种字符构成。‘X’表示墙，不能放灯，也不需要点亮‘.’表示居民点，可以放灯，需要点亮如果灯放在i位置，可以让i-1，i和i+1三个位置被点亮返回如果点亮str中所有需要点亮的位置，至少需要几盏灯 123456789101112131415161718192021222324252627282930// str[index....]位置，自由选择放灯还是不放灯// str[0..index-1]位置呢？已经做完决定了，那些放了灯的位置，存在lights里// 要求选出能照亮所有.的方案，并且在这些有效的方案中，返回最少需要几个灯public static int process(char[] str, int index, HashSet&lt;Integer&gt; lights) &#123; if (index == str.length) &#123; // 结束的时候 for (int i = 0; i &lt; str.length; i++) &#123; if (str[i] != 'X') &#123; // 当前位置是点的话 if (!lights.contains(i - 1) &amp;&amp; !lights.contains(i) &amp;&amp; !lights.contains(i + 1)) &#123; return Integer.MAX_VALUE; &#125; &#125; &#125; return lights.size(); &#125; else &#123; // str还没结束 // i X . //当i位置不放灯的递归答案 int no = process(str, index + 1, lights); int yes = Integer.MAX_VALUE; //当i位置是'.'，并且放灯的答案 if (str[index] == '.') &#123; lights.add(index); yes = process(str, index + 1, lights); lights.remove(index); &#125; //求最小值 return Math.min(no, yes); &#125;&#125; 123456789101112131415161718192021222324252627282930//贪心算法// i位置为 X --&gt;i = i+1// i位置为i时：// -&gt; i+1位置为X --&gt; i放灯, i=i+2// -&gt; i+1位置为i// -&gt; i+2位置为X--&gt;i+1放灯，i=i+3// -&gt; i+2位置为i--&gt;i+1放灯，i=i+3public static int minLight2(String road) &#123; char[] str = road.toCharArray(); int index = 0; int light = 0; while (index &lt; str.length) &#123; if (str[index] == 'X') &#123; index++; &#125; else &#123; // i -&gt; . //不管什么情况，都需要找个位置放灯，然后移动下标 light++; if (index + 1 == str.length) &#123; break; &#125; else &#123; if (str[index + 1] == 'X') &#123; index = index + 2; &#125; else &#123; index = index + 3; &#125; &#125; &#125; &#125; return light;&#125; 12345678一块金条切成两半，是需要花费和长度数值一样的铜板的。比如长度为20的金条，不管怎么切，都要花费20个铜板。 一群人想整分整块金条，怎么分最省铜板? 例如,给定数组&#123;10,20,30&#125;，代表一共三个人，整块金条长度为60，金条要分成10，20，30三个部分。如果先把长度60的金条分成10和50，花费60; 再把长度50的金条分成20和30，花费50;一共花费110铜板。但如果先把长度60的金条分成30和30，花费60;再把长度30金条分成10和20， 花费30;一共花费90铜板。输入一个数组，返回分割的最小代价。 12345678910111213//暴力递归public static int process(int[] arr, int pre) &#123; if (arr.length == 1) &#123; return pre; &#125; int ans = Integer.MAX_VALUE; for (int i = 0; i &lt; arr.length; i++) &#123; for (int j = i + 1; j &lt; arr.length; j++) &#123; ans = Math.min(ans, process(copyAndMergeTwo(arr, i, j), pre + arr[i] + arr[j])); &#125; &#125; return ans;&#125; 12345678910111213141516//贪心算法//哈夫曼树，数据压入小根堆中，依次弹出两个数相加（累加到sum），并再次压入栈中，一直到栈中只剩下一个元素public static int lessMoney2(int[] arr) &#123; PriorityQueue&lt;Integer&gt; pQ = new PriorityQueue&lt;&gt;(); for (int i = 0; i &lt; arr.length; i++) &#123; pQ.add(arr[i]); &#125; int sum = 0; int cur = 0; while (pQ.size() &gt; 1) &#123; cur = pQ.poll() + pQ.poll(); sum += cur; pQ.add(cur); &#125; return sum;&#125; 1234567输入: 正数数组costs、正数数组profits、正数K、正数Mcosts[i]表示i号项目的花费profits[i]表示i号项目在扣除花费之后还能挣到的钱(利润)K表示你只能串行的最多做k个项目M表示你初始的资金说明: 每做完一个项目，马上获得的收益，可以支持你去做下一个项目。不能并行的做项目。输出：你最后获得的最大钱数。 1234567891011121314151617181920212223242526272829303132//贪心算法//按照花费放进小根堆中，按照利润放到大根堆中//弹出小于当前资金（W）的项目，依次塞到大根堆中，取堆顶那个，重复循环，直到项目达到K个public static int findMaximizedCapital(int K, int W, int[] Profits, int[] Capital) &#123; //小根堆 PriorityQueue&lt;Program&gt; minCostQ = new PriorityQueue&lt;&gt;(new MinCostComparator()); //大根堆 PriorityQueue&lt;Program&gt; maxProfitQ = new PriorityQueue&lt;&gt;(new MaxProfitComparator()); for (int i = 0; i &lt; Profits.length; i++) &#123; minCostQ.add(new Program(Profits[i], Capital[i])); &#125; for (int i = 0; i &lt; K; i++) &#123; while (!minCostQ.isEmpty() &amp;&amp; minCostQ.peek().c &lt;= W) &#123; maxProfitQ.add(minCostQ.poll()); &#125; if (maxProfitQ.isEmpty()) &#123; return W; &#125; W += maxProfitQ.poll().p; &#125; return W;&#125;public static class Program &#123; public int p; public int c; public Program(int p, int c) &#123; this.p = p; this.c = c; &#125;&#125; 并查集1234561）有若干个样本a、b、c、d…类型假设是V2）在并查集中一开始认为每个样本都在单独的集合里3）用户可以在任何时候调用如下两个方法： boolean isSameSet(V x, V y) : 查询样本x和样本y是否属于一个集合 void union(V x, V y) : 把x和y各自所在集合的所有样本合并成一个集合4） isSameSet和union方法的代价越低越好 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class Code01_UnionFind &#123; public static class Node&lt;V&gt; &#123; V value; public Node(V v) &#123; value = v; &#125; &#125; public static class UnionSet&lt;V&gt; &#123; //样本对应的样本节点链 public HashMap&lt;V, Node&lt;V&gt;&gt; nodes; //每个样本节点对应的父样本节点 public HashMap&lt;Node&lt;V&gt;, Node&lt;V&gt;&gt; parents; //样本头节店和它底下的链路数量 public HashMap&lt;Node&lt;V&gt;, Integer&gt; sizeMap; public UnionSet(List&lt;V&gt; values) &#123; nodes = new HashMap&lt;&gt;(); parents = new HashMap&lt;&gt;(); sizeMap = new HashMap&lt;&gt;(); for (V cur : values) &#123; Node&lt;V&gt; node = new Node&lt;&gt;(cur); nodes.put(cur, node); parents.put(node, node); sizeMap.put(node, 1); &#125; &#125; //扁平化链表，调用该方法次数越多，它的时间复杂度越低，因为链表约扁平 // 从点cur开始，一直往上找，找到不能再往上的代表点，返回 public Node&lt;V&gt; findFather(Node&lt;V&gt; cur) &#123; //扁平化操作，把一条链表的长度，规整成所有都指向最终的头节点即可 Stack&lt;Node&lt;V&gt;&gt; path = new Stack&lt;&gt;(); while (cur != parents.get(cur)) &#123; path.push(cur); cur = parents.get(cur); &#125; // cur头节点 while (!path.isEmpty()) &#123; parents.put(path.pop(), cur); &#125; return cur; &#125; public boolean isSameSet(V a, V b) &#123; if (!nodes.containsKey(a) || !nodes.containsKey(b)) &#123; return false; &#125; return findFather(nodes.get(a)) == findFather(nodes.get(b)); &#125; public void union(V a, V b) &#123; if (!nodes.containsKey(a) || !nodes.containsKey(b)) &#123; return; &#125; Node&lt;V&gt; aHead = findFather(nodes.get(a)); Node&lt;V&gt; bHead = findFather(nodes.get(b)); if (aHead != bHead) &#123; int aSetSize = sizeMap.get(aHead); int bSetSize = sizeMap.get(bHead); //数量短的链表合并到数量长的链表中，降低扁平化的循环次数 Node&lt;V&gt; big = aSetSize &gt;= bSetSize ? aHead : bHead; Node&lt;V&gt; small = big == aHead ? bHead : aHead; parents.put(small, big); sizeMap.put(big, aSetSize + bSetSize); sizeMap.remove(small); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728// (1,10,13) (2,10,37) (400,500,37)// 如果两个user，a字段一样、或者b字段一样、或者c字段一样，就认为是一个人// 请合并users，返回合并之后的用户数量public static int mergeUsers(List&lt;User&gt; users) &#123; UnionSet&lt;User&gt; unionFind = new UnionSet&lt;&gt;(users); HashMap&lt;String, User&gt; mapA = new HashMap&lt;&gt;(); HashMap&lt;String, User&gt; mapB = new HashMap&lt;&gt;(); HashMap&lt;String, User&gt; mapC = new HashMap&lt;&gt;(); for(User user : users) &#123; if(mapA.containsKey(user.a)) &#123; unionFind.union(user, mapA.get(user.a)); &#125;else &#123; mapA.put(user.a, user); &#125; if(mapB.containsKey(user.b)) &#123; unionFind.union(user, mapB.get(user.b)); &#125;else &#123; mapB.put(user.b, user); &#125; if(mapC.containsKey(user.c)) &#123; unionFind.union(user, mapC.get(user.c)); &#125;else &#123; mapC.put(user.c, user); &#125; &#125; // 向并查集询问，合并之后，还有多少个集合？ return unionFind.getSetNum();&#125; 图123451）由点的集合和边的集合构成2）虽然存在有向图和无向图的概念，但实际上都可以用有向图来表达3）边上可能带有权值 123456789101112131415161718192021// 点结构的描述 A 0public class Node &#123; //点上的值 public int value; //入度（多少条边指向这个点） public int in; //出度（多少条边出这个点） public int out; //点连出去的节点 public ArrayList&lt;Node&gt; nexts; //点连出去的边 public ArrayList&lt;Edge&gt; edges; public Node(int value) &#123; this.value = value; in = 0; out = 0; nexts = new ArrayList&lt;&gt;(); edges = new ArrayList&lt;&gt;(); &#125;&#125; 1234567891011121314//边public class Edge &#123; //权重 public int weight; //边的方向 public Node from; public Node to; public Edge(int weight, Node from, Node to) &#123; this.weight = weight; this.from = from; this.to = to; &#125;&#125; 123456789101112//图public class Graph &#123; //&lt;编号，点&gt; public HashMap&lt;Integer, Node&gt; nodes; //边 public HashSet&lt;Edge&gt; edges; public Graph() &#123; nodes = new HashMap&lt;&gt;(); edges = new HashSet&lt;&gt;(); &#125;&#125; 12345678910111213141516171819202122232425262728//把各种数据结构的图表达形式转换成固定的算法解析的格式// matrix 所有的边// N*3 的矩阵// [weight, from节点上面的值，to节点上面的值]public static Graph createGraph(Integer[][] matrix) &#123; Graph graph = new Graph(); for (int i = 0; i &lt; matrix.length; i++) &#123; // matrix[0][0], matrix[0][1] matrix[0][2] Integer weight = matrix[i][0]; Integer from = matrix[i][1]; Integer to = matrix[i][2]; if (!graph.nodes.containsKey(from)) &#123; graph.nodes.put(from, new Node(from)); &#125; if (!graph.nodes.containsKey(to)) &#123; graph.nodes.put(to, new Node(to)); &#125; Node fromNode = graph.nodes.get(from); Node toNode = graph.nodes.get(to); Edge newEdge = new Edge(weight, fromNode, toNode); fromNode.nexts.add(toNode); fromNode.out++; toNode.in++; fromNode.edges.add(newEdge); graph.edges.add(newEdge); &#125; return graph;&#125; 1234567891011宽度优先遍历1，利用队列实现2，从源节点开始依次按照宽度进队列，然后弹出3，每弹出一个点，把该节点所有没有进过队列的邻接点放入队列4，直到队列变空深度优先遍历1，利用栈实现2，从源节点开始把节点按照深度放入栈，然后弹出3，每弹出一个点，把该节点下一个没有进过栈的邻接点放入栈4，直到栈变空 123456789101112131415161718192021// 从node出发，进行宽度优先遍历// SET 过滤重复的节点public static void bfs(Node node) &#123; if (node == null) &#123; return; &#125; Queue&lt;Node&gt; queue = new LinkedList&lt;&gt;(); HashSet&lt;Node&gt; set = new HashSet&lt;&gt;(); queue.add(node); set.add(node); while (!queue.isEmpty()) &#123; Node cur = queue.poll(); System.out.println(cur.value); for (Node next : cur.nexts) &#123; if (!set.contains(next)) &#123; set.add(next); queue.add(next); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425//深度优先遍历//先把节点压入栈中，输出，然后遍历它的next节点，发现没遍历过则压入原节点和next节点（并打印），break//等next节点的深度遍历完后，最后重新弹出原节点继续遍历没被遍历完的next节点，周而复始public static void dfs(Node node) &#123; if (node == null) &#123; return; &#125; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); HashSet&lt;Node&gt; set = new HashSet&lt;&gt;(); stack.add(node); set.add(node); System.out.println(node.value); while (!stack.isEmpty()) &#123; Node cur = stack.pop(); for (Node next : cur.nexts) &#123; if (!set.contains(next)) &#123; stack.push(cur); stack.push(next); set.add(next); System.out.println(next.value); break; &#125; &#125; &#125;&#125; 12345678图的拓扑排序算法1）在图中找到所有入度为0的点输出2）把所有入度为0的点在图中删掉，继续找入度为0的点输出，周而复始3）图的所有点都被删除后，依次输出的顺序就是拓扑排序要求：有向图且其中没有环应用：事件安排、编译顺序 12345678910111213141516171819202122232425262728// directed graph and no looppublic static List&lt;Node&gt; sortedTopology(Graph graph) &#123; // key：某一个node // value：剩余的入度 HashMap&lt;Node, Integer&gt; inMap = new HashMap&lt;&gt;(); // 剩余入度为0的点，才能进这个队列 Queue&lt;Node&gt; zeroInQueue = new LinkedList&lt;&gt;(); for (Node node : graph.nodes.values()) &#123; inMap.put(node, node.in); if (node.in == 0) &#123; zeroInQueue.add(node); &#125; &#125; // 拓扑排序的结果，依次加入result List&lt;Node&gt; result = new ArrayList&lt;&gt;(); while (!zeroInQueue.isEmpty()) &#123; Node cur = zeroInQueue.poll(); result.add(cur); for (Node next : cur.nexts) &#123; inMap.put(next, inMap.get(next) - 1); if (inMap.get(next) == 0) &#123; zeroInQueue.add(next); &#125; &#125; &#125; return result;&#125; 1234567最小生成树算法之Kruskal1）总是从权值最小的边开始考虑，依次考察权值依次变大的边2）当前的边要么进入最小生成树的集合，要么丢弃3）如果当前的边进入最小生成树的集合中不会形成环，就要当前边4）如果当前的边进入最小生成树的集合中会形成环，就不要当前边5）考察完所有边之后，最小生成树的集合也得到了 1234567891011121314151617181920//所有边权重排序，并依次使用并查集判断是否需要使用边来合并from和to的节点//如果是无向图，因为按照集合边淘汰原则，丢失了（无向边=来回的双向边）双向边的一部分，所以需要补边public static Set&lt;Edge&gt; kruskalMST(Graph graph) &#123; UnionFind unionFind = new UnionFind(); unionFind.makeSets(graph.nodes.values()); //根据边的权重排序，小根堆 PriorityQueue&lt;Edge&gt; priorityQueue = new PriorityQueue&lt;&gt;(new EdgeComparator()); for (Edge edge : graph.edges) &#123; // M 条边 priorityQueue.add(edge); // O(logM) &#125; Set&lt;Edge&gt; result = new HashSet&lt;&gt;(); while (!priorityQueue.isEmpty()) &#123; // M 条边 Edge edge = priorityQueue.poll(); // O(logM) if (!unionFind.isSameSet(edge.from, edge.to)) &#123; // O(1) result.add(edge); unionFind.union(edge.from, edge.to); &#125; &#125; return result; &#125; 12345678最小生成树算法之Prim1）可以从任意节点出发来寻找最小生成树2）某个点加入到被选取的点中后，解锁这个点出发的所有新的边3）在所有解锁的边中选最小的边，然后看看这个边会不会形成环4）如果会，不要当前边，继续考察剩下解锁的边中最小的边，重复3）5）如果不会，要当前边，将该边的指向点加入到被选取的点中，重复2）6）当所有点都被选取，最小生成树就得到了 123456789101112131415161718192021222324252627282930313233public static Set&lt;Edge&gt; primMST(Graph graph) &#123; // 解锁的边进入小根堆 PriorityQueue&lt;Edge&gt; priorityQueue = new PriorityQueue&lt;&gt;(new EdgeComparator()); // 哪些点被解锁出来了 HashSet&lt;Node&gt; nodeSet = new HashSet&lt;&gt;(); Set&lt;Edge&gt; result = new HashSet&lt;&gt;(); // 依次挑选的的边在result里 //for循环主要是为了防止森林，多个图 for (Node node : graph.nodes.values()) &#123; // 随便挑了一个点 // node 是开始点 if (!nodeSet.contains(node)) &#123; nodeSet.add(node); for (Edge edge : node.edges) &#123; // 由一个点，解锁所有相连的边 priorityQueue.add(edge); &#125; while (!priorityQueue.isEmpty()) &#123; Edge edge = priorityQueue.poll(); // 弹出解锁的边中，最小的边 Node toNode = edge.to; // 可能的一个新的点 if (!nodeSet.contains(toNode)) &#123; // 不含有的时候，就是新的点 nodeSet.add(toNode); result.add(edge); //解锁了新的点，解锁新的边 for (Edge nextEdge : toNode.edges) &#123; priorityQueue.add(nextEdge); &#125; &#125; &#125; &#125; // break; &#125; return result;&#125; 123456Dijkstra算法1）Dijkstra算法必须指定一个源点2）生成一个源点到各个点的最小距离表，一开始只有一条记录，即原点到自己的最小距离为0，源点到其他所有点的最小距离都为正无穷大3）从距离表中拿出没拿过记录里的最小记录，通过这个点发出的边，更新源点到各个点的最小距离表，不断重复这一步4）源点到所有的点记录如果都被拿过一遍，过程停止，最小距离表得到了 12345678910111213141516171819202122232425262728293031323334353637383940414243public static HashMap&lt;Node, Integer&gt; dijkstra1(Node from) &#123; // 从head出发到所有点的最小距离 // key : 从head出发到达key // value : 从head出发到达key的最小距离 // 如果在表中，没有T的记录，含义是从head出发到T这个点的距离为正无穷 HashMap&lt;Node, Integer&gt; distanceMap = new HashMap&lt;&gt;(); distanceMap.put(from, 0); // 已经求过距离的节点，存在selectedNodes中，以后再也不碰 HashSet&lt;Node&gt; selectedNodes = new HashSet&lt;&gt;(); // from 0 Node minNode = getMinDistanceAndUnselectedNode(distanceMap, selectedNodes); while (minNode != null) &#123; int distance = distanceMap.get(minNode); for (Edge edge : minNode.edges) &#123; Node toNode = edge.to; if (!distanceMap.containsKey(toNode)) &#123; distanceMap.put(toNode, distance + edge.weight); &#125; else &#123; distanceMap.put(edge.to, Math.min(distanceMap.get(toNode), distance + edge.weight)); &#125; &#125; selectedNodes.add(minNode); minNode = getMinDistanceAndUnselectedNode(distanceMap, selectedNodes); &#125; return distanceMap;&#125;public static Node getMinDistanceAndUnselectedNode( HashMap&lt;Node, Integer&gt; distanceMap, HashSet&lt;Node&gt; touchedNodes) &#123; Node minNode = null; int minDistance = Integer.MAX_VALUE; for (Entry&lt;Node, Integer&gt; entry : distanceMap.entrySet()) &#123; Node node = entry.getKey(); int distance = entry.getValue(); if (!touchedNodes.contains(node) &amp;&amp; distance &lt; minDistance) &#123; minNode = node; minDistance = distance; &#125; &#125; return minNode;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131//改进：优化每个节点都需要遍历获取最小路径的问题public static Node getMinDistanceAndUnselectedNode( HashMap&lt;Node, Integer&gt; distanceMap, HashSet&lt;Node&gt; touchedNodes) &#123; Node minNode = null; int minDistance = Integer.MAX_VALUE; for (Entry&lt;Node, Integer&gt; entry : distanceMap.entrySet()) &#123; Node node = entry.getKey(); int distance = entry.getValue(); if (!touchedNodes.contains(node) &amp;&amp; distance &lt; minDistance) &#123; minNode = node; minDistance = distance; &#125; &#125; return minNode;&#125;public static class NodeRecord &#123; public Node node; public int distance; public NodeRecord(Node node, int distance) &#123; this.node = node; this.distance = distance; &#125;&#125;public static class NodeHeap &#123; private Node[] nodes; // 实际的堆结构 // key 某一个node， value 上面堆中的位置 private HashMap&lt;Node, Integer&gt; heapIndexMap; // key 某一个节点， value 从源节点出发到该节点的目前最小距离 private HashMap&lt;Node, Integer&gt; distanceMap; private int size; // 堆上有多少个点 public NodeHeap(int size) &#123; nodes = new Node[size]; heapIndexMap = new HashMap&lt;&gt;(); distanceMap = new HashMap&lt;&gt;(); size = 0; &#125; public boolean isEmpty() &#123; return size == 0; &#125; // 有一个点叫node，现在发现了一个从源节点出发到达node的距离为distance // 判断要不要更新，如果需要的话，就更新 public void addOrUpdateOrIgnore(Node node, int distance) &#123; if (inHeap(node)) &#123; distanceMap.put(node, Math.min(distanceMap.get(node), distance)); insertHeapify(node, heapIndexMap.get(node)); &#125; if (!isEntered(node)) &#123; nodes[size] = node; heapIndexMap.put(node, size); distanceMap.put(node, distance); insertHeapify(node, size++); &#125; &#125; public NodeRecord pop() &#123; NodeRecord nodeRecord = new NodeRecord(nodes[0], distanceMap.get(nodes[0])); swap(0, size - 1); heapIndexMap.put(nodes[size - 1], -1); distanceMap.remove(nodes[size - 1]); // free C++同学还要把原本堆顶节点析构，对java同学不必 nodes[size - 1] = null; heapify(0, --size); return nodeRecord; &#125; private void insertHeapify(Node node, int index) &#123; while (distanceMap.get(nodes[index]) &lt; distanceMap.get(nodes[(index - 1) / 2])) &#123; swap(index, (index - 1) / 2); index = (index - 1) / 2; &#125; &#125; private void heapify(int index, int size) &#123; int left = index * 2 + 1; while (left &lt; size) &#123; int smallest = left + 1 &lt; size &amp;&amp; distanceMap.get(nodes[left + 1]) &lt; distanceMap.get(nodes[left]) ? left + 1 : left; smallest = distanceMap.get(nodes[smallest]) &lt; distanceMap.get(nodes[index]) ? smallest : index; if (smallest == index) &#123; break; &#125; swap(smallest, index); index = smallest; left = index * 2 + 1; &#125; &#125; private boolean isEntered(Node node) &#123; return heapIndexMap.containsKey(node); &#125; private boolean inHeap(Node node) &#123; return isEntered(node) &amp;&amp; heapIndexMap.get(node) != -1; &#125; private void swap(int index1, int index2) &#123; heapIndexMap.put(nodes[index1], index2); heapIndexMap.put(nodes[index2], index1); Node tmp = nodes[index1]; nodes[index1] = nodes[index2]; nodes[index2] = tmp; &#125;&#125;// 改进后的dijkstra算法// 从head出发，所有head能到达的节点，生成到达每个节点的最小路径记录并返回public static HashMap&lt;Node, Integer&gt; dijkstra2(Node head, int size) &#123; NodeHeap nodeHeap = new NodeHeap(size); nodeHeap.addOrUpdateOrIgnore(head, 0); HashMap&lt;Node, Integer&gt; result = new HashMap&lt;&gt;(); while (!nodeHeap.isEmpty()) &#123; NodeRecord record = nodeHeap.pop(); Node cur = record.node; int distance = record.distance; for (Edge edge : cur.edges) &#123; nodeHeap.addOrUpdateOrIgnore(edge.to, edge.weight + distance); &#125; result.put(cur, distance); &#125; return result;&#125; 暴力递归12345暴力递归就是尝试 1，把问题转化为规模缩小了的同类问题的子问题2，有明确的不需要继续进行递归的条件(base case)3，有当得到了子问题的结果之后的决策过程4，不记录每一个子问题的解 汉诺塔问题1打印n层汉诺塔从最左边移动到最右边的全部过程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566//1.汉诺塔简单版本写法public static void hanoi1(int n) &#123; leftToRight(n);&#125;// 请把1~N层圆盘 从左 -&gt; 右public static void leftToRight(int n) &#123; if (n == 1) &#123; System.out.println(\"Move 1 from left to right\"); return; &#125; leftToMid(n - 1); System.out.println(\"Move \" + n + \" from left to right\"); midToRight(n - 1);&#125;// 请把1~N层圆盘 从左 -&gt; 中public static void leftToMid(int n) &#123; if (n == 1) &#123; System.out.println(\"Move 1 from left to mid\"); return; &#125; leftToRight(n - 1); System.out.println(\"Move \" + n + \" from left to mid\"); rightToMid(n - 1);&#125;public static void rightToMid(int n) &#123; if (n == 1) &#123; System.out.println(\"Move 1 from right to mid\"); return; &#125; rightToLeft(n - 1); System.out.println(\"Move \" + n + \" from right to mid\"); leftToMid(n - 1);&#125;public static void midToRight(int n) &#123; if (n == 1) &#123; System.out.println(\"Move 1 from mid to right\"); return; &#125; midToLeft(n - 1); System.out.println(\"Move \" + n + \" from mid to right\"); leftToRight(n - 1);&#125;public static void midToLeft(int n) &#123; if (n == 1) &#123; System.out.println(\"Move 1 from mid to left\"); return; &#125; midToRight(n - 1); System.out.println(\"Move \" + n + \" from mid to left\"); rightToLeft(n - 1);&#125;public static void rightToLeft(int n) &#123; if (n == 1) &#123; System.out.println(\"Move 1 from right to left\"); return; &#125; rightToMid(n - 1); System.out.println(\"Move \" + n + \" from right to left\"); midToLeft(n - 1);&#125; 1234567891011121314151617181920212223/*思想:（from -&gt; to） 拆成三个大步： 1.把N-1的圆盘移动到 other上 2.把N的圆盘移动到to上 3.把N-1的圆盘移动到to上（这步操作等于递归N-1的圆盘重新移动） 移动的最优步数：(2^n -1)*/public static void hanoi2(int n) &#123; if (n &gt; 0) &#123; func(n, \"left\", \"right\", \"mid\"); &#125;&#125;// 1~i 圆盘 目标是from -&gt; to， other是另外一个public static void func(int N, String from, String to, String other) &#123; if (N == 1) &#123; // base System.out.println(\"Move 1 from \" + from + \" to \" + to); &#125; else &#123; func(N - 1, from, other, to); System.out.println(\"Move \" + N + \" from \" + from + \" to \" + to); func(N - 1, other, to, from); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041//非递归的版本public static class Record &#123; public boolean finish1; public int base; public String from; public String to; public String other; public Record(boolean f1, int b, String f, String t, String o) &#123; finish1 = false; base = b; from = f; to = t; other = o; &#125;&#125;public static void hanoi3(int N) &#123; if (N &lt; 1) &#123; return; &#125; Stack&lt;Record&gt; stack = new Stack&lt;&gt;(); stack.add(new Record(false, N, \"left\", \"right\", \"mid\")); while (!stack.isEmpty()) &#123; Record cur = stack.pop(); if (cur.base == 1) &#123; System.out.println(\"Move 1 from \" + cur.from + \" to \" + cur.to); if (!stack.isEmpty()) &#123; stack.peek().finish1 = true; &#125; &#125; else &#123; if (!cur.finish1) &#123; stack.push(cur); stack.push(new Record(false, cur.base - 1, cur.from, cur.other, cur.to)); &#125; else &#123; System.out.println(\"Move \" + cur.base + \" from \" + cur.from + \" to \" + cur.to); stack.push(new Record(false, cur.base - 1, cur.other, cur.to, cur.from)); &#125; &#125; &#125;&#125; 123给你一个栈，请你逆序这个栈，不能申请额外的数据结构，只能使用递归函数。 123456789101112131415161718192021222324252627282930/*思路：1.先把栈底的元素拿出来2.再递归调用函数依次拿出每次栈底的数据，重新push进去*/public static void reverse(Stack&lt;Integer&gt; stack) &#123; if (stack.isEmpty()) &#123; return; &#125; //依次取出每次迭代的栈中的栈底元素 int i = f(stack); //迭代取栈数据 reverse(stack); //最后栈底的元素肯定是原先栈头的元素，塞进去 stack.push(i);&#125;public static int f(Stack&lt;Integer&gt; stack) &#123; //先取出栈元素，如果等于空，则直接返回栈底元素 int result = stack.pop(); if (stack.isEmpty()) &#123; return result; &#125; else &#123; //如果栈还不为空，则继续一直到返回栈底的元素 int last = f(stack); //重新将当前函数中的栈元素放到栈中 stack.push(result); return last; &#125;&#125; 1打印一个字符串的全部子序列 12345678910111213141516171819202122232425262728/*思路：深度优先遍历，到了每个index判断index是否要拼接到path里，yes/no，一直到index==length时，添加进集合*/public static List&lt;String&gt; subs(String s) &#123; char[] str = s.toCharArray(); String path = \"\"; List&lt;String&gt; ans = new ArrayList&lt;&gt;(); process1(str, 0, ans, path); return ans;&#125;// str固定，不变// index此时来到的位置, 要 or 不要// 如果index来到了str中的终止位置，把沿途路径所形成的答案，放入ans中// 之前做出的选择，就是pathpublic static void process1(char[] str, int index, List&lt;String&gt; ans, String path) &#123; if (index == str.length) &#123; ans.add(path); return; &#125; //不添加路径 String no = path; process1(str, index + 1, ans, no); //拼接路径 String yes = path + String.valueOf(str[index]); process1(str, index + 1, ans, yes);&#125; 1打印一个字符串的全部子序列，要求不要出现重复字面值的子序列 12345678910111213141516171819202122232425// str index setpublic static List&lt;String&gt; subsNoRepeat(String s) &#123; char[] str = s.toCharArray(); String path = \"\"; HashSet&lt;String&gt; set = new HashSet&lt;&gt;(); process2(str, 0, set, path); List&lt;String&gt; ans = new ArrayList&lt;&gt;(); for (String cur : set) &#123; ans.add(cur); &#125; return ans;&#125;public static void process2(char[] str, int index, HashSet&lt;String&gt; set, String path) &#123; if (index == str.length) &#123; set.add(path); return; &#125; String no = path; process2(str, index + 1, set, no); String yes = path + String.valueOf(str[index]); process2(str, index + 1, set, yes);&#125; 1打印一个字符串的全部排列 12345678910111213141516171819202122232425262728/*思路：index=0，大于等于index的元素都有机会和index的元素进行交换，做出不同的排列，index++，依次排，递归排完后还原现场，把交换的数据交换回来*/public static ArrayList&lt;String&gt; permutation(String str) &#123; ArrayList&lt;String&gt; res = new ArrayList&lt;&gt;(); if (str == null || str.length() == 0) &#123; return res; &#125; char[] chs = str.toCharArray(); process(chs, 0, res); return res;&#125;// str[0..i-1]已经做好决定的// str[i...]都有机会来到i位置// i终止位置，str当前的样子，就是一种结果 -&gt; anspublic static void process(char[] str, int i, ArrayList&lt;String&gt; ans) &#123; if (i == str.length) &#123; ans.add(String.valueOf(str)); &#125; // 如果i没有终止，i... 都可以来到i位置 for (int j = i; j &lt; str.length; j++) &#123; // j i后面所有的字符都有机会 swap(str, i, j); process(str, i + 1, ans); //还原交换现场 swap(str, i, j); &#125;&#125; 1打印一个字符串的全部排列，要求不要出现重复的排列 123456789101112131415161718192021222324252627282930313233343536/* 思想：分支限界 要交换的数值和index上的数值相同则跳过*/public static ArrayList&lt;String&gt; permutationNoRepeat(String str) &#123; ArrayList&lt;String&gt; res = new ArrayList&lt;&gt;(); if (str == null || str.length() == 0) &#123; return res; &#125; char[] chs = str.toCharArray(); process2(chs, 0, res); return res;&#125;// str[0..i-1]已经做好决定的// str[i...]都有机会来到i位置// i终止位置，str当前的样子，就是一种结果 -&gt; anspublic static void process2(char[] str, int i, ArrayList&lt;String&gt; res) &#123; if (i == str.length) &#123; res.add(String.valueOf(str)); return; &#125; boolean[] visit = new boolean[26]; // visit[0 1 .. 25] for (int j = i; j &lt; str.length; j++) &#123; // str[j] = 'a' -&gt; 0 visit[0] -&gt; 'a' // str[j] = 'z' -&gt; 25 visit[25] -&gt; 'z' if (!visit[str[j] - 'a']) &#123; visit[str[j] - 'a'] = true; swap(str, i, j); process2(str, i + 1, res); swap(str, i, j); &#125; &#125;&#125; 123456**从左往右的尝试模型1**规定1和A对应、2和B对应、3和C对应...那么一个数字字符串比如\"111”就可以转化为:\"AAA\"、\"KA\"和\"AK\"给定一个只有数字字符组成的字符串str，返回有多少种转化结果 12345678910111213141516171819202122232425262728293031323334353637/*思路：找到BaseCase 递归（i、i+1），下个递归是（i+1、i+2）分支限界 i+1 &lt;str.length , i+1 &lt; 26*/public static int number(String str) &#123; if (str == null || str.length() == 0) &#123; return 0; &#125; return process(str.toCharArray(), 0);&#125;// str[0...i-1]已经转化完了，固定了// i之前的位置，如何转化已经做过决定了, 不用再关心// i... 有多少种转化的结果public static int process(char[] str, int i) &#123; if (i == str.length) &#123; // base case return 1; &#125; if (str[i] == '0') &#123; return 0; &#125; if (str[i] == '1') &#123; int res = process(str, i + 1); if (i + 1 &lt; str.length) &#123; res += process(str, i + 2); &#125; return res; &#125; if (str[i] == '2') &#123; int res = process(str, i + 1); if (i + 1 &lt; str.length &amp;&amp; (str[i + 1] &gt;= '0' &amp;&amp; str[i + 1] &lt;= '6')) &#123; res += process(str, i + 2); // (i和i+1)作为单独的部分，后续有多少种方法 &#125; return res; &#125; return process(str, i + 1);&#125; 123456789101112131415161718192021222324252627282930/*暴力递归改动态规划*/public static int dpWays2(String s) &#123; if (s == null || s.length() == 0) &#123; return 0; &#125; char[] str = s.toCharArray(); int N = str.length; int[] dp = new int[N+1]; dp[N] = 1; for(int i = N-1; i &gt;= 0; i--) &#123; if (str[i] == '0') &#123; dp[i] = 0; &#125; if (str[i] == '1') &#123; dp[i] = dp[i + 1]; if (i + 1 &lt; str.length) &#123; dp[i] += dp[i + 2]; &#125; &#125; if (str[i] == '2') &#123; dp[i] = dp[i + 1]; if (i + 1 &lt; str.length &amp;&amp; (str[i + 1] &gt;= '0' &amp;&amp; str[i + 1] &lt;= '6')) &#123; dp[i] += dp[i + 2]; // (i和i+1)作为单独的部分，后续有多少种方法 &#125; &#125; &#125; return dp[0];&#125; 背包问题1234567**从左往右的尝试模型2**给定两个长度都为N的数组weights和values，weights[i]和values[i]分别代表 i号物品的重量和价值。给定一个正数bag，表示一个载重bag的袋子，你装的物品不能超过这个重量。返回你能装下最多的价值是多少? 1234567891011121314151617181920212223242526272829/*思路：寻找baseCase，两种情况，要么背，要么不背，计算背的重量超过bag就返回*/public static int getMaxValue(int[] w, int[] v, int bag) &#123; return process(w, v, 0, 0, bag);&#125;// 不变 ： w[] v[] bag// index... 最大价值// 0..index-1上做了货物的选择，使得你已经达到的重量是多少alreadyW// 如果返回-1，认为没有方案// 如果不返回-1，认为返回的值是真实价值public static int process(int[] w, int[] v, int index, int alreadyW, int bag) &#123; if (alreadyW &gt; bag) &#123; return -1; &#125; // 重量没超 if (index == w.length) &#123; return 0; &#125; int p1 = process(w, v, index + 1, alreadyW, bag); int p2next = process(w, v, index + 1, alreadyW + w[index], bag); int p2 = -1; if (p2next != -1) &#123; p2 = v[index] + p2next; &#125; return Math.max(p1, p2);&#125; 123456789101112131415161718192021222324252627/*思路：背包没剩余空间就返回*/public static int maxValue(int[] w, int[] v, int bag) &#123; return process(w, v, 0, bag);&#125;// 只剩下rest的空间了，// index...货物自由选择，但是剩余空间不要小于0// 返回 index...货物能够获得的最大价值public static int process(int[] w, int[] v, int index, int rest) &#123; if (rest &lt; 0) &#123; // base case 1 return -1; &#125; // rest &gt;=0 if (index == w.length) &#123; // base case 2 return 0; &#125; // 有货也有空间 int p1 = process(w, v, index + 1, rest); int p2 = -1; int p2Next = process(w, v, index + 1, rest - w[index]); if(p2Next!=-1) &#123; p2 = v[index] + p2Next; &#125; return Math.max(p1, p2);&#125; 12345678910111213141516/*暴力递归改动态规划*/public static int dpWay(int[] w, int[] v, int bag) &#123; int N = w.length; int[][] dp = new int[N + 1][bag + 1]; for (int index = N - 1; index &gt;= 0; index--) &#123; for (int rest = 0; rest &lt;= bag; rest++) &#123; dp[index][rest] = dp[index + 1][rest]; if (rest &gt;= w[index]) &#123; dp[index][rest] = Math.max(dp[index][rest], v[index] + dp[index + 1][rest - w[index]]); &#125; &#125; &#125; return dp[0][bag];&#125; 1234567**范围上尝试的模型**给定一个整型数组arr，代表数值不同的纸牌排成一条线，玩家A和玩家B依次拿走每张纸牌，规定玩家A先拿，玩家B后拿，但是每个玩家每次只能拿走最左或最右的纸牌，玩家A和玩家B都绝顶聪明。请返回最后获胜者的分数。 123456789101112131415161718192021222324252627282930313233343536373839/*思路： f函数表示先手获取的卡牌，f函数先手肯定会取一个对后手取牌最不好的结果 s函数表示后手选择的卡牌，s函数后手肯定只能选择先手留给你的最差的结果*/public static int win1(int[] arr) &#123; if (arr == null || arr.length == 0) &#123; return 0; &#125; return Math.max( f(arr, 0, arr.length - 1), s(arr, 0, arr.length - 1) );&#125;// L....R// F S L+1..R// L..R-1public static int f(int[] arr, int L, int R) &#123; if (L == R) &#123; return arr[L]; &#125; return Math.max( arr[L] + s(arr, L + 1, R), arr[R] + s(arr, L, R - 1) );&#125;// arr[L..R]public static int s(int[] arr, int L, int R) &#123; if (L == R) &#123; return 0; &#125; return Math.min( f(arr, L + 1, R), // arr[i] f(arr, L, R - 1) // arr[j] );&#125; 123456789101112131415161718192021222324252627282930313233/*暴力递归改动态规划*/public static int win2(int[] arr) &#123; if (arr == null || arr.length == 0) &#123; return 0; &#125; int N = arr.length; int[][] f = new int[N][N]; int[][] s = new int[N][N]; for(int i = 0; i &lt; N;i++) &#123; f[i][i] = arr[i]; &#125; // s[i][i] = 0; for(int i = 1; i &lt; N;i++) &#123; int L =0; int R =i; while(L &lt; N &amp;&amp; R &lt; N) &#123; f[L][R] = Math.max( arr[L] + s[L + 1][ R], arr[R] + s[L][R - 1] ); s[L][R] = Math.min( f[L + 1][R], // arr[i] f[L][R - 1] // arr[j] ); L++; R++; &#125; &#125; return Math.max(f[0][N-1], s[0][N-1]);&#125; 皇后问题123456N皇后问题是指在N*N的棋盘上要摆N个皇后，要求任何两个皇后不同行、不同列， 也不在同一条斜线上给定一个整数n，返回n皇后的摆法有多少种。 n&#x3D;1，返回1n&#x3D;2或3，2皇后和3皇后问题无论怎么摆都不行，返回0n&#x3D;8，返回92 1234567891011121314151617181920212223242526272829303132333435363738394041424344public static int num1(int n) &#123; if (n &lt; 1) &#123; return 0; &#125; // record[0] ? record[1] ? record[2] int[] record = new int[n]; // record[i] -&gt; i行的皇后，放在了第几列 return process1(0, record, n);&#125;// 潜台词：record[0..i-1]的皇后，任何两个皇后一定都不共行、不共列，不共斜线// 目前来到了第i行// record[0..i-1]表示之前的行，放了的皇后位置// n代表整体一共有多少行 0~n-1行// 返回值是，摆完所有的皇后，合理的摆法有多少种public static int process1(int i, int[] record, int n) &#123; if (i == n) &#123; // 终止行 return 1; &#125; // 没有到终止位置，还有皇后要摆 int res = 0; for (int j = 0; j &lt; n; j++) &#123; // 当前行在i行，尝试i行所有的列 -&gt; j // 当前i行的皇后，放在j列，会不会和之前(0..i-1)的皇后，不共行共列或者共斜线， // 如果是，认为有效 // 如果不是，认为无效 if (isValid(record, i, j)) &#123; record[i] = j; res += process1(i + 1, record, n); &#125; &#125; return res;&#125;// record[0..i-1]你需要看，record[i...]不需要看// 返回i行皇后，放在了j列，是否有效public static boolean isValid(int[] record, int i, int j) &#123; for (int k = 0; k &lt; i; k++) &#123; // 之前的某个k行的皇后 // k, record[k] i, j //不能和列、左对角线、右对角线匹配上 if (j == record[k] || Math.abs(record[k] - j) == Math.abs(i - k)) &#123; return false; &#125; &#125; return true;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/*N皇后的位运算优化，优化常数项，复杂度都相同。*/// 请不要超过32皇后问题public static int num2(int n) &#123; if (n &lt; 1 || n &gt; 32) &#123; return 0; &#125; // 如果你是13皇后问题，limit 最右13个1，其他都是0 int limit = n == 32 ? -1 : (1 &lt;&lt; n) - 1; return process2(limit, 0, 0, 0);&#125;// limit 划定了问题的规模 -&gt; 固定// colLim 列的限制，1的位置不能放皇后，0的位置可以// leftDiaLim 左斜线的限制，1的位置不能放皇后，0的位置可以// rightDiaLim 右斜线的限制，1的位置不能放皇后，0的位置可以public static int process2( int limit, int colLim, int leftDiaLim, int rightDiaLim) &#123; // base case 要么有结果（相等），要么放不下皇后（pos=0不进循环，直接return） if (colLim == limit) &#123; return 1; &#125; // 所有可以放皇后的位置，都在pos上 // colLim | leftDiaLim | rightDiaLim -&gt; 总限制 // ~ (colLim | leftDiaLim | rightDiaLim) -&gt; 取反会产生一大堆左侧的1， //limit &amp; (...) 可以把左侧的一坨0干扰，右侧每个1，可尝试 int pos = limit &amp; ( ~(colLim | leftDiaLim | rightDiaLim) ); int mostRightOne = 0; int res = 0; while (pos != 0) &#123; // 取取出pos中，最右侧的1来，剩下位置都是0 mostRightOne = pos &amp; (~pos + 1); pos = pos - mostRightOne; //累加计算的结果 res += process2(limit, colLim | mostRightOne, (leftDiaLim | mostRightOne) &lt;&lt; 1, (rightDiaLim | mostRightOne) &gt;&gt;&gt; 1); &#125; return res;&#125; 1234567891011121314//两种皇后优化时间的对比public static void main(String[] args) &#123; int n = 10; long start = System.currentTimeMillis(); System.out.println(num2(n)); long end = System.currentTimeMillis(); System.out.println(\"cost time: \" + (end - start) + \"ms\"); start = System.currentTimeMillis(); System.out.println(num1(n)); end = System.currentTimeMillis(); System.out.println(\"cost time: \" + (end - start) + \"ms\");&#125; 动态规划1234567**什么暴力递归可以继续优化？**有重复调用同一个子问题的解，这种递归可以优化如果每一个子问题都是不同的解，无法优化也不用优化**任何暴力尝试，只要有重复计算的过程，把可变参数的结构变成固化的过程，做成缓存，再精细之后，就是动态规划** 1234567**暴力递归和动态规划的关系**某一个暴力递归，有解的重复调用，就可以把这个暴力递归优化成动态规划任何动态规划问题，都一定对应着某一个有解的重复调用的暴力递归但不是所有的暴力递归，都一定对应着动态规划 123456789**如何找到某个问题的动态规划方式？**1）设计暴力递归：重要原则+4种常见尝试模型！重点！2）分析有没有重复解：套路解决3）用记忆化搜索 -&gt; 用严格表结构实现动态规划：套路解决4）看看能否继续优化：套路解决 123456789**常见的4种尝试模型**1）从左往右的尝试模型2）范围上的尝试模型3）多样本位置全对应的尝试模型4）寻找业务限制的尝试模型 12345678**暴力递归到动态规划的套路**1）你已经有了一个不违反原则的暴力递归，而且的确存在解的重复调用2）找到哪些参数的变化会影响返回值，对每一个列出变化范围3）参数间的所有的组合数量，意味着表大小4）记忆化搜索的方法就是傻缓存，非常容易得到5）规定好严格表的大小，分析位置的依赖顺序，然后从基础填写到最终解6）对于有枚举行为的决策过程，进一步优化 1234567假设有排成一行的N个位置，记为1~N，N 一定大于或等于 2开始时机器人在其中的M位置上(M 一定是 1~N 中的一个)如果机器人来到1位置，那么下一步只能往右来到2位置；如果机器人来到N位置，那么下一步只能往左来到 N-1 位置；如果机器人来到中间位置，那么下一步可以往左走或者往右走；规定机器人必须走 K 步，最终能来到P位置(P也是1~N中的一个)的方法有多少种给定四个参数 N、M、K、P，返回方法数。 1234567891011121314151617181920212223242526272829303132333435363738394041/*思想： 最小化问题 每次走一步，有哪些选择，制定baseCase*/public static int ways1(int N, int M, int K, int P) &#123; // 参数无效直接返回0 if (N &lt; 2 || K &lt; 1 || M &lt; 1 || M &gt; N || P &lt; 1 || P &gt; N) &#123; return 0; &#125; // 总共N个位置，从M点出发，还剩K步，返回最终能达到P的方法数 return walk(N, M, K, P);&#125;// N : 位置为1 ~ N，固定参数// cur : 当前在cur位置，可变参数// rest : 还剩res步没有走，可变参数// P : 最终目标位置是P，固定参数// 该函数的含义：只能在1~N这些位置上移动，当前在cur位置，走完rest步之后，停在P位置的方法数作为返回值返回public static int walk(int N, int cur, int rest, int P) &#123; // 如果没有剩余步数了，当前的cur位置就是最后的位置 // 如果最后的位置停在P上，那么之前做的移动是有效的 // 如果最后的位置没在P上，那么之前做的移动是无效的 if (rest == 0) &#123; return cur == P ? 1 : 0; &#125; // 如果还有rest步要走，而当前的cur位置在1位置上，那么当前这步只能从1走向2 // 后续的过程就是，来到2位置上，还剩rest-1步要走 if (cur == 1) &#123; return walk(N, 2, rest - 1, P); &#125; // 如果还有rest步要走，而当前的cur位置在N位置上，那么当前这步只能从N走向N-1 // 后续的过程就是，来到N-1位置上，还剩rest-1步要走 if (cur == N) &#123; return walk(N, N - 1, rest - 1, P); &#125; // 如果还有rest步要走，而当前的cur位置在中间位置上，那么当前这步可以走向左，也可以走向右 // 走向左之后，后续的过程就是，来到cur-1位置上，还剩rest-1步要走 // 走向右之后，后续的过程就是，来到cur+1位置上，还剩rest-1步要走 // 走向左、走向右是截然不同的方法，所以总方法数要都算上 return walk(N, cur + 1, rest - 1, P) + walk(N, cur - 1, rest - 1, P);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243/*思路：记忆搜索下的动态规划：（暴力递归重复计算做缓存）任何暴力尝试，只要有重复计算的过程，把可变参数的结构变成固化的过程，做成缓存，再精细之后，就是动态规划*/public static int waysCache(int N, int M, int K, int P) &#123; // 参数无效直接返回0 if (N &lt; 2 || K &lt; 1 || M &lt; 1 || M &gt; N || P &lt; 1 || P &gt; N) &#123; return 0; &#125; int[][] dp = new int[N+1][K+1]; for(int row = 0; row &lt;= N; row++) &#123; for(int col = 0; col &lt;= K; col++) &#123; dp[row][col] = -1; &#125; &#125; return walkCache(N, M, K, P,dp);&#125;// HashMap&lt;String, Integer&gt; (19,100) \"19_100\"// 我想把所有cur和rest的组合，返回的结果，加入到缓存里public static int walkCache(int N, int cur, int rest, int P, int[][] dp) &#123; if(dp[cur][rest] != -1) &#123; return dp[cur][rest]; &#125; if (rest == 0) &#123; dp[cur][rest] = cur == P ? 1 : 0; return dp[cur][rest]; &#125; if (cur == 1) &#123; dp[cur][rest] = walkCache(N, 2, rest - 1, P, dp); return dp[cur][rest]; &#125; if (cur == N) &#123; dp[cur][rest] =walkCache(N, N - 1, rest - 1, P,dp); return dp[cur][rest]; &#125; dp[cur][rest] = walkCache(N, cur + 1, rest - 1, P,dp) + walkCache(N, cur - 1, rest - 1, P, dp); return dp[cur][rest];&#125; 1234给定数组arr，arr中所有的值都为正数且不重复每个值代表一种面值的货币，每种面值的货币可以使用任意张再给定一个整数 aim，代表要找的钱数求组成 aim 的方法数 12345678910111213141516171819//暴力递归// arr中都是正数且无重复值，返回组成aim的方法数public static int ways1(int[] arr, int aim) &#123; if (arr == null || arr.length == 0 || aim &lt; 0) &#123; return 0; &#125; return process1(arr, 0, aim);&#125;public static int process1(int[] arr, int index, int rest) &#123; if(index == arr.length) &#123; return rest == 0 ? 1 : 0 ; &#125; int ways = 0; for(int zhang = 0; zhang * arr[index] &lt;= rest ;zhang++) &#123; ways += process1(arr, index + 1, rest - (zhang * arr[index]) ); &#125; return ways;&#125; 12345678910111213141516171819202122232425262728293031323334353637/*暴力递归改记忆搜索*/public static int ways2(int[] arr, int aim) &#123; if (arr == null || arr.length == 0 || aim &lt; 0) &#123; return 0; &#125; int[][] dp = new int[arr.length+1][aim+1]; // 一开始所有的过程，都没有计算呢 // dp[..][..] = -1 for(int i = 0 ; i &lt; dp.length; i++) &#123; for(int j = 0 ; j &lt; dp[0].length; j++) &#123; dp[i][j] = -1; &#125; &#125; return process2(arr, 0, aim , dp);&#125;// 如果index和rest的参数组合，是没算过的，dp[index][rest] == -1// 如果index和rest的参数组合，是算过的，dp[index][rest] &gt; - 1public static int process2(int[] arr, int index, int rest, int[][] dp) &#123; if(dp[index][rest] != -1) &#123; return dp[index][rest]; &#125; if(index == arr.length) &#123; dp[index][rest] = rest == 0 ? 1 :0; return dp[index][rest]; &#125; int ways = 0; for(int zhang = 0; zhang * arr[index] &lt;= rest ;zhang++) &#123; ways += process2(arr, index + 1, rest - (zhang * arr[index]) , dp ); &#125; dp[index][rest] = ways; return ways;&#125; 123456789101112131415161718192021/*标准动态规划*/public static int ways3(int[] arr, int aim) &#123; if (arr == null || arr.length == 0 || aim &lt; 0) &#123; return 0; &#125; int N = arr.length; int[][] dp = new int[N + 1][aim + 1]; dp[N][0] = 1;// dp[N][1...aim] = 0; for(int index = N - 1; index &gt;= 0; index--) &#123; for(int rest = 0; rest &lt;= aim; rest++) &#123; int ways = 0; for(int zhang = 0; zhang * arr[index] &lt;= rest ;zhang++) &#123; ways += dp[index + 1] [rest - (zhang * arr[index])]; &#125; dp[index][rest] = ways; &#125; &#125; return dp[0][aim];&#125; 1234567891011121314151617181920/*优化的动态规划,省略动态规划的枚举行为*/public static int ways4(int[] arr, int aim) &#123; if (arr == null || arr.length == 0 || aim &lt; 0) &#123; return 0; &#125; int N = arr.length; int[][] dp = new int[N + 1][aim + 1]; dp[N][0] = 1;// dp[N][1...aim] = 0; for(int index = N - 1; index &gt;= 0; index--) &#123; for(int rest = 0; rest &lt;= aim; rest++) &#123; dp[index][rest] = dp[index+1][rest]; if(rest - arr[index] &gt;= 0) &#123; dp[index][rest] += dp[index][rest - arr[index]]; &#125; &#125; &#125; return dp[0][aim];&#125; 12345678public static void main(String[] args) &#123; int[] arr = &#123; 5, 10,50,100 &#125;; int sum = 1000; System.out.println(ways1(arr, sum)); System.out.println(ways2(arr, sum)); System.out.println(ways3(arr, sum)); System.out.println(ways4(arr, sum));&#125; 12345给定一个字符串str，给定一个字符串类型的数组arr。arr里的每一个字符串，代表一张贴纸，你可以把单个字符剪开使用，目的是拼出str来。返回需要至少多少张贴纸可以完成这个任务。例子：str&#x3D; &quot;babac&quot;，arr &#x3D; &#123;&quot;ba&quot;,&quot;c&quot;,&quot;abcd&quot;&#125;至少需要两张贴纸&quot;ba&quot;和&quot;abcd&quot;，因为使用这两张贴纸，把每一个字符单独剪开，含有2个a、2个b、1个c。是可以拼出str的。所以返回2。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/*思路：把贴纸都转换成二维数组存储26个字母的数量，通过数量相减计算字符串rest的字符*/public static int minStickers1(String[] stickers, String target) &#123; int n = stickers.length; int[][] map = new int[n][26];// stickers -&gt; [26] [26] [26] for (int i = 0; i &lt; n; i++) &#123; char[] str = stickers[i].toCharArray(); for (char c : str) &#123; map[i][c - 'a']++; &#125; &#125; HashMap&lt;String, Integer&gt; dp = new HashMap&lt;&gt;(); dp.put(\"\", 0); return process1(dp, map, target);&#125;// dp 傻缓存，如果t已经算过了，直接返回dp中的值// t 剩余的目标// 0..N每一个字符串所含字符的词频统计// 返回值是-1，map 中的贴纸 怎么都无法restpublic static int process1( HashMap&lt;String, Integer&gt; dp, int[][] map, String rest) &#123; if (dp.containsKey(rest)) &#123; return dp.get(rest); &#125; // 以下就是正式的递归调用过程 int ans = Integer.MAX_VALUE; // ans -&gt; 搞定rest，使用的最少的贴纸数量 int n = map.length; // N种贴纸 int[] tmap = new int[26]; // tmap 去替代 rest char[] target = rest.toCharArray(); for (char c : target) &#123; tmap[c - 'a']++; &#125; for (int i = 0; i &lt; n; i++) &#123; // 枚举当前第一张贴纸是谁？ if (map[i][target[0] - 'a'] == 0) &#123; continue; &#125; StringBuilder sb = new StringBuilder(); // i 贴纸， j 枚举a~z字符 for (int j = 0; j &lt; 26; j++) &#123; // if (tmap[j] &gt; 0) &#123; // j这个字符是target需要的 for (int k = 0; k &lt; Math.max(0, tmap[j] - map[i][j]); k++) &#123; sb.append((char) ('a' + j)); &#125; &#125; &#125; // sb -&gt; i String s = sb.toString(); int tmp = process1(dp, map, s); if (tmp != -1) &#123; ans = Math.min(ans, 1 + tmp); &#125; &#125; // ans 系统最大 rest dp.put(rest, ans == Integer.MAX_VALUE ? -1 : ans); return dp.get(rest);&#125; 123**多样本位置全对应的尝试模型**两个字符串的最长公共子序列问题 12345678910111213141516171819202122232425262728293031/*思路把样本数据当做二维数组，求最右下角的值，就是问题的答案db[i][j]赋值的四种思考方式： 1.db[i][j] = db[i-1][j-1] : 最长子序列和两个字符串的最后字符无关 2.db[i][j] = db[i-1][j] ：最长子序列和str1最后字符串无关 3.db[i][j] = db[i][j-1] ：最长子序列和str2最后字符串无关 4.db[i][j] = db[i-1][j-1] + 1 : str1和str2最后字符相同（满足str1[i] = str2[j]）*/public static int lcse(char[] str1, char[] str2) &#123; int[][] dp = new int[str1.length][str2.length]; dp[0][0] = str1[0] == str2[0] ? 1 : 0; for (int i = 1; i &lt; str1.length; i++) &#123; dp[i][0] = Math.max(dp[i - 1][0], str1[i] == str2[0] ? 1 : 0); &#125; for (int j = 1; j &lt; str2.length; j++) &#123; dp[0][j] = Math.max(dp[0][j - 1], str1[0] == str2[j] ? 1 : 0); &#125; for (int i = 1; i &lt; str1.length; i++) &#123; for (int j = 1; j &lt; str2.length; j++) &#123; dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]); if (str1[i] == str2[j]) &#123; dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - 1] + 1); &#125; &#125; &#125; return dp[str1.length - 1][str2.length - 1];&#125; 1234567**寻找业务限制的尝试模型**给定一个数组，代表每个人喝完咖啡准备刷杯子的时间只有一台咖啡机，一次只能洗一个杯子，时间耗费a，洗完才能洗下一杯每个咖啡杯也可以自己挥发干净，时间耗费b，咖啡杯可以并行挥发返回让所有咖啡杯变干净的最早完成时间三个参数：int[] arr、int a、int b 1234567891011121314151617181920212223// process(drinks, 3, 10, 0,0)// a 洗一杯的时间 固定变量// b 自己挥发干净的时间 固定变量// drinks 每一个员工喝完的时间 固定变量// drinks[0..index-1]都已经干净了，不用你操心了// drinks[index...]都想变干净，这是我操心的，washLine表示洗的机器何时可用// drinks[index...]变干净，最少的时间点返回public static int process(int[] drinks, int a, int b, int index, int washLine) &#123; if (index == drinks.length - 1) &#123; return Math.min(Math.max(washLine, drinks[index]) + a, drinks[index] + b); &#125; // 剩不止一杯咖啡 // wash是我当前的咖啡杯，洗完的时间 int wash = Math.max(washLine, drinks[index]) + a;// 洗，index一杯，结束的时间点 // index+1...变干净的最早时间 int next1 = process(drinks, a, b, index + 1, wash); // index.... int p1 = Math.max(wash, next1); int dry = drinks[index] + b; // 挥发，index一杯，结束的时间点 int next2 = process(drinks, a, b, index + 1, washLine); int p2 = Math.max(dry, next2); return Math.min(p1, p2);&#125; 123456789101112131415161718192021222324252627282930313233/*暴力递归改动态规划根据每一杯咖啡的washLine的最大值来定二维数组washLine的最大值是所有咖啡都放咖啡机洗的时间*/public static int dp(int[] drinks, int a, int b) &#123; if (a &gt;= b) &#123; return drinks[drinks.length - 1] + b; &#125; // a &lt; b int N = drinks.length; int limit = 0; // 咖啡机什么时候可用 for (int i = 0; i &lt; N; i++) &#123; limit = Math.max(limit, drinks[i]) + a; &#125; int[][] dp = new int[N][limit + 1]; // N-1行，所有的值 for (int washLine = 0; washLine &lt;= limit; washLine++) &#123; dp[N - 1][washLine] = Math.min(Math.max(washLine, drinks[N - 1]) + a, drinks[N - 1] + b); &#125; for (int index = N - 2; index &gt;= 0; index--) &#123; for (int washLine = 0; washLine &lt;= limit; washLine++) &#123; int p1 = Integer.MAX_VALUE; int wash = Math.max(washLine, drinks[index]) + a; if (wash &lt;= limit) &#123; p1 = Math.max(wash, dp[index + 1][wash]); &#125; int p2 = Math.max(drinks[index] + b, dp[index + 1][washLine]); dp[index][washLine] = Math.min(p1, p2); &#125; &#125; return dp[0][0];&#125; 123456请同学们自行搜索或者想象一个象棋的棋盘，然后把整个棋盘放入第一象限，棋盘的最左下角是(0,0)位置那么整个棋盘就是横坐标上9条线、纵坐标上10条线的区域给你三个 参数 x，y，k返回“马”从(0,0)位置出发，必须走k步最后落在(x,y)上的方法数有多少种? 1234567891011121314151617181920//暴力递归// 马从(0,0)出发，有K步要走，并且一定要走完，最终来到x，y位置的方法数是多少public static int way1(int x, int y, int k) &#123; if (k == 0) &#123; return x == 0 &amp;&amp; y == 0 ? 1 : 0; &#125; if (x &lt; 0 || x &gt; 9 || y &lt; 0 || y &gt; 8) &#123; return 0; &#125; // 有步数要走, x，y 也是棋盘上的位置 // 马的走法，有8个位置能一步走到x,y return f(x + 2, y - 1, k - 1) + f(x + 2, y + 1, k - 1) + f(x + 1, y + 2, k - 1) + f(x - 1, y + 2, k - 1) + f(x - 2, y + 1, k - 1) + f(x - 2, y - 1, k - 1) + f(x - 1, y - 2, k - 1) + f(x + 1, y - 2, k - 1);&#125; 12345678910111213141516171819202122232425//另一种暴力递归public static int ways2(int x, int y, int k) &#123; return p(0,0,k,x,y);&#125;// 当前来到row，col位置，还剩rest步，走完rest步之后，来到x，y位置，方法数多少public static int p(int row, int col, int rest, int x, int y) &#123; if(rest == 0) &#123; return row == x &amp;&amp; col == y ? 1 :0; &#125; if (row &lt; 0 || row &gt; 9 || col &lt; 0 || col &gt; 8) &#123; return 0; &#125; return p(row + 2, col - 1, rest - 1, x, y) + p(row + 2, col + 1, rest - 1, x, y) + p(row + 1, col + 2, rest - 1, x, y) + p(row - 1, col + 2, rest - 1, x, y) + p(row - 2, col + 1, rest - 1, x, y) + p(row - 2, col - 1, rest - 1, x, y) + p(row - 1, col - 2, rest - 1, x, y) + p(row + 1, col - 2, rest - 1, x, y);&#125; 123456789101112131415161718192021222324252627//动态规划public static int ways3(int x, int y, int k) &#123; int[][][] dp = new int[10][9][k + 1];// 0~k dp[0][0][0] = 1; // dp[..][..][0] = 0 for (int level = 1; level &lt;= k; level++) &#123; // level层，x y for (int i = 0; i &lt; 10; i++) &#123; // x可能性 for (int j = 0; j &lt; 9; j++) &#123; // y的可能性 dp[i][j][level] = getValue(dp, i + 2, j - 1, level - 1) + getValue(dp, i + 2, j + 1, level - 1) + getValue(dp, i + 1, j + 2, level - 1) + getValue(dp, i - 1, j + 2, level - 1) + getValue(dp, i - 2, j + 1, level - 1) + getValue(dp, i - 2, j - 1, level - 1) + getValue(dp, i - 1, j - 2, level - 1) + getValue(dp, i + 1, j - 2, level - 1); &#125; &#125; &#125; return dp[x][y][k];&#125;public static int getValue(int[][][] dp, int x, int y, int k) &#123; if (x &lt; 0 || x &gt; 9 || y &lt; 0 || y &gt; 8) &#123; return 0; &#125; return dp[x][y][k];&#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://midkuro.gitee.io/categories/algorithm/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"algorithm","slug":"algorithm","permalink":"https://midkuro.gitee.io/tags/algorithm/"}]},{"title":"'多线程与高并发'","slug":"juc-base","date":"2020-10-29T14:31:00.000Z","updated":"2020-12-17T02:48:39.319Z","comments":true,"path":"2020/10/29/juc-base/","link":"","permalink":"https://midkuro.gitee.io/2020/10/29/juc-base/","excerpt":"","text":"多线程与高并发 进程和线程的区别？ 答案：进程就是一个程序运行起来的状态，线程是一个进程中的不同的执行路径。专业：进程是OS分配资源的基本单位，线程是执行调度的基本单位。分配资源最重要的是：独立的内存空间，线程调度执行（线程共享进程的内存空间，没有自己独立的内存空间） 纤程：用户态的线程，线程中的线程，切换和调度不需要经过OS 锁升级过程：无锁、偏向锁、自旋锁(CAS)、重量级锁 可重入锁：对象头中记录线程ID volatile：可见性（MESI）、指令重排序（内存屏障） Atomic原子类：CAS 123456789final Object object = new Object();Synchronized(object) &#123; //当前线程让出锁:object，进入等待队列，等待其他线程唤醒它 object.wait(); //当前线程唤醒处于等待队列的线程（无法选择哪一个线程） object.notify(); //当前线程让出CPU资源，然后重新加入到抢占CPU的线程队列，可能依旧能够抢占到CPU Thread.yield();&#125; 基本wait和notify是成对出现的。一个线程wait让出锁之后，需要另一个线程调用notify唤醒处于等待队列中的线程。 AQS工具类ReentrantLock1234567891011121314Lock lock = new ReentrantLock();public void executeMethod() &#123; try &#123; lock.lock(); //synchronized(this) for (int i = 0; i &lt; 10; i++) &#123; TimeUnit.SECONDS.sleep(1); System.out.println(i); &#125; &#125; catch (InterruptedException e) &#123; &#125; finally &#123; lock.unlock(); &#125;&#125; ReentrantLock和Synchronized的区别： 1.Synchronized是自动加锁和解锁，ReentrantLock是手动的。 2.Synchronized使用锁升级的概念加锁，而ReentrantLock使用的CAS+volatile加锁。 3.Synchronized没办法唤醒等待队列中指定的线程，而ReentrantLock提供Condition可以做到。 4.Synchronized一执行无法取消，而ReentrantLock提供了tryLock方法，指定时间尝试获取锁。 CountDownLatch1234567891011121314151617181920212223Thread[] threads = new Thread[100];CountDownLatch latch = new CountDownLatch(threads.length);for(int i=0; i&lt;threads.length; i++) &#123; threads[i] = new Thread(()-&gt;&#123; int result = 0; for(int j=0; j&lt;10000; j++) result += j; //当闭锁数量等于0时开放 latch.countDown(); &#125;);&#125;for (int i = 0; i &lt; threads.length; i++) &#123; threads[i].start();&#125;try &#123; latch.await();&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;System.out.println(\"end latch\"); CountDownLatch又称闭锁、门栓，可以延迟线程的进度直到其到达终止状态。闭锁相当于一扇门，在闭锁到达结束状态之前，这扇门一直是关闭的，没有任何线程能够通过，当到达结束状态时，这扇门会打开并允许所有线程的通过。 当闭锁到达结束状态后，将不会再改变状态，因此这扇门将永远保持打开状态。闭锁可以用来确保某些活动直到其他活动都完成了后才继续执行。 CyclicBarrier12345678910111213CyclicBarrier barrier = new CyclicBarrier(20, () -&gt; System.out.println(\"满人，发车\"));for(int i=0; i&lt;100; i++) &#123; new Thread(()-&gt;&#123; try &#123; barrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;).start();&#125; CyclicBarrier栅栏类似闭锁，与闭锁的区别在于，所有线程都必须到达栅栏位置，才能执行，闭锁用于等待时间，而栅栏用于等待其他线程。 闭锁不能被重复使用，而栅栏可以被重复使用，它类似于坐动车，满人了，发车，人没满，就一直等到人满，一直循环载客。 ReadWriteLock12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class T10_TestReadWriteLock &#123; static Lock lock = new ReentrantLock(); private static int value; static ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); static Lock readLock = readWriteLock.readLock(); static Lock writeLock = readWriteLock.writeLock(); public static void read(Lock lock) &#123; try &#123; lock.lock(); Thread.sleep(1000); System.out.println(\"read over!\"); //模拟读取操作 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void write(Lock lock, int v) &#123; try &#123; lock.lock(); Thread.sleep(1000); value = v; System.out.println(\"write over!\"); //模拟写操作 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; //Runnable readR = ()-&gt; read(lock); Runnable readR = ()-&gt; read(readLock); //Runnable writeR = ()-&gt;write(lock, new Random().nextInt()); Runnable writeR = ()-&gt;write(writeLock, new Random().nextInt()); for(int i=0; i&lt;18; i++) new Thread(readR).start(); for(int i=0; i&lt;2; i++) new Thread(writeR).start(); &#125;&#125; 读写锁，当读锁时，支持其他读锁的访问，所以它是个共享锁，但是不支持写锁的访问，如果一个线程中先获取了读锁，并尝试再获取写锁，那么将会产生死锁。 细节分析 Semaphore12345678910111213141516171819202122232425262728293031323334353637public class T11_TestSemaphore &#123; public static void main(String[] args) &#123; //Semaphore s = new Semaphore(2); Semaphore s = new Semaphore(2, true); //允许一个线程同时执行 //Semaphore s = new Semaphore(1); new Thread(()-&gt;&#123; try &#123; s.acquire(); System.out.println(\"T1 running...\"); Thread.sleep(200); System.out.println(\"T1 running...\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; s.release(); &#125; &#125;).start(); new Thread(()-&gt;&#123; try &#123; s.acquire(); System.out.println(\"T2 running...\"); Thread.sleep(200); System.out.println(\"T2 running...\"); //释放一个许可给信号量 s.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; 计数信号量Counting Semaphore用于控制同时访问某个特性资源的操作数量，或者同时执行某个执行的数据量。 Semaphore管理着一组虚拟的许可permit，许可的初始数量可通过构造函数指定，在执行操作时可以首先获得许可，并在使用以后释放许可，如果没有许可，那么acquire将阻塞直到有许可。 LockSupport12345678910111213141516171819202122232425262728public class T13_TestLockSupport &#123; public static void main(String[] args) &#123; Thread t = new Thread(()-&gt;&#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(i); if(i == 5) &#123; LockSupport.park(); &#125; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); t.start(); LockSupport.unpark(t); /*try &#123; TimeUnit.SECONDS.sleep(8); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"after 8 senconds!\"); LockSupport.unpark(t);*/ &#125;&#125; LockSupport的park和unpark类似于Sync的wait和notify。它的unpark类似于停车位，被调用时后等于没停车位了，所以线程当线程调用park时，将不会在阻塞，也就是说，它的调用是能累积影响park的执行的。 12面试题：实现一个容器，提供两个方法，add，size，写两个线程，线程1添加10个元素到容器中，线程2实现监控元素的个数，当个数到达5个时，线程2给出提示并结束 1234//1.加锁实现时，需要满足List必须使得线程可见（voliate并不具备使对象中的属性内容线程可见）//2.使用sync需要结合wait和notify实现，需要保证List线程可见//3.使用CountDownLatch需要使用两个，否则无法保证size==5时，线程2先结束。需要保证List线程可见//4.使用LockSupport实现 123456789101112131415161718192021222324252627282930313233343536373839public class T07_LockSupport_WithoutSleep &#123; List lists = new ArrayList(); public void add(Object o) &#123; lists.add(o); &#125; public int size() &#123; return lists.size(); &#125; static Thread t1 = null, t2 = null; public static void main(String[] args) &#123; T07_LockSupport_WithoutSleep c = new T07_LockSupport_WithoutSleep(); t1 = new Thread(() -&gt; &#123; System.out.println(\"t1启动\"); for (int i = 0; i &lt; 10; i++) &#123; c.add(new Object()); System.out.println(\"add \" + i); if (c.size() == 5) &#123; LockSupport.unpark(t2); LockSupport.park(); &#125; &#125; &#125;, \"t1\"); t2 = new Thread(() -&gt; &#123; LockSupport.park(); System.out.println(\"t2 结束\"); LockSupport.unpark(t1); &#125;, \"t2\"); t2.start(); t1.start(); &#125;&#125; 12面试题：写一个固定容量同步容器，拥有put和get方法，以及getCount方法，能够支持2个生产者线程以及10个消费者线程的阻塞调用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class MyContainer1&lt;T&gt; &#123; final private LinkedList&lt;T&gt; lists = new LinkedList&lt;&gt;(); final private int MAX = 10; //最多10个元素 private int count = 0; public synchronized void put(T t) &#123; //想想为什么用while而不是用if？ //因为有可能 get--》put--》put--》，那么后面的put没有重复判断，依旧是满的 while(lists.size() == MAX) &#123; try &#123; this.wait(); //effective java &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; lists.add(t); ++count; this.notifyAll(); //通知消费者线程进行消费 &#125; public synchronized T get() &#123; T t = null; while(lists.size() == 0) &#123; try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; t = lists.removeFirst(); count --; this.notifyAll(); //通知生产者进行生产，因为无法指定线程 return t; &#125; public static void main(String[] args) &#123; MyContainer1&lt;String&gt; c = new MyContainer1&lt;&gt;(); //启动消费者线程 for(int i=0; i&lt;10; i++) &#123; new Thread(()-&gt;&#123; for(int j=0; j&lt;5; j++) System.out.println(c.get()); &#125;, \"c\" + i).start(); &#125; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //启动生产者线程 for(int i=0; i&lt;2; i++) &#123; new Thread(()-&gt;&#123; for(int j=0; j&lt;25; j++) c.put(Thread.currentThread().getName() + \" \" + j); &#125;, \"p\" + i).start(); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * 面试题：写一个固定容量同步容器，拥有put和get方法，以及getCount方法， * 能够支持2个生产者线程以及10个消费者线程的阻塞调用 * * 使用wait和notify/notifyAll来实现 * * 使用Lock和Condition来实现 * 对比两种方式，Condition的方式可以更加精确的指定哪些线程被唤醒 * */import java.util.LinkedList;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class MyContainer2&lt;T&gt; &#123; final private LinkedList&lt;T&gt; lists = new LinkedList&lt;&gt;(); final private int MAX = 10; //最多10个元素 private int count = 0; private Lock lock = new ReentrantLock(); private Condition producer = lock.newCondition();//本质是个等待队列 private Condition consumer = lock.newCondition();//创建两个等待队列 public void put(T t) &#123; try &#123; lock.lock(); while(lists.size() == MAX) &#123; //想想为什么用while而不是用if？ producer.await(); &#125; lists.add(t); ++count; consumer.signalAll(); //通知消费者线程进行消费,精确指定消费者和生产者等待队列 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public T get() &#123; T t = null; try &#123; lock.lock(); while(lists.size() == 0) &#123; consumer.await(); &#125; t = lists.removeFirst(); count --; producer.signalAll(); //通知生产者进行生产 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; return t; &#125; public static void main(String[] args) &#123; MyContainer2&lt;String&gt; c = new MyContainer2&lt;&gt;(); //启动消费者线程 for(int i=0; i&lt;10; i++) &#123; new Thread(()-&gt;&#123; for(int j=0; j&lt;5; j++) System.out.println(c.get()); &#125;, \"c\" + i).start(); &#125; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //启动生产者线程 for(int i=0; i&lt;2; i++) &#123; new Thread(()-&gt;&#123; for(int j=0; j&lt;25; j++) c.put(Thread.currentThread().getName() + \" \" + j); &#125;, \"p\" + i).start(); &#125; &#125;&#125; AQS123456789public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; //最外层的 ReentrantLock.lock() public void lock() &#123; sync.lock(); &#125;&#125; 123456789101112131415161718192021222324//ReentrantLock的内部类abstract static class Sync extends AbstractQueuedSynchronizer &#123; final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //CAS尝试获取锁 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果当前线程已经独占了，则自增state，可重入 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041//ReentrantLock的内部类static final class NonfairSync extends Sync &#123; final void lock() &#123; //如果state是0，则直接获得锁 if (compareAndSetState(0, 1)) //设置当前线程独占这把锁 setExclusiveOwnerThread(Thread.currentThread()); else //否则根据是否公平锁进行获取锁 acquire(1); &#125; //调用父类实现 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; final boolean nonfairTryAcquire(int acquires) &#123; //拿到当前线程 final Thread current = Thread.currentThread(); //获取当前状态 int c = getState(); //如果没人获得线程，通过CAS对state值做变更，获取锁 if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果得到锁的线程和当前线程一致，则增加获取锁的次数，重入 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; //用于存储子类的各种状态信息，由子类自定义实现 private volatile int state; //双向链表，存储线程信息 static final class Node &#123; volatile Node prev; volatile Node next; volatile Thread thread; &#125; public final void acquire(int arg) &#123; //回调子类实现的tryAcquire方法 //获取不到锁时，调用acquireQueued进入队列等待 //addWaiter(Node.EXCLUSIVE), arg)添加一个排它的等待者 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; // Node.EXCLUSIVE for exclusive, Node.SHARED for shared //排它锁或者共享锁 private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure //等待队列的最后一个节点 Node pred = tail; if (pred != null) &#123; //新节点的prev指针指向末尾节点 node.prev = pred; //使用CAS设置最后一个节点，设置成功则原末尾节点的next指向新的节点 //它只对链表中的最后一个节点使用CAS自旋方式添加新节点保证安全性 //AQS的核心，相比Sync，提高了加锁的效率 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //获取Node的前置结点 final Node p = node.predecessor(); //如果前置节点是头结点，并且尝试越过前置节点获取锁 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //如果能获取到,设置当前节点为头结点 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //如果获取不到，则进行Park阻塞，等待前置节点释放锁唤醒等待队列 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;&#125; JDK1.9之后有的一个VarHandle，可以用来指针指向普通对象中的地址，代替它执行原子性的操作，如CAS、getAndAdd等等，和反射的区别是，它效率比反射快很多，可以理解它是直接操作二进制码。 12345678910111213141516public class T01_HelloVarHandle &#123; int x = 8; private static VarHandle handle; //用于指向对象的某个属性 static &#123; try &#123; //指向当前T01_HelloVarHandle类对象的x属性的int类型 handle = MethodHandles.lookup().findVarHandle(T01_HelloVarHandle.class, \"x\", int.class); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125;&#125; AQS效率高的核心：使用CAS操作链表中的头/尾节点，而不是加锁整张链表，所以效率高。 1234567ReentrantLock.lock() -&gt;sync.lock() -&gt;NonfairSync.lock() -&gt;AbstractQueuedSynchronizer.acquire() -&gt;NonfairSync.tryAcquire() -&gt;AbstractQueuedSynchronizer.addWaiter() -&gt;AbstractQueuedSynchronizer.acquireQueued() 强软弱虚ThreadLocal可以用于Spring的声明式事务中，保证在同一个线程中，获取到的数据源都是同一个。 123456789101112//ThreadLocal.set(T)public void set(T value) &#123; //获取当前线程 Thread t = Thread.currentThread(); //获取当前线程中的ThreadLocalMap对象 ThreadLocalMap map = getMap(t); if (map != null) //《当前ThreadLocal，value》 map.set(this, value); else createMap(t, value);&#125; 1234567891011121314151617181920static class ThreadLocalMap &#123; /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as \"stale entries\" in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125;&#125; 阻塞队列BlockingQueue 方法以四种形式出现，对于不能立即满足但可能在将来某一时刻可以满足的操作，这四种形式的处理方式不同：第一种是抛出一个异常，第二种是返回一个特殊值（null 或 false，具体取决于操作），第三种是在操作可以成功前，无限期地阻塞当前线程，第四种是在放弃前只在给定的最大时间限制内阻塞。下表中总结了这些方法： 抛出异常 特殊值 阻塞 超时 入队列 add(e) offer(e) put(e) offer(e, time, unit) 出队列 remove() poll() take() poll(time, unit) peek() 123456789101112add(E):该API是由Collection接口提供的，AbstractQueue类实现，如果队列满了添加失败会抛异常offer(E)：由Queue接口提供，如果队列满了会返回false，否则trueput(E):放元素进队列，如果队列满了会进行阻塞，直到有人从队列中取走元素poll()：从队列中取出一个元素，并且从队列里移除该元素，队列为空时返回nulltake()：从队列里取元素，如果队列为空会进行阻塞，直到有人放了元素进队列peek()：从队列中获取元素，但是不把该元素从队列里移除 Queue和List的区别：Queue多了很多对线程操作友好的API，并且Queue主要用于线程之间的通信，而List用于存储。 有界队列 ArrayBlockingQueue ：基于数组实现的阻塞队列 LinkedBlockingQueue ：不设置大小时默认长度是Integer.MAX_VALUE，内部是基于链表实现的。 SynchronousQueue ：内部容量为零，用于两个线程交换数据用。 无界队列 ConcurrentLinkedQueue ：无锁队列，采用CAS操作，具有较高吞吐量 PriorityBlockingQueue ：具有优先级的阻塞队列，优先级高的先弹出 DelayedQueue ：延时队列，内部实现其实是采用带时间的优先队列 LinkedTransferQueue ：线程间数据交换的利器，是一个由链表结构组成的无界阻塞TransferQueue队列。多了tryTransfer和transfer方法。transfer进去后将一直阻塞到有人take走，与SynchronousQueue 的不同是它内部有容量大小。 详细分析 无界队列的put 操作永远都不会阻塞，空间限制来源于系统资源的限制，底层都使用CAS无锁编程。 区别相同点： LinkedBlockingQueue和ArrayBlockingQueue都是可阻塞的队列，内部都是使用ReentrantLock和Condition来保证生产和消费的同步； 当队列为空，消费者线程被阻塞；当队列装满，生产者线程被阻塞；使用Condition的方法来同步和通信：await()和signal()； 不同点： ArrayBlockingQueue 实现简单，表现稳定，生产者和消费者使用同一个锁，通常性能不如后者。 LinkedBlockingQueue 生产者和消费者两把锁是分开的，所以竞争会小一些。 ArrayBlockingQueue 内部维护了一个数组final Object[] items存储数据，在生产和消费的时候，是直接将枚举对象插入或移除的，不会产生或销毁任何额外的对象实例。 LinkedBlockingQueue内部维护的是一个链表结构，在生产和消费的时候，需要创建Node对象进行插入或移除，大批量数据的系统中，其对于GC的压力会比较大。 LinkedBlockingQueue 的构造方法默认使用Integer.MAX_VALUE长度，而ArrayBlockingQueue的数组长度需要在创建时指定。 双端队列 123456普通队列(一端进另一端出):Queue queue = new LinkedList() 或 Deque deque = new LinkedList()双端队列(两端都可进出)Deque deque = new LinkedList()堆栈Deque deque = new LinkedList() Java堆栈Stack类已经过时，Java官方推荐使用Deque替代Stack使用。Deque堆栈操作方法：push()、pop()、peek()。 Deque 继承自 Queue,直接实现了它的有 LinkedList, ArayDeque, ConcurrentLinkedDeque 等。Deque 支持容量受限的双端队列，也支持大小不固定的。一般双端队列大小不确定。Deque 接口定义了一些从头部和尾部访问元素的方法。比如分别在头部、尾部进行插入、删除、获取元素。 抛出异常 特殊值 抛出异常 特殊值 插入 addFirst(e) offerFirst(e) addLast(e) offerLast(e) 删除 removeFirst() pollFirst() removeLast() pollLast() 检查 getFirst() peekFirst() getLast() peekLast() Deque接口扩展(继承)了 Queue 接口。在将双端队列用作队列时，将得到 FIFO（先进先出）行为。将元素添加到双端队列的末尾，从双端队列的开头移除元素。从 Queue 接口继承的方法完全等效于 Deque 方法，如下表所示： Queue方法 Deque方法 add(e) addLast(e) offer(e) offerLast(e) remove() removeFirst() poll() pollFirst() element() getFirst() peek() peekFirst() 双端队列也可用作 LIFO（后进先出）堆栈。应优先使用此接口而不是遗留 Stack 类。在将双端队列用作堆栈时，元素被推入双端队列的开头并从双端队列开头弹出。堆栈方法完全等效于 Deque 方法，如下表所示： Stack方法 Deque方法 push(e) addFirst(e) pop() removeFirst() peek() peekFirst() 线程池12345678910@FunctionalInterfacepublic interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public interface Future&lt;V&gt; &#123; /** * Attempts to cancel execution of this task. This attempt will * fail if the task has already completed, has already been cancelled, * or could not be cancelled for some other reason. If successful, * and this task has not started when &#123;@code cancel&#125; is called, * this task should never run. If the task has already started, * then the &#123;@code mayInterruptIfRunning&#125; parameter determines * whether the thread executing this task should be interrupted in * an attempt to stop the task. * * &lt;p&gt;After this method returns, subsequent calls to &#123;@link #isDone&#125; will * always return &#123;@code true&#125;. Subsequent calls to &#123;@link #isCancelled&#125; * will always return &#123;@code true&#125; if this method returned &#123;@code true&#125;. * * @param mayInterruptIfRunning &#123;@code true&#125; if the thread executing this * task should be interrupted; otherwise, in-progress tasks are allowed * to complete * @return &#123;@code false&#125; if the task could not be cancelled, * typically because it has already completed normally; * &#123;@code true&#125; otherwise */ boolean cancel(boolean mayInterruptIfRunning); /** * Returns &#123;@code true&#125; if this task was cancelled before it completed * normally. * * @return &#123;@code true&#125; if this task was cancelled before it completed */ boolean isCancelled(); /** * Returns &#123;@code true&#125; if this task completed. * * Completion may be due to normal termination, an exception, or * cancellation -- in all of these cases, this method will return * &#123;@code true&#125;. * * @return &#123;@code true&#125; if this task completed */ boolean isDone(); /** * Waits if necessary for the computation to complete, and then * retrieves its result. * * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting */ V get() throws InterruptedException, ExecutionException; /** * Waits if necessary for at most the given time for the computation * to complete, and then retrieves its result, if available. * * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting * @throws TimeoutException if the wait timed out */ V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; 1234567891011public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123; &#125;public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run();&#125; CompletableFuture12345678910111213CompletableFuture&lt;Double&gt; futureTM = CompletableFuture.supplyAsync(()-&gt;priceOfTM());CompletableFuture&lt;Double&gt; futureTB = CompletableFuture.supplyAsync(()-&gt;priceOfTB());CompletableFuture&lt;Double&gt; futureJD = CompletableFuture.supplyAsync(()-&gt;priceOfJD());//阻塞获取所有结果，管理多个fefure的结果CompletableFuture.allOf(futureTM, futureTB, futureJD).join();//多线程执行完毕后的后续操作CompletableFuture.supplyAsync(()-&gt;priceOfTM()) .thenApply(String::valueOf) .thenApply(str-&gt; \"price \" + str) .thenAccept(System.out::println); 123456789101112131415161718192021222324252627282930313233343536373839404142public class Test &#123; volatile static String s = \"\"; public static void main(String[] args) throws IOException, InterruptedException &#123; CompletableFuture&lt;String&gt; c = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; Thread.sleep(3000); System.out.println(\"c1\"); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; return \"world\"; &#125;).thenApply(Tets::sum); CompletableFuture&lt;String&gt; c2 = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; Thread.sleep(1000); System.out.println(\"c2\"); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; return \"hello \"; &#125;).thenApply(Tets::sum); //输出 hello world System.out.println(\"---s = \" + s); CompletableFuture.allOf(c, c2).join(); System.out.println(\"all\"); System.in.read(); &#125; public static String sum(String st) &#123; System.out.println(\"======\" + st); s += st; System.out.println(\"====\" + s); return s; &#125;&#125; 细节分析 ThreadPoolExecutor12345ThreadPoolExecutorForkJoinPool: 分解汇总的任务 用很少的线程可以执行很多的任务（子任务）TPE做不到先执行子任务 CPU密集型 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize：核心线程数，核心线程会一直存活，即使没有任务需要处理。当线程数小于核心线程数时，即使现有的线程空闲，线程池也会优先创建新线程来处理任务，而不是直接交给现有的线程处理。 核心线程在allowCoreThreadTimeout被设置为true时会超时退出，默认情况下不会退出。 maximumPoolSize：一个任务被提交到线程池以后，首先会找有没有空闲存活线程，如果有则直接执行，如果没有则会缓存到工作队列中，如果工作队列满了，则会创建一个新线程，然后从工作队列的头部取出一个任务交由新线程来处理，而将刚提交的任务放入工作队列尾部。线程池不会无限制的去创建新线程，当线程池中的线程数达到maximunPoolSize（最大线程池线程数量）时达到阈值。 keepAliveTime：一个线程如果处于空闲状态，并且当前的线程数量大于corePoolSize，那么在指定时间后，这个空闲线程会被销毁 unit：空间线程存活时间单位 workQueue ：工作队列 新任务被提交后，会先进入到此工作队列中，任务调度时再从队列中取出任务。jdk中提供了四种工作队列： ①ArrayBlockingQueue 基于数组的有界阻塞队列，按FIFO排序。新任务进来后，会放到该队列的队尾，有界的数组可以防止资源耗尽问题。当线程池中线程数量达到corePoolSize后，再有新任务进来，则会将任务放入该队列的队尾，等待被调度。如果队列已经是满的，则创建一个新线程，如果线程数量已经达到maxPoolSize，则会执行拒绝策略。 ②LinkedBlockingQuene 基于链表的无界阻塞队列（其实最大容量为Interger.MAX），按照FIFO排序。由于该队列的近似无界性，当线程池中线程数量达到corePoolSize后，再有新任务进来，会一直存入该队列，而不会去创建新线程直到maxPoolSize，因此使用该工作队列时，参数maxPoolSize其实是不起作用的。 ③SynchronousQuene 一个不缓存任务的阻塞队列，生产者放入一个任务必须等到消费者取出这个任务。也就是说新任务进来时，不会缓存，而是直接被调度执行该任务，如果没有可用线程，则创建新线程，如果线程数量达到maxPoolSize，则执行拒绝策略。 ④PriorityBlockingQueue 具有优先级的无界阻塞队列，优先级通过参数Comparator实现 threadFactory ：线程工厂 创建一个新线程时使用的工厂，可以用来设定线程名、是否为daemon线程等等 handler ：拒绝策略 123public interface RejectedExecutionHandler &#123; void rejectedExecution(Runnable r, ThreadPoolExecutor executor);&#125; 当工作队列中的任务已到达最大限制，并且线程池中的线程数量也达到最大限制，这时如果有新任务提交进来，该如何处理呢。这里的拒绝策略，就是解决这个问题的，jdk中提供了4中拒绝策略： ①CallerRunsPolicy 该策略下，在调用者线程中直接执行被拒绝任务的run方法，除非线程池已经shutdown，则直接抛弃任务。 12345678public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; public CallerRunsPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125;&#125; ②AbortPolicy 该策略下，直接丢弃任务，并抛出RejectedExecutionException异常。 12345678public static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); &#125;&#125; ③DiscardPolicy 该策略下，直接丢弃任务，什么都不做。 12345public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125;&#125; ④DiscardOldestPolicy 该策略下，抛弃进入队列最早的那个任务，然后尝试把这次拒绝的任务放入队列。 123456789public static class DiscardOldestPolicy implements RejectedExecutionHandler &#123; public DiscardOldestPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125;&#125; 123456//案例ThreadPoolExecutor tpe = new ThreadPoolExecutor(2, 4, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(4), Executors.defaultThreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy()); ExecutorsSingleThreadExecutor 为什么有单线程池？ 任务队列、线程池生命周期 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 使用LinkedBlockingQueue，长度是Integer.MAX_VALUE，会堆满OOM。 newCachedThreadPool12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 使用SynchronousQueue等有线程池接收到任务之后，才返回，maximumPoolSize=Integer.MAX_VALUE，线程太多CPU切换，瘫痪。 newFixedThreadPool12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 使用LinkedBlockingQueue，长度是Integer.MAX_VALUE，会堆满OOM。 newScheduledThreadPool1234public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125; 使用DelayedWorkQueue延时队列处理任务， maximumPoolSize=Integer.MAX_VALUE，线程太多CPU切换，瘫痪。 ThreadPoolExecutor源码1234567891011121314151617181920212223242526272829303132333435// 1. `ctl`，可以看做一个int类型的数字，高3位表示线程池状态，低29位表示worker数量private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));// 2. `COUNT_BITS`，`Integer.SIZE`为32，所以`COUNT_BITS`为29private static final int COUNT_BITS = Integer.SIZE - 3;// 3. `CAPACITY`，线程池允许的最大线程数。1左移29位，然后减1，即为 2^29 - 1private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bits// 4. 线程池有5种状态，按大小排序如下：RUNNING &lt; SHUTDOWN &lt; STOP &lt; TIDYING &lt; TERMINATEDprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// Packing and unpacking ctl// 5. `runStateOf()`，获取线程池状态，通过按位与操作，低29位将全部变成0private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;// 6. `workerCountOf()`，获取线程池worker数量，通过按位与操作，高3位将全部变成0private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;// 7. `ctlOf()`，根据线程池状态和线程池worker数量，生成ctl值private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;/* * Bit field accessors that don't require unpacking ctl. * These depend on the bit layout and on workerCount being never negative. */// 8. `runStateLessThan()`，线程池状态小于xxprivate static boolean runStateLessThan(int c, int s) &#123; return c &lt; s;&#125;// 9. `runStateAtLeast()`，线程池状态大于等于xxprivate static boolean runStateAtLeast(int c, int s) &#123; return c &gt;= s;&#125; 1234567891011121314151617181920212223242526272829303132333435/** * The queue used for holding tasks and handing off to worker * threads. We do not require that workQueue.poll() returning * null necessarily means that workQueue.isEmpty(), so rely * solely on isEmpty to see if the queue is empty (which we must * do for example when deciding whether to transition from * SHUTDOWN to TIDYING). This accommodates special-purpose * queues such as DelayQueues for which poll() is allowed to * return null even if it may later return non-null when delays * expire. *///线程池工作队列private final BlockingQueue&lt;Runnable&gt; workQueue;/*** Lock held on access to workers set and related bookkeeping.* While we could use a concurrent set of some sort, it turns out* to be generally preferable to use a lock. Among the reasons is* that this serializes interruptIdleWorkers, which avoids* unnecessary interrupt storms, especially during shutdown.* Otherwise exiting threads would concurrently interrupt those* that have not yet interrupted. It also simplifies some of the* associated statistics bookkeeping of largestPoolSize etc. We* also hold mainLock on shutdown and shutdownNow, for the sake of* ensuring workers set is stable while separately checking* permission to interrupt and actually interrupting.*///线程池内部的Lock锁，用于Workers集合的变更加锁private final ReentrantLock mainLock = new ReentrantLock();/*** Set containing all worker threads in pool. Accessed only when*///线程池工作线程集合private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); // worker数量比核心线程数小，直接创建worker执行任务 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // worker数量超过核心线程数，任务直接进入队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 线程池状态不是RUNNING状态，说明执行过shutdown命令，需要对新加入的任务执行reject()操作。 // 这儿为什么需要recheck，是因为任务入队列前后，线程池的状态可能会发生变化。 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 这儿为什么需要判断0值，主要是在线程池构造方法中，核心线程数允许为0 else if (workerCountOf(recheck) == 0) //给线程池至少创建一个线程（非核心线程） addWorker(null, false); &#125; // 如果线程池不是运行状态，或者任务进入队列失败，则尝试创建worker执行任务。 // 这儿有3点需要注意： // 1. 线程池不是运行状态时，addWorker内部会判断线程池状态 // 2. addWorker第2个参数表示是否创建核心线程 // 3. addWorker返回false，则说明任务执行失败，需要执行reject操作 else if (!addWorker(command, false)) reject(command);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148/* * Methods for creating, running and cleaning up after workers *//** * Checks if a new worker can be added with respect to current * pool state and the given bound (either core or maximum). If so, * the worker count is adjusted accordingly, and, if possible, a * new worker is created and started, running firstTask as its * first task. This method returns false if the pool is stopped or * eligible to shut down. It also returns false if the thread * factory fails to create a thread when asked. If the thread * creation fails, either due to the thread factory returning * null, or due to an exception (typically OutOfMemoryError in * Thread.start()), we roll back cleanly. * * @param firstTask the task the new thread should run first (or * null if none). Workers are created with an initial first task * (in method execute()) to bypass queuing when there are fewer * than corePoolSize threads (in which case we always start one), * or when the queue is full (in which case we must bypass queue). * Initially idle threads are usually created via * prestartCoreThread or to replace other dying workers. * * @param core if true use corePoolSize as bound, else * maximumPoolSize. (A boolean indicator is used here rather than a * value to ensure reads of fresh values after checking other pool * state). * @return true if successful *///firstTask：添加的线程任务//core：是否使用核心线程进行启动该任务（当队列满了才是false）private boolean addWorker(Runnable firstTask, boolean core) &#123; //双重死循环的目的是判断线程池的状态，若是当前线程池可以创建线程则通过 CAS 操作增加线程数； retry: for (;;) &#123; int c = ctl.get(); //获取当前线程池的状态（32位的前3位） int rs = runStateOf(c); // Check if queue empty only if necessary. //if中的条件等价于下边描述： //(rs &gt; SHUTDOWN) || //(rs == SHUTDOWN || firstTask != null) || //(rs == SHUTDOWN || workQueue.isEmpty()) //1. 线程池状态&gt;SHUTDOWN 直接返回false //2. 线程池状态==SHUTDOWN且first不为null，直接返回false //3. 线程池状态==SHUTDOWN且工作且任务队列为空，直接返回false if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; //内部自旋 获取创建线程令牌的过程 for (;;) &#123; //获取线程池内的工作线程数 int wc = workerCountOf(c); //当前线程池内的工作线程数已达最大值，无法添加进工作队列 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // compareAndIncrementWorkerCount(c) 可能会有多个线程在申请，需要以CAS的方式进行 //条件成立：说明记录线程数量已经加1成功，相当于申请到了一块令牌。 //条件失败：说明可能有其它线程，修改过ctl这个值了。 //可能发生过什么事？ //1.其它线程execute() 申请过令牌了，在这之前。导致CAS失败 //2.外部线程可能调用过 shutdown() 或者 shutdownNow() 导致线程池状态发生变化了，咱们知道 ctl 高3位表示状态 状态改变后，cas也会失败。 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl //重新获取线程池状态，变化则继续执行外层循环，否则继续执行内层循环 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; //表示创建的worker是否已经启动，false未启动 true启动 boolean workerStarted = false; //表示创建的worker是否添加到池子中了 默认false 未添加 true是添加。 boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; //为什么要做 t != null 这个判断？ //为了防止ThreadFactory 实现类有bug，因为ThreadFactory 是一个接口，谁都可以实现。 //万一哪个 小哥哥 脑子一热，有bug，创建出来的线程 是null、、 //Doug lea考虑的比较全面。肯定会防止他自己的程序报空指针，所以这里一定要做！ if (t != null) &#123; //worker的添加必须得是串行的，因此需要加锁 final ReentrantLock mainLock = this.mainLock; //持有全局锁，可能会阻塞，直到获取成功为止，同一时刻 操纵 线程池内部相关的操作，都必须持锁。 mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); //条件一：rs &lt; SHUTDOWN 成立：最正常状态，当前线程池为RUNNING状态. //条件二：前置条件：当前线程池状态不是RUNNING状态。 //(rs == SHUTDOWN &amp;&amp; firstTask == null) 当前状态为SHUTDOWN状态且firstTask为空。其实判断的就是SHUTDOWN状态下的特殊情况， //只不过这里不再判断队列是否为空了 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; //t.isAlive() 当线程start后，线程isAlive会返回true。 //防止脑子发热的程序员，ThreadFactory创建线程返回给外部之前，将线程start了 if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); //条件成立：说明当前线程数量是一个新高。更新largestPoolSize if (s &gt; largestPoolSize) largestPoolSize = s; //表示线程已经追加进线程池中了。 workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; //条件成立:说明 添加worker成功 //条件失败：说明线程池在lock之前，线程池状态发生了变化，导致添加失败。 if (workerAdded) &#123; //成功后，则将创建的worker启动，线程启动。 t.start(); //启动标记设置为true workerStarted = true; &#125; &#125; &#125; finally &#123; //失败时做什么清理工作？ //1.释放令牌 //2.将当前worker清理出workers集合 if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 123456789101112131415161718192021222324252627282930313233343536//Worker本身是一个Runnable，并且继承了AQS，自身就是一把锁，防止多个线程同时增强同一个Workerprivate final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 这儿是Worker的关键所在，使用了线程工厂创建了一个线程。传入的参数为当前worker this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; // 省略代码...&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; // 调用unlock()是为了让外部可以中断 w.unlock(); // allow interrupts // 这个变量用于判断是否进入过自旋（while循环） boolean completedAbruptly = true; try &#123; // 这儿是自旋 // 1. 如果firstTask不为null，则执行firstTask； // 2. 如果firstTask为null，则调用getTask()从队列获取任务。 // 3. 阻塞队列的特性就是：当队列为空时，当前线程会被阻塞等待 while (task != null || (task = getTask()) != null) &#123; // 这儿对worker进行加锁，是为了达到下面的目的 // 1. 降低锁范围，提升性能 // 2. 保证每个worker执行的任务是串行的 w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt // 如果线程池正在停止，则对当前线程进行中断操作 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); // 执行任务，且在执行前后通过`beforeExecute()`和`afterExecute()`来扩展其功能。 // 这两个方法在当前类里面为空实现。 try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; // 帮助gc task = null; // 已完成任务数加一 w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; // 自旋操作被退出，说明线程池正在结束 processWorkerExit(w, completedAbruptly); &#125;&#125; WorkStealingPool 线程池里的每个线程都有自己的工作队列，当其他线程没有任务执行时，则会去其他线程偷取它的工作队列里的任务进行执行。 1234567//Executors.newWorkStealingPool();public static ExecutorService newWorkStealingPool() &#123; return new ForkJoinPool (Runtime.getRuntime().availableProcessors(), ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true);&#125; 123//没有返回值的任务public abstract class RecursiveAction extends ForkJoinTask&lt;Void&gt; &#123;&#125; 123//有返回值的任务public abstract class RecursiveTask&lt;V&gt; extends ForkJoinTask&lt;V&gt; &#123;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class T12_ForkJoinPool &#123; static int[] nums = new int[1000000]; static final int MAX_NUM = 50000; static Random r = new Random(); static &#123; for(int i=0; i&lt;nums.length; i++) &#123; nums[i] = r.nextInt(100); &#125; System.out.println(\"---\" + Arrays.stream(nums).sum()); //stream api &#125; static class AddTask extends RecursiveAction &#123; int start, end; AddTask(int s, int e) &#123; start = s; end = e; &#125; @Override protected void compute() &#123; if(end-start &lt;= MAX_NUM) &#123; long sum = 0L; for(int i=start; i&lt;end; i++) sum += nums[i]; System.out.println(\"from:\" + start + \" to:\" + end + \" = \" + sum); &#125; else &#123; int middle = start + (end-start)/2; AddTask subTask1 = new AddTask(start, middle); AddTask subTask2 = new AddTask(middle, end); subTask1.fork(); subTask2.fork(); &#125; &#125; &#125; static class AddTaskRet extends RecursiveTask&lt;Long&gt; &#123; private static final long serialVersionUID = 1L; int start, end; AddTaskRet(int s, int e) &#123; start = s; end = e; &#125; @Override protected Long compute() &#123; if(end-start &lt;= MAX_NUM) &#123; long sum = 0L; for(int i=start; i&lt;end; i++) sum += nums[i]; return sum; &#125; int middle = start + (end-start)/2; AddTaskRet subTask1 = new AddTaskRet(start, middle); AddTaskRet subTask2 = new AddTaskRet(middle, end); subTask1.fork(); subTask2.fork(); return subTask1.join() + subTask2.join(); &#125; &#125; public static void main(String[] args) throws IOException &#123; /*ForkJoinPool fjp = new ForkJoinPool(); AddTask task = new AddTask(0, nums.length); fjp.execute(task);*/ T12_ForkJoinPool temp = new T12_ForkJoinPool(); ForkJoinPool fjp = new ForkJoinPool(); AddTaskRet task = new AddTaskRet(0, nums.length); fjp.execute(task); long result = task.join(); System.out.println(result); //System.in.read(); &#125;&#125; Disruptor底层使用环状数组，采用复用覆盖消息的方式，并且默认为数组中的数据创建对象，通过覆盖对象中的属性值达到减少GC频率的目的。 1234567891011public class LongEvent &#123; private long value; public long getValue() &#123; return value; &#125; public void setValue(long value) &#123; this.value = value; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738public class Main &#123; public static void handleEvent(LongEvent event, long sequence, boolean endOfBatch) &#123; System.out.println(event); &#125; public static void translate(LongEvent event, long sequence, ByteBuffer buffer) &#123; event.setValue(buffer.getLong(0)); &#125; public static void main(String[] args) throws Exception &#123; // Specify the size of the ring buffer, must be power of 2. int bufferSize = 1024; // Construct the Disruptor Disruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(LongEvent::new, bufferSize, DaemonThreadFactory.INSTANCE); // Connect the handler disruptor.handleEventsWith(Main::handleEvent); // Start the Disruptor, starts all threads running disruptor.start(); // Get the ring buffer from the Disruptor to be used for publishing. RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer(); ByteBuffer bb = ByteBuffer.allocate(8); for (long l = 0; true; l++) &#123; bb.putLong(0, l); ringBuffer.publishEvent(Main::translate, bb); Thread.sleep(1000); &#125; &#125;&#125;","categories":[{"name":"Thread","slug":"Thread","permalink":"https://midkuro.gitee.io/categories/Thread/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.gitee.io/tags/Thread/"}]},{"title":"'JVM 虚拟机'","slug":"jvm-base","date":"2020-10-29T14:31:00.000Z","updated":"2020-12-21T13:15:25.952Z","comments":true,"path":"2020/10/29/jvm-base/","link":"","permalink":"https://midkuro.gitee.io/2020/10/29/jvm-base/","excerpt":"","text":"JVM Class格式Java虚拟机规范规定，Class文件格式采用类似C语言结构体的伪结构来存储数据，这种结构只有两种数据类型：无符号数和表。 无符号数属于基本数据类型，主要可以用来描述数字、索引符号、数量值或者按照UTF-8编码构成的字符串值，大小使用u1、u2、u4、u8分别表示1字节、2字节、4字节和8字节。 表是由多个无符号数或者其他表作为数据项构成的复合数据类型，所有的表都习惯以“_info”结尾。表主要用于描述有层次关系的复合结构的数据，比如方法、字段。需要注意的是class文件是没有分隔符的，所以每个的二进制数据类型都是严格定义的。具体的顺序定义如下： 从二进制的数据来看： 通过javap编译成可视化语言来看： 12345678910111213141516171819cafe babe 0000 0034 000f 0a00 0300 0c07000d 0700 0e01 0006 3c69 6e69 743e 01000328 2956 0100 0443 6f64 6501 000f 4c696e65 4e75 6d62 6572 5461 626c 6501 00046d61 696e 0100 1628 5b4c 6a61 7661 2f6c616e 672f 5374 7269 6e67 3b29 5601 000a536f 7572 6365 4669 6c65 0100 134a 766d436c 6173 7346 6f72 6d61 742e 6a61 76610c00 0400 0501 0013 6b75 726f 2f4a 766d436c 6173 7346 6f72 6d61 7401 0010 6a617661 2f6c 616e 672f 4f62 6a65 6374 00210002 0003 0000 0000 0002 0001 0004 00050001 0006 0000 001d 0001 0001 0000 00052ab7 0001 b100 0000 0100 0700 0000 06000100 0000 0300 0900 0800 0900 0100 06000000 1900 0000 0100 0000 01b1 0000 00010007 0000 0006 0001 0000 0006 0001 000a0000 0002 000b 1234567魔法数字： cafe babe次版本号： 0000主版本号： 0034 JDK1.8常量数量： 000f 从1开始#1常量 ： 0a 表示表中第十项（CONSTANT_Methodref_info） : 00 03 指向#3常量 ： 00 0c 指向#13常量 详情可查阅查阅： 类初始化的过程 加载 1.通过一个类的全限定名来获取定义此类的二进制字节流。 2.将这个字节流所代表的的静态存储结构转化成访问区的运行时数据结构。 3.在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 验证文件格式验证、元数据验证、字节码验证、符号引用验证等等。 如验证是否以0xCAFEBABE开头 准备为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。 这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配到Java堆中。 正常情况下，这里初始化的值是静态变量的数据类型的默认值，而不是属性指定的值，如果它还被final修饰了，那么将会在这个阶段直接初始化成属性指定的值。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 初始化执行类构造器&lt;clinit&gt;()方法，&lt;clinit&gt;()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的，静态语句块中只能访问到定义在静态语句之前的变量。 也就是说，静态属性和静态代码块的赋值和调用在初始化过程中执行，先执行父类的，再执行子类的。 1234567891011121314151617181920public class T001_ClassLoadingProcedure &#123; public static void main(String[] args) &#123; //ClassLoader加载T对象： //1.加载 //2.验证 //3.准备--初始化静态变量默认值count = 0; T t = null //4.解析--按照顺序赋值静态变量 count = 2; T t = new T();---&gt;调用构造方法--&gt;count++; System.out.println(T.count); //输出3 &#125;&#125;class T &#123; public static int count = 2; //0 public static T t = new T(); // null private T() &#123; count ++; &#125;&#125; 123456789101112131415161718192021public class T001_ClassLoadingProcedure &#123; public static void main(String[] args) &#123; //ClassLoader加载T对象： //1.加载 //2.验证 //3.准备--初始化静态变量默认值count = 0; T t = null //4.解析--按照顺序赋值静态变量 T t = new T();---&gt;调用构造方法--&gt;count++; count = 1; // --按照顺序赋值静态变量 count = 2;（覆盖掉之前的值） System.out.println(T.count); //输出2 &#125;&#125;class T &#123; public static T t = new T(); // null public static int count = 2; //0 private T() &#123; count ++; &#125;&#125; 如果是Object o = new Object()，有以下几步： 1、申请内存空间，这时候成员变量均是默认值 2、调用构造方法，初始化成员变量值 3、建立栈上和堆内存对象的关联关系 123456//当我们调用构造方法时，java的底层的字节码指令如下：0: new #2 // class java/lang/Object 申请内存空间3: dup // 复制内存空间地址，供以调用构造方法时出栈使用4: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 调用构造方法7: astore_1 // Object o 指向开辟的内存地址8: return 类加载器 如果一个类加载器收到了类加载的请求，它不会先尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己加载。 这里的父-子是通过使用组合关系，而不是使用继承关系。 父类加载器不是类加载器的加载器，也不是类加载器的父类加载器。双亲委派是一个孩子向父亲方向，然后父亲向孩子方向的双亲委派过程。 为什么用双亲委派机制？ 安全，保证了Java程序的稳定运行。避免核心类库被用户覆盖。 查看各个类加载器加载的路径及信息可以查阅Launcher.java 123BootStrap ClassLoader:sun.boot.class.pathExtClassLoader:java.ext.dirsAppClassLoader：java.class.path JDK破坏双亲委派机制的历史 双亲委派模型的第一次被破坏发生在双亲委派模型出现之前，由于双亲委派模型在JDK1.2之后才被引入，为了向前兼容，JDK1.2之后添加了一个findClass()方法。 双亲委派模型的第二次被破坏是由于模型自身的缺陷导致的，有些标准服务是由启动类加载器（Bootstrap）去加载的，但它又需要调用独立厂商实现并部署在应用程序的ClassPath下的代码，为了解决这个问题，引入了线程上下文类加载器，如果有了线程上下文类加载器，父类加载器将会请求子类加载器去完成类加载动作。 双亲委派模型的第三次被破坏是由于用户对程序动态性的追求导致的。如热替换、热部署。 假设每个程序都有一个自己的类加载器，当需要更换一个代码片段时，就把这个代码片段连同类加载器一起换掉实现代码的热替换。 自定义类加载器的实现是通过继承ClassLoader并复写它的findClass方法即可。若要破坏双亲委派模型，则还需要重写loadClass方法。 123456789101112@Overrideprotected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try &#123; //File To byte[] byte[] bytes = FileUtils.readFileToByteArray(new File(\"xxx\")); //调用父类的defineClass装载 return defineClass(name, bytes, 0, bytes.length); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return super.findClass(name); //throws ClassNotFoundException&#125; 编译器和解释器Java默认采用混合模式，初期通过编译器编译Class文件的代码，当出现热点代码时，会通过JIT解释器把热点代码解释成本地代码，提高运行效率。 123456# 热点代码的阈值频次-XX:CompileThreshold = 10000# 使用编译器运行-Xcomp#使用解释器运行-Xint 内存模型 Synchronized加锁原语、CPU缓存、MESI、缓存行、缓存对齐 详细内容 对象定位句柄池、直接指针 原语指令1234567891011public class Hello_03 &#123; public static void main(String[] args) &#123; Hello_03 h = new Hello_03(); int i = h.m1(); &#125; public int m1() &#123; int i = 1; i = i++; return i; &#125;&#125; 上文代码将解析成以下原语指令： 1234567891011121314151617#main方法#开辟堆上的内存空间，并压入栈中 0 new #2 &lt;com/jvm/c4_RuntimeDataAreaAndInstructionSet/Hello_03&gt; #复制栈中的内存空间对象地址，并压入栈中 3 dup #弹出栈中复制的对象，调用构造方法&lt;init&gt;初始化属性 4 invokespecial #3 &lt;com/jvm/c4_RuntimeDataAreaAndInstructionSet/Hello_03.&lt;init&gt;&gt; #弹出内存空间对象地址，赋值地址给局部变量表中index=1的对象 7 astore_1 #把局部变量表index=1的对象压入操作数栈中 8 aload_1 #使用invokevirtual执行m1方法，将返回值压入栈中 9 invokevirtual #4 &lt;com/jvm/c4_RuntimeDataAreaAndInstructionSet/Hello_03.m1&gt;#把方法返回的结果集弹出操作数栈，赋值局部变量表中index=2的对象12 istore_2#结束方法13 return 1234567891011121314#m1方法#压入常量值 1入操作数栈 const前面的i表示整数int0 iconst_1#常量值1出栈，赋值局部变量表中index=1的对象1 istore_1#把局部变量表中index=1的对象压入栈中2 iload_1#局部变量表中的index=1的对象自增13 iinc 1 by 1#弹出栈，赋值给局部变量表中index=1对象6 istore_1#把i压入操作数栈中（压入调用该方法的操作数栈中）7 iload_18 ireturn 12345678910#局部变量表#main方法---静态方法没有thisindex name0 args1 h2 i#m1方法---index=0是this对象index name0 this1 i 1234567891011invokeinterface:用以调用接口方法，在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。invokevirtual:指令用于调用对象的实例方法，根据对象的实际类型进行分派,用于多态，public方法invokestatic：调用一个类的静态方法invokespecial:指令用于调用一些需要特殊处理的实例方法，包括实例初始化方法（构造方法）、私有方法和父类方法。invokedynamic：JDK1.7新加入的一个虚拟机指令，它允许应用级别的代码来确定执行哪一个方法调用。只有在调用要执行的时候，才会进行这种判断,从而达到动态语言的支持。如lumbda的函数式接口（A::a） 垃圾回收 详细内容 参数123456789101112131415#小型程序。默认情况下不会是这种选项，HotSpot会根据计算及配置和JDK版本自动选择收集器-XX:+UseSerialGC = Serial New (DefNew) + Serial Old#这个组合已经很少用（在某些版本中已经废弃）-XX:+UseParNewGC = ParNew + SerialOld-XX:+UseConc(urrent)MarkSweepGC = ParNew + CMS + Serial Old#JDK1.8默认-XX:+UseParallelGC = Parallel Scavenge + Parallel Old (1.8默认) 【PS + SerialOld】-XX:+UseParallelOldGC = Parallel Scavenge + Parallel Old#JDK1.9默认-XX:+UseG1GC = G1 12查看默认参数配置+XX:+PrintCommandLineFlags -version 标准： - 开头，所有的HotSpot都支持 非标准：-X 开头，特定版本HotSpot支持特定命令 不稳定：-XX 开头，下个版本可能取消 12345678910public class HelloGC &#123; public static void main(String[] args) &#123; System.out.println(\"HelloGC!\"); List list = new LinkedList(); for(;;) &#123; byte[] b = new byte[1024*1024]; list.add(b); &#125; &#125;&#125; 1234567891011#区分概念：内存泄漏memory leak，内存溢出out of memoryjava -XX:+PrintCommandLineFlags HelloGC#-Xmn10M 新生代大小 -Xms40M 堆最小内存 -Xmx60M 堆最大内存 -XX:+PrintGC输出GC信息java -Xmn10M -Xms40M -Xmx60M -XX:+PrintCommandLineFlags -XX:+PrintGC HelloGC #打印GC详细信息 打印GC时间 打印GC的原因PrintGCDetails PrintGCTimeStamps PrintGCCausesjava -XX:+UseConcMarkSweepGC -XX:+PrintCommandLineFlags HelloGCjava -XX:+PrintFlagsInitial 默认参数值java -XX:+PrintFlagsFinal 最终参数值java -XX:+PrintFlagsFinal | grep xxx 找到对应的参数java -XX:+PrintFlagsFinal -version |grep GC GC日志详解 调优 吞吐量：用户代码时间 /（用户代码执行时间 + 垃圾回收时间） 响应时间：STW越短，响应时间越好 所谓调优，首先确定，追求吞吐量优先，还是响应时间优先？还是在满足一定的响应时间的情况下，要求达到多大的吞吐量…，吞吐量优先 一般（PS + PO），响应时间 一般（1.8 G1） 什么是调优？ 根据需求进行JVM规划和预调优 优化运行JVM运行环境（慢，卡顿） 解决JVM运行过程中出现的各种问题(OOM) 规划调优 调优，从业务场景开始，没有业务场景的调优都是耍流氓 无监控（压力测试，能看到结果），不调优 步骤： 熟悉业务场景（没有最好的垃圾回收器，只有最合适的垃圾回收器） 响应时间、停顿时间 [CMS G1 ZGC] （需要给用户作响应） 吞吐量 = 用户时间 /( 用户时间 + GC时间) [PS] 预调优 选择回收器组合 计算内存需求（经验值 1.5G 16G） 选定CPU（越高越好） 设定年代大小、升级年龄 设定日志参数（循环5个日志文件，100M） -Xloggc:/opt/xxx/logs/xxx-xxx-gc-%t.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCCause 或者每天产生一个日志文件 观察日志情况 预调优 QPS:一秒内查询的并发量 TPS：一秒内业务的并发量 案例1：垂直电商，最高每日百万订单，处理订单系统需要什么样的服务器配置？ 这个问题比较业余，因为很多不同的服务器配置都能支撑(1.5G 16G) 1小时360000集中时间段， 100个订单/秒，（找一小时内的高峰期，1000订单/秒） 经验值， 非要计算：一个订单产生需要多少内存？512K * 1000 500M内存 专业一点儿问法：要求响应时间100ms 压测！ 案例2：12306遭遇春节大规模抢票应该如何支撑？ 12306应该是中国并发量最大的秒杀网站： 号称并发量100W最高 CDN -&gt; LVS -&gt; NGINX -&gt; 业务系统 -&gt; 每台机器1W并发（10K问题） 100台机器 普通电商订单 -&gt; 下单 -&gt;订单系统（IO）减库存 -&gt;等待用户付款 12306的一种可能的模型： 下单 -&gt; 减库存 和 订单(redis kafka) 同时异步进行 -&gt;等付款 减库存最后还会把压力压到一台服务器 可以做分布式本地库存 + 单独服务器做库存均衡 大流量的处理方法：分而治之 怎么得到一个事务会消耗多少内存？ 弄台机器，看能承受多少TPS？是不是达到目标？扩容或调优，让它达到 用压测来确定 优化环境 有一个50万PV的资料类网站（从磁盘提取文档到内存）原服务器32位，1.5G 的堆，用户反馈网站比较缓慢，因此公司决定升级，新的服务器为64位，16G 的堆内存，结果用户反馈卡顿十分严重，反而比以前效率更低了 123456781.为什么原网站慢? 很多用户浏览数据，很多数据load到内存，内存不足，频繁GC，STW长，响应时间变慢2.为什么会更卡顿？ 内存越大，FGC时间越长3.咋办？ PS -&gt; PN + CMS 或者 G1 系统CPU经常100%，如何调优？ 123456**CPU100%那么一定有线程在占用系统资源**1. 找出哪个进程cpu高（top）2. 该进程中的哪个线程cpu高（top -Hp）3. 导出该线程的堆栈 (jstack)4. 查找哪个方法（栈帧）消耗时间 (jstack)5. 工作线程占比高 | 垃圾回收线程占比高 系统内存飙高，如何查找问题？ 121. 导出堆内存 (jmap)2. 分析 (jhat jvisualvm mat jprofiler ... ) 如何监控JVM？ jstat jvisualvm jprofiler arthas top… jstack12345678910111213141516jstack Usage: jstack [-l] &lt;pid&gt; (to connect to running process) jstack -F [-m] [-l] &lt;pid&gt; (to connect to a hung process) jstack [-m] [-l] &lt;executable&gt; &lt;core&gt; (to connect to a core file) jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt; (to connect to a remote debug server)Options: -F to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung) -m to print both java and native frames (mixed mode) -l long listing. Prints additional information about locks -h or -help to print this help message 123456789101112131415161718[root@localhost ~]# jstack -l &lt;pid&gt;//JVM内部的Reference Handler的守护线程 线程号 nid=0x12f27 十六进制\"Reference Handler\" #2 daemon prio=10 os_prio=0 tid=0x00007f00e41d1000 nid=0x12f27 in Object.wait() [0x00007f00ad648000] //线程状态WAITING，等待其他线程nonitor唤醒 java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x00000006c80eada8&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153) //持有的锁 Locked ownable synchronizers: - None\"VM Thread\" os_prio=0 tid=0x00007f00e41c7000 nid=0x12f26 runnable //GC线程正在运行\"GC task thread#0 (ParallelGC)\" os_prio=0 tid=0x00007f00e401e800 nid=0x12f1e runnable 两个线程都互相等待锁信息，死锁。 1234567891011\"Thread-1\": at com.kuro.concurrent.LockedOwnThread.run(LockedOwnThread.java:47) - waiting to lock &lt;0x000000076c5806f8&gt; (a java.lang.Class for java.lang.Object) - locked &lt;0x000000076c636568&gt; (a java.lang.Class for com.mirana.concurrent.LockedOwnThread) - locked &lt;0x000000076c6392f0&gt; (a com.kuro.concurrent.LockedOwnThread)\"Thread-0\": at com.kuro.concurrent.LockedOwnThread$AThread.run(LockedOwnThread.java:27) - waiting to lock &lt;0x000000076c636568&gt; (a java.lang.Class for com.mirana.concurrent.LockedOwnThread) - locked &lt;0x000000076c5806f8&gt; (a java.lang.Class for java.lang.Object)Found 1 deadlock. 案例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/*** 从数据库中读取信用数据，套用模型，并把结果进行记录和传输*/public class T15_FullGC_Problem01 &#123; private static class CardInfo &#123; BigDecimal price = new BigDecimal(0.0); String name = \"张三\"; int age = 5; Date birthdate = new Date(); public void m() &#123;&#125; &#125; private static ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(50,new ThreadPoolExecutor.DiscardOldestPolicy()); public static void main(String[] args) throws Exception &#123; executor.setMaximumPoolSize(50); for (;;)&#123; modelFit(); Thread.sleep(100); &#125; &#125; private static void modelFit()&#123; List&lt;CardInfo&gt; taskList = getAllCardInfo(); taskList.forEach(info -&gt; &#123; // do something executor.scheduleWithFixedDelay(() -&gt; &#123; //do sth with info info.m(); &#125;, 2, 3, TimeUnit.SECONDS); &#125;); &#125; private static List&lt;CardInfo&gt; getAllCardInfo()&#123; List&lt;CardInfo&gt; taskList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 100; i++) &#123; CardInfo ci = new CardInfo(); taskList.add(ci); &#125; return taskList; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738391.java -Xms200M -Xmx200M -XX:+PrintGC T15_FullGC_Problem012.一般是运维团队首先受到报警信息（CPU Memory）3.top命令观察到问题：内存不断增长 CPU占用率居高不下4.top -Hp 观察进程中的线程，哪个线程CPU和内存占比高5.jps定位具体java进程jstack 定位线程状况重点关注：WAITING BLOCKEDwaiting on &lt;0x0000000088ca3310&gt; (a java.lang.Object)假如有一个进程中100个线程，很多线程都在waiting on ，一定要找到是哪个线程持有这把锁怎么找？搜索jstack dump的信息，找 ，看哪个线程持有这把锁RUNNABLE为什么阿里规范里规定，线程的名称（尤其是线程池）都要写有意义的名称怎么样自定义线程池里的线程名称？（自定义ThreadFactory）6.jinfo pid7.jstat -gc 动态观察gc情况 / 阅读GC日志发现频繁GC / arthas观察 / jconsole/jvisualVM/ Jprofiler（最好用）jstat -gc 4655 500 : 每个500个毫秒打印GC的情况8.jmap - histo 4655 | head -20，查找有多少对象产生9jmap -dump:format=b,file=xxx pid ：线上系统，内存特别大，jmap执行期间会对进程产生很大影响，甚至卡顿（电商不适合）1：设定了参数HeapDump，OOM的时候会自动产生堆转储文件2：很多服务器备份（高可用），停掉这台服务器对其他服务器不影响3：在线定位(一般小点儿公司用不到)10.java -Xms20M -Xmx20M -XX:+UseParallelGC -XX:+HeapDumpOnOutOfMemoryError T15_FullGC_Problem0111.使用MAT / jhat /jvisualvm 进行dump文件分析jhat -J-mx512M xxx.dump http://localhost:7000拉到最后：找到对应链接 可以使用OQL查找特定问题对象12.找到代码的问题原因是因为创建线程的频率比消费线程的频率高，线程池队列上锁引起等待的线程堆积过多，才造成的对象过多内存泄漏 远程连接 jconsole远程服务器程序，程序启动需要增加以下参数： 1java -Djava.rmi.server.hostname&#x3D;192.168.17.11 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port&#x3D;11111 -Dcom.sun.management.jmxremote.authenticate&#x3D;false -Dcom.sun.management.jmxremote.ssl&#x3D;false XXX 案例汇总OOM产生的原因多种多样，有些程序未必产生OOM，不断FGC(CPU飙高，但内存回收特别少) （上面案例） 硬件升级系统反而卡顿的问题（见上） 线程池不当运用产生OOM问题（见上） tomcat http-header-size过大问题 lambda表达式导致方法区溢出问题(MethodArea / Perm Metaspace) 12345678java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at sun.instrument.InstrumentationImpl.loadClassAndStartAgent(InstrumentationImpl.java:388) at sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(InstrumentationImpl.java:411) Caused by: java.lang.OutOfMemoryError: Compressed class space 栈溢出问题 -Xss设定太小 比较一下这两段程序的异同，分析哪一个是更优的写法： 12345678Object o = null;for(int i=0; i&lt;100; i++) &#123; o = new Object(); //业务处理&#125;for(int i=0; i&lt;100; i++) &#123; Object o = new Object();&#125; 重写finalize引发频繁GC 小米云，HBase同步系统，系统通过nginx访问超时报警，最后排查，C++程序员重写finalize引发频繁GC问题 为什么C++程序员会重写finalize？（new delete） finalize耗时比较长（200ms） 如果有一个系统，内存一直消耗不超过10%，但是观察GC日志，发现FGC总是频繁产生，会是什么引起的？ System.gc() 参数汇总GC常用参数 -Xmn -Xms -Xmx -Xss 年轻代 最小堆 最大堆 栈空间 -XX:+UseTLAB 使用TLAB，默认打开 -XX:+PrintTLAB 打印TLAB的使用情况 -XX:TLABSize 设置TLAB大小 -XX:+DisableExplictGC System.gc()不管用 ，FGC -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationConcurrentTime (低) 打印应用程序时间 -XX:+PrintGCApplicationStoppedTime （低） 打印暂停时长 -XX:+PrintReferenceGC （重要性低） 记录回收了多少种不同引用类型的引用 -verbose:class 类加载详细过程 -XX:+PrintVMOptions -XX:+PrintFlagsFinal -XX:+PrintFlagsInitial 必须会用 -Xloggc:opt/log/gc.log -XX:MaxTenuringThreshold 升代年龄，最大值15 锁自旋次数 -XX:PreBlockSpin 热点代码检测参数-XX:CompileThreshold 逃逸分析 标量替换 … 这些不建议设置 Parallel常用参数 -XX:SurvivorRatio -XX:PreTenureSizeThreshold 大对象到底多大 -XX:MaxTenuringThreshold -XX:+ParallelGCThreads 并行收集器的线程数，同样适用于CMS，一般设为和CPU核数相同 -XX:+UseAdaptiveSizePolicy 自动选择各区大小比例 CMS常用参数 -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreads CMS线程数量 -XX:CMSInitiatingOccupancyFraction 使用多少比例的老年代后开始CMS收集，默认是68%(近似值)，如果频繁发生SerialOld卡顿，应该调小，（频繁CMS回收） -XX:+UseCMSCompactAtFullCollection 在FGC时进行压缩 -XX:CMSFullGCsBeforeCompaction 多少次FGC之后进行压缩 -XX:+CMSClassUnloadingEnabled -XX:CMSInitiatingPermOccupancyFraction 达到什么比例时进行Perm回收 GCTimeRatio 设置GC时间占用程序运行时间的百分比 -XX:MaxGCPauseMillis 停顿时间，是一个建议时间，GC会尝试用各种手段达到这个时间，比如减小年轻代 G1常用参数 -XX:+UseG1GC -XX:MaxGCPauseMillis 建议值，G1会尝试调整Young区的块数来达到这个值 -XX:GCPauseIntervalMillis ？GC的间隔时间 -XX:+G1HeapRegionSize 分区大小，建议逐渐增大该值，1 2 4 8 16 32。 随着size增加，垃圾的存活时间更长，GC间隔更长，但每次GC的时间也会更长 ZGC做了改进（动态区块大小） G1NewSizePercent 新生代最小比例，默认为5% G1MaxNewSizePercent 新生代最大比例，默认为60% GCTimeRatio GC时间建议比例，G1会根据这个值调整堆空间 ConcGCThreads 线程数量 InitiatingHeapOccupancyPercent 启动G1的堆空间占用比例","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/tags/JVM/"}]},{"title":"'内存与IO，磁盘IO，网络IO'","slug":"io-base","date":"2020-10-29T14:31:00.000Z","updated":"2020-11-25T16:07:36.551Z","comments":true,"path":"2020/10/29/io-base/","link":"","permalink":"https://midkuro.gitee.io/2020/10/29/io-base/","excerpt":"","text":"内存与IO，磁盘IO，网络IO文件描述符12常用软件：yum install -y strace lsof pmap tcpdump 1234567VFS: 虚拟文件系统 案例[root@node01 ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/sda3 202092480 10776508 181050220 6% /tmpfs 1954400 0 1954400 0% /dev/shm/dev/sda1 198337 27795 160302 15% /boot 12345df Filesystem 1K-blocks Used Available Use% Mounted on&#x2F;dev&#x2F;sda3 202092480 7187520 184639208 4% &#x2F;tmpfs 1954400 0 1954400 0% &#x2F;dev&#x2F;shm&#x2F;dev&#x2F;sda1 198337 27795 160302 15% &#x2F;boot 1234测试pipeline类型：&#123; echo $BASHPID ; read x; &#125; | &#123; cat ; echo $BASHPID ; read y; &#125; 测试socket类型：exec 8&lt;&gt; &#x2F;dev&#x2F;tcp&#x2F;www.baidu.com&#x2F;80 12345678910111213141516171819202122232425262728lsof -op $$【以下是整合的结果】COMMAND PID USER FD TYPE DEVICE OFFSET NODE NAMEbash 4398 root cwd DIR 8,3 10227872 &#x2F;root&#x2F;mashibingbash 4398 root rtd DIR 8,3 2 &#x2F;bash 4398 root txt REG 8,3 7077890 &#x2F;bin&#x2F;bashbash 4398 root mem REG 8,3 1572903 &#x2F;lib64&#x2F;libresolv-2.12.sobash 4398 root mem REG 8,3 1572891 &#x2F;lib64&#x2F;libnss_dns-2.12.sobash 4398 root mem REG 8,3 1709499 &#x2F;usr&#x2F;lib&#x2F;locale&#x2F;locale-archivebash 4398 root mem REG 8,3 1572893 &#x2F;lib64&#x2F;libnss_files-2.12.sobash 4398 root mem REG 8,3 1572877 &#x2F;lib64&#x2F;libc-2.12.sobash 4398 root mem REG 8,3 1572883 &#x2F;lib64&#x2F;libdl-2.12.sobash 4398 root mem REG 8,3 1572920 &#x2F;lib64&#x2F;libtinfo.so.5.7bash 4398 root mem REG 8,3 1572867 &#x2F;lib64&#x2F;ld-2.12.sobash 4398 root mem REG 8,3 1968395 &#x2F;usr&#x2F;lib64&#x2F;gconv&#x2F;gconv-modules.cachebash 4398 root &quot;0u CHR 136,2 0t0 5 &#x2F;dev&#x2F;pts&#x2F;2&quot;bash 4398 root 1u CHR 136,2 0t0 5 &#x2F;dev&#x2F;pts&#x2F;2bash 4513 root &quot;0r FIFO 0,8 0t0 39968 pipe&quot;bash 4398 root 2u CHR 136,2 0t0 5 &#x2F;dev&#x2F;pts&#x2F;2bash 4398 root &quot;6r REG 8,3 0t0 10227564 &#x2F;root&#x2F;ooxx.txt&quot;bash 4398 root &quot;8u IPv4 39172 0t0 TCP node01:54723-&gt;104.193.88.123:http (CLOSE_WAIT)&quot;&quot;bash 4398 root 255u CHR 136,2 0t0 5 &#x2F;dev&#x2F;pts&#x2F;2read a &lt;&amp; 6通过读取6号文件描述符，查看0t4的offset变化一切皆文件：这里主要展示 socket&#x2F;pipeline另外，fd，文件描述符代表打开的文件，有inode号和seek偏移指针的概念 12345678910111213141516171819202122管道：1，衔接，前一个命令的输出作为后一个命令的输入2，管道会触发创建【子进程】echo $$ | more --&gt;当前bash的进程号echo $BASHPID | more --&gt;当前bash的子进程的进程号原因：$$ 高于 | 使用linux的时候：父子进程父进程的数据，子进程可不可以看得到？ 不能常规思想，进程是数据隔离的！进阶思想，父进程其实可以让子进程看到数据！ &#96;export&#96;linux中export的环境变量，子进程的修改不会破坏父进程父进程的修改也不会破坏子进程Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。 12345678vi /etc/sysctl.conf#脏页的策略vm.dirty_background_ratio = 0vm.dirty_background_bytes = 1048576vm.dirty_ratio = 0vm.dirty_bytes = 1048576vm.dirty_writeback_centisecs = 5000vm.dirty_expire_centisecs = 30000 虚拟内存和内存映射 磁盘IO12345678//最基本的file写，每次都要调用内核态写数据public static void testBasicFileIO() throws Exception &#123; File file = new File(path); FileOutputStream out = new FileOutputStream(file); while(true)&#123; out.write(data); &#125;&#125; 12345678910//测试buffer文件IO，达到一个缓冲区大小时调用内核态// jvm 8kB syscall write(8KBbyte[])public static void testBufferedFileIO() throws Exception &#123; File file = new File(path); BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(file)); while(true)&#123; out.write(data); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//mmap通过映射进程和内核态的共享区域public static void testRandomAccessFileWrite() throws Exception &#123; RandomAccessFile raf = new RandomAccessFile(path, \"rw\"); raf.write(\"hello mashibing\\n\".getBytes()); raf.write(\"hello seanzhou\\n\".getBytes()); System.out.println(\"write------------\"); System.in.read(); raf.seek(4); raf.write(\"ooxx\".getBytes()); System.out.println(\"seek---------\"); System.in.read(); FileChannel rafchannel = raf.getChannel(); //mmap 堆外 和文件映射的 byte not objtect MappedByteBuffer map = rafchannel.map(FileChannel.MapMode.READ_WRITE, 0, 4096); map.put(\"@@@\".getBytes()); //不是系统调用 但是数据会到达 内核的pagecache //曾经我们是需要out.write() 这样的系统调用，才能让程序的data 进入内核的pagecache //曾经必须有用户态内核态切换 //mmap的内存映射，依然是内核的pagecache体系所约束的！！！ //换言之，丢数据 //你可以去github上找一些 其他C程序员写的jni扩展库，使用linux内核的Direct IO //直接IO是忽略linux的pagecache //是把pagecache 交给了程序自己开辟一个字节数组当作pagecache，动用代码逻辑来维护一致性/dirty。。。一系列复杂问题 System.out.println(\"map--put--------\"); System.in.read(); //map.force(); // flush raf.seek(0); ByteBuffer buffer = ByteBuffer.allocate(8192); //ByteBuffer buffer = ByteBuffer.allocateDirect(1024); int read = rafchannel.read(buffer); //buffer.put() System.out.println(buffer); buffer.flip(); System.out.println(buffer); for (int i = 0; i &lt; buffer.limit(); i++) &#123; Thread.sleep(200); System.out.print(((char)buffer.get(i))); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738//直接缓冲区public void whatByteBuffer()&#123; // ByteBuffer buffer = ByteBuffer.allocate(1024); ByteBuffer buffer = ByteBuffer.allocateDirect(1024); System.out.println(\"postition: \" + buffer.position()); System.out.println(\"limit: \" + buffer.limit()); System.out.println(\"capacity: \" + buffer.capacity()); System.out.println(\"mark: \" + buffer); buffer.put(\"123\".getBytes()); System.out.println(\"-------------put:123......\"); System.out.println(\"mark: \" + buffer); buffer.flip(); //读写交替 System.out.println(\"-------------flip......\"); System.out.println(\"mark: \" + buffer); buffer.get(); System.out.println(\"-------------get......\"); System.out.println(\"mark: \" + buffer); buffer.compact(); System.out.println(\"-------------compact......\"); System.out.println(\"mark: \" + buffer); buffer.clear(); System.out.println(\"-------------clear......\"); System.out.println(\"mark: \" + buffer);&#125; 网络IO123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class SocketIOPropertites &#123; //server socket listen property: //缓冲区大小 private static final int RECEIVE_BUFFER = 10; //监听阻塞的超时时限 private static final int SO_TIMEOUT = 0; private static final boolean REUSE_ADDR = false; //内核中等待队列的大小（无关联进程的四元组数量）（等同于丢包） private static final int BACK_LOG = 2; //client socket listen property on server endpoint: private static final boolean CLI_KEEPALIVE = false; private static final boolean CLI_OOB = false; private static final int CLI_REC_BUF = 20; private static final boolean CLI_REUSE_ADDR = false; private static final int CLI_SEND_BUF = 20; private static final boolean CLI_LINGER = true; private static final int CLI_LINGER_N = 0; private static final int CLI_TIMEOUT = 0; private static final boolean CLI_NO_DELAY = false; /* StandardSocketOptions.TCP_NODELAY StandardSocketOptions.SO_KEEPALIVE StandardSocketOptions.SO_LINGER StandardSocketOptions.SO_RCVBUF StandardSocketOptions.SO_SNDBUF StandardSocketOptions.SO_REUSEADDR */ public static void main(String[] args) &#123; ServerSocket server = null; try &#123; server = new ServerSocket(); server.bind(new InetSocketAddress(9090), BACK_LOG); server.setReceiveBufferSize(RECEIVE_BUFFER); server.setReuseAddress(REUSE_ADDR); server.setSoTimeout(SO_TIMEOUT); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; System.out.println(\"server up use 9090!\"); try &#123; while (true) &#123; // System.in.read(); //分水岭： Socket client = server.accept(); //阻塞的，没有 -1 一直卡着不动 accept(4, System.out.println(\"client port: \" + client.getPort()); client.setKeepAlive(CLI_KEEPALIVE); client.setOOBInline(CLI_OOB); client.setReceiveBufferSize(CLI_REC_BUF); client.setReuseAddress(CLI_REUSE_ADDR); client.setSendBufferSize(CLI_SEND_BUF); client.setSoLinger(CLI_LINGER, CLI_LINGER_N); client.setSoTimeout(CLI_TIMEOUT); client.setTcpNoDelay(CLI_NO_DELAY); //client.read //阻塞 没有 -1 0 new Thread( () -&gt; &#123; try &#123; InputStream in = client.getInputStream(); BufferedReader reader = new BufferedReader(new InputStreamReader(in)); char[] data = new char[1024]; while (true) &#123; int num = reader.read(data); if (num &gt; 0) &#123; System.out.println(\"client read some data is :\" + num + \" val :\" + new String(data, 0, num)); &#125; else if (num == 0) &#123; System.out.println(\"client readed nothing!\"); continue; &#125; else &#123; System.out.println(\"client readed -1...\"); System.in.read(); client.close(); break; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; ).start(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; server.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728public class SocketClient &#123; public static void main(String[] args) &#123; try &#123; Socket client = new Socket(\"192.168.150.11\",9090); client.setSendBufferSize(20); //TCP缓存优化发包，优化不需要每次小字节都发送过去，攒一批再发 client.setTcpNoDelay(false); OutputStream out = client.getOutputStream(); InputStream in = System.in; BufferedReader reader = new BufferedReader(new InputStreamReader(in)); while(true)&#123; String line = reader.readLine(); if(line != null )&#123; byte[] bb = line.getBytes(); for (byte b : bb) &#123; out.write(b); &#125; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; TCP的拥塞： 若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏，这种情况就叫做网络拥塞。 建立TCP连接时会发送客户端能接受的数据包大小（滑动窗口），每次接收到数据包时会返回服务端可接收的数据包大小（滑动窗口大小），如果客户端发送的数据包超过了服务端的能接收的大小，客户端需要阻塞等待服务端的处理。 MTU：数据包大小 MSS：数据大小 BIO123456789101112131415161718192021222324252627282930313233343536public class SocketBIO &#123; public static void main(String[] args) throws Exception &#123; ServerSocket server = new ServerSocket(8090,20); System.out.println(\"step1: new ServerSocket(8090) \"); while (true) &#123; Socket client = server.accept(); //阻塞1 System.out.println(\"step2:client\\t\" + client.getPort()); new Thread(new Runnable()&#123; public void run() &#123; InputStream in = null; try &#123; in = client.getInputStream(); BufferedReader reader = new BufferedReader(new InputStreamReader(in)); while(true)&#123; String dataline = reader.readLine(); //阻塞2 if(null != dataline)&#123; System.out.println(dataline); &#125;else&#123; client.close(); break; &#125; &#125; System.out.println(\"客户端断开\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125;&#125; NIO123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class SocketNIO &#123; // what why how public static void main(String[] args) throws Exception &#123; LinkedList&lt;SocketChannel&gt; clients = new LinkedList&lt;&gt;(); ServerSocketChannel ss = ServerSocketChannel.open(); //服务端开启监听：接受客户端 ss.bind(new InetSocketAddress(9090)); ss.configureBlocking(false); //重点 OS NONBLOCKING!!! //只让接受客户端 不阻塞// ss.setOption(StandardSocketOptions.TCP_NODELAY, false);// StandardSocketOptions.TCP_NODELAY// StandardSocketOptions.SO_KEEPALIVE// StandardSocketOptions.SO_LINGER// StandardSocketOptions.SO_RCVBUF// StandardSocketOptions.SO_SNDBUF// StandardSocketOptions.SO_REUSEADDR while (true) &#123; //接受客户端的连接 Thread.sleep(1000); SocketChannel client = ss.accept(); //不会阻塞？ -1 NULL //accept 调用内核了：1，没有客户端连接进来，返回值？在BIO 的时候一直卡着，但是在NIO ，不卡着，返回-1，NULL //如果来客户端的连接，accept 返回的是这个客户端的fd 5，client object //NONBLOCKING 就是代码能往下走了，只不过有不同的情况 if (client == null) &#123; // System.out.println(\"null.....\"); &#125; else &#123; client.configureBlocking(false); //重点 socket（服务端的listen socket&lt;连接请求三次握手后，往我这里扔，我去通过accept 得到 连接的socket&gt;，连接socket&lt;连接后的数据读写使用的&gt; ） int port = client.socket().getPort(); System.out.println(\"client..port: \" + port); clients.add(client); &#125; ByteBuffer buffer = ByteBuffer.allocateDirect(4096); //可以在堆里 堆外 //遍历已经链接进来的客户端能不能读写数据 for (SocketChannel c : clients) &#123; //串行化！！！！ 多线程！！ int num = c.read(buffer); // &gt;0 -1 0 //不会阻塞 if (num &gt; 0) &#123; buffer.flip(); byte[] aaa = new byte[buffer.limit()]; buffer.get(aaa); String b = new String(aaa); System.out.println(c.socket().getPort() + \" : \" + b); buffer.clear(); &#125; &#125; &#125; &#125;&#125; Linux内核函数1234567891011121314151617181920212223242526272829303132333435//创建文件描述符int socket(int domain, int type, int protocol);//绑定四元组地址int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);//监听来自客户端的tcp socket的连接请求,backlog是等待队列数量int listen(int sockfd, int backlog);//和新的客户端建立连接int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);//读取客户端发送的数据ssize_t recv(int sockfd, void *buf, size_t len, int flags);//发送需要轮训的【fd列表、事件】、要监视的描述符的数目、超时配置（-1=阻塞）int poll(struct pollfd *fds, nfds_t nfds, int timeout);//设置fd的相关内容、如读写、非阻塞int fcntl(int fd, int cmd, ... /* arg */ );//开辟一个大小为size的红黑树空间，返回epfd（类似于红黑树的根节点）int epoll_create(int size);//添加fd到红黑树 op操作如add/del, fd是需要添加进红黑树的文件描述符,epoll_event监听事件int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);//通过传递红黑树的epfd，拉取链表中已经就绪的fdint epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);//EPOLL中文件描述符的状态EPOLLIN 连接到达；有数据来临；The associated file is available for read(2) operations.EPOLLOUT 有数据要写The associated file is available for write(2) operations. 多路复用器 12345678910111213#LINUX中的JVM参数来控制使用EPOLL还是POLL，默认是选择性能最好的那个-Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.EPollSelectorProvider-Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.PollSelectorProvider#追踪Linux内核调用javac SocketMultiplexingSingleThreadv1.classstrace -ff -o out java SocketMultiplexingSingleThreadv1#Linux模拟客户端创建连接nc 192.168.163.1 9090#Linux模拟服务端等待客户端连接nc -l 192.168.163.1 9090 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141public class SocketMultiplexingSingleThreadv1 &#123; private ServerSocketChannel server = null; private Selector selector = null; //linux 多路复用器（select poll epoll kqueue） nginx event&#123;&#125; int port = 9090; public void initServer() &#123; try &#123; server = ServerSocketChannel.open(); server.configureBlocking(false); server.bind(new InetSocketAddress(port)); //如果在epoll模型下，open--》 epoll_create -&gt; fd3 selector = Selector.open(); // select poll *epoll 优先选择：epoll 但是可以 -D修正 //server 约等于 listen状态的 fd4 /* register 如果： select，poll：jvm里开辟一个数组 fd4 放进去 epoll： epoll_ctl(fd3,ADD,fd4,EPOLLIN */ server.register(selector, SelectionKey.OP_ACCEPT); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void start() &#123; initServer(); System.out.println(\"服务器启动了。。。。。\"); try &#123; while (true) &#123; //死循环 Set&lt;SelectionKey&gt; keys = selector.keys(); System.out.println(keys.size()+\" size\"); //1,调用多路复用器(select,poll or epoll (epoll_wait)) /* select()是啥意思： 1，select，poll 其实 内核的select（fd4） poll(fd4) 2，epoll： 其实 内核的 epoll_wait() *, 参数可以带时间：没有时间，0 ： 阻塞，有时间设置一个超时 selector.wakeup() 结果返回0 懒加载： 其实再触碰到selector.select()调用的时候触发了epoll_ctl的调用 */ while (selector.select() &gt; 0) &#123; Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); //返回的有状态的fd集合 Iterator&lt;SelectionKey&gt; iter = selectionKeys.iterator(); //so，管你啥多路复用器，你呀只能给我状态，我还得一个一个的去处理他们的R/W。同步好辛苦！！！！！！！！ // NIO 自己对着每一个fd调用系统调用，浪费资源，那么你看，这里是不是调用了一次select方法，知道具体的那些可以R/W了？ //幕兰，是不是很省力？ //我前边可以强调过，socket： listen 通信 R/W while (iter.hasNext()) &#123; SelectionKey key = iter.next(); iter.remove(); //set 不移除会重复循环处理 if (key.isAcceptable()) &#123; //看代码的时候，这里是重点，如果要去接受一个新的连接 //语义上，accept接受连接且返回新连接的FD对吧？ //那新的FD怎么办？ //select，poll，因为他们内核没有空间，那么在jvm中保存和前边的fd4那个listen的一起 //epoll： 我们希望通过epoll_ctl把新的客户端fd注册到内核空间 acceptHandler(key); &#125; else if (key.isReadable()) &#123; readHandler(key); //连read 还有 write都处理了 //在当前线程，这个方法可能会阻塞 ，如果阻塞了十年，其他的IO早就没电了。。。 //所以，为什么提出了 IO THREADS //redis 是不是用了epoll，redis是不是有个io threads的概念 ，redis是不是单线程的 //tomcat 8,9 异步的处理方式 IO 和 处理上 解耦 &#125; &#125; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void acceptHandler(SelectionKey key) &#123; try &#123; ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel client = ssc.accept(); //来啦，目的是调用accept接受客户端 fd7 client.configureBlocking(false); ByteBuffer buffer = ByteBuffer.allocate(8192); //前边讲过了 // 0.0 我类个去 //你看，调用了register /* select，poll：jvm里开辟一个数组 fd7 放进去 epoll： epoll_ctl(fd3,ADD,fd7,EPOLLIN */ client.register(selector, SelectionKey.OP_READ, buffer); System.out.println(\"-------------------------------------------\"); System.out.println(\"新客户端：\" + client.getRemoteAddress()); System.out.println(\"-------------------------------------------\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void readHandler(SelectionKey key) &#123; SocketChannel client = (SocketChannel) key.channel(); ByteBuffer buffer = (ByteBuffer) key.attachment(); buffer.clear(); int read = 0; try &#123; while (true) &#123; read = client.read(buffer); if (read &gt; 0) &#123; buffer.flip(); while (buffer.hasRemaining()) &#123; client.write(buffer); &#125; buffer.clear(); &#125; else if (read == 0) &#123; break; &#125; else &#123; client.close(); break; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; SocketMultiplexingSingleThreadv1 service = new SocketMultiplexingSingleThreadv1(); service.start(); &#125;&#125; 底层实现 状态 四次分手： 1.服务端发起断开连接的FIN通知 2.客户端接收FIN通知并返回FIN_ACK确认 3.客户端也发送断开连接的FIN通知 4.服务端接受FIN通知并返回ACK确认 经过正常的四次分手后，客户端处于 closed 状态 由于是服务端先发起断开请求，所以服务端处于TIME_WAIT状态 如果服务端代码中没有写client.close()： 1.客户端发起了断开连接的FIN通知 2.服务端接收到FIN通知并返回FIN_ACK确认 3.服务端自身标记成 close_wait 状态 4.客户端接收到FIN_ACK，标记自身状态为FIN_WAIT2等待服务端发送FIN通知 4.由于服务端没有编写client.close()，所以不会发送四次分手的二次确认 5.客户端没有收到客户端也想断开FIN的通知，依旧是 FIN_WAIT2 状态 单Selector单线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122public class SocketMultiplexingSingleThreadv1_1 &#123; private ServerSocketChannel server = null; private Selector selector = null; int port = 9090; public void initServer() &#123; try &#123; server = ServerSocketChannel.open(); server.configureBlocking(false); server.bind(new InetSocketAddress(port)); selector = Selector.open(); // select poll *epoll server.register(selector, SelectionKey.OP_ACCEPT); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void start() &#123; initServer(); System.out.println(\"服务器启动了。。。。。\"); try &#123; while (true) &#123; while (selector.select() &gt; 0) &#123; Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iter = selectionKeys.iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); iter.remove(); if (key.isAcceptable()) &#123; acceptHandler(key); &#125; else if (key.isReadable()) &#123; readHandler(key); //只处理了 read 并注册 关心这个key的write事件 &#125; else if(key.isWritable())&#123; writeHandler(key); &#125; &#125; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void writeHandler(SelectionKey key) &#123; System.out.println(\"write handler...\"); SocketChannel client = (SocketChannel) key.channel(); ByteBuffer buffer = (ByteBuffer) key.attachment(); buffer.flip(); while (buffer.hasRemaining()) &#123; try &#123; client.write(buffer); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; buffer.clear(); key.cancel(); try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void acceptHandler(SelectionKey key) &#123; try &#123; ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel client = ssc.accept(); client.configureBlocking(false); ByteBuffer buffer = ByteBuffer.allocate(8192); client.register(selector, SelectionKey.OP_READ, buffer); System.out.println(\"-------------------------------------------\"); System.out.println(\"新客户端：\" + client.getRemoteAddress()); System.out.println(\"-------------------------------------------\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void readHandler(SelectionKey key) &#123; System.out.println(\"read handler.....\"); SocketChannel client = (SocketChannel) key.channel(); ByteBuffer buffer = (ByteBuffer) key.attachment(); buffer.clear(); int read = 0; try &#123; while (true) &#123; read = client.read(buffer); //处理读事件中注册写事件 if (read &gt; 0) &#123; client.register(key.selector(),SelectionKey.OP_WRITE,buffer); //关心 OP_WRITE 其实就是关系send-queue是不是有空间 &#125; else if (read == 0) &#123; break; &#125; else &#123; client.close(); break; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; SocketMultiplexingSingleThreadv1_1 service = new SocketMultiplexingSingleThreadv1_1(); service.start(); &#125;&#125; 在上面单线程的Selector中，先accept、read、write，都处于一个单线程中，没有什么问题，但是会造成CPU资源无法充分利用，若有其中一个Client处理了很长时间，会导致事件的堆积。 单Selector多线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120public class SocketMultiplexingSingleThreadv1_1 &#123; private ServerSocketChannel server = null; private Selector selector = null; int port = 9090; public void initServer() &#123; try &#123; server = ServerSocketChannel.open(); server.configureBlocking(false); server.bind(new InetSocketAddress(port)); selector = Selector.open(); // select poll *epoll server.register(selector, SelectionKey.OP_ACCEPT); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void start() &#123; initServer(); System.out.println(\"服务器启动了。。。。。\"); try &#123; while (true) &#123; while (selector.select() &gt; 0) &#123; Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iter = selectionKeys.iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); iter.remove(); if (key.isAcceptable()) &#123; acceptHandler(key); &#125; else if (key.isReadable()) &#123; //若不增加cancel方法，则会造成多次调用 //key.cancel(); 等同于取消注册Selctor，调用epoll_crl(fd,del) readHandler(key); //只处理了 read 并注册 关心这个key的write事件 &#125; else if(key.isWritable())&#123; //若不增加cancel方法，则会造成多次调用 //key.cancel(); writeHandler(key); &#125; &#125; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void writeHandler(SelectionKey key) &#123; System.out.println(\"write handler...\"); SocketChannel client = (SocketChannel) key.channel(); ByteBuffer buffer = (ByteBuffer) key.attachment(); buffer.flip(); while (buffer.hasRemaining()) &#123; try &#123; client.write(buffer); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; buffer.clear(); key.cancel(); try &#123; client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void acceptHandler(SelectionKey key) &#123; try &#123; ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel client = ssc.accept(); client.configureBlocking(false); ByteBuffer buffer = ByteBuffer.allocate(8192); client.register(selector, SelectionKey.OP_READ, buffer); System.out.println(\"-------------------------------------------\"); System.out.println(\"新客户端：\" + client.getRemoteAddress()); System.out.println(\"-------------------------------------------\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void readHandler(SelectionKey key) &#123; System.out.println(\"read handler.....\"); SocketChannel client = (SocketChannel) key.channel(); ByteBuffer buffer = (ByteBuffer) key.attachment(); buffer.clear(); int read = 0; try &#123; while (true) &#123; read = client.read(buffer); if (read &gt; 0) &#123; client.register(key.selector(),SelectionKey.OP_WRITE,buffer); &#125; else if (read == 0) &#123; break; &#125; else &#123; client.close(); break; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; SocketMultiplexingSingleThreadv1_1 service = new SocketMultiplexingSingleThreadv1_1(); service.start(); &#125;&#125; 多Selector单线程12345V1版本：混合模式，只有一个线程负责accept，每个都会被分配client，进行R&#x2F;W V2版本：index&#x3D;[0]的Selector只注册ACCEPT事件，其他Selector注册R&#x2F;W事件 V3版本：创建Boss线程组，多个Selector负责ACCEPT事件，创建Wroker线程组，多个Select负责R&#x2F;W事件 123456789101112131415161718192021public class MainSocketServer &#123; public static void main(String[] args) throws IOException &#123; //V3启动代码 //创建Boss线程组，线程数量num=3 SelectorThreadGroup bossGroup = new SelectorThreadGroup(3); //创建Worker线程组，线程数量num=3 SelectorThreadGroup workerGroup = new SelectorThreadGroup(3); //启动线程 bossGroup.start(); workerGroup.start(); //绑定Boss和Worker关系 bossGroup.setWorker(workerGroup); //Boss线程组注册ServerSocker bossGroup.bind(7777, 8888, 9999); //V1、V2的启动代码 //SelectorThreadGroup stg = new SelectorThreadGroup(3); //stg.start(); //stg.bind(7777, 8888, 9999); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103// 每线程对应一个selector，// 多线程情况下，该主机，该程序的并发客户端被分配到多个selector上//注意，每个客户端，只绑定到其中一个selector//不会有交互问题public class SelectorThread implements Runnable &#123; SelectorThreadGroup stg; Selector selector; //线程和线程组之间的通信队列 LinkedBlockingDeque&lt;Channel&gt; queue = new LinkedBlockingDeque&lt;&gt;(); public SelectorThread(SelectorThreadGroup stg) throws IOException &#123; this.stg = stg; this.selector = Selector.open(); &#125; @Override public void run() &#123; try &#123; while (true) &#123; //1.阻塞 无事件注册时依靠wakeup()唤醒 int num = selector.select(); //2.处理selectkeys if (num &gt; 0) &#123; Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); //每个Selector内部串行处理事件，多线程Selector各自处理不同的事件 //多个Selector的事件互不影响，无需调用key.cancel while (iterator.hasNext()) &#123; SelectionKey next = iterator.next(); iterator.remove(); if (next.isAcceptable()) &#123; acceptHandler(next); &#125; else if (next.isReadable()) &#123; readHandler(next); &#125; &#125; &#125; //3,处理一些task : listen client 队列中有新的需要注册到Selector的事件 while (!queue.isEmpty()) &#123; Channel channel = queue.take(); registerChannel(channel); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; //注册Channel public void registerChannel(Channel channel) throws IOException &#123; if (channel instanceof ServerSocketChannel) &#123; ServerSocketChannel server = (ServerSocketChannel) channel; server.register(selector, SelectionKey.OP_ACCEPT); System.out.println(Thread.currentThread().getName() + \" \" + server.getLocalAddress() + \" ServerSocket has register to Selector...\"); &#125; else &#123; SocketChannel client = (SocketChannel) channel; client.configureBlocking(false); ByteBuffer byteBuffer = ByteBuffer.allocate(4096); client.register(selector, SelectionKey.OP_READ, byteBuffer); System.out.println(Thread.currentThread().getName() + \" \" + client.getRemoteAddress() + \" Socket has register to Selector...\"); &#125; &#125; public void acceptHandler(SelectionKey key) throws IOException &#123; ServerSocketChannel channel = (ServerSocketChannel) key.channel(); System.out.println(Thread.currentThread().getName() + \" \" + channel.getLocalAddress() + \" accept listen...\"); SocketChannel client = channel.accept(); //根据线程组的规则挑选一个Selector进行事件注册 stg.registerV3(client); //stg.registerV2(client); //stg.registerV1(client); &#125; public void readHandler(SelectionKey key) throws IOException &#123; SocketChannel channel = (SocketChannel) key.channel(); System.out.println(Thread.currentThread().getName() + \" register read...\" + channel.getRemoteAddress()); ByteBuffer byteBuffer = (ByteBuffer) key.attachment(); byteBuffer.clear(); while (true) &#123; int read = channel.read(byteBuffer); if (read &gt; 0) &#123; byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; channel.write(byteBuffer); &#125; byteBuffer.clear(); &#125; else if (read == 0) &#123; break; &#125; else &#123; key.channel(); System.out.println(\"断开连接:\" + channel.getRemoteAddress()); break; &#125; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class SelectorThreadGroup &#123; SelectorThread[] sts; //用于计算数组下标 AtomicInteger count = new AtomicInteger(); //V3版本专用：默认启动类都是Boss组，需要存储Worker组的信息 SelectorThreadGroup worker = this; public SelectorThreadGroup(int num) throws IOException &#123; //num 线程数 sts = new SelectorThread[num]; for (int i = 0; i &lt; num; i++) &#123; sts[i] = new SelectorThread(this); &#125; &#125; //启动线程 public void start() &#123; for (int i = 0; i &lt; sts.length; i++) &#123; new Thread(sts[i]).start(); &#125; &#125; public void setWorker(SelectorThreadGroup worker) &#123; this.worker = worker; &#125; //创建ServerSocker的端口监听 public void bind(int... ports) throws IOException &#123; for (int port : ports) &#123; ServerSocketChannel server = ServerSocketChannel.open(); server.bind(new InetSocketAddress(port)); server.configureBlocking(false); registerV3(server); //registerV2(server); //registerV1(server); &#125; System.out.println(\"服务器启动了......\"); &#125; //V3版本：Boss线程组的Selector进行注册accept事件，Worker线程组注册R/W事件 public void registerV3(Channel channel) &#123; SelectorThread st = null; if (channel instanceof ServerSocketChannel) &#123; //注册ACCEPT到BOSS组，从STG对象中挑选Selector(复用V1版本的方法) st = this.nextSelectorV1(); &#125; else &#123; //注册R/W到Worker组，从workers对象中挑选Selector(复用V1版本的方法) st = worker.nextSelectorV1(); &#125; //1,通过队列传递数据 消息 st.queue.add(channel); //2,通过打断阻塞，让对应的线程去自己在打断后完成注册selector st.selector.wakeup(); &#125; //V2版本：只挑第一个Selector进行注册accept事件 public void registerV2(Channel channel) &#123; SelectorThread st = null; if (channel instanceof ServerSocketChannel) &#123; st = sts[0]; &#125; else &#123; st = nextSelectorV2(); &#125; st.queue.add(channel); st.selector.wakeup(); &#125; //V2版本：返回sts数组[1 - num]下标的其中一个Selector public SelectorThread nextSelectorV2() &#123; int index = count.getAndIncrement() % (sts.length - 1); return sts[index + 1]; &#125; //V1版本：根据轮训规则随便挑一个Selector进行注册 public void registerV1(Channel channel) &#123; SelectorThread st = nextSelectorV1(); st.queue.add(channel); st.selector.wakeup(); &#125; //V1版本：轮训返回sts数组中的其中一个Selector public SelectorThread nextSelectorV1() &#123; int index = count.getAndIncrement() % sts.length; return sts[index]; &#125;&#125; Netty响应式编程缓冲池概念在对象引用的实现中，每当一个Buffer实例没有被引用时，则会销毁该对象实例，如被GC回收，但是Buffer对象创建时的内存分配开销是比较大的，如果频繁创建Buffer对象，频繁进行内存分配释放，则开销较大，影响性能，故在netty4中新增了对象池化机制，即Buffer对象没有被引用时，可以放到一个对象缓存池中，而不是马上销毁，当需要时，则重新从对象缓存池中取出，而不需要重新创建。 PooledByteBuf继承于AbstractReferenceCountedByteBuf，在引用计数的基础上，添加池化机制减少对象创建，内存分配释放，提高性能。 1234567891011121314151617181920212223242526272829303132333435363738394041// 泛型T控制底层底层存放数据的实现// 如字节数组byte[]，Java NIO的ByteBufferabstract class PooledByteBuf&lt;T&gt; extends AbstractReferenceCountedByteBuf &#123; // 核心字段recyclerHandle // 每个对象实例包含一个recyclerHandle字段， // 该字段作为中介，将该对象实例放到该对象实例所在的类的对象池（类级别字段）中 // Handle类的value字段指向该对象 private final Recycler.Handle&lt;PooledByteBuf&lt;T&gt;&gt; recyclerHandle; protected PoolChunk&lt;T&gt; chunk; protected long handle; protected T memory; protected int offset; protected int length; int maxLength; PoolThreadCache cache; private ByteBuffer tmpNioBuf; private ByteBufAllocator allocator; // 中间省略其他方法 ... // 该对象引用计数为0时，释放该对象 // 调用recycle方法，将该对象实例放到其所在类的对象缓存池中 @Override protected final void deallocate() &#123; if (handle &gt;= 0) &#123; final long handle = this.handle; this.handle = -1; memory = null; tmpNioBuf = null; chunk.arena.free(chunk, handle, maxLength, cache); chunk = null; recycle(); &#125; &#125; private void recycle() &#123; recyclerHandle.recycle(this); &#125;&#125; PooledDirectByteBuf直接内存的池化实现类 RECYCLER为PooledDirectByteBuf类的对象实例缓存池； newInstance方法，从缓存池RECYCLER获取一个DirectByteBuf的对象实例，然后调用reuse重置该buf，然后返回给调用方。 1234567891011121314151617181920212223242526272829final class PooledDirectByteBuf extends PooledByteBuf&lt;ByteBuffer&gt; &#123; private static final Recycler&lt;PooledDirectByteBuf&gt; RECYCLER = new Recycler&lt;PooledDirectByteBuf&gt;() &#123; @Override protected PooledDirectByteBuf newObject(Handle&lt;PooledDirectByteBuf&gt; handle) &#123; return new PooledDirectByteBuf(handle, 0); &#125; &#125;; static PooledDirectByteBuf newInstance(int maxCapacity) &#123; PooledDirectByteBuf buf = RECYCLER.get(); buf.reuse(maxCapacity); return buf; &#125; ...&#125;PooledDirectByteBuf的reuse实现： /** * Method must be called before reuse this &#123;@link PooledByteBufAllocator&#125; */ final void reuse(int maxCapacity) &#123; maxCapacity(maxCapacity); setRefCnt(1); setIndex0(0, 0); discardMarks();&#125; PooledHeapByteBuf堆内存的池化实现类 123456789101112131415161718class PooledHeapByteBuf extends PooledByteBuf&lt;byte[]&gt; &#123; private static final Recycler&lt;PooledHeapByteBuf&gt; RECYCLER = new Recycler&lt;PooledHeapByteBuf&gt;() &#123; @Override protected PooledHeapByteBuf newObject(Handle&lt;PooledHeapByteBuf&gt; handle) &#123; return new PooledHeapByteBuf(handle, 0); &#125; &#125;; static PooledHeapByteBuf newInstance(int maxCapacity) &#123; PooledHeapByteBuf buf = RECYCLER.get(); buf.reuse(maxCapacity); return buf; &#125; ...&#125; ByteBuf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Testpublic void myBytebuf()&#123; //基于直接内存的ByteBuf 初始容量 8byte，最大容量20byte //ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(8, 20); //不基于pool 池化的堆内存ByteBuf //ByteBuf buf = UnpooledByteBufAllocator.DEFAULT.heapBuffer(8, 20); //池化的 堆内存 ByteBuf ByteBuf buf = PooledByteBufAllocator.DEFAULT.heapBuffer(8, 20); print(buf); buf.writeBytes(new byte[]&#123;1,2,3,4&#125;); print(buf); buf.writeBytes(new byte[]&#123;1,2,3,4&#125;); print(buf); buf.writeBytes(new byte[]&#123;1,2,3,4&#125;); print(buf); buf.writeBytes(new byte[]&#123;1,2,3,4&#125;); print(buf); buf.writeBytes(new byte[]&#123;1,2,3,4&#125;); print(buf); buf.writeBytes(new byte[]&#123;1,2,3,4&#125;); print(buf);&#125;public static void print(ByteBuf buf)&#123; //是否可读状态 System.out.println(\"buf.isReadable() :\"+buf.isReadable()); //读的起始下标 System.out.println(\"buf.readerIndex() :\"+buf.readerIndex()); //可读的字节长度 System.out.println(\"buf.readableBytes() \"+buf.readableBytes()); //是否可写状态 System.out.println(\"buf.isWritable() :\"+buf.isWritable()); //写的起始下标 System.out.println(\"buf.writerIndex() :\"+buf.writerIndex()); //可写的字节长度 System.out.println(\"buf.writableBytes() :\"+buf.writableBytes()); //当前ByteBuf容量 System.out.println(\"buf.capacity() :\"+buf.capacity()); //ByteBuf最大容量 System.out.println(\"buf.maxCapacity() :\"+buf.maxCapacity()); //是否直接内存 System.out.println(\"buf.isDirect() :\"+buf.isDirect()); System.out.println(\"--------------\");&#125; 客户端1234567891011121314151617181920212223242526272829303132@Testpublic void clientMode() throws Exception &#123; //类似于管理Selector的线程组 NioEventLoopGroup thread = new NioEventLoopGroup(1); //客户端模式：Netty提供的NioSocketChannl NioSocketChannel client = new NioSocketChannel(); //将client注册到Selector中，等同于 epoll_ctl(5,ADD,3) thread.register(client); //响应式编程：创建一个管道，添加一个处理类，接收到消息时响应调用处理 ChannelPipeline p = client.pipeline(); p.addLast(new MyInHandler()); //reactor 异步的特征 异步注册监听事件 ChannelFuture connect = client.connect(new InetSocketAddress(\"192.168.150.11\", 9090)); //sync进行同步阻塞，等待注册完成 ChannelFuture sync = connect.sync(); //创建拷贝的ByteBuf ByteBuf buf = Unpooled.copiedBuffer(\"hello server\".getBytes()); //发送消息并且刷新（异步操作） ChannelFuture send = client.writeAndFlush(buf); //阻塞等待发送成功 send.sync(); //关闭通道并阻塞等待关闭成功 sync.channel().closeFuture().sync(); System.out.println(\"client over....\");&#125; 123456789101112131415161718192021222324252627282930//该注解用于多个Client响应时共享Handler对象，否则一个Handler只能给一个Client使用@ChannelHandler.Sharableclass MyInHandler extends ChannelInboundHandlerAdapter &#123; //响应式注册 @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"client registed...\"); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"client active...\"); &#125; //响应式读取，将接受到的内容写回给Server端 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; //msg = client.read() 默认调用得到的，可以直接强转 ByteBuf buf = (ByteBuf) msg; //这里不能直接用 buf.readCharSequence 读成字符串，因为读出来后，buffer内容将被清空 //CharSequence str = buf.readCharSequence(buf.readableBytes(), CharsetUtil.UTF_8); //调用getCharSequence读取Buffer内容，但是内容不会被清空 CharSequence str = buf.getCharSequence(0,buf.readableBytes(), CharsetUtil.UTF_8); //输出内容 System.out.println(str); //回写有内容的Buffer给Server ctx.writeAndFlush(buf); &#125;&#125; 服务端1234567891011121314151617181920212223242526@Testpublic void serverMode() throws Exception &#123; //类似于管理Selector的线程组 NioEventLoopGroup thread = new NioEventLoopGroup(1); //服务端模式：NioServerSocketChannel NioServerSocketChannel server = new NioServerSocketChannel(); //将client注册到Selector中，等同于 epoll_ctl(5,ADD,3) thread.register(server); //响应式编程：创建一个管道，添加一个处理类，接收到消息时响应调用处理 ChannelPipeline p = server.pipeline(); //添加响应式处理事件 //accept接收客户端，并且注册到selector(传参Selector线程组、Client的READ响应事件) p.addLast(new MyAcceptHandler(thread,new MyInHandler())); //优化的方案，添加一层 p.addLast(new MyAcceptHandler(thread,new ChannelInit())); //异步注册监听事件 ChannelFuture bind = server.bind(new InetSocketAddress(\"192.168.150.1\", 9090)); //bind.sync() 阻塞 并 阻塞等待Server发送关闭请求（理论上永远不会发生，主要是为了让Main线程进入Wait状态，子进程进行Netty事件监听工作，而不结束程序） bind.sync().channel().closeFuture().sync(); System.out.println(\"server close....\");&#125; 12345678910111213141516171819202122232425262728293031class MyAcceptHandler extends ChannelInboundHandlerAdapter&#123; private final EventLoopGroup selector; private final ChannelHandler handler; public MyAcceptHandler(EventLoopGroup thread, ChannelHandler myInHandler) &#123; this.selector = thread; this.handler = myInHandler; //ChannelInit &#125; @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"server registerd...\"); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // listen socket accept client // socket R/W //accept 我怎么没调用额？ //Netty 自动调用了 SocketChannel client = (SocketChannel) msg; //1.响应式的 handler //下文案例优化的相应注释：client::pipeline[ChannelInit] ChannelPipeline p = client.pipeline(); p.addLast(handler); //2.注册 selector.register(client); &#125;&#125; 优化由于使用注解@ChannelHandler.Sharable造成所有客户端都使用了同一个Handler对象，如果每个客户端都想要独立的Handler对象呢？ 1234567891011121314//为啥要有一个inithandler，可以没有，但是MyInHandler就得设计成单例//思想：外层包一个Handler，复写它的Register方法，当注册的时候，在Register中创建各自的Handler@ChannelHandler.Sharableclass ChannelInit extends ChannelInboundHandlerAdapter&#123; @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception &#123; Channel client = ctx.channel(); ChannelPipeline p = client.pipeline(); //在原有的基础Handler上再添加新的Handler p.addLast(new MyInHandler()); //2.client::pipeline[ChannelInit,MyInHandler] //然后移除自身的Handler ctx.pipeline().remove(this); //3.client::pipeline[MyInHandler] &#125;&#125; Netty客户端123456789101112131415161718192021@Testpublic void nettyClient() throws InterruptedException, IOException &#123; NioEventLoopGroup group = new NioEventLoopGroup(1); Bootstrap bootstrap = new Bootstrap(); ChannelFuture connect = bootstrap.group(group) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); pipeline.addLast(new MyHandler()); &#125; &#125;) .connect(new InetSocketAddress(\"192.168.1.134\", 9090)); connect.sync(); NioSocketChannel client = (NioSocketChannel) connect.channel(); ByteBuf buf = Unpooled.copiedBuffer(\"hello server\".getBytes()); ChannelFuture channelFuture = client.writeAndFlush(buf); channelFuture.sync();&#125; Netty服务端1234567891011121314151617@Testpublic void nettyServer() throws InterruptedException &#123; NioEventLoopGroup group = new NioEventLoopGroup(1); ServerBootstrap bootstrap = new ServerBootstrap(); //Server需要绑定Boss和Worker线程组，这里偷懒复用同一个 ChannelFuture bind = bootstrap.group(group, group) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;NioServerSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel channel) throws Exception &#123; ChannelPipeline pipeline = channel.pipeline(); pipeline.addLast(new MyHandler()); &#125; &#125;) .bind(new InetSocketAddress(\"192.168.3.32\", 9090)); bind.sync().channel().closeFuture().sync();&#125; 手写RPC框架 1234//动态代理调用的接口interface Say &#123; String saySomething(String hello);&#125; 消费者123456789101112131415//消费者的启动函数public class MainConsumer &#123; public static void main(String[] args) throws InterruptedException &#123; //如果这里包含了Provider的服务，则将走本地调用 for (int i = 0; i &lt; 20; i++) &#123; String Isay = \"~~~hello~~~~\" + i; new Thread(() -&gt; &#123; Say say = ProxyUtils.proxy(Say.class); String recv = say.saySomething(Isay); System.out.println(\"I say : 【\" + Isay + \"】 and provider return ：\" + recv); &#125;).start(); &#125; &#125;&#125; 动态代理1234567891011121314151617181920212223242526272829//利用JDK的动态代理public class ProxyUtils &#123; public static &lt;T&gt; T proxy(Class&lt;T&gt; clazz) &#123; ClassLoader classLoader = clazz.getClassLoader(); Class&lt;?&gt;[] classes = &#123;clazz&#125;; return (T) Proxy.newProxyInstance(classLoader, classes, (proxy, method, args) -&gt; &#123; //如何设计我们的consumer对于provider的调用过程 //调用 服务，方法，参数 ==》 封装成message [content] Class&lt;?&gt;[] parameterTypes = method.getParameterTypes(); String methodName = method.getName(); String name = clazz.getName(); Object object = Dispatcher.get(clazz.getName()); //从本地对象中获取，判断是否是本地调用，若是本地调用，则直接反射方法，若不是，则走RPC if (object != null) &#123; System.out.println(\"走本地调用：FC...\"); Method m = clazz.getMethod(methodName, parameterTypes); return m.invoke(object, args); &#125; System.out.println(\"走RPC调用：RPC...\"); //消息体 MsgBody msgBody = new MsgBody(name, methodName, args, parameterTypes); //调用Socket发送请求 SynchronousQueue&lt;Object&gt; blockQueue = ClientFactory.getFactory().transport(msgBody); //如果从IO ，未来回来了，怎么将代码执行到这里 return blockQueue.take(); &#125;); &#125;&#125; 协议123456789101112131415161718192021public class MsgHeader implements Serializable &#123; //拆包的协议 public int protocol; //唯一ID public String uuid; //消息体长度 public long dataLen; //Consumer发给Provider的协议 public static final int tranProtocol = 0x1010; //Provider发给Consumer的协议 public static final int recvProtocol = 0x0101; public MsgHeader(int protocol, String uuid, long dataLen) &#123; this.protocol = protocol; this.uuid = uuid; this.dataLen = dataLen; &#125; //省略get、set、toString方法&#125; 12345678910111213141516171819public class MsgBody implements Serializable &#123; //RPC远程调用接口名称 String name; //RPC远程调用方法名 String method; //参数 Object[] args; //方法类型 Class&lt;?&gt;[] parameterTypes; public MsgBody(String name, String method, Object[] args, Class&lt;?&gt;[] parameterTypes) &#123; this.name = name; this.method = method; this.args = args; this.parameterTypes = parameterTypes; &#125; //省略get、set、toString方法&#125; 1234567891011121314151617//序列化对象的工具类public class SerializableUtils &#123; static ByteArrayOutputStream baos = new ByteArrayOutputStream(); public synchronized static byte[] toBytes(Object object) throws IOException &#123; baos.reset(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(object); return baos.toByteArray(); &#125; public static Object toObject(byte[] bytes) throws IOException, ClassNotFoundException &#123; ByteArrayInputStream bais = new ByteArrayInputStream(bytes); ObjectInputStream ois = new ObjectInputStream(bais); return ois.readObject(); &#125;&#125; 链接池123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//链接池工厂public class ClientFactory &#123; //访问同一个Server最多能创建的Client数量 int size = 10; private static final ClientFactory factory = new ClientFactory(); ConcurrentHashMap&lt;InetSocketAddress, ClientPool&gt; pools = new ConcurrentHashMap&lt;&gt;(); public static ClientFactory getFactory() &#123; return factory; &#125; private ClientFactory() &#123; &#125; //获得一个NioSocketChannel链接 public NioSocketChannel getClientChannel(InetSocketAddress server) &#123; ClientPool pool = pools.get(server); //懒加载 if (pool == null) &#123; pools.putIfAbsent(server, new ClientPool(size)); pool = pools.get(server); &#125; try &#123; return pool.getClient(server); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return null; &#125; public SynchronousQueue&lt;Object&gt; transport(MsgBody msgBody) throws Exception &#123; //requestID+message ，本地要缓存 SynchronousQueue&lt;Object&gt; blockQueue = new SynchronousQueue&lt;&gt;(); String uuid = UUID.randomUUID().toString(); CallBackUtils.add(uuid, blockQueue); //协议：【header&lt;&gt;】【msgBody】 byte[] bodyBytes = SerializableUtils.toBytes(msgBody); MsgHeader header = new MsgHeader(MsgHeader.tranProtocol, uuid, bodyBytes.length); byte[] headerBytes = SerializableUtils.toBytes(header); //通过打印headerBytes查看协议头有多少字节 //System.out.println(\"headerBytes : \" + headerBytes.length); ByteBuf byteBuf = PooledByteBufAllocator.DEFAULT.heapBuffer(headerBytes.length + bodyBytes.length); byteBuf.writeBytes(headerBytes); byteBuf.writeBytes(bodyBytes); //连接池：：取得连接 //获取连接过程中： 开始-创建，过程-直接取 InetSocketAddress server = new InetSocketAddress(\"localhost\", 9090); NioSocketChannel clientChannel = getClientChannel(server); //5，发送--&gt; 走IO out --&gt;走Netty（event 驱动） ChannelFuture channelFuture = clientChannel.writeAndFlush(byteBuf); channelFuture.sync(); return blockQueue; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class ClientPool &#123; //采用最简单的轮训算法 Random random = new Random(); //缓存链接的数组 NioSocketChannel[] clients; //懒加载client public ClientPool(int num) &#123; clients = new NioSocketChannel[num]; &#125; //这里偷懒全局加锁 public synchronized NioSocketChannel getClient(InetSocketAddress server) throws InterruptedException &#123; int index = random.nextInt(clients.length); NioSocketChannel client = clients[index]; //如果client存在则返回--》需要注意的是，它是允许多个线程持有同一个client if (client != null &amp;&amp; client.isActive()) &#123; return client; &#125; //如果client不存在则创建，并返回 clients[index] = create(server); return clients[index]; &#125; public NioSocketChannel create(InetSocketAddress server) throws InterruptedException &#123; //创建只有一个EventLoop的工作组 NioEventLoopGroup worker = new NioEventLoopGroup(1); Bootstrap bootstrap = new Bootstrap(); ChannelFuture connect = bootstrap.group(worker) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); //这里用了拆包协议，下文会详细讲解 pipeline.addLast(new ProtocolDecoder()); //具体处理回调的Handler pipeline.addLast(new ConsumerHandler()); &#125; &#125;) .connect(server); connect.sync(); return (NioSocketChannel) connect.channel(); &#125;&#125; 生产者12345678910111213141516171819202122232425262728293031//Provider启动类public class MainProvider &#123; public static void main(String[] args) throws InterruptedException &#123; //1个Selector.ACCPET的EventLoop线程组 NioEventLoopGroup boss = new NioEventLoopGroup(1); //20个Selector处理R/W的工作组 NioEventLoopGroup worker = new NioEventLoopGroup(20); ServerBootstrap bootstrap = new ServerBootstrap(); ChannelFuture bind = bootstrap.group(boss, worker) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; System.out.println(\"server accept client port: \" + ch.remoteAddress().getPort()); ChannelPipeline pipeline = ch.pipeline(); //1.原始的思想 //pipeline.addList(new ProviderRequestHandler()); //2.进阶的思想 pipeline.addLast(new ProtocolDecoder()); pipeline.addLast(new ProviderHandler()); &#125; &#125;) .bind(new InetSocketAddress(\"localhost\", 9090)); bind.sync().channel().closeFuture().sync(); &#125;&#125; 实现类1234567public class MySay implements Say &#123; @Override public String saySomething(String hello) &#123; return \"I say Hello back\"; &#125;&#125; 12345Provider原始思想的Handler：1.读取到ByteBuf后，根据消息头的大小进行数据分割，由于前面预测试输出过一个MsgHttper对象的byte数组大小为1432.所以读取的前143个字节的数据转换成MsgHeader对象3.然后根据MsgHeader的属性dataLen获取到消息体大小4.然后读取dataLen个字节的数据转换成MsgBody对象 1234567891011121314151617181920//原始的思想的Handlerpublic class ProviderRequestHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object buf) throws Exception &#123; ByteBuf byteBuf = (ByteBuf) buf; if (byteBuf.readableBytes() &gt; 143) &#123; byte[] headBytes = new byte[143]; byteBuf.readBytes(headBytes, byteBuf.readerIndex(), headBytes.length); MsgHeader header = (MsgHeader) SerializableUtils.toObject(headBytes); System.out.println(header); if (byteBuf.readableBytes() &gt;= header.dataLen) &#123; byte[] bodyBytes = new byte[(int) header.dataLen]; byteBuf.readBytes(bodyBytes); MsgBody msgBody = (MsgBody) SerializableUtils.toObject(bodyBytes); System.out.println(msgBody); &#125; &#125; &#125;&#125; 思考：这种设计在并发的情况下会不会产生问题？一个ByteBuf对象包含一个完整的数据包吗？ 解码器 根据上文的思想，需要实现拆包和缓存不完整的数据包和下次数据包进行拼接，而Netty框架肯定也考虑了这个问题，对种现象进行了封装，称做 解码器，它的作用是实现数据包的拆包操作，并将拆好的数据包添加进一个List&lt;Object&gt; obj中，它会一个一个传递给下一个Handler。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 用于对Byte数据按照不同的协议进行解码 */public class ProtocolDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf buf, List&lt;Object&gt; out) throws Exception &#123; ByteBuf byteBuf = (ByteBuf) buf; //因为一个buffer中可能有多个数据包，使用while循环读取多次 while (byteBuf.readableBytes() &gt; 143) &#123; byte[] headBytes = new byte[143]; //使用getBytes先获取头信息，readIndex指针不移动 byteBuf.getBytes(byteBuf.readerIndex(), headBytes); MsgHeader header = (MsgHeader) SerializableUtils.toObject(headBytes); //数据拆包，如果可读数据包含一个完整的msgBody大小时，则进行读取，否则跳出当前循环等待拼接下次数据包 if (byteBuf.readableBytes() - headBytes.length &gt;= header.dataLen) &#123; //由于之前读取没有移动readIndex，所以现在让它移动指针 byteBuf.readBytes(headBytes.length); //把数据先读到byte数组里，再判断不同协议转换成不同的对象进行拆包 byte[] msgBytes = new byte[(int) header.dataLen]; byteBuf.readBytes(msgBytes); //如果是Client发送给Server的拆包操作，以tranPrototol协议来拆包 if (header.protocol == MsgHeader.tranProtocol) &#123; MsgBody msgBody = (MsgBody) SerializableUtils.toObject(msgBytes); //将数据拆成Header和MsgBody，添加进out，传递给下一个Handler out.add(new ProtocolMessage(header, msgBody)); &#125; else if (header.protocol == MsgHeader.recvProtocol) &#123; //如果是Client接受Server返回的拆包操作，以recvProtocol协议拆包 Object result = SerializableUtils.toObject(msgBytes); //将数据拆成Header和result，添加进out，传递给下一个Handler out.add(new ProtocolMessage(header, result)); &#125; &#125; else &#123; break; &#125; &#125; &#125;&#125; 12345678910111213141516public class ProtocolMessage &#123; MsgHeader header; MsgBody msgBody; Object result; //Consumer发送的协议封包 public ProtocolMessage(MsgHeader header, MsgBody msgBody) &#123; this.header = header; this.msgBody = msgBody; &#125; //Provider发送的协议封包 public ProtocolMessage(MsgHeader header, Object result) &#123; this.header = header; this.result = result; &#125;&#125; 1234这里做具体ChannelRead的IO逻辑： 如果假设处理完了，要给客户端返回了~！！！需要注意哪些环节~?1.因为是个RPC，得返回Header带过来的uuid！！！！2.关注RPC通信协议 protocol,在client那一侧也要解决解码问题3.业务数据处理 12345678910111213141516业务处理的几种策略:1.直接在当前方法处理IO 和 业务 和 返回 弊端：processSelectorKeys和runTask(业务处理)捆绑，其他Channel需要等待它的处理2.自己创建线程池 需要注意：当前线程和处理业务的线程肯定不是同一个线程3.业务逻辑传递给其他EventLoop,每一个EventLoop都有一个单线程、Selector、还有一个task队列 编码：ctx.executor().parent().next().execute() 好处：将processSelectorKeys和runAllTasks解耦，可以将runAllTasks的压力分散到其他Selector中 需要注意：当前线程和处理业务线程可能不是同一个线程，处理业务线程可能是其他EventLoop的单线程4.使用netty自己的eventloop来处理业务及返回 编码：ctx.executor().execute(); 作用：将所有processSelectorKeys先处理完，然后再开始按顺序执行runAllTasks 需要注意：当前线程和处理业务的线程肯定是同一个线程，都是由用一个EventLoop的单线程处理 1234567891011121314151617181920212223242526272829303132333435363738public class ProviderHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object out) throws Exception &#123; //ByteToMessageDecoder的拆包会拆好的数据包一个一个传递给下一个handler ProtocolMessage pmsg = (ProtocolMessage) out; //当前线程 String ioThreadName = Thread.currentThread().getName(); //反射执行目标方法 ctx.executor().parent().next().execute(() -&gt; &#123; String taskThreadName = Thread.currentThread().getName(); String param = (String) pmsg.msgBody.args[0]; //String result = ioThreadName + \" recv say : 【\" + param + \"】 and send by \" + taskThreadName; Object result = null; try &#123; //反射调用API Object object = Dispatcher.get(pmsg.msgBody.name); Class&lt;?&gt; clazz = object.getClass(); Method m = clazz.getMethod(pmsg.msgBody.method, pmsg.msgBody.parameterTypes); result = m.invoke(object, pmsg.msgBody.args); //写结果集 byte[] resultBytes = SerializableUtils.toBytes(result); MsgHeader header = new MsgHeader(MsgHeader.recvProtocol, pmsg.header.uuid, resultBytes.length); byte[] headerBytes = SerializableUtils.toBytes(header); ByteBuf byteBuf = PooledByteBufAllocator.DEFAULT.heapBuffer(headerBytes.length + resultBytes.length); byteBuf.writeBytes(headerBytes); byteBuf.writeBytes(resultBytes); ctx.writeAndFlush(byteBuf); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); &#125;&#125; 1234567891011//Provider发送完消息后回过头看Consumer的接收回复消息的Handler//Consumer也用了拆包，所以这里是一个完整的数据包，回调CallBck唤醒阻塞的线程public class ConsumerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object out) throws Exception &#123; //1.解析数据转换成对象 ProtocolMessage pmsg = (ProtocolMessage) out; //2.获取uuid回调callback CallBackUtils.callback(pmsg.header.uuid, pmsg.result); &#125;&#125; 123456789101112131415public class CallBackUtils &#123; static ConcurrentHashMap&lt;String, SynchronousQueue&lt;Object&gt;&gt; map = new ConcurrentHashMap&lt;&gt;(); public static void add(String uuid, SynchronousQueue queue) &#123; map.put(uuid, queue); &#125; //往队列里塞返回值，使得Consumer的调用线程不再阻塞 public static void callback(String uuid, Object result) throws InterruptedException &#123; SynchronousQueue queue = map.get(uuid); queue.put(result); //移除掉已经使用的内容，否则map会很大 map.remove(uuid); &#125;&#125; 总结","categories":[{"name":"NIO","slug":"NIO","permalink":"https://midkuro.gitee.io/categories/NIO/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"NIO","slug":"NIO","permalink":"https://midkuro.gitee.io/tags/NIO/"}]},{"title":"'Spring的循环依赖'","slug":"spring-circularReferences","date":"2020-10-24T14:30:00.000Z","updated":"2020-10-19T06:02:19.195Z","comments":true,"path":"2020/10/24/spring-circularReferences/","link":"","permalink":"https://midkuro.gitee.io/2020/10/24/spring-circularReferences/","excerpt":"","text":"Spring的循环依赖循环依赖有两种方式：构造函数参数循环依赖，以及属性循环依赖，构造函数参数循环依赖是没有办法解决的，所以我们常说的Spring解决的循环依赖一般指的是属性循环依赖。 Spring的循环依赖是通过建立三级缓存实现的，三级缓存主要是为了解决在AOP情况下，出现循环依赖的问题，当然，其中的一级+二级是为了解决读取不完整的性能问题，如果没了三级缓存，使用二级缓存也能够实现功能，但是会在每次创建Bean的时候调用动态代理的判断逻辑，影响性能问题。 1234567891011//一级缓存，单例池，用于存储已经初始化完成的Bean实例（完整品）/** Cache of singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);//二级缓存，单例池，读取到不完整的Bean性能更高,用于存储未彻底完成初始化的bean实例（半成品）/** Cache of early singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; earlySingletonObjects = new ConcurrentHashMap&lt;&gt;(16);//三级缓存，用于存储创建Bean的匿名内部类对象&lt;ObjectFactory&gt;，解决创建动态代理逻辑性能，解耦 bean动态代理问题/** Cache of singleton factories: bean name to ObjectFactory. */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16); 案例123456789101112131415161718@Componentpublic class A &#123; @Autowired public B b; public B getB() &#123; return b; &#125; public void setB(B b) &#123; this.b = b; &#125; public int div(int i, int j) &#123; System.out.println(\"MathCalculator...div...\"); return i / j; &#125;&#125; 12345678910111213@Servicepublic class B &#123; @Autowired private A a; public A getA() &#123; return a; &#125; public void setA(A a) &#123; this.a = a; &#125;&#125; 123456789101112131415161718@Aspect@Componentpublic class LogAspects &#123; // 抽取公共的切入点表达式 // 1、本类引用 // 2、其他的切面引用 @Pointcut(\"execution(public int spring.cricle.A.*(..))\") public void pointCut() &#123; &#125; // @Before在目标方法之前切入；切入点表达式（指定在哪个方法切入） @Before(\"pointCut()\") public void logStart(JoinPoint joinPoint) &#123; Object[] args = joinPoint.getArgs(); System.out.println(\"\" + joinPoint.getSignature().getName() + \"运行。。。@Before:参数列表是：&#123;\" + Arrays.asList(args) + \"&#125;\"); &#125;&#125; 12345@Configuration@EnableAspectJAutoProxy@ComponentScan(\"spring.cricle\")public class Config &#123;&#125; 1234567@Testpublic void test02() &#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(Config.class); A a = context.getBean(A.class); System.out.println(a.div(1, 2)); context.close();&#125; 可以看到上面的A.java类和B.java类是属性循环依赖的关系，并且A类被AOP代理了，接下来分析一下怎么循环依赖的问题。 分析摘取部分创建Bean的源码上分析： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253protected &lt;T&gt; T doGetBean( String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; /* 省略部分代码 */ bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; /* 省略部分代码 */ if (!typeCheckOnly) &#123; //1.标记当前bean处于正在创建状态 markBeanAsCreated(beanName); &#125; try &#123; //创建bean实例 // Create bean instance. if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; /* 省略部分代码 */ &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; /* 省略部分代码 */ &#125; return (T) bean;&#125; 12345678910111213141516171819202122232425public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, \"Bean name must not be null\"); synchronized (this.singletonObjects) &#123; //1.从缓存中获取bean实例 Object singletonObject = this.singletonObjects.get(beanName); //2.如果bean实例不存在缓存中 if (singletonObject == null) &#123; /* 省略部分源码 */ try &#123; //3.将调用函数式接口() -&gt; &#123; return createBean(beanName, mbd, args);&#125; singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; catch (IllegalStateException ex) &#123; /* 省略部分源码 */ &#125; if (newSingleton) &#123; //4.将初始化完成的bean添加到一级缓存中 addSingleton(beanName, singletonObject); &#125; &#125; return singletonObject; &#125;&#125; 12345678910protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; //将初始化好的bean添加到一级缓存中 this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); //添加bean实例到注册列表中 this.registeredSingletons.add(beanName); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//doCreateBean创建A类的Bean部分伪代码protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; /* 省略部分代码 */ if (instanceWrapper == null) &#123; //1.实例化A对象，开辟内存空间 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; /* 省略部分代码 */ // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. // 2.实例化完成后，判断是否需要提前暴露该对象，结果为true // 满足条件：单例、开启允许循环依赖的配置、并且该Bean处于正在创建状态 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\"); &#125; //3.添加Bean的工厂对象到三级缓存中 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; //4.给A的属性赋值（也就是属性B） populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; /* 省略部分代码 */ &#125; if (earlySingletonExposure) &#123; //5.从二级缓存中获取对象，并比较，下文再分析它 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; /* 省略部分代码 */ &#125; &#125; /* 省略部分代码 */ return exposedObject;&#125; 12345678910111213141516171819202122/** * Add the given singleton factory for building the specified singleton * if necessary. * &lt;p&gt;To be called for eager registration of singletons, e.g. to be able to * resolve circular references. * @param beanName the name of the bean * @param singletonFactory the factory for the singleton object */protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(singletonFactory, \"Singleton factory must not be null\"); synchronized (this.singletonObjects) &#123; if (!this.singletonObjects.containsKey(beanName)) &#123; //把singletonFactory匿名内部类添加到三级缓存中 //匿名内部类：【() -&gt; getEarlyBeanReference(beanName, mbd, bean)】 this.singletonFactories.put(beanName, singletonFactory); //如果二级缓存中存在该bean，则移除 this.earlySingletonObjects.remove(beanName); //添加该bean到注册工厂中 this.registeredSingletons.add(beanName); &#125; &#125;&#125; 所以在给Bean对象开辟内存空间，完成实例化之后，就会将该Bean对象存放在三级缓存singletonFactories中。 然后才调用populateBean方法 1234567891011121314151617181920212223242526272829303132333435363738protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123; /* 省略部分代码 */ PropertyDescriptor[] filteredPds = null; if (hasInstAwareBpps) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; //根据【@Autowired】的实现类【AbstractAutowireCapableBeanFactory】 if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; //通过调用它的postProcessProperties获取属性B PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; return; &#125; &#125; pvs = pvsToUse; &#125; &#125; &#125; if (needsDepCheck) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; if (pvs != null) &#123; //给Bean（A）的赋值属性B applyPropertyValues(beanName, mbd, bw, pvs); &#125; &#125; 通过跟踪上文AbstractAutowireCapableBeanFactory.postProcessProperties()方法，想要给A类赋予B属性，就需要先创建B对象，最终它会调用来创建B对象。 12345public Object resolveCandidate(String beanName, Class&lt;?&gt; requiredType, BeanFactory beanFactory) throws BeansException &#123; //beanName:B类 return beanFactory.getBean(beanName);&#125; B类的创建Bean实例的逻辑和A类相同，因为B类也需要调用populateBean给属性A赋值，在给A赋值的过程中，最终会重新回到上文中的resolveCandidate调用beanFactory.getBean()获取A对象的实例，接着进一步分析调用getBean()-doGetBean()的方法。 12345678910111213141516171819202122232425protected &lt;T&gt; T doGetBean( String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; String beanName = transformedBeanName(name); Object bean; //1.获取Bean的缓存（其中包括从一级、二级、三级缓存中获取） //2.由于之前已经创建过A实例并存在第三缓存中，所以这里能够返回一个A对象 // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isTraceEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.trace(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); &#125; else &#123; logger.trace(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); &#125; &#125; bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; /* 省略部分代码 */&#125; 123456789101112131415161718192021222324252627282930313233343536//allowEarlyReference参数默认为true@Nullableprotected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; // Quick check for existing instance without full singleton lock //1.先从一级缓存中获取对象，若存在则返回 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; //2.若对象不存在，则从二级缓存中查找该对象 singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; synchronized (this.singletonObjects) &#123; // Consistent creation of early reference within full singleton lock singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; singletonObject = this.earlySingletonObjects.get(beanName); //3.若对象不存在一级、二级缓存中时，并且存在于三级缓存中时 if (singletonObject == null) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; //4.调用工厂对象的getObject()方法【() -&gt; getEarlyBeanReference(beanName, mbd, bean)】 // 提前，实际上是调用了【AnnotationAwareAspectJAutoProxyCreator】 // 最终返回一个动态代理对象Proxy singletonObject = singletonFactory.getObject(); //将该动态代理对象存放到二级缓存中 this.earlySingletonObjects.put(beanName, singletonObject); //把该bean的函数接口从三级缓存中移除 this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; &#125; &#125; return singletonObject;&#125; 123456789101112131415//获取初始化B类的属性A的实例protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; //动态代理的【AnnotationAwareAspectJAutoProxyCreator】将在这里调用 if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; &#125; //返回被AOP代理的A类的Proxy对象 return exposedObject;&#125; 123456789//AnnotationAwareAspectJAutoProxyCreator.getEarlyBeanReference@Overridepublic Object getEarlyBeanReference(Object bean, String beanName) &#123; //把对象加入到AOP处理的缓存集合中 Object cacheKey = getCacheKey(bean.getClass(), beanName); this.earlyProxyReferences.put(cacheKey, bean); //最终还是调用了AOP动态代理包装原对象，并返回 return wrapIfNecessary(bean, beanName, cacheKey);&#125; 所以在这时候，就能够返回一个A类的动态代理对象，是在初始化B类，给B类开辟实例空间后，准备赋值属性A时，调用beanFactory.getBean(A)时创建的。 当给B类的初始化成功后，最终会调用addSingleton()方法，添加到一级缓存中，然后调用链将回到初始化实例的函数上，B的初始化是由于初始化A时，需要赋值A的属性B，才会被调度的。 这时候，当A初始化完成后，doCreateBean()方法的第五步： 123456789101112131415if (earlySingletonExposure) &#123; //这时候从二级缓存中获取的bean实例，是一个动态代理对象proxy Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; //bean对象是一个原生实例，它是被createBeanInstance（）创建出来的 //exposedObject是一个原生实例，因为在初始化B时已经调用了AOP的动态代理创建过一次proxy对象 //所以原生Bean再次调用BeanPostProcessor.postProcessAfterInitialization，AOP内部有缓存不会再创建对象 //所以这个逻辑【exposedObject == bean】在生成AOP动态代理时为true //所以初始化A成功之后，会将对外暴露的实例（原生）替换成动态代理对象 if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; /* 省略部分代码 */ &#125;&#125; 总结： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748getBean(A)-&gt; doGetBean(A) #判断A对象是否存在缓存中 -&gt; getSingleton(A) #标记A对象正在被创建 -&gt; markBeanAsCreated(A) -&gt; getSingleton(beanName, ObjectFactory&lt;?&gt;) -&gt; ObjectFactory.createBean() -&gt; doCreateBean(A) -&gt; createBeanInstance() #添加bean相关的【getEarlyBeanReference】函数接口到三级缓存中 -&gt; addSingletonFactory(beanName, singletonObject) -&gt; populateBean() #给A对象属性赋值时调用getBean创建B类的实例 -&gt; getBean(B) -&gt; doGetBean(B) -&gt; markBeanAsCreated(B) -&gt; getSingleton(beanName, ObjectFactory&lt;?&gt;) -&gt; createBean() -&gt; doCreateBean(B) -&gt; createBeanInstance() -&gt; addSingletonFactory(beanName, singletonObject) -&gt; populateBean() #给B对象属性赋值时调用getBean创建A类实例 -&gt; getBean(A) -&gt; doGetBean(A) #尝试从缓存中获取A对象，并将(proxy)A对象存放在二级缓存中 -&gt; getSingleton(A) #从三级缓存中调用特殊的BeanPostProcessor -&gt; ObjectFactory.getEarlyBeanReference #AbstractAutoProxyCreator，创建动态代理对象 -&gt; getEarlyBeanReference #将原对象包装成动态代理对象 -&gt; wrapIfNecessary(A) #返回动态代理对象A -&gt; return proxyA #通过反射把A对象赋值到B对象的属性中 -&gt; applyPropertyValues() #将初始化B存放在一级缓存中 -&gt; addSinleton(B) #通过反射把B对象赋值到A对象的属性中 -&gt; applyPropertyValues() #从二级缓存中获取proxyA -&gt; getSingleton(beanName, false); # exposedObject和bean都是原生A对象，二级缓存中的是proxyA -&gt; if (exposedObject == bean) &#123; exposeObject = proxyA&#125; #添加动态代理对象到一级缓存中 -&gt; addSingleton(proxyA) 在没有添加动态代理的情况下，使用二级缓存就能解决循环依赖的问题，其调度过程如下图： “本篇文章主要摘自参考资料”","categories":[{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/tags/Spring/"}]},{"title":"'Spring的IOC容器创建过程'","slug":"spring-initialization","date":"2020-10-22T14:30:00.000Z","updated":"2020-10-19T06:19:43.917Z","comments":true,"path":"2020/10/22/spring-initialization/","link":"","permalink":"https://midkuro.gitee.io/2020/10/22/spring-initialization/","excerpt":"","text":"Spring的IOC容器创建过程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 刷新前的预处理12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Prepare this context for refreshing, setting its startup date and * active flag as well as performing any initialization of property sources. *///刷新前的预处理;protected void prepareRefresh() &#123; // Switch to active. //记录时间和状态 this.startupDate = System.currentTimeMillis(); this.closed.set(false); this.active.set(true); if (logger.isDebugEnabled()) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Refreshing \" + this); &#125; else &#123; logger.debug(\"Refreshing \" + getDisplayName()); &#125; &#125; //1.初始化一些属性配置，子类自定义个性化的属性设置方法； // Initialize any placeholder property sources in the context environment. initPropertySources(); //2.检验属性的合法等 // Validate that all properties marked as required are resolvable: // see ConfigurablePropertyResolver#setRequiredProperties getEnvironment().validateRequiredProperties(); //3.保存容器中的一些早期的事件； // Store pre-refresh ApplicationListeners... if (this.earlyApplicationListeners == null) &#123; this.earlyApplicationListeners = new LinkedHashSet&lt;&gt;(this.applicationListeners); &#125; else &#123; // Reset local application listeners to pre-refresh state. this.applicationListeners.clear(); this.applicationListeners.addAll(this.earlyApplicationListeners); &#125; // Allow for the collection of early ApplicationEvents, // to be published once the multicaster is available... this.earlyApplicationEvents = new LinkedHashSet&lt;&gt;();&#125; 12345678/** * &lt;p&gt;Replace any stub property sources with actual instances. * @see org.springframework.core.env.PropertySource.StubPropertySource * @see org.springframework.web.context.support.WebApplicationContextUtils#initServletPropertySources */protected void initPropertySources() &#123; // For subclasses: do nothing by default.&#125; 刷新Bean工厂12345678910111213/** * Tell the subclass to refresh the internal bean factory. * @return the fresh BeanFactory instance * @see #refreshBeanFactory() * @see #getBeanFactory() *///刷新【创建】BeanFactory；protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; //刷新BeanFactory； refreshBeanFactory(); //2.返回刚才GenericApplicationContext创建的BeanFactory对象【DefaultListableBeanFactory】 return getBeanFactory();&#125; GenericApplicationContext构造方法中创建了一个this.beanFactory = new DefaultListableBeanFactory(); 123456789@Overrideprotected final void refreshBeanFactory() throws IllegalStateException &#123; if (!this.refreshed.compareAndSet(false, true)) &#123; throw new IllegalStateException( \"GenericApplicationContext does not support multiple refresh attempts: just call 'refresh' once\"); &#125; //设置序列化id； this.beanFactory.setSerializationId(getId());&#125; BeanFactory的预准备工作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * Configure the factory's standard context characteristics, * such as the context's ClassLoader and post-processors. * @param beanFactory the BeanFactory to configure */protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; //1.设置BeanFactory的类加载器、支持表达式解析器... // Tell the internal bean factory to use the context's class loader etc. beanFactory.setBeanClassLoader(getClassLoader()); beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); //2.添加部分BeanPostProcessor【ApplicationContextAwareProcessor】 // Configure the bean factory with context callbacks. beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); //3.设置忽略的自动装配的接口EnvironmentAware、EmbeddedValueResolverAware、xxx； beanFactory.ignoreDependencyInterface(EnvironmentAware.class); beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); //4.注册可以解析的自动装配；我们能直接在任何组件中自动注入： // BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext // BeanFactory interface not registered as resolvable type in a plain factory. // MessageSource registered (and found for autowiring) as a bean. beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); //5.添加BeanPostProcessor【ApplicationListenerDetector】 // Register early post-processor for detecting inner beans as ApplicationListeners. beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this)); //6.添加编译时的AspectJ； // Detect a LoadTimeWeaver and prepare for weaving, if found. if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // Set a temporary ClassLoader for type matching. beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; // Register default environment beans. //给BeanFactory中注册一些能用的组件； // environment【ConfigurableEnvironment】、 if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; // systemProperties【Map&lt;String, Object&gt;】、 if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; // systemEnvironment【Map&lt;String, Object&gt;】 if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125;&#125; BeanFactory的后置处理工作12345678910/** * Modify the application context's internal bean factory after its standard * initialization. All bean definitions will have been loaded, but no beans * will have been instantiated yet. This allows for registering special * BeanPostProcessors etc in certain ApplicationContext implementations. * @param beanFactory the bean factory used by the application context *///子类通过重写这个方法来在BeanFactory创建并预准备完成以后做进一步的设置protected void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123;&#125; 执行BeanFactory的后置处理器123456789101112131415/** * Instantiate and invoke all registered BeanFactoryPostProcessor beans, * respecting explicit order if given. * &lt;p&gt;Must be called before singleton instantiation. */protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); // Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime // (e.g. through an @Bean method registered by ConfigurationClassPostProcessor) if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143public static void invokeBeanFactoryPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; // Invoke BeanDefinitionRegistryPostProcessors first, if any. Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;(); if (beanFactory instanceof BeanDefinitionRegistry) &#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;(); for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; BeanDefinitionRegistryPostProcessor registryProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; registryProcessor.postProcessBeanDefinitionRegistry(registry); registryProcessors.add(registryProcessor); &#125; else &#123; regularPostProcessors.add(postProcessor); &#125; &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let the bean factory post-processors apply to them! // Separate between BeanDefinitionRegistryPostProcessors that implement // PriorityOrdered, Ordered, and the rest. List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;(); // First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered. //执行BeanFactoryPostProcessor的方法: //1.获取所有的BeanDefinitionRegistryPostProcessor； String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; //2.先执行实现了PriorityOrdered优先级接口的BeanDefinitionRegistryPostProcessor if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); //3.执行BeanDefinitionRegistryPostProcessor方法 invokeBeanDefinitionRegistryPostProcessorBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered. postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; //4.在执行实现了Ordered顺序接口的BeanDefinitionRegistryPostProcessor； if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); // Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear. boolean reiterate = true; while (reiterate) &#123; reiterate = false; postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; //5.最后执行没有实现任何优先级或者是顺序接口的BeanDefinitionRegistryPostProcessors； postProcessor.postProcessBeanDefinitionRegistry(registry) if (!processedBeans.contains(ppName)) &#123; currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); reiterate = true; &#125; &#125; sortPostProcessors(currentRegistryProcessors, beanFactory); registryProcessors.addAll(currentRegistryProcessors); invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry); currentRegistryProcessors.clear(); &#125; // Now, invoke the postProcessBeanFactory callback of all processors handled so far. invokeBeanFactoryPostProcessors(registryProcessors, beanFactory); invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // Invoke factory processors registered with the context instance. invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let the bean factory post-processors apply to them! //再执行BeanFactoryPostProcessor的方法: //1.获取所有的BeanFactoryPostProcessor String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // Separate between BeanFactoryPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; if (processedBeans.contains(ppName)) &#123; // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered. sortPostProcessors(priorityOrderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // Next, invoke the BeanFactoryPostProcessors that implement Ordered. List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(orderedPostProcessorNames.size()); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; sortPostProcessors(orderedPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // Finally, invoke all other BeanFactoryPostProcessors. List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(nonOrderedPostProcessorNames.size()); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); // Clear cached merged bean definitions since the post-processors might have // modified the original metadata, e.g. replacing placeholders in values... beanFactory.clearMetadataCache();&#125; 12345678910/** * Invoke the given BeanDefinitionRegistryPostProcessor beans. */private static void invokeBeanDefinitionRegistryPostProcessors( Collection&lt;? extends BeanDefinitionRegistryPostProcessor&gt; postProcessors, BeanDefinitionRegistry registry) &#123; for (BeanDefinitionRegistryPostProcessor postProcessor : postProcessors) &#123; postProcessor.postProcessBeanDefinitionRegistry(registry); &#125;&#125; 注册BeanPostProcessor123protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; //1.获取所有的 BeanPostProcessor;后置处理器都默认可以通过PriorityOrdered、Ordered接口来执行优先级 //不同接口类型的BeanPostProcessor；在Bean创建前后的执行时机是不一样的 //BeanPostProcessor、 //DestructionAwareBeanPostProcessor、 //InstantiationAwareBeanPostProcessor、 //SmartInstantiationAwareBeanPostProcessor、 //MergedBeanDefinitionPostProcessor【internalPostProcessors】 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // Register BeanPostProcessorChecker that logs an info message when // a bean is created during BeanPostProcessor instantiation, i.e. when // a bean is not eligible for getting processed by all BeanPostProcessors. int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // Separate between BeanPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; //2.先注册PriorityOrdered优先级接口的BeanPostProcessor； if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, register the BeanPostProcessors that implement PriorityOrdered. sortPostProcessors(priorityOrderedPostProcessors, beanFactory); //把每一个BeanPostProcessor；添加到BeanFactory中 registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // Next, register the BeanPostProcessors that implement Ordered. //3.再注册Ordered接口的 List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : orderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; sortPostProcessors(orderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // Now, register all regular BeanPostProcessors. //4.最后注册没有实现任何优先级接口的 List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // Finally, re-register all internal BeanPostProcessors. sortPostProcessors(internalPostProcessors, beanFactory); //5.最终注册MergedBeanDefinitionPostProcessor； registerBeanPostProcessors(beanFactory, internalPostProcessors); // Re-register post-processor for detecting inner beans as ApplicationListeners, // moving it to the end of the processor chain (for picking up proxies etc). //6.注册一个ApplicationListenerDetector；来在Bean创建完成后检查是否是ApplicationListener //如果是，则添加 applicationContext.addApplicationListener((ApplicationListener&lt;?&gt;) bean); beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));&#125; 初始化MessageSource组件1234567891011121314151617181920212223242526272829303132333435363738/** * Initialize the MessageSource. * Use parent's if none defined in this context. *///（做国际化功能；消息绑定，消息解析）；protected void initMessageSource() &#123; //1.获取BeanFactory ConfigurableListableBeanFactory beanFactory = getBeanFactory(); //2.看容器中是否有id为messageSource的，类型是MessageSource的组件 if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) &#123; //如果有赋值给messageSource this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class); // Make MessageSource aware of parent MessageSource. if (this.parent != null &amp;&amp; this.messageSource instanceof HierarchicalMessageSource) &#123; HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource; if (hms.getParentMessageSource() == null) &#123; // Only set parent context as parent MessageSource if no parent MessageSource // registered already. hms.setParentMessageSource(getInternalParentMessageSource()); &#125; &#125; if (logger.isTraceEnabled()) &#123; logger.trace(\"Using MessageSource [\" + this.messageSource + \"]\"); &#125; &#125; else &#123; // Use empty MessageSource to be able to accept getMessage calls. //如果没有自己创建一个DelegatingMessageSource； DelegatingMessageSource dms = new DelegatingMessageSource(); dms.setParentMessageSource(getInternalParentMessageSource()); this.messageSource = dms; //3.把创建好的MessageSource注册在容器中，以后获取国际化配置文件的值的时候，可以自动注入MessageSource； beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource); if (logger.isTraceEnabled()) &#123; logger.trace(\"No '\" + MESSAGE_SOURCE_BEAN_NAME + \"' bean, using [\" + this.messageSource + \"]\"); &#125; &#125;&#125; 12345678910111213//取出国际化配置文件中的某个key的值；能按照区域信息获取；public interface MessageSource &#123; @Nullable String getMessage(String code, @Nullable Object[] args, @Nullable String defaultMessage, Locale locale); String getMessage(String code, @Nullable Object[] args, Locale locale) throws NoSuchMessageException; String getMessage(MessageSourceResolvable resolvable, Locale locale) throws NoSuchMessageException;&#125; 初始化事件派发器123456789101112131415161718192021222324252627/** * Initialize the ApplicationEventMulticaster. * Uses SimpleApplicationEventMulticaster if none defined in the context. * @see org.springframework.context.event.SimpleApplicationEventMulticaster */protected void initApplicationEventMulticaster() &#123; //1.获取BeanFactory ConfigurableListableBeanFactory beanFactory = getBeanFactory(); //2.从BeanFactory中获取applicationEventMulticaster的ApplicationEventMulticaster； if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); if (logger.isTraceEnabled()) &#123; logger.trace(\"Using ApplicationEventMulticaster [\" + this.applicationEventMulticaster + \"]\"); &#125; &#125; else &#123; //3.如果上一步没有配置；创建一个SimpleApplicationEventMulticaster this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); //4.将创建的ApplicationEventMulticaster添加到BeanFactory中，以后其他组件直接自动注入 beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); if (logger.isTraceEnabled()) &#123; logger.trace(\"No '\" + APPLICATION_EVENT_MULTICASTER_BEAN_NAME + \"' bean, using \" + \"[\" + this.applicationEventMulticaster.getClass().getSimpleName() + \"]\"); &#125; &#125;&#125; 初始化剩下指定的Bean1234567891011/** * Template method which can be overridden to add context-specific refresh work. * Called on initialization of special beans, before instantiation of singletons. * &lt;p&gt;This implementation is empty. * @throws BeansException in case of errors * @see #refresh() *///留给子容器（子类），子类重写这个方法，在容器刷新的时候可以自定义逻辑；protected void onRefresh() throws BeansException &#123; // For subclasses: do nothing by default.&#125; 注册ApplicationListener123456789101112131415161718192021222324252627282930/** * Add beans that implement ApplicationListener as listeners. * Doesn't affect other listeners, which can be added without being beans. */protected void registerListeners() &#123; // Register statically specified listeners first. for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! //1.从容器中拿到所有的ApplicationListener String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) &#123; //2.将每个监听器添加到事件派发器中； getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); &#125; // Publish early application events now that we finally have a multicaster... Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; if (!CollectionUtils.isEmpty(earlyEventsToProcess)) &#123; for (ApplicationEvent earlyEvent : earlyEventsToProcess) &#123; //3.派发之前步骤产生的事件； getApplicationEventMulticaster().multicastEvent(earlyEvent); &#125; &#125;&#125; 初始化所有剩下的单实例bean；1234567891011121314151617181920212223242526272829303132333435/** * Finish the initialization of this context's bean factory, * initializing all remaining singleton beans. */protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // Initialize conversion service for this context. if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal)); &#125; // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. //主要看这个方法 beanFactory.preInstantiateSingletons();&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Overridepublic void preInstantiateSingletons() throws BeansException &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Pre-instantiating singletons in \" + this); &#125; // Iterate over a copy to allow for init methods which in turn register new bean definitions. // While this may not be part of the regular factory bootstrap, it does otherwise work fine. //1.获取容器中的所有Bean，依次进行初始化和创建对象 List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // Trigger initialization of all non-lazy singleton beans... for (String beanName : beanNames) &#123; //2.获取Bean的定义信息；RootBeanDefinition RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); //3.Bean不是抽象的，是单实例的，不是懒加载； if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; //3.1 判断是否是FactoryBean；是否是实现FactoryBean接口的Bean； instanceof FactoryBean if (isFactoryBean(beanName)) &#123; Object bean = getBean(FACTORY_BEAN_PREFIX + beanName); if (bean instanceof FactoryBean) &#123; FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean; boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged( (PrivilegedAction&lt;Boolean&gt;) ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; getBean(beanName); &#125; &#125; &#125; else &#123; //3.2 是工厂Bean。利用getBean(beanName);创建对象 getBean(beanName); &#125; &#125; &#125; //4.所有Bean都利用getBean创建完成以后； //检查所有的Bean是否是SmartInitializingSingleton接口的；如果是；就执行afterSingletonsInstantiated()；(EnventListener) // Trigger post-initialization callback for all applicable beans... for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125;, getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172@SuppressWarnings(\"unchecked\")protected &lt;T&gt; T doGetBean( String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. //1.先获取缓存中保存的单实例Bean。如果能获取到说明这个Bean之前被创建过（所有创建过的单实例Bean都会被缓存起来） //当出现循环引用时，依靠它当中的三级缓存获取未完全初始化完成的半成品对象 Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isTraceEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.trace(\"Returning eagerly cached instance of singleton bean '\" + beanName + \"' that is not fully initialized yet - a consequence of a circular reference\"); &#125; else &#123; logger.trace(\"Returning cached instance of singleton bean '\" + beanName + \"'\"); &#125; &#125; bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // Fail if we're already creating this bean instance: // We're assumably within a circular reference. if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // Check if bean definition exists in this factory. //2.缓存中获取不到，开始Bean的创建对象流程； BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &#123; return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); &#125; else if (args != null) &#123; // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else if (requiredType != null) &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; else &#123; return (T) parentBeanFactory.getBean(nameToLookup); &#125; &#125; if (!typeCheckOnly) &#123; //3.标记当前bean已经被创建,避免多线程重复创建 markBeanAsCreated(beanName); &#125; try &#123; //4.获取Bean的定义信息； RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. //5.获取当前Bean依赖的其他Bean;如果有按照getBean()把依赖的Bean先创建出来； String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dep + \"'\"); &#125; registerDependentBean(dep, beanName); try &#123; getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"'\" + beanName + \"' depends on missing bean '\" + dep + \"'\", ex); &#125; &#125; &#125; // Create bean instance. if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; //6.启动单实例Bean的创建流程； //7.将创建的Bean添加到缓存中singletonObjects； //ioc容器就是这些Map；很多的Map里面保存了单实例Bean，环境信息。。。。； return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); if (!StringUtils.hasLength(scopeName)) &#123; throw new IllegalStateException(\"No scope name defined for bean ´\" + beanName + \"'\"); &#125; Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, () -&gt; &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // Check if required type matches the type of the actual bean instance. if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; return convertedBean; &#125; catch (TypeMismatchException ex) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Failed to convert bean '\" + name + \"' to required type '\" + ClassUtils.getQualifiedName(requiredType) + \"'\", ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Creating instance of bean '\" + beanName + \"'\"); &#125; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // Prepare method overrides. try &#123; mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, \"Validation of method overrides failed\", ex); &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. //1.让BeanPostProcessor先拦截返回代理对象； //【InstantiationAwareBeanPostProcessor】：提前执行； //先触发：postProcessBeforeInstantiation()； //如果有返回值：触发postProcessAfterInitialization()； Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, \"BeanPostProcessor before instantiation of bean failed\", ex); &#125; try &#123; Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isTraceEnabled()) &#123; logger.trace(\"Finished creating instance of bean '\" + beanName + \"'\"); &#125; return beanInstance; &#125; catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) &#123; // A previously detected exception with proper bean creation context already, // or illegal singleton state to be communicated up to DefaultSingletonBeanRegistry. throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException( mbdToUse.getResourceDescription(), beanName, \"Unexpected exception during bean creation\", ex); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; //1.利用工厂方法或者对象的构造器创建出Bean实例； instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; //2.允许后置处理器修改Bean定义 //调用【MergedBeanDefinitionPostProcessor.postProcessMergedBeanDefinition】 applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Post-processing of merged bean definition failed\", ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Eagerly caching bean '\" + beanName + \"' to allow for resolving potential circular references\"); &#125; addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; //3.Bean属性赋值 populateBean(beanName, mbd, instanceWrapper); //4.Bean初始化 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Initialization of bean failed\", ex); &#125; &#125; if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, \"Bean with name '\" + beanName + \"' has been injected into other beans [\" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + \"] in its raw version as part of a circular reference, but has eventually been \" + \"wrapped. This means that said other beans do not use the final version of the \" + \"bean. This is often the result of over-eager type matching - consider using \" + \"'getBeanNamesForType' with the 'allowEagerInit' flag turned off, for example.\"); &#125; &#125; &#125; &#125; // Register bean as disposable. try &#123; //5.注册Bean的销毁方法；只是注册，IOC容器关闭时未调用 registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Invalid destruction signature\", ex); &#125; return exposedObject;&#125; 12345678910//允许后置处理器修改Bean定义protected void applyMergedBeanDefinitionPostProcessors(RootBeanDefinition mbd, Class&lt;?&gt; beanType, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; //调用【MergedBeanDefinitionPostProcessor.postProcessMergedBeanDefinition】 if (bp instanceof MergedBeanDefinitionPostProcessor) &#123; MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp; bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123; if (bw == null) &#123; if (mbd.hasPropertyValues()) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, \"Cannot apply property values to null instance\"); &#125; else &#123; // Skip property population phase for null instance. return; &#125; &#125; // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the // state of the bean before properties are set. This can be used, for example, // to support styles of field injection. if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; //拿到InstantiationAwareBeanPostProcessor后置处理器调用【postProcessAfterInstantiation()】； if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; return; &#125; &#125; &#125; &#125; PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); int resolvedAutowireMode = mbd.getResolvedAutowireMode(); if (resolvedAutowireMode == AUTOWIRE_BY_NAME || resolvedAutowireMode == AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. if (resolvedAutowireMode == AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // Add property values based on autowire by type if applicable. if (resolvedAutowireMode == AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE); PropertyDescriptor[] filteredPds = null; if (hasInstAwareBpps) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; //拿到InstantiationAwareBeanPostProcessor后置处理器调用【postProcessPropertyValues()；】 InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvsToUse == null) &#123; return; &#125; &#125; pvs = pvsToUse; &#125; &#125; &#125; if (needsDepCheck) &#123; if (filteredPds == null) &#123; filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); &#125; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; if (pvs != null) &#123; //应用Bean属性的值；为属性利用setter方法等进行赋值； applyPropertyValues(beanName, mbd, bw, pvs); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; invokeAwareMethods(beanName, bean); return null; &#125;, getAccessControlContext()); &#125; else &#123; //1.执行Aware接口方法 //BeanNameAware\\BeanClassLoaderAware\\BeanFactoryAware invokeAwareMethods(beanName, bean); &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; //2.执行后置处理器初始化之前 //BeanPostProcessor.postProcessBeforeInitialization（）; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; //3.执行初始化方法 invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; //4.执行后置处理器初始化之后 //BeanPostProcessor.postProcessAfterInitialization()； wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 12345678910111213141516171819202122232425262728293031323334protected void invokeInitMethods(String beanName, Object bean, @Nullable RootBeanDefinition mbd) throws Throwable &#123; //是否是InitializingBean接口的实现；执行接口规定的初始化； boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(\"Invoking afterPropertiesSet() on bean with name '\" + beanName + \"'\"); &#125; if (System.getSecurityManager() != null) &#123; try &#123; AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) () -&gt; &#123; ((InitializingBean) bean).afterPropertiesSet(); return null; &#125;, getAccessControlContext()); &#125; catch (PrivilegedActionException pae) &#123; throw pae.getException(); &#125; &#125; else &#123; ((InitializingBean) bean).afterPropertiesSet(); &#125; &#125; if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) &#123; //是否自定义初始化方法； String initMethodName = mbd.getInitMethodName(); if (StringUtils.hasLength(initMethodName) &amp;&amp; !(isInitializingBean &amp;&amp; \"afterPropertiesSet\".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) &#123; invokeCustomInitMethod(beanName, bean, mbd); &#125; &#125;&#125; 完成BeanFactory的初始化工作12345678910111213141516171819protected void finishRefresh() &#123; // Clear context-level resource caches (such as ASM metadata from scanning). clearResourceCaches(); //1.初始化和生命周期有关的后置处理器【LifecycleProcessor】 // Initialize lifecycle processor for this context. initLifecycleProcessor(); // Propagate refresh to lifecycle processor first. //2.拿到前面定义的生命周期处理器（BeanFactory）；回调onRefresh()； getLifecycleProcessor().onRefresh(); // Publish the final event. //3.发布容器刷新完成事件； publishEvent(new ContextRefreshedEvent(this)); // Participate in LiveBeansView MBean, if active. LiveBeansView.registerApplicationContext(this);&#125; 1234567891011121314151617181920212223protected void initLifecycleProcessor() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); //实现【LifecycleProcessor】接口【void onRefresh();void onClose();】 if (beanFactory.containsLocalBean(LIFECYCLE_PROCESSOR_BEAN_NAME)) &#123; this.lifecycleProcessor = beanFactory.getBean(LIFECYCLE_PROCESSOR_BEAN_NAME, LifecycleProcessor.class); if (logger.isTraceEnabled()) &#123; logger.trace(\"Using LifecycleProcessor [\" + this.lifecycleProcessor + \"]\"); &#125; &#125; else &#123; //默认从容器中找是否有lifecycleProcessor的组件【LifecycleProcessor】； //如果没有，则new DefaultLifecycleProcessor();加入到容器； DefaultLifecycleProcessor defaultProcessor = new DefaultLifecycleProcessor(); defaultProcessor.setBeanFactory(beanFactory); this.lifecycleProcessor = defaultProcessor; beanFactory.registerSingleton(LIFECYCLE_PROCESSOR_BEAN_NAME, this.lifecycleProcessor); if (logger.isTraceEnabled()) &#123; logger.trace(\"No '\" + LIFECYCLE_PROCESSOR_BEAN_NAME + \"' bean, using \" + \"[\" + this.lifecycleProcessor.getClass().getSimpleName() + \"]\"); &#125; &#125;&#125; 总结 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167Spring容器的refresh()【创建刷新】;1、prepareRefresh()刷新前的预处理; 1）、initPropertySources()初始化一些属性设置;子类自定义个性化的属性设置方法； 2）、getEnvironment().validateRequiredProperties();检验属性的合法等 3）、earlyApplicationEvents= new LinkedHashSet&lt;ApplicationEvent&gt;();保存容器中的一些早期的事件；2、obtainFreshBeanFactory();获取BeanFactory； 1）、refreshBeanFactory();刷新【创建】BeanFactory； 创建了一个this.beanFactory = new DefaultListableBeanFactory(); 设置id； 2）、getBeanFactory();返回刚才GenericApplicationContext创建的BeanFactory对象； 3）、将创建的BeanFactory【DefaultListableBeanFactory】返回；3、prepareBeanFactory(beanFactory);BeanFactory的预准备工作（BeanFactory进行一些设置）； 1）、设置BeanFactory的类加载器、支持表达式解析器... 2）、添加部分BeanPostProcessor【ApplicationContextAwareProcessor】 3）、设置忽略的自动装配的接口EnvironmentAware、EmbeddedValueResolverAware、xxx； 4）、注册可以解析的自动装配；我们能直接在任何组件中自动注入： BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext 5）、添加BeanPostProcessor【ApplicationListenerDetector】 6）、添加编译时的AspectJ； 7）、给BeanFactory中注册一些能用的组件； environment【ConfigurableEnvironment】、 systemProperties【Map&lt;String, Object&gt;】、 systemEnvironment【Map&lt;String, Object&gt;】4、postProcessBeanFactory(beanFactory);BeanFactory准备工作完成后进行的后置处理工作； 1）、子类通过重写这个方法来在BeanFactory创建并预准备完成以后做进一步的设置======================以上是BeanFactory的创建及预准备工作==================================5、invokeBeanFactoryPostProcessors(beanFactory);执行BeanFactoryPostProcessor的方法； BeanFactoryPostProcessor：BeanFactory的后置处理器。在BeanFactory标准初始化之后执行的； 两个接口：BeanFactoryPostProcessor、BeanDefinitionRegistryPostProcessor 1）、执行BeanFactoryPostProcessor的方法； 先执行BeanDefinitionRegistryPostProcessor 1）、获取所有的BeanDefinitionRegistryPostProcessor； 2）、看先执行实现了PriorityOrdered优先级接口的BeanDefinitionRegistryPostProcessor、 postProcessor.postProcessBeanDefinitionRegistry(registry) 3）、在执行实现了Ordered顺序接口的BeanDefinitionRegistryPostProcessor； postProcessor.postProcessBeanDefinitionRegistry(registry) 4）、最后执行没有实现任何优先级或者是顺序接口的BeanDefinitionRegistryPostProcessors； postProcessor.postProcessBeanDefinitionRegistry(registry) 再执行BeanFactoryPostProcessor的方法 1）、获取所有的BeanFactoryPostProcessor 2）、看先执行实现了PriorityOrdered优先级接口的BeanFactoryPostProcessor、 postProcessor.postProcessBeanFactory() 3）、在执行实现了Ordered顺序接口的BeanFactoryPostProcessor； postProcessor.postProcessBeanFactory() 4）、最后执行没有实现任何优先级或者是顺序接口的BeanFactoryPostProcessor； postProcessor.postProcessBeanFactory()6、registerBeanPostProcessors(beanFactory);注册BeanPostProcessor（Bean的后置处理器）【 intercept bean creation】 不同接口类型的BeanPostProcessor；在Bean创建前后的执行时机是不一样的 BeanPostProcessor、 DestructionAwareBeanPostProcessor、 InstantiationAwareBeanPostProcessor、 SmartInstantiationAwareBeanPostProcessor、 MergedBeanDefinitionPostProcessor【internalPostProcessors】、 1）、获取所有的 BeanPostProcessor;后置处理器都默认可以通过PriorityOrdered、Ordered接口来执行优先级 2）、先注册PriorityOrdered优先级接口的BeanPostProcessor； 把每一个BeanPostProcessor；添加到BeanFactory中 beanFactory.addBeanPostProcessor(postProcessor); 3）、再注册Ordered接口的 4）、最后注册没有实现任何优先级接口的 5）、最终注册MergedBeanDefinitionPostProcessor； 6）、注册一个ApplicationListenerDetector；来在Bean创建完成后检查是否是ApplicationListener，如果是 applicationContext.addApplicationListener((ApplicationListener&lt;?&gt;) bean);7、initMessageSource();初始化MessageSource组件（做国际化功能；消息绑定，消息解析）； 1）、获取BeanFactory 2）、看容器中是否有id为messageSource的，类型是MessageSource的组件 如果有赋值给messageSource，如果没有自己创建一个DelegatingMessageSource； MessageSource：取出国际化配置文件中的某个key的值；能按照区域信息获取； 3）、把创建好的MessageSource注册在容器中，以后获取国际化配置文件的值的时候，可以自动注入MessageSource； beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource); MessageSource.getMessage(String code, Object[] args, String defaultMessage, Locale locale);8、initApplicationEventMulticaster();初始化事件派发器； 1）、获取BeanFactory 2）、从BeanFactory中获取applicationEventMulticaster的ApplicationEventMulticaster； 3）、如果上一步没有配置；创建一个SimpleApplicationEventMulticaster 4）、将创建的ApplicationEventMulticaster添加到BeanFactory中，以后其他组件直接自动注入9、onRefresh();留给子容器（子类） 1、子类重写这个方法，在容器刷新的时候可以自定义逻辑；10、registerListeners();给容器中将所有项目里面的ApplicationListener注册进来； 1、从容器中拿到所有的ApplicationListener 2、将每个监听器添加到事件派发器中； getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); 3、派发之前步骤产生的事件；11、finishBeanFactoryInitialization(beanFactory);初始化所有剩下的单实例bean； 1、beanFactory.preInstantiateSingletons();初始化后剩下的单实例bean 1）、获取容器中的所有Bean，依次进行初始化和创建对象 2）、获取Bean的定义信息；RootBeanDefinition 3）、Bean不是抽象的，是单实例的，是懒加载； 1）、判断是否是FactoryBean；是否是实现FactoryBean接口的Bean； 2）、不是工厂Bean。利用getBean(beanName);创建对象 0、getBean(beanName)； ioc.getBean(); 1、doGetBean(name, null, null, false); 2、先获取缓存中保存的单实例Bean。如果能获取到说明这个Bean之前被创建过（所有创建过的单实例Bean都会被缓存起来） 从private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);获取的 3、缓存中获取不到，开始Bean的创建对象流程； 4、标记当前bean已经被创建 5、获取Bean的定义信息； 6、【获取当前Bean依赖的其他Bean;如果有按照getBean()把依赖的Bean先创建出来；】 7、启动单实例Bean的创建流程； 1）、createBean(beanName, mbd, args); 2）、Object bean = resolveBeforeInstantiation(beanName, mbdToUse);让BeanPostProcessor先拦截返回代理对象； 【InstantiationAwareBeanPostProcessor】：提前执行； 先触发：postProcessBeforeInstantiation()； 如果有返回值：触发postProcessAfterInitialization()； 3）、如果前面的InstantiationAwareBeanPostProcessor没有返回代理对象；调用4） 4）、Object beanInstance = doCreateBean(beanName, mbdToUse, args);创建Bean 1）、【创建Bean实例】；createBeanInstance(beanName, mbd, args); 利用工厂方法或者对象的构造器创建出Bean实例； 2）、applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); 调用MergedBeanDefinitionPostProcessor的postProcessMergedBeanDefinition(mbd, beanType, beanName); 3）、【Bean属性赋值】populateBean(beanName, mbd, instanceWrapper); 赋值之前： 1）、拿到InstantiationAwareBeanPostProcessor后置处理器； postProcessAfterInstantiation()； 2）、拿到InstantiationAwareBeanPostProcessor后置处理器； postProcessPropertyValues()； =====赋值之前：=== 3）、应用Bean属性的值；为属性利用setter方法等进行赋值； applyPropertyValues(beanName, mbd, bw, pvs); 4）、【Bean初始化】initializeBean(beanName, exposedObject, mbd); 1）、【执行Aware接口方法】invokeAwareMethods(beanName, bean);执行xxxAware接口的方法 BeanNameAware\\BeanClassLoaderAware\\BeanFactoryAware 2）、【执行后置处理器初始化之前】applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); BeanPostProcessor.postProcessBeforeInitialization（）; 3）、【执行初始化方法】invokeInitMethods(beanName, wrappedBean, mbd); 1）、是否是InitializingBean接口的实现；执行接口规定的初始化； 2）、是否自定义初始化方法； 4）、【执行后置处理器初始化之后】applyBeanPostProcessorsAfterInitialization BeanPostProcessor.postProcessAfterInitialization()； 5）、注册Bean的销毁方法； 5）、将创建的Bean添加到缓存中singletonObjects； ioc容器就是这些Map；很多的Map里面保存了单实例Bean，环境信息。。。。； 所有Bean都利用getBean创建完成以后； 检查所有的Bean是否是SmartInitializingSingleton接口的；如果是；就执行afterSingletonsInstantiated()；12、finishRefresh();完成BeanFactory的初始化创建工作；IOC容器就创建完成； 1）、initLifecycleProcessor();初始化和生命周期有关的后置处理器；LifecycleProcessor 默认从容器中找是否有lifecycleProcessor的组件【LifecycleProcessor】；如果没有new DefaultLifecycleProcessor(); 加入到容器； 写一个LifecycleProcessor的实现类，可以在BeanFactory void onRefresh(); void onClose(); 2）、 getLifecycleProcessor().onRefresh(); 拿到前面定义的生命周期处理器（BeanFactory）；回调onRefresh()； 3）、publishEvent(new ContextRefreshedEvent(this));发布容器刷新完成事件； 4）、liveBeansView.registerApplicationContext(this); ======总结=========== 1）、Spring容器在启动的时候，先会保存所有注册进来的Bean的定义信息； 1）、xml注册bean；&lt;bean&gt; 2）、注解注册Bean；@Service、@Component、@Bean、xxx 2）、Spring容器会合适的时机创建这些Bean 1）、用到这个bean的时候；利用getBean创建bean；创建好以后保存在容器中； 2）、统一创建剩下所有的bean的时候；finishBeanFactoryInitialization()； 3）、后置处理器；BeanPostProcessor 1）、每一个bean创建完成，都会使用各种后置处理器进行处理；来增强bean的功能； AutowiredAnnotationBeanPostProcessor:处理自动注入 AnnotationAwareAspectJAutoProxyCreator:来做AOP功能； xxx.... 增强的功能注解： AsyncAnnotationBeanPostProcessor .... 4）、事件驱动模型； ApplicationListener；事件监听； ApplicationEventMulticaster；事件派发： 整体的动态代理体系流程 “本篇文章主要摘自参考资料”","categories":[{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/tags/Spring/"}]},{"title":"'响应式web'","slug":"reactor-webflux","date":"2020-10-21T14:30:00.000Z","updated":"2020-11-30T13:50:05.023Z","comments":true,"path":"2020/10/21/reactor-webflux/","link":"","permalink":"https://midkuro.gitee.io/2020/10/21/reactor-webflux/","excerpt":"","text":"响应式web长轮训短轮询去服务端查询的时候，不管库存量有没有变化，服务器就立即返回结果了。 长轮询则不是，在长轮询中，服务器如果检测到库存量没有变化的话，将会把当前请求挂起一段时间（这个时间也叫作超时时间，一般是90秒）。在这个时间里，服务器会去检测库存量有没有变化，检测到变化就立即返回，否则就一直等到超时为止。 而对于客户端来说，不管是长轮询还是短轮询，客户端的动作都是一样的，就是不停的去请求，不同的是服务端，短轮询情况下服务端每次请求不管有没有变化都会立即返回结果，而长轮询情况下，如果有变化才会立即返回结果，而没有变化的话，则不会再立即给客户端返回结果，直到超时为止。 背压 Backpressure在数据流从上游生产者向下游消费者传输的过程中，上游生产速度大于下游消费速度，导致下游的 Buffer 溢出，这种现象就叫做 Backpressure 出现。 SSE所谓的SSE(Sever-Sent Event),就是浏览器向服务器发送了一个HTTP请求，保持长连接，服务器不断单向地向浏览器推送“信息”，这么做是为了节省网络资源，不用一直发请求，建立新连接。 它是基于HTTP协议通信的。JS基于EventSource实现，后台基于text/event-stream;charset=utf-8。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@RestController@RequestMapping(path = \"/sse\")public class SseRest &#123; private static Map&lt;String, SseEmitter&gt; sseCache = new ConcurrentHashMap&lt;&gt;(); @GetMapping(path = \"/subscribe\") public SseEmitter subscribe(String id) &#123; // 超时时间设置为1小时 SseEmitter sseEmitter = new SseEmitter(3600000L); sseCache.put(id, sseEmitter); // 超时回调 触发 sseEmitter.onTimeout(() -&gt; sseCache.remove(id)); // 结束之后的回调触发 sseEmitter.onCompletion(() -&gt; System.out.println(\"完成！！！\")); return sseEmitter; &#125; @GetMapping(path = \"/push\") public String push(String id, String content) throws IOException &#123; SseEmitter sseEmitter = sseCache.get(id); if (sseEmitter != null) &#123; // 发送消息 sseEmitter.send(content); &#125; return \"over\"; &#125; @GetMapping(path = \"over\") public String over(String id) &#123; SseEmitter sseEmitter = sseCache.get(id); if (sseEmitter != null) &#123; // 执行完毕，断开连接 sseEmitter.complete(); sseCache.remove(id); &#125; return \"over\"; &#125; @GetMapping(path = \"/push-all\") public String pushAll(String content) throws IOException &#123; for (String s : sseCache.keySet()) &#123; SseEmitter sseEmitter = sseCache.get(s); if (sseEmitter != null) &#123; // 发送消息 sseEmitter.send(content); &#125; &#125; return \"over\"; &#125;&#125; 1234567891011121314151617181920212223242526272829&lt;!-- user1.html--&gt;&lt;!doctype html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;!-- for HTML5 --&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /&gt; &lt;title&gt;Sse测试文档&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;sse 测试&lt;/div&gt;&lt;div id=\"result\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;&lt;script&gt; var source = new EventSource('http://localhost/sse/subscribe?id=user1'); source.onmessage = function (event) &#123; text = document.getElementById('result').innerText; text += '\\n' + event.data; document.getElementById('result').innerText = text; &#125;; &lt;!-- 添加一个开启回调 --&gt; source.onopen = function (event) &#123; text = document.getElementById('result').innerText; text += '\\n 开启: '; console.log(event); document.getElementById('result').innerText = text; &#125;;&lt;/script&gt; 12345678910111213141516171819202122232425262728293031&lt;!-- user2.html--&gt;&lt;!doctype html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;!-- for HTML5 --&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /&gt; &lt;title&gt;Sse测试文档&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;sse 测试&lt;/div&gt;&lt;div id=\"result\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;&lt;script&gt;&lt;!-- H5 里的对象 --&gt; var source = new EventSource('http://localhost/sse/subscribe?id=user2'); source.onmessage = function (event) &#123; text = document.getElementById('result').innerText; text += '\\n' + event.data; document.getElementById('result').innerText = text; &#125;; &lt;!-- 添加一个开启回调 --&gt; source.onopen = function (event) &#123; text = document.getElementById('result').innerText; text += '\\n 开启: '; console.log(event); document.getElementById('result').innerText = text; &#125;;&lt;/script&gt; RXJava21234&lt;dependency&gt; &lt;groupId&gt;io.reactivex.rxjava2&lt;/groupId&gt; &lt;artifactId&gt;rxjava&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class RXJavaTest &#123; // 同步 public static void main(String[] args) &#123; // Observable 被观察者 Observable&lt;String&gt; girl = Observable.create(new ObservableOnSubscribe&lt;String&gt;() &#123; // emitter 发射器，发射体 @Override public void subscribe(ObservableEmitter&lt;String&gt; emitter) throws Exception &#123; // onNext可以 无限次调用 System.out.println(Thread.currentThread().getName()); emitter.onNext(\"1\"); Thread.sleep(1000); System.out.println(Thread.currentThread().getName()); emitter.onNext(\"2\"); Thread.sleep(1000); System.out.println(Thread.currentThread().getName()); emitter.onNext(\"3\"); Thread.sleep(1000); emitter.onNext(\"4\"); Thread.sleep(1000); emitter.onNext(\"5\"); Thread.sleep(1000); emitter.onComplete(); &#125; &#125;); // Observer 观察者 Observer&lt;String&gt; man = new Observer&lt;String&gt;() &#123; @Override public void onSubscribe(Disposable d) &#123; // TODO Auto-generated method stub System.out.println(\"onSubscribe\" + d); &#125; @Override public void onNext(String t) &#123; // TODO Auto-generated method stub System.out.println(Thread.currentThread().getName()); System.out.println(\"onNext \" + t); &#125; @Override public void onError(Throwable e) &#123; // TODO Auto-generated method stub System.out.println(\"onError \" + e.getMessage()); &#125; @Override public void onComplete() &#123; // TODO Auto-generated method stub System.out.println(\"onComplete\"); &#125; &#125;; girl.subscribe(man); &#125;&#125; 方法 说明 Schedulers.computation() 适用于计算密集型任务 Schedulers.io() 适用于 IO 密集型任务 Schedulers.trampoline() 在某个调用 schedule 的线程执行 Schedulers.newThread() 每个 Worker 对应一个新线程 Schedulers.single() 所有 Worker 使用同一个线程执行任务 Schedulers.from(Executor) 使用 Executor 作为任务执行的线程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class RXJavaTest2 &#123; // 异步 public static void main(String[] args) throws InterruptedException &#123; // 被观察者 Observable.create(new ObservableOnSubscribe&lt;String&gt;() &#123; @Override public void subscribe(ObservableEmitter&lt;String&gt; emitter) throws Exception &#123; emitter.onNext(\"1\"); emitter.onNext(\"2\"); emitter.onNext(\"3\"); emitter.onNext(\"4\"); emitter.onNext(\"5\"); emitter.onComplete(); &#125; &#125;) // 哪个线程是观察者 .observeOn( Schedulers.computation() ) .subscribeOn( Schedulers.computation()) .subscribe(new Observer&lt;String&gt;() &#123; @Override public void onSubscribe(Disposable d) &#123; System.out.println(\"onSubscribe...\"); &#125; @Override public void onNext(String t) &#123; System.out.println(\"onNext\"); &#125; @Override public void onError(Throwable e) &#123; System.out.println(\"onError\"); &#125; @Override public void onComplete() &#123; System.out.println(\"onComplete\"); &#125; &#125;) ; Thread.sleep(10000); &#125;&#125; Reactor 响应式编程能够防止雪崩 Flux1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// 静态方法生成FluxString[] s = new String[] &#123;\"xx\",\"oo\"&#125;;// just 已知元素数量和内容 使用// Flux&lt;String&gt; flux1 = Flux.just(s);// flux1.subscribe(System.out::println);Flux&lt;String&gt; flux2 = Flux.just(\"xx\",\"xxx\");// flux2.subscribe(System.out::println);//fromArray方法List&lt;String&gt; list = Arrays.asList(\"hello\", \"world\");Flux&lt;String&gt; flux3 = Flux.fromIterable(list);// flux3.subscribe(System.out::println);//fromStream方法Stream&lt;String&gt; stream = Stream.of(\"hi\", \"hello\");Flux&lt;String&gt; flux4 = Flux.fromStream(stream);// flux4.subscribe(System.out::println);//range方法Flux&lt;Integer&gt; range = Flux.range(0, 5);// range.subscribe(System.out::println);//interval方法, take方法限制个数为5个Flux&lt;Long&gt; longFlux = Flux.interval(Duration.ofSeconds(1)).take(5);longFlux.subscribe(System.out::println);//链式Flux.range(1, 5).subscribe(System.out::println);// 合并Flux&lt;String&gt; mergeWith = flux3.mergeWith(flux4);mergeWith.subscribe(System.out::println);System.out.println(\"---\");// 结合为元祖Flux&lt;String&gt; source1 = Flux.just(\"111\", \"world\",\"333\");Flux&lt;String&gt; source2 = Flux.just(\"2111\", \"xxx\");Flux&lt;Tuple2&lt;String, String&gt;&gt; zip = source1.zipWith(source2);zip.subscribe(tuple -&gt; &#123; System.out.println(tuple.getT1() + \" -&gt; \" + tuple.getT2());&#125;); 12345678// 同步动态创建，next 只能被调用一次Flux.generate(sink -&gt; &#123; sink.next(\"xx\"); sink.complete();&#125;).subscribe(System.out::print);&#125; 1234567891011//异步动态创建Flux.create(sink -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; sink.next(\"xxoo:\" + i); &#125; sink.complete();&#125;).subscribe(System.out::println); Mono12345678910111213141516@Servicepublic class PersonService &#123; static ConcurrentHashMap&lt;Integer, Person&gt; map = new ConcurrentHashMap&lt;&gt;(); static &#123; for (int i = 0; i &lt; 100; i++) &#123; Person person = new Person(); person.setId(i); person.setName(\"yangchaoyue\" + i); map.put(i, person); &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445@RestController@RequestMapping(\"/person\")public class PersonController &#123; @Autowired PersonService personSrv; @GetMapping(\"\") Mono&lt;Object&gt; get(String name)&#123; System.out.println(\"线程 get\" + Thread.currentThread().getName()); System.out.println(\"---1\"); // 异步 Mono&lt;Object&gt; mono = Mono.create(sink -&gt; &#123; // 组装数据序列 System.out.println(\"线程 create\" + Thread.currentThread().getName()); sink.success(personSrv.getPerson()); &#125;) .doOnSubscribe(sub -&gt; &#123; // 1 订阅 System.out.println(\"xxx\"); &#125;) .doOnNext(data -&gt; &#123; // 得到数据 System.out.println(\"data:\" + data); &#125;) .doOnSuccess(onSuccess -&gt; &#123; // 整体完成 System.out.println(\"onSuccess\"); &#125;); System.out.println(\"---2\"); // SpringMvc 值 在这个环节准备好 // 得到一个包装 数据序列 -&gt; 包含特征 -&gt; 容器 拿到这个序列 -&gt; 执行序列里的方法 // Ajax a() -&gt; b(c()) -&gt; // 1, 写回调接口 ， 让b调 // 2, 直接传方法过去 // 看起来 像是异步，实质上，阻塞的过程 在容器内部 return mono; &#125;&#125; 123456789输出（同一个线程运行）：线程 getreactor-http-nio-3---1---2xxx线程 createreactor-http-nio-3线程 getPersonreactor-http-nio-3data:com.mashibing.admin.pojo.Person@577e0635onSuccess 1234567891011121314151617@GetMapping(\"xxoo\")// ServerHttpRequest webFlux 中特有// 拓展思维，SpringCloud Gateway//没有HttpServlet，request里也没有sesionMono&lt;Object&gt; get2(ServerHttpRequest request,String name,WebSession session)&#123; if(StringUtils.isEmpty(session.getAttribute(\"code\"))) &#123; System.out.println(\"需要这样设置session值\"); session.getAttributes().put(\"code\", 250); &#125; //需要这样设置属性 request.getQueryParams().add(\"key\",\"value\"); System.out.println(\"code = \" + session.getAttribute(\"code\")); return Mono.just(\"么么哒\");&#125; 1234567891011121314151617181920212223242526//基于webFlux和netty的响应式编程SSE@GetMapping(value = \"/sse\", produces = MediaType.TEXT_EVENT_STREAM_VALUE)public Flux&lt;String&gt; sse()&#123; // 1. 封装对象 Flux&lt;String&gt; flux = Flux.fromStream(IntStream.range(1, 10).mapToObj(i -&gt; &#123; try &#123; Thread.sleep(new Random().nextInt(3000)); &#125; catch (InterruptedException e) &#123; &#125; return \"xxoo\" + i; &#125;)) .doOnSubscribe(sub -&gt; &#123; System.out.println(\"sub 了\"); &#125;) .doOnComplete(() -&gt; &#123; System.out.println(\"doOnComplete\"); &#125;) .doOnNext(data -&gt; &#123; System.out.println(\"有data了~\" + data); &#125;) ; // 2. 对象 连带里面的方法 给了容器 return flux;&#125; WebFlux","categories":[{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/tags/Spring/"}]},{"title":"'Spring的扩展原理'","slug":"spring-extends","date":"2020-10-21T14:30:00.000Z","updated":"2020-10-17T14:51:48.549Z","comments":true,"path":"2020/10/21/spring-extends/","link":"","permalink":"https://midkuro.gitee.io/2020/10/21/spring-extends/","excerpt":"","text":"Spring扩展原理BeanFactoryPostProcessor BeanPostProcessor：bean后置处理器，bean创建对象初始化前后进行拦截工作的 BeanFactoryPostProcessor：beanFactory的后置处理器； 在BeanFactory标准初始化之后调用，来定制和修改BeanFactory的内容； 所有的bean定义已经保存加载到beanFactory，但是bean的实例还未创建 1234567891011121314@FunctionalInterfacepublic interface BeanFactoryPostProcessor &#123; /** * Modify the application context's internal bean factory after its standard * initialization. All bean definitions will have been loaded, but no beans * will have been instantiated yet. This allows for overriding or adding * properties even to eager-initializing beans. * @param beanFactory the bean factory used by the application context * @throws org.springframework.beans.BeansException in case of errors */ void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; 1234567891011121314//自定义的BeanFactoryPostProcessor@Componentpublic class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println(\"MyBeanFactoryPostProcessor...postProcessBeanFactory...\"); int count = beanFactory.getBeanDefinitionCount(); String[] names = beanFactory.getBeanDefinitionNames(); System.out.println(\"当前BeanFactory中有\"+count+\" 个Bean\"); System.out.println(Arrays.asList(names)); &#125;&#125; 原理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667//AnnotationConfigApplicationContext.refresh()//1.IOC容器创建对象@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); //2.执行BeanFactoryPostProcessors // Invoke factory processors registered as beans in the context. //3.和registerBeanPostProcessors相同，按顺序执行实现了PriorityOrdered、Ordered、NonOrdered的对象 invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); //4.执行BeanFactoryPostProcessors在初始化创建其他组件前面执行 // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; BeanDefinitionRegistryPostProcessorBeanDefinitionRegistryPostProcessor继承BeanFactoryPostProcessor ``BeanFactoryPostProcessor是在**所有的bean定义已经保存加载到beanFactory`**之后调用 BeanDefinitionRegistryPostProcessor在所有bean定义信息将要被加载，bean实例还未创建的； 所以优先于BeanFactoryPostProcessor执行；并且内部调用的postProcessBeanDefinitionRegistry方法优先于postProcessBeanFactory方法。 123456789101112131415//继承BeanFactoryPostProcessorpublic interface BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor &#123; /** * Modify the application context's internal bean definition registry after its * standard initialization. All regular bean definitions will have been loaded, * but no beans will have been instantiated yet. This allows for adding further * bean definitions before the next post-processing phase kicks in. * @param registry the bean definition registry used by the application context * @throws org.springframework.beans.BeansException in case of errors */ //增加postProcessBeanDefinitionRegistry();方法 void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException;&#125; 123456789101112131415161718192021//自定义BeanDefinitionRegistryPostProcessor@Componentpublic class MyBeanDefinitionRegistryPostProcessor implements BeanDefinitionRegistryPostProcessor&#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; // TODO Auto-generated method stub System.out.println(\"MyBeanDefinitionRegistryPostProcessor...bean的数量：\"+beanFactory.getBeanDefinitionCount()); &#125; //BeanDefinitionRegistry Bean定义信息的保存中心，以后BeanFactory就是按照BeanDefinitionRegistry里面保存的每一个bean定义信息创建bean实例； @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; // TODO Auto-generated method stub System.out.println(\"postProcessBeanDefinitionRegistry...bean的数量：\"+registry.getBeanDefinitionCount()); //给容器中再额外添加一些组件；通过new RootBeanDefinition()或者BeanDefinitionBuilder //RootBeanDefinition beanDefinition = new RootBeanDefinition(Blue.class); AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.rootBeanDefinition(Blue.class).getBeanDefinition(); registry.registerBeanDefinition(\"hello\", beanDefinition); &#125;&#125; ApplicationListener用于监听 ApplicationEvent 及其下面的子事件 12345678910@FunctionalInterfacepublic interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener &#123; /** * Handle an application event. * @param event the event to respond to */ void onApplicationEvent(E event);&#125; 12345678910@Componentpublic class MyApplicationListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; //当容器中发布此事件以后，方法触发 @Override public void onApplicationEvent(ApplicationEvent event) &#123; // TODO Auto-generated method stub System.out.println(\"收到事件：\"+event); &#125;&#125; 12345678@Testpublic void test01()&#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(ExtConfig.class); //发布事件； applicationContext.publishEvent(new ApplicationEvent(new String(\"我发布的事件\")) &#123; &#125;); applicationContext.close();&#125; 1234567891011121314151617181920212223/** * Finish the refresh of this context, invoking the LifecycleProcessor's * onRefresh() method and publishing the * &#123;@link org.springframework.context.event.ContextRefreshedEvent&#125;. *///AbstractApplicationContext.refresh()结束时调用，容器刷新完成protected void finishRefresh() &#123; // Clear context-level resource caches (such as ASM metadata from scanning). clearResourceCaches(); // Initialize lifecycle processor for this context. initLifecycleProcessor(); // Propagate refresh to lifecycle processor first. getLifecycleProcessor().onRefresh(); // Publish the final event. //发布刷新事件 publishEvent(new ContextRefreshedEvent(this)); // Participate in LiveBeansView MBean, if active. LiveBeansView.registerApplicationContext(this);&#125; 123456789101112131415161718192021222324252627282930313233343536//事件发布流程protected void publishEvent(Object event, @Nullable ResolvableType eventType) &#123; Assert.notNull(event, \"Event must not be null\"); // Decorate event as an ApplicationEvent if necessary ApplicationEvent applicationEvent; if (event instanceof ApplicationEvent) &#123; applicationEvent = (ApplicationEvent) event; &#125; else &#123; applicationEvent = new PayloadApplicationEvent&lt;&gt;(this, event); if (eventType == null) &#123; eventType = ((PayloadApplicationEvent&lt;?&gt;) applicationEvent).getResolvableType(); &#125; &#125; // Multicast right now if possible - or lazily once the multicaster is initialized if (this.earlyApplicationEvents != null) &#123; this.earlyApplicationEvents.add(applicationEvent); &#125; else &#123; //1.获取事件的派发器 //2.multicastEvent派发事件 getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); &#125; // Publish event via parent context as well... if (this.parent != null) &#123; if (this.parent instanceof AbstractApplicationContext) &#123; ((AbstractApplicationContext) this.parent).publishEvent(event, eventType); &#125; else &#123; this.parent.publishEvent(event); &#125; &#125;&#125; 1234567891011121314151617@Overridepublic void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123; ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); Executor executor = getTaskExecutor(); //获取到所有的ApplicationListener； for (ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123; //如果有Executor，可以支持使用Executor进行异步派发； if (executor != null) &#123; executor.execute(() -&gt; invokeListener(listener, event)); &#125; else &#123; //否则，同步的方式直接执行listener方法；拿到listener回调onApplicationEvent方法； invokeListener(listener, event); &#125; &#125;&#125; 12345678910111213141516171819202122232425//AbstractApplicationContext.protected void registerListeners() &#123; // Register statically specified listeners first. for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! //从容器中拿到所有的监听器，把他们注册到applicationEventMulticaster中； String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) &#123; //将listener注册到ApplicationEventMulticaster中 getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); &#125; // Publish early application events now that we finally have a multicaster... Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; if (!CollectionUtils.isEmpty(earlyEventsToProcess)) &#123; for (ApplicationEvent earlyEvent : earlyEventsToProcess) &#123; getApplicationEventMulticaster().multicastEvent(earlyEvent); &#125; &#125;&#125; 12345678910//使用注解实现监听事件@Servicepublic class UserService &#123; @EventListener(classes=&#123;ApplicationEvent.class&#125;) public void listen(ApplicationEvent event)&#123; System.out.println(\"UserService\"+event); &#125;&#125; 1234//该注解由该类实现功能public class EventListenerMethodProcessor implements SmartInitializingSingleton, ApplicationContextAware, BeanFactoryPostProcessor &#123;&#125; 1234567891011121314151617181920212223public interface SmartInitializingSingleton &#123; /** * Invoked right at the end of the singleton pre-instantiation phase, * with a guarantee that all regular singleton beans have been created * already. &#123;@link ListableBeanFactory#getBeansOfType&#125; calls within * this method won't trigger accidental side effects during bootstrap. * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; This callback won't be triggered for singleton beans * lazily initialized on demand after &#123;@link BeanFactory&#125; bootstrap, * and not for any other bean scope either. Carefully use it for beans * with the intended bootstrap semantics only. */ void afterSingletonsInstantiated();&#125;/*SmartInitializingSingleton 原理：-&gt;afterSingletonsInstantiated(); 1）、ioc容器创建对象并refresh()； 2）、finishBeanFactoryInitialization(beanFactory);初始化剩下的单实例bean； 1）、先创建所有的单实例bean；getBean(); 2）、获取所有创建好的单实例bean，判断是否是SmartInitializingSingleton类型的； 如果是就调用afterSingletonsInstantiated();*/ “本篇文章主要摘自参考资料”","categories":[{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/tags/Spring/"}]},{"title":"'Spring的声明式事务'","slug":"spring-transaction","date":"2020-10-20T14:30:00.000Z","updated":"2020-11-01T12:22:09.694Z","comments":true,"path":"2020/10/20/spring-transaction/","link":"","permalink":"https://midkuro.gitee.io/2020/10/20/spring-transaction/","excerpt":"","text":"Spring的声明式事务编码12345678910111213&lt;!-- 导入相关依赖：数据源、数据库驱动、Spring-jdbc模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031//开启基于注解的事务管理功能；@EnableTransactionManagement@Configurationpublic class TxConfig &#123; //配置数据源 @Bean public DataSource dataSource() throws Exception&#123; ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(\"root\"); dataSource.setPassword(\"123456\"); dataSource.setDriverClass(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/test\"); return dataSource; &#125; //配置JdbcTemplate @Bean public JdbcTemplate jdbcTemplate() throws Exception&#123; //Spring对@Configuration类会特殊处理；给容器中加组件的方法，多次调用都只是从容器中找组件 JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource()); return jdbcTemplate; &#125; //注册事务管理器在容器中 @Bean public PlatformTransactionManager transactionManager() throws Exception&#123; //配置事务管理器来控制事务; return new DataSourceTransactionManager(dataSource()); &#125;&#125; 123456789101112131415@Servicepublic class UserService &#123; @Autowired private UserDao userDao; //给方法上标注 @Transactional 表示当前方法是一个事务方法； @Transactional public void insertUser()&#123; userDao.insert(); //otherDao.other();xxx System.out.println(\"插入完成...\"); int i = 10/0; &#125;&#125; 原理和动态代理类似，主要关注@EnableTransactionManagement注解 12345678910111213@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented//给容器中注册了一个TransactionManagementConfigurationSelector//利用TransactionManagementConfigurationSelector给容器中会导入组件@Import(&#123;TransactionManagementConfigurationSelector.class&#125;)public @interface EnableTransactionManagement &#123; boolean proxyTargetClass() default false; AdviceMode mode() default AdviceMode.PROXY; int order() default Integer.MAX_VALUE;&#125; 12345678910111213141516171819202122232425262728293031public class TransactionManagementConfigurationSelector extends AdviceModeImportSelector&lt;EnableTransactionManagement&gt; &#123; /** * Returns &#123;@link ProxyTransactionManagementConfiguration&#125; or * &#123;@code AspectJ(Jta)TransactionManagementConfiguration&#125; for &#123;@code PROXY&#125; * and &#123;@code ASPECTJ&#125; values of &#123;@link EnableTransactionManagement#mode()&#125;, * respectively. */ @Override protected String[] selectImports(AdviceMode adviceMode) &#123; //根据上文注解，默认是PROXY switch (adviceMode) &#123; case PROXY: //给容器中注册了： //【AutoProxyRegistrarProxy】 和 【ProxyTransactionManagementConfiguration】 return new String[] &#123;AutoProxyRegistrar.class.getName(), ProxyTransactionManagementConfiguration.class.getName()&#125;; case ASPECTJ: return new String[] &#123;determineTransactionAspectClass()&#125;; default: return null; &#125; &#125; private String determineTransactionAspectClass() &#123; return (ClassUtils.isPresent(\"javax.transaction.Transactional\", getClass().getClassLoader()) ? TransactionManagementConfigUtils.JTA_TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME : TransactionManagementConfigUtils.TRANSACTION_ASPECT_CONFIGURATION_CLASS_NAME); &#125;&#125; 先看看AutoProxyRegistrar做了什么？ 12345678910111213141516171819202122232425262728293031323334353637383940414243public class AutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; private final Log logger = LogFactory.getLog(getClass()); @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; boolean candidateFound = false; Set&lt;String&gt; annTypes = importingClassMetadata.getAnnotationTypes(); for (String annType : annTypes) &#123; AnnotationAttributes candidate = AnnotationConfigUtils.attributesFor(importingClassMetadata, annType); if (candidate == null) &#123; continue; &#125; Object mode = candidate.get(\"mode\"); //根据@EnableTransactionManagement参数 Object proxyTargetClass = candidate.get(\"proxyTargetClass\"); if (mode != null &amp;&amp; proxyTargetClass != null &amp;&amp; AdviceMode.class == mode.getClass() &amp;&amp; Boolean.class == proxyTargetClass.getClass()) &#123; candidateFound = true; if (mode == AdviceMode.PROXY) &#123; //最终注册InfrastructureAdvisorAutoProxyCreator AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry); if ((Boolean) proxyTargetClass) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); return; &#125; &#125; &#125; &#125; if (!candidateFound &amp;&amp; logger.isInfoEnabled()) &#123; String name = getClass().getSimpleName(); logger.info(String.format(\"%s was imported but no annotations were found \" + \"having both 'mode' and 'proxyTargetClass' attributes of type \" + \"AdviceMode and boolean respectively. This means that auto proxy \" + \"creator registration and configuration may not have occurred as \" + \"intended, and components may not be proxied as expected. Check to \" + \"ensure that %s has been @Import'ed on the same class where these \" + \"annotations are declared; otherwise remove the import of %s \" + \"altogether.\", name, name, name)); &#125; &#125;&#125; AutoProxyRegistrar给容器中注册了一个InfrastructureAdvisorAutoProxyCreator，它的作用是利用后置处理器机制在对象创建以后，包装对象，返回一个代理对象（增强器），代理对象执行方法利用拦截器链进行调用； 那么ProxyTransactionManagementConfiguration做了什么呢？ 123456789101112131415161718192021222324252627282930313233343536373839@Configuration(proxyBeanMethods = false)@Role(BeanDefinition.ROLE_INFRASTRUCTURE)public class ProxyTransactionManagementConfiguration extends AbstractTransactionManagementConfiguration &#123; //给容器中注册事务增强器 @Bean(name = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public BeanFactoryTransactionAttributeSourceAdvisor transactionAdvisor( TransactionAttributeSource transactionAttributeSource, TransactionInterceptor transactionInterceptor) &#123; BeanFactoryTransactionAttributeSourceAdvisor advisor = new BeanFactoryTransactionAttributeSourceAdvisor(); //添加事务属性（解析事务注解） advisor.setTransactionAttributeSource(transactionAttributeSource); advisor.setAdvice(transactionInterceptor); if (this.enableTx != null) &#123; advisor.setOrder(this.enableTx.&lt;Integer&gt;getNumber(\"order\")); &#125; return advisor; &#125; @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionAttributeSource transactionAttributeSource() &#123; return new AnnotationTransactionAttributeSource(); &#125; @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionInterceptor transactionInterceptor(TransactionAttributeSource transactionAttributeSource) &#123; TransactionInterceptor interceptor = new TransactionInterceptor(); //保存了事务属性信息， interceptor.setTransactionAttributeSource(transactionAttributeSource); if (this.txManager != null) &#123; //保存了事务管理器； interceptor.setTransactionManager(this.txManager); &#125; return interceptor; &#125;&#125; 123456789101112131415161718//创建事务属性解析的构造器public AnnotationTransactionAttributeSource(boolean publicMethodsOnly) &#123; this.publicMethodsOnly = publicMethodsOnly; if (jta12Present || ejb3Present) &#123; this.annotationParsers = new LinkedHashSet&lt;&gt;(4); //添加注解的解析器，解析注解的配置信息 this.annotationParsers.add(new SpringTransactionAnnotationParser()); if (jta12Present) &#123; this.annotationParsers.add(new JtaTransactionAnnotationParser()); &#125; if (ejb3Present) &#123; this.annotationParsers.add(new Ejb3TransactionAnnotationParser()); &#125; &#125; else &#123; this.annotationParsers = Collections.singleton(new SpringTransactionAnnotationParser()); &#125; &#125; 12345678910111213141516@SuppressWarnings(\"serial\")//它是一个方法拦截器，MethodInterceptor，和AOP的相同，通过代理对象执行拦截器链public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable &#123; //代理对象调用invoke执行 拦截器链 @Override @Nullable public Object invoke(MethodInvocation invocation) throws Throwable &#123; // Work out the target class: may be &#123;@code null&#125;. // The TransactionAttributeSource should be passed the target class // as well as the method, which may be from an interface. Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null); // Adapt to TransactionAspectSupport's invokeWithinTransaction... return invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129//事务的拦截器链@Nullableprotected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, final InvocationCallback invocation) throws Throwable &#123; // If the transaction attribute is null, the method is non-transactional. TransactionAttributeSource tas = getTransactionAttributeSource(); //获取事务属性 final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null); //获取事务管理器，如果事先没有添加指定任何transactionmanger，最终会从容器中按照类型获取一个PlatformTransactionManager； final TransactionManager tm = determineTransactionManager(txAttr); if (this.reactiveAdapterRegistry != null &amp;&amp; tm instanceof ReactiveTransactionManager) &#123; ReactiveTransactionSupport txSupport = this.transactionSupportCache.computeIfAbsent(method, key -&gt; &#123; if (KotlinDetector.isKotlinType(method.getDeclaringClass()) &amp;&amp; KotlinDelegate.isSuspend(method)) &#123; throw new TransactionUsageException( \"Unsupported annotated transaction on suspending function detected: \" + method + \". Use TransactionalOperator.transactional extensions instead.\"); &#125; ReactiveAdapter adapter = this.reactiveAdapterRegistry.getAdapter(method.getReturnType()); if (adapter == null) &#123; throw new IllegalStateException(\"Cannot apply reactive transaction to non-reactive return type: \" + method.getReturnType()); &#125; return new ReactiveTransactionSupport(adapter); &#125;); return txSupport.invokeWithinTransaction( method, targetClass, invocation, txAttr, (ReactiveTransactionManager) tm); &#125; PlatformTransactionManager ptm = asPlatformTransactionManager(tm); final String joinpointIdentification = methodIdentification(method, targetClass, txAttr); if (txAttr == null || !(ptm instanceof CallbackPreferringPlatformTransactionManager)) &#123; // Standard transaction demarcation with getTransaction and commit/rollback calls. //如果需要的话，创建一个事务TransactionInfo //从事务管理器中获取一个数据源链接，并创建TransactionInfo后，将&lt;TransactionInfo&gt;放到ThreadLocal中，保证了一个方法中，多次从链接池中获取的数据源对象都是同一个。 TransactionInfo txInfo = createTransactionIfNecessary(ptm, txAttr, joinpointIdentification); Object retVal; try &#123; // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. // 执行目标方法 retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // target invocation exception //如果异常，获取到事务管理器，利用事务管理根据配置的异常捕获信息回滚操作；rollback completeTransactionAfterThrowing(txInfo, ex); throw ex; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; if (retVal != null &amp;&amp; vavrPresent &amp;&amp; VavrDelegate.isVavrTry(retVal)) &#123; // Set rollback-only in case of Vavr failure matching our rollback rules... TransactionStatus status = txInfo.getTransactionStatus(); if (status != null &amp;&amp; txAttr != null) &#123; retVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status); &#125; &#125; //如果正常，利用事务管理器，提交事务 commitTransactionAfterReturning(txInfo); return retVal; &#125; else &#123; Object result; final ThrowableHolder throwableHolder = new ThrowableHolder(); // It's a CallbackPreferringPlatformTransactionManager: pass a TransactionCallback in. try &#123; result = ((CallbackPreferringPlatformTransactionManager) ptm).execute(txAttr, status -&gt; &#123; TransactionInfo txInfo = prepareTransactionInfo(ptm, txAttr, joinpointIdentification, status); try &#123; Object retVal = invocation.proceedWithInvocation(); if (retVal != null &amp;&amp; vavrPresent &amp;&amp; VavrDelegate.isVavrTry(retVal)) &#123; // Set rollback-only in case of Vavr failure matching our rollback rules... retVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status); &#125; return retVal; &#125; catch (Throwable ex) &#123; if (txAttr.rollbackOn(ex)) &#123; // A RuntimeException: will lead to a rollback. if (ex instanceof RuntimeException) &#123; throw (RuntimeException) ex; &#125; else &#123; throw new ThrowableHolderException(ex); &#125; &#125; else &#123; // A normal return value: will lead to a commit. throwableHolder.throwable = ex; return null; &#125; &#125; finally &#123; cleanupTransactionInfo(txInfo); &#125; &#125;); &#125; catch (ThrowableHolderException ex) &#123; throw ex.getCause(); &#125; catch (TransactionSystemException ex2) &#123; if (throwableHolder.throwable != null) &#123; logger.error(\"Application exception overridden by commit exception\", throwableHolder.throwable); ex2.initApplicationException(throwableHolder.throwable); &#125; throw ex2; &#125; catch (Throwable ex2) &#123; if (throwableHolder.throwable != null) &#123; logger.error(\"Application exception overridden by commit exception\", throwableHolder.throwable); &#125; throw ex2; &#125; // Check result state: It might indicate a Throwable to rethrow. if (throwableHolder.throwable != null) &#123; throw throwableHolder.throwable; &#125; return result; &#125;&#125; 123456789101112131415161718192021222324252627282930//获取事务管理器的方法@Nullableprotected TransactionManager determineTransactionManager(@Nullable TransactionAttribute txAttr) &#123; // Do not attempt to lookup tx manager if no tx attributes are set if (txAttr == null || this.beanFactory == null) &#123; return getTransactionManager(); &#125; //如果事务注解有qualifier属性，则通过Bean名称获取 String qualifier = txAttr.getQualifier(); if (StringUtils.hasText(qualifier)) &#123; return determineQualifiedTransactionManager(this.beanFactory, qualifier); &#125; else if (StringUtils.hasText(this.transactionManagerBeanName)) &#123; return determineQualifiedTransactionManager(this.beanFactory, this.transactionManagerBeanName); &#125; else &#123; //若没有，则获取IOC容器中默认的事务管理器 TransactionManager defaultTransactionManager = getTransactionManager(); if (defaultTransactionManager == null) &#123; defaultTransactionManager = this.transactionManagerCache.get(DEFAULT_TRANSACTION_MANAGER_KEY); if (defaultTransactionManager == null) &#123; //在IOC中按照类型获取 defaultTransactionManager = this.beanFactory.getBean(TransactionManager.class); this.transactionManagerCache.putIfAbsent( DEFAULT_TRANSACTION_MANAGER_KEY, defaultTransactionManager); &#125; &#125; return defaultTransactionManager; &#125;&#125; 12345678910111213141516171819202122232425262728protected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, final String joinpointIdentification) &#123; // If no name specified, apply method identification as transaction name. if (txAttr != null &amp;&amp; txAttr.getName() == null) &#123; txAttr = new DelegatingTransactionAttribute(txAttr) &#123; @Override public String getName() &#123; return joinpointIdentification; &#125; &#125;; &#125; TransactionStatus status = null; if (txAttr != null) &#123; if (tm != null) &#123; status = tm.getTransaction(txAttr); &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Skipping transactional joinpoint [\" + joinpointIdentification + \"] because no transaction manager has been configured\"); &#125; &#125; &#125; //预初始化事务管理器对象 return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);&#125; 1234567891011121314151617181920212223242526272829protected TransactionInfo prepareTransactionInfo(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, String joinpointIdentification, @Nullable TransactionStatus status) &#123; TransactionInfo txInfo = new TransactionInfo(tm, txAttr, joinpointIdentification); if (txAttr != null) &#123; // We need a transaction for this method... if (logger.isTraceEnabled()) &#123; logger.trace(\"Getting transaction for [\" + txInfo.getJoinpointIdentification() + \"]\"); &#125; // The transaction manager will flag an error if an incompatible tx already exists. txInfo.newTransactionStatus(status); &#125; else &#123; // The TransactionInfo.hasTransaction() method will return false. We created it only // to preserve the integrity of the ThreadLocal stack maintained in this class. if (logger.isTraceEnabled()) &#123; logger.trace(\"No need to create transaction for [\" + joinpointIdentification + \"]: This method is not transactional.\"); &#125; &#125; // We always bind the TransactionInfo to the thread, even if we didn't create // a new transaction here. This guarantees that the TransactionInfo stack // will be managed correctly even if no transaction was created by this aspect. //绑定事务对象 txInfo.bindToThread(); return txInfo;&#125; 12345678private static final ThreadLocal&lt;TransactionInfo&gt; transactionInfoHolder = new NamedThreadLocal&lt;&gt;(\"Current aspect-driven transaction\");private void bindToThread() &#123; // Expose current TransactionStatus, preserving any existing TransactionStatus // for restoration after this transaction is complete. this.oldTransactionInfo = transactionInfoHolder.get(); transactionInfoHolder.set(this);&#125; 失效 一个有@Transactional的方法被没有@Transactional方法调用时，会导致Transactional作用失效。也是最容易出现的情况。 由于使用Spring AOP代理造成的，因为只有当事务方法被当前类以外的代码调用时，才会由Spring生成的代理对象来管理。 123456789101112131415@Componentpublic class UserService &#123; @Autowired JdbcTemplate jdbcTemplate; public void A() &#123; B(); &#125; @Transactional public void B() &#123; t.insert(\"sql\"); System.out.println(1 / 0); &#125;&#125; 像上面这种案例中，同类中的方法调用，在调用A()方法时，就会导致B()方法的@Transactional注解失效。 1234567891011@Componentpublic class AService &#123; @Autowired JdbcTemplate jdbcTemplate; @Transactional public void B() &#123; t.update(\"update lm_sys_log set log_time = GETDATE() where user_name = '111' \"); System.out.println(1 / 0); &#125;&#125; 123456789101112@Componentpublic class UserService &#123; @Autowired JdbcTemplate jdbcTemplate; @Autowired AService a; public void A() &#123; a.B(); &#125;&#125; 像这种就跨类调用的话，注解就能生效。 对非public方法进行事务注解。@Transactional 将会失效。 原因：是应为在Spring AOP代理时，事务拦截器在目标方法前后进行拦截，DynamicAdvisedInterceptor的intercept 方法会获取Transactional注解的事务配置信息， 因为在Spring AOP 代理时，如上图所示 TransactionInterceptor （事务拦截器）在目标方法执行前后进行拦截，DynamicAdvisedInterceptor（CglibAopProxy 的内部类）的 intercept 方法或 JdkDynamicAopProxy 的 invoke 方法会间接调用 AbstractFallbackTransactionAttributeSource的 computeTransactionAttribute 方法会间接调用 AbstractFallbackTransactionAttributeSource的 computeTransactionAttribute 方法，这个方法会获取Transactional 注解的事务配置信息。他会首先校验事务方法的修饰符是不是public，不是 public则不会获取@Transactional 的属性配置信息。 Transactional 事务配置属性中的propagation 属性配置的问题。 当propagation属性配置为： TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常 在一个类中A方法被事务注释，B方法也被事务注释，但在执行B方法是报错，但是异常被A catch 住，此时事务也会失效。 12345678910111213@Transactionalpublic void B() &#123; t.insert(\"sql\"); System.out.println(1 / 0);&#125;@Transactionalpublic void A() &#123; try &#123; B(); &#125; catch (Exception e) &#123; &#125;&#125; “本篇文章主要摘自参考资料” .","categories":[{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/tags/Spring/"}]},{"title":"'Spring的Aop原理和实现'","slug":"spring-aop","date":"2020-10-20T14:30:00.000Z","updated":"2020-11-02T01:13:08.095Z","comments":true,"path":"2020/10/20/spring-aop/","link":"","permalink":"https://midkuro.gitee.io/2020/10/20/spring-aop/","excerpt":"","text":"Spring的Aop原理和实现BeanPostProcessorBeanPostProcessor是一个后置处理器，用于在所有bean初始化前后进行一些处理工作； 1234567891011121314151617package org.springframework.beans.factory.config;import org.springframework.beans.BeansException;import org.springframework.lang.Nullable;public interface BeanPostProcessor &#123; //在Bean初始化之前调用 @Nullable default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125; //在Bean初始化之后调用 @Nullable default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; return bean; &#125;&#125; 该BeanPostProcessor在spring底层中大量使用，比如我们需要获取ApplicationContext时，需要实现ApplicationContextAware接口 123public interface ApplicationContextAware extends Aware &#123; void setApplicationContext(ApplicationContext arg0) throws BeansException;&#125; 那么setApplicationContext在什么时候调用呢？spring底层有一个ApplicationContextAwareProcessor类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class ApplicationContextAwareProcessor implements BeanPostProcessor &#123; private final ConfigurableApplicationContext applicationContext; private final StringValueResolver embeddedValueResolver; public ApplicationContextAwareProcessor(ConfigurableApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; this.embeddedValueResolver = new EmbeddedValueResolver(applicationContext.getBeanFactory()); &#125; @Nullable public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; //1.判断Bean是否实现了Aware接口，否则直接返回bean if (!(bean instanceof EnvironmentAware) &amp;&amp; !(bean instanceof EmbeddedValueResolverAware) &amp;&amp; !(bean instanceof ResourceLoaderAware) &amp;&amp; !(bean instanceof ApplicationEventPublisherAware) &amp;&amp; !(bean instanceof MessageSourceAware) &amp;&amp; !(bean instanceof ApplicationContextAware)) &#123; return bean; &#125; else &#123; AccessControlContext acc = null; if (System.getSecurityManager() != null) &#123; acc = this.applicationContext.getBeanFactory().getAccessControlContext(); &#125; if (acc != null) &#123; AccessController.doPrivileged(() -&gt; &#123; this.invokeAwareInterfaces(bean); return null; &#125;, acc); &#125; else &#123; //调用Aware实现的方法 this.invokeAwareInterfaces(bean); &#125; return bean; &#125; &#125; private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; //实现了ApplicationContextAware接口时，调用其实现的setApplicationContext方法 if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; &#125;&#125; 可以看到，spring源码中通过BeanPostProcessor接口，在容器自动装配bean的之前，对实现了ApplicationContextAware接口的bean进行了方法回调。 那么BeanPostProcessor接口又是在什么时候被调用的呢？通过跟踪源码调用链得知，当一个bean被初始化时，会调用AbstractBeanFactory的doGetBean方法，该方法中将会调用AbstractAutowireCapableBeanFactory的doCreateBean方法，以下是摘取部分doCreateBean方法： 1234567891011protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; /* 省略部分代码 */ try &#123; //给Bean的属性赋值 this.populateBean(beanName, mbd, instanceWrapper); exposedObject = this.initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable arg17) &#123; /* 省略部分代码 */ &#125; /* 省略部分代码 */&#125; 从源码看到它先调用populateBean方法给刚创建好的bean对象进行属性赋值，然后调用initializeBean方法 1234567891011121314151617181920212223protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123; /* 省略部分代码 */ //Bean的实例已经创建好了 Object wrappedBean = bean; if(mbd == null || !mbd.isSynthetic()) &#123; //调用BeanPostProcessor后置处理器的Before方法 wrappedBean = this.applyBeanPostProcessorsBeforeInitialization(bean, beanName); &#125; try &#123; //执行初始化方法（如@PostConstruct方法） this.invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable arg5) &#123; throw new BeanCreationException(mbd != null?mbd.getResourceDescription():null, beanName, \"Invocation of init method failed\", arg5); &#125; if(mbd == null || !mbd.isSynthetic()) &#123; //调用BeanPostProcessor后置处理器的After方法 wrappedBean = this.applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 123456789101112131415public Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName) throws BeansException &#123; Object result = existingBean; Object current; for (Iterator arg3 = this.getBeanPostProcessors().iterator(); arg3.hasNext(); result = current) &#123; BeanPostProcessor processor = (BeanPostProcessor) arg3.next(); current = processor.postProcessBeforeInitialization(result, beanName); if (current == null) &#123; return result; &#125; &#125; return result; &#125; 可以看到在initializeBean中调用了applyBeanPostProcessorsBeforeInitialization，该方法中将遍历容器中所有的BeanPostProcessor；挨个执行beforeInitialization方法，一但返回null，则跳出循环，不会执行后面的BeanPostProcessor.postProcessorsBeforeInitialization。 而applyBeanPostProcessorsAfterInitialization方法也和上文的方法中相似，也就是说，在初始化bean的过程中，其调用顺序如下： populateBean(); //给Bean的属性赋值 initializeBean { ​ applyBeanPostProcessorsBeforeInitialization(bean, beanName); //Bean初始化之前调用 ​ invokeInitMethods(beanName, wrappedBean, mbd); //执行自定义初始化 ​ postProcessBeforeInitialization(result, beanName); //Bean初始化之后调用 } Spring底层大量使用了BeanPostProcessor接口，比如我们的@Init、@destory，该注解工作的原理在于InitDestroyAnnotationBeanPostProcessor类，通过BeanPostProcessor的特性，扫描Bean的注解和方法，判断是否包含@Init、@destory注解，如果有，则进行方法反射调用。 还有如@Autowired、@PostConstruct，都是有其对应的XXXBeanPostProcessor接口。 Aware自定义组件想要使用Spring容器底层的一些组件（ApplicationContext，BeanFactory，xxx），可以通过实现xxxAware，在创建对象时，会调用接口规定的方法注入相关组件。 12public interface Aware &#123;&#125; 如ApplicationContextAware，对应ApplicationContextAwareProcessor。 AOP概念 AOP：【动态代理】 指在程序运行期间动态的将某段代码切入到指定方法指定位置进行运行的编程方式； 1、导入aop模块；Spring AOP：(spring-aspects) 2、定义一个业务逻辑类（MathCalculator）；在业务逻辑运行的时候将日志进行打印（方法之前、方法运行结束、方法出现异常，xxx） 3、定义一个日志切面类（LogAspects）：切面类里面的方法需要动态感知MathCalculator.div运行到哪里然后执行； 通知方法： 前置通知(@Before)：logStart：在目标方法(div)运行之前运行 后置通知(@After)：logEnd：在目标方法(div)运行结束之后运行（无论方法正常结束还是异常结束） 返回通知(@AfterReturning)：logReturn：在目标方法(div)正常返回之后运行 异常通知(@AfterThrowing)：logException：在目标方法(div)出现异常以后运行 环绕通知(@Around)：动态代理，手动推进目标方法运行（joinPoint.procced()） 4、给切面类的目标方法标注何时何地运行（通知注解）； 5、将切面类和业务逻辑类（目标方法所在类）都加入到容器中; 6、必须告诉Spring哪个类是切面类(给切面类上加一个注解：@Aspect) 7、给配置类中加 @EnableAspectJAutoProxy 【开启基于注解的aop模式】 1234567891011121314151617181920212223242526272829303132333435363738/** * 切面类 * @Aspect： 告诉Spring当前类是一个切面类 */@Aspectpublic class LogAspects &#123; //抽取公共的切入点表达式 //1、本类引用 //2、其他的切面引用 @Pointcut(\"execution(public int com.MathCalculator.*(..))\") public void pointCut()&#123;&#125;; //@Before在目标方法之前切入；切入点表达式（指定在哪个方法切入） @Before(\"pointCut()\") public void logStart(JoinPoint joinPoint)&#123; Object[] args = joinPoint.getArgs(); System.out.println(\"\"+joinPoint.getSignature().getName()+\"运行。。。@Before:参数列表是：&#123;\"+Arrays.asList(args)+\"&#125;\"); &#125; //方法不在本类中直接使用类路径 @After(\"com.LogAspects.pointCut()\") public void logEnd(JoinPoint joinPoint)&#123; System.out.println(\"\"+joinPoint.getSignature().getName()+\"结束。。。@After\"); &#125; //JoinPoint一定要出现在参数表的第一位，returning设置接受返回值参数 @AfterReturning(value=\"pointCut()\",returning=\"result\") public void logReturn(JoinPoint joinPoint,Object result)&#123; System.out.println(\"\"+joinPoint.getSignature().getName()+\"正常返回。。。@AfterReturning:运行结果：&#123;\"+result+\"&#125;\"); &#125; //设置接受返回值参数 @AfterThrowing(value=\"pointCut()\",throwing=\"exception\") public void logException(JoinPoint joinPoint,Exception exception)&#123; System.out.println(\"\"+joinPoint.getSignature().getName()+\"异常。。。异常信息：&#123;\"+exception+\"&#125;\"); &#125;&#125; 123456public class MathCalculator &#123; public int div(int i,int j)&#123; System.out.println(\"MathCalculator...div...\"); return i/j; &#125;&#125; 12345678910111213141516@EnableAspectJAutoProxy@Configurationpublic class MainConfigOfAOP &#123; //业务逻辑类加入容器中 @Bean public MathCalculator calculator()&#123; return new MathCalculator(); &#125; //切面类加入到容器中 @Bean public LogAspects logAspects()&#123; return new LogAspects(); &#125;&#125; 123456789public class MainTest &#123; public static void main(String[] args) &#123; AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class); MathCalculator bean = applicationContext.getBean(MathCalculator.class); bean.div(1, 2); applicationContext.close(); &#125;&#125; 总结： 1、将业务逻辑组件和切面类都加入到容器中；告诉Spring哪个是切面类（@Aspect） 2、在切面类上的每一个通知方法上标注通知注解，告诉Spring何时何地运行（切入点表达式） 3、开启基于注解的aop模式；@EnableAspectJAutoProxy 原理学习AOP原理的方向：【看给容器中注册了什么组件，这个组件什么时候工作，这个组件的功能是什么？】 @EnableAspectJAutoProxy注解是什么呢？ 先了解这个ImportBeanDefinitionRegistrar接口的功能： 123456789public interface ImportBeanDefinitionRegistrar &#123; default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry, BeanNameGenerator importBeanNameGenerator) &#123; this.registerBeanDefinitions(importingClassMetadata, registry); &#125; default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; &#125;&#125; 它的作用是通过实现ImportBeanDefinitionRegistrar接口的方法，创建自定义的对象和BeanDefinetion对象并设置相关属性，然后将BeanDefinetion注册到BeanDefinitionRegistry中，完成Bean对象的注册。 回过头来看看@EnableAspectJAutoProxy注解 123456789@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(&#123;AspectJAutoProxyRegistrar.class&#125;)public @interface EnableAspectJAutoProxy &#123; boolean proxyTargetClass() default false; boolean exposeProxy() default false;&#125; 可以看到有注解@Import({AspectJAutoProxyRegistrar.class})，该注解的作用是给容器中导入AspectJAutoProxyRegistrar，利用AspectJAutoProxyRegistrar自定义给容器中注册bean。 1234567891011121314151617class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123; public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; //注册一个bean对象 AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); if (enableAspectJAutoProxy != null) &#123; if (enableAspectJAutoProxy.getBoolean(\"proxyTargetClass\")) &#123; AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); &#125; if (enableAspectJAutoProxy.getBoolean(\"exposeProxy\")) &#123; AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); &#125; &#125; &#125;&#125; 那么它注册了什么Bean呢？ 接着跟踪AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry);，将会调用该方法 123456@Nullablepublic static BeanDefinition registerAspectJAnnotationAutoProxyCreatorIfNecessary(BeanDefinitionRegistry registry, @Nullable Object source) &#123; //注册Bean或者更新Bean---&gt;AnnotationAwareAspectJAutoProxyCreator return registerOrEscalateApcAsRequired(AnnotationAwareAspectJAutoProxyCreator.class, registry, source);&#125; 1234567891011121314151617181920212223242526@Nullableprivate static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, @Nullable Object source) &#123; Assert.notNull(registry, \"BeanDefinitionRegistry must not be null\"); //如果容器中已经包含internalAutoProxyCreator，则升级该对象 if (registry.containsBeanDefinition(\"org.springframework.aop.config.internalAutoProxyCreator\")) &#123; BeanDefinition beanDefinition1 = registry .getBeanDefinition(\"org.springframework.aop.config.internalAutoProxyCreator\"); if (!cls.getName().equals(beanDefinition1.getBeanClassName())) &#123; int currentPriority = findPriorityForClass(beanDefinition1.getBeanClassName()); int requiredPriority = findPriorityForClass(cls); if (currentPriority &lt; requiredPriority) &#123; beanDefinition1.setBeanClassName(cls.getName()); &#125; &#125; return null; &#125; else &#123; //如果容器中没有包含internalAutoProxyCreator，则创建该Bean RootBeanDefinition beanDefinition = new RootBeanDefinition(cls); beanDefinition.setSource(source); beanDefinition.getPropertyValues().add(\"order\", Integer.valueOf(Integer.MIN_VALUE)); beanDefinition.setRole(2); registry.registerBeanDefinition(\"org.springframework.aop.config.internalAutoProxyCreator\", beanDefinition); return beanDefinition; &#125;&#125; 也就是说，AspectJAutoProxyRegistrar类给容器中注册了一个BeanName等于internalAutoProxyCreator的AnnotationAwareAspectJAutoProxyCreator对象（注解装配模式的切面自动代理创建器）。 AnnotationAwareAspectJAutoProxyCreator是个什么对象呢？ 先分析一下它的继承关系 12345678910111213AnnotationAwareAspectJAutoProxyCreator: -&gt; extends AspectJAwareAdvisorAutoProxyCreator -&gt; extends AbstractAdvisorAutoProxyCreator -&gt; extends AbstractAutoProxyCreator -&gt; implements SmartInstantiationAwareBeanPostProcessor -&gt; implements BeanFactoryAware -&gt; extends ProxyProcessorSupport ProxyProcessorSupport -&gt; extends ProxyConfig -&gt; implements Ordered -&gt; implements BeanClassLoaderAware -&gt; implements AopInfrastructureBean 程序启动时，会先调度AbstractApplicationContext的刷新容器方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. //3、注册bean的后置处理器 registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); //4、完成BeanFactory初始化工作；创建剩下的单实例bean // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 可以看到其中有一个方法是registerBeanPostProcessors，用来注册Bean的后置处理器 12345678/** * Instantiate and register all BeanPostProcessor beans, * respecting explicit order if given. * &lt;p&gt;Must be called before any instantiation of application beans. */protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; //3.1、获取IOC容器已经定义了的需要创建对象的所有BeanPostProcessor String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // Register BeanPostProcessorChecker that logs an info message when // a bean is created during BeanPostProcessor instantiation, i.e. when // a bean is not eligible for getting processed by all BeanPostProcessors. int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; //3.2、给容器中加别的BeanPostProcessor beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // 分离BeanPostProcessor，判断是否实现PriorityOrdered extends Ordered接口，进行优先级的排序 // Separate between BeanPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;(); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; //3.3、优先注册实现了PriorityOrdered接口的BeanPostProcessor // First, register the BeanPostProcessors that implement PriorityOrdered. sortPostProcessors(priorityOrderedPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); //3.4、再给容器中注册实现了Ordered接口的BeanPostProcessor； // Next, register the BeanPostProcessors that implement Ordered. List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(orderedPostProcessorNames.size()); for (String ppName : orderedPostProcessorNames) &#123; //AnnotationAwareAspectJAutoProxyCreator实现了Ordered接口，将在这里调度getBean创建对象 BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; //按照优先级排序 sortPostProcessors(orderedPostProcessors, beanFactory); //3.5、注册到BeanFactory工厂中 registerBeanPostProcessors(beanFactory, orderedPostProcessors); //3.6、注册没实现优先级接口的BeanPostProcessor； // Now, register all regular BeanPostProcessors. List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(nonOrderedPostProcessorNames.size()); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // Finally, re-register all internal BeanPostProcessors. sortPostProcessors(internalPostProcessors, beanFactory); registerBeanPostProcessors(beanFactory, internalPostProcessors); // Re-register post-processor for detecting inner beans as ApplicationListeners, // moving it to the end of the processor chain (for picking up proxies etc). beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));&#125; 在第一步的注释位置断点，可以看到所有已经定义了的需要创建对象的后置处理器包含了org.springframework.aop.config.internalAutoProxyCreator的Bean名称 由于AnnotationAwareAspectJAutoProxyCreator类最终实现了Ordered接口，将调用getBean方法创建对象 1234@Overridepublic &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType) throws BeansException &#123; return doGetBean(name, requiredType, null, false);&#125; 123456789101112131415161718192021222324252627282930313233343536373839/** * Return an instance, which may be shared or independent, of the specified bean. * @param name the name of the bean to retrieve * @param requiredType the required type of the bean to retrieve * @param args arguments to use when creating a bean instance using explicit arguments * (only applied when creating a new instance as opposed to retrieving an existing one) * @param typeCheckOnly whether the instance is obtained for a type check, * not for actual use * @return an instance of the bean * @throws BeansException if the bean could not be created */@SuppressWarnings(\"unchecked\")protected &lt;T&gt; T doGetBean( String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly) throws BeansException &#123; //4.2.1、先从缓存中获取当前bean，如果能获取到，说明bean是之前被创建过的，直接使用，否则再创建； // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; /* 省略部分代码 */ &#125; else &#123; // Create bean instance. if (mbd.isSingleton()) &#123; //当IOC容器第一次获取Bean的单实例时，获取不到，将创建Bean sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; //3.4 创建Bean实例并且返回 return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; /* 省略部分代码 */ &#125; &#125;); /* 省略部分代码 */ &#125; &#125; /* 省略部分代码 */&#125; 接下来分析一下创建Bean实例的过程： 1234567891011121314151617181920212223242526272829@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; /* 省略部分代码 */ try &#123; // 给后置处理器一个机会来创建一个代理对象替代目标实例 // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, \"BeanPostProcessor before instantiation of bean failed\", ex); &#125; try &#123; //3.4 调用doCreateBean创建实例 Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isTraceEnabled()) &#123; logger.trace(\"Finished creating instance of bean '\" + beanName + \"'\"); &#125; return beanInstance; &#125; catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) &#123; /* 省略部分代码 */ &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; //3.4.1、创建Bean的实例 instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; /* 省略部分代码 */ //Bean的实例已经创建成功 // Initialize the bean instance. Object exposedObject = bean; try &#123; //3.4.2、给Bean的属性赋值 populateBean(beanName, mbd, instanceWrapper); //3.4.3 初始化bean； exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; /* 省略部分代码 */ &#125; /* 省略部分代码 */ return exposedObject;&#125; 进一步分析initializeBean方法： 1234567891011121314151617181920212223242526272829303132333435protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123; invokeAwareMethods(beanName, bean); return null; &#125;, getAccessControlContext()); &#125; else &#123; //3.4.3.1、处理Aware接口的方法回调，将会回调实现BeanFactoryAware接口的setBeanFactory方法 invokeAwareMethods(beanName, bean); &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; //3.4.3.2、执行后置处理器的postProcessBeforeInitialization（） wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; //3.4.3.3、执行自定义的初始化方法 invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; //3.4.3.4、执行后置处理器的postProcessAfterInitialization（） wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125; 进一步观看它是如何处理Aware接口的方法回调的，invokeAwareMethods方法： 123456789101112131415161718private void invokeAwareMethods(String beanName, Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof BeanNameAware) &#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; if (bean instanceof BeanClassLoaderAware) &#123; ClassLoader bcl = getBeanClassLoader(); if (bcl != null) &#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); &#125; &#125; //实现了BeanFactoryAware接口的类，将会调用setBeanFactory方法 //将会调用实现类的AbstractAdvisorAutoProxyCreator.setBeanFactory方法 if (bean instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); &#125; &#125;&#125; 也就是说，invokeAwareMethods方法将会调用实现类实现的BeanFactoryAware.setBeanFactory()，通过之前的继承树分析，AnnotationAwareAspectJAutoProxyCreator实现了BeanFactoryAware接口。 123public interface BeanFactoryAware extends Aware &#123; void setBeanFactory(BeanFactory arg0) throws BeansException;&#125; 观察AnnotationAwareAspectJAutoProxyCreator类的链路的setBeanFactory实现关系： 12345AbstractAutoProxyCreator.setBeanFactory();//父类复写setBeanFactory方法，内部调用AbstractAdvisorAutoProxyCreator.initBeanFactory方法AbstractAdvisorAutoProxyCreator.setBeanFactory(); -&gt; initBeanFactory();//父类复写initBeanFactory方法AnnotationAwareAspectJAutoProxyCreator.initBeanFactory方法(); 通过分析链路调用，最终将会调用AbstractAdvisorAutoProxyCreator.setBeanFactory方法 12345678910public void setBeanFactory(BeanFactory beanFactory) &#123; super.setBeanFactory(beanFactory); if (!(beanFactory instanceof ConfigurableListableBeanFactory)) &#123; throw new IllegalArgumentException( \"AdvisorAutoProxyCreator requires a ConfigurableListableBeanFactory: \" + beanFactory); &#125; else &#123; //将调用子类的AnnotationAwareAspectJAutoProxyCreator.initBeanFactory this.initBeanFactory((ConfigurableListableBeanFactory) beanFactory); &#125;&#125; 而initBeanFactory方法被子类复写，最终调用了AnnotationAwareAspectJAutoProxyCreator.initBeanFactory方法 123456789protected void initBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; super.initBeanFactory(beanFactory); //创建了反射的AspectJ通知工厂 if (this.aspectJAdvisorFactory == null) &#123; this.aspectJAdvisorFactory = new ReflectiveAspectJAdvisorFactory(beanFactory); &#125; //创建了AspectJ通知构建器的适配器 this.aspectJAdvisorsBuilder = new BeanFactoryAspectJAdvisorsBuilderAdapter(this, beanFactory, this.aspectJAdvisorFactory);&#125; 以上是创建和注册AnnotationAwareAspectJAutoProxyCreator的过程，接下来分析创建完Bean实例后逻辑。 回过头来接着看AbstractApplicationContext.refresh方法的第四步注释： 1234567891011/*** Finish the initialization of this context's bean factory,* initializing all remaining singleton beans.*/protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; /* 省略部分代码 */ // 4.完成BeanFactory初始化工作；创建剩下的单实例bean // Instantiate all remaining (non-lazy-init) singletons. beanFactory.preInstantiateSingletons();&#125; 1234567891011121314151617181920@Overridepublic void preInstantiateSingletons() throws BeansException &#123; /* 省略部分代码 */ List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames); // Trigger initialization of all non-lazy singleton beans... for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; /* 省略部分代码 */ &#125; else &#123; //4.2 创建容器中未被创建的Bean对象 getBean(beanName); &#125; &#125; &#125; /* 省略部分代码 */&#125; 这时候再回到上文的getBean方法，重新回顾它的调用链： 12345678getBean:-&gt; doGetBean() #先从缓存中获取当前bean，如果能获取到，说明bean是之前被创建过的，直接使用 -&gt; getSingleton() #否则再调用createBean方法创建 -&gt; createBean() -&gt; resolveBeforeInstantiation() -&gt; doCreateBean() Spring就是在这里保证了单实例的Bean只被创建一次，只要创建好的Bean都会被缓存起来； 在createBean创建Bean的过程中，会先调用resolveBeforeInstantiation方法，该方法的作用是给后置处理器一个机会来创建一个代理对象替代目标实例，如果能返回代理对象就使用，如果不能就将调用doCreateBean创建Bean实例。 1234567891011121314151617181920@Nullableprotected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) &#123; Object bean = null; if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) &#123; // Make sure bean class is actually resolved at this point. if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; Class&lt;?&gt; targetType = determineTargetType(beanName, mbd); if (targetType != null) &#123; //后置处理器先尝试返回对象； bean = applyBeanPostProcessorsBeforeInstantiation(targetType, beanName); //如果对象不为空，则调用BeanPostProcessor.postProcessAfterInitialization if (bean != null) &#123; bean = applyBeanPostProcessorsAfterInitialization(bean, beanName); &#125; &#125; &#125; mbd.beforeInstantiationResolved = (bean != null); &#125; return bean;&#125; 进一步分析applyBeanPostProcessorsBeforeInstantiation方法 123456789101112131415@Nullableprotected Object applyBeanPostProcessorsBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; //判断BeanPostProcessor是否为InstantiationAwareBeanPostProcessor类型 if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; //调用InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation Object result = ibp.postProcessBeforeInstantiation(beanClass, beanName); if (result != null) &#123; return result; &#125; &#125; &#125; return null;&#125; 根据上文的继承关系分析得知，AnnotationAwareAspectJAutoProxyCreator的父类实现了SmartInstantiationAwareBeanPostProcessor接口 12public interface SmartInstantiationAwareBeanPostProcessor extends InstantiationAwareBeanPostProcessor&#123;&#125; 123456public interface InstantiationAwareBeanPostProcessor extends BeanPostProcessor &#123; @Nullable default Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; return null; &#125;&#125; 所以可以得出结论，最终会在这里调用AnnotationAwareAspectJAutoProxyCreator的父类AbstractAutoProxyCreator实现的postProcessBeforeInstantiation方法，用来尝试创建代理对象替代目标对象。 值得注意的是，InstantiationAwareBeanPostProcessor和BeanPostProcessor不太一样。 BeanPostProcessor.postProcessBeforeInitialization：是在Bean对象创建完成初始化前后调用的InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation：是在创建Bean实例之前先尝试用后置处理器返回对象的 它们的调用时机不同，并且它们的方法名不同，一个是Initialization，另一个是Instantiation。 所以能够得到一个结论，AnnotationAwareAspectJAutoProxyCreator在所有bean创建之前会有一个拦截，会先调用InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation()，先尝试返回bean的代理实例。 接下来了解InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation()方法 1234567891011121314151617181920212223242526272829303132@Overridepublic Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) &#123; Object cacheKey = getCacheKey(beanClass, beanName); if (!StringUtils.hasLength(beanName) || !this.targetSourcedBeans.contains(beanName)) &#123; //1.判断当前bean是否在advisedBeans中（保存了所有需要增强bean） if (this.advisedBeans.containsKey(cacheKey)) &#123; return null; &#125; //2.判断当前bean是否是基础类型的Advice、Pointcut、Advisor、AopInfrastructureBean 或者是否是切面（@Aspect） if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return null; &#125; &#125; // Create proxy here if we have a custom TargetSource. // Suppresses unnecessary default instantiation of the target bean: // The TargetSource will handle target instances in a custom fashion. TargetSource targetSource = getCustomTargetSource(beanClass, beanName); if (targetSource != null) &#123; if (StringUtils.hasLength(beanName)) &#123; this.targetSourcedBeans.add(beanName); &#125; Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource); Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; return null;&#125; isInfrastructureClass方法是用来判断该Bean是否是切面的基础类型 12345678910protected boolean isInfrastructureClass(Class&lt;?&gt; beanClass) &#123; boolean retVal = Advice.class.isAssignableFrom(beanClass) || Pointcut.class.isAssignableFrom(beanClass) || Advisor.class.isAssignableFrom(beanClass) || AopInfrastructureBean.class.isAssignableFrom(beanClass); if (retVal &amp;&amp; logger.isTraceEnabled()) &#123; logger.trace(\"Did not attempt to auto-proxy infrastructure class [\" + beanClass.getName() + \"]\"); &#125; return retVal;&#125; 而AnnotationAwareAspectJAutoProxyCreator复写了该方法，增加了一个@Aspect注解的切面判断： 123456@Overrideprotected boolean isInfrastructureClass(Class&lt;?&gt; beanClass) &#123; //检测父类实现的基础类型判断和Aspect注解判断 return (super.isInfrastructureClass(beanClass) || (this.aspectJAdvisorFactory != null &amp;&amp; this.aspectJAdvisorFactory.isAspect(beanClass)));&#125; 1234@Overridepublic boolean isAspect(Class&lt;?&gt; clazz) &#123; return (hasAspectAnnotation(clazz) &amp;&amp; !compiledByAjc(clazz));&#125; shouldSkip方法用来判断是否跳过当前Bean 12345678910111213@Overrideprotected boolean shouldSkip(Class&lt;?&gt; beanClass, String beanName) &#123; // 获取候选的增强器（切面里面的通知方法） // TODO: Consider optimization by caching the list of the aspect names List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); for (Advisor advisor : candidateAdvisors) &#123; if (advisor instanceof AspectJPointcutAdvisor &amp;&amp; ((AspectJPointcutAdvisor) advisor).getAspectName().equals(beanName)) &#123; return true; &#125; &#125; return super.shouldSkip(beanClass, beanName);&#125; 123protected boolean shouldSkip(Class&lt;?&gt; beanClass, String beanName) &#123; return AutoProxyUtils.isOriginalInstance(beanName, beanClass);&#125; 跟踪源码后，最终InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation()尝试创建代理对象失败，将调用doCreateBean创建普通实例，最终会在initializeBean()方法中，调用BeanPostProcessor后置处理器的实现。 由于AbstractAutoProxyCreator类实现了postProcessAfterInitialization方法，所以将被调用。 1234567891011@Overridepublic Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &#123; if (bean != null) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) &#123; //在需要的时候进行包装 return wrapIfNecessary(bean, beanName, cacheKey); &#125; &#125; return bean;&#125; 12345678910111213141516171819202122232425262728protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) &#123; if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) &#123; return bean; &#125; if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) &#123; return bean; &#125; //判断当前bean是否是基础类型的Advice、Pointcut、Advisor、AopInfrastructureBean 或者是否是切面（@Aspect） if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) &#123; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; &#125; // 获取当前bean的所有增强器（通知方法） Object[] specificInterceptors // Create proxy if we have advice. Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) &#123; //保存当前bean在advisedBeans中；表示当前Bean已经被增强处理 this.advisedBeans.put(cacheKey, Boolean.TRUE); //如果当前bean需要增强，创建当前bean的代理对象； Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; &#125; this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean;&#125; 进一步分析getAdvicesAndAdvisorsForBean方法 1234567891011@Override@Nullableprotected Object[] getAdvicesAndAdvisorsForBean( Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) &#123; //找到可用的增强器 List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName); if (advisors.isEmpty()) &#123; return DO_NOT_PROXY; &#125; return advisors.toArray();&#125; 123456789101112protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) &#123; //获取所有候选的增强器 List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors(); //找到可以应用在当前Bean的增强器 List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName); extendAdvisors(eligibleAdvisors); if (!eligibleAdvisors.isEmpty()) &#123; //给增强器排序 eligibleAdvisors = sortAdvisors(eligibleAdvisors); &#125; return eligibleAdvisors;&#125; 123456789101112protected List&lt;Advisor&gt; findAdvisorsThatCanApply( List&lt;Advisor&gt; candidateAdvisors, Class&lt;?&gt; beanClass, String beanName) &#123; ProxyCreationContext.setCurrentProxiedBeanName(beanName); try &#123; //最后调用AOP的工具类进行pointCut的match操作 return AopUtils.findAdvisorsThatCanApply(candidateAdvisors, beanClass); &#125; finally &#123; ProxyCreationContext.setCurrentProxiedBeanName(null); &#125;&#125; 回到wrapIfNecessary方法，当获取到的advisors增强器不为空时，将调用createProxy创建代理对象 1234567891011121314151617181920212223242526272829303132protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) &#123; if (this.beanFactory instanceof ConfigurableListableBeanFactory) &#123; AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); &#125; ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.copyFrom(this); if (!proxyFactory.isProxyTargetClass()) &#123; if (shouldProxyTargetClass(beanClass, beanName)) &#123; proxyFactory.setProxyTargetClass(true); &#125; else &#123; evaluateProxyInterfaces(beanClass, proxyFactory); &#125; &#125; //获取所有应用在当前Bean的增强器（通知方法） Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); //保存到proxyFactory proxyFactory.addAdvisors(advisors); proxyFactory.setTargetSource(targetSource); customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) &#123; proxyFactory.setPreFiltered(true); &#125; //用代理工厂创建对象 return proxyFactory.getProxy(getProxyClassLoader());&#125; 进一步分析proxyFactory.getProxy(getProxyClassLoader());是怎么通过代理工厂创建代理对象的 123public Object getProxy(@Nullable ClassLoader classLoader) &#123; return createAopProxy().getProxy(classLoader);&#125; 123456protected final synchronized AopProxy createAopProxy() &#123; if (!this.active) &#123; activate(); &#125; return getAopProxyFactory().createAopProxy(this);&#125; 123456789101112131415161718192021@Overridepublic AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &#123; Class&lt;?&gt; targetClass = config.getTargetClass(); if (targetClass == null) &#123; throw new AopConfigException(\"TargetSource cannot determine target class: \" + \"Either an interface or a target is required for proxy creation.\"); &#125; //Spring支持两种代理模式：由spring自行决定 //当Bean实现了接口时，使用jdk动态代理，否则使用Cglib动态代理,可以强制设置使用cglib动态代理 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &#123; //创建JDK的动态代理 return new JdkDynamicAopProxy(config); &#125; //创建Cglib的动态代理 return new ObjenesisCglibAopProxy(config); &#125; else &#123; return new JdkDynamicAopProxy(config); &#125;&#125; 由于我们没有实现接口，所以spring选择了创建Cglib动态代理对象，容器中保存了组件的代理对象（cglib增强后的对象），这个对象里面保存了详细信息（比如增强器，目标对象，xxx）； 比如可以看到存储在代理对象中的通知方法、切入方法、切入时机等等信息 接着进下一步执行的方法，可以看到cglib动态代理对象执行了intercept方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Override@Nullablepublic Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; Object oldProxy = null; boolean setProxyContext = false; Object target = null; TargetSource targetSource = this.advised.getTargetSource(); try &#123; if (this.advised.exposeProxy) &#123; // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; &#125; //要切入的目标对象 // Get as late as possible to minimize the time we \"own\" the target, in case it comes from a pool... target = targetSource.getTarget(); Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null); //根据ProxyFactory对象获取将要执行的目标方法拦截器链； List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; // Check whether we only have one InvokerInterceptor: that is, // no real advice, but just reflective invocation of the target. if (chain.isEmpty() &amp;&amp; Modifier.isPublic(method.getModifiers())) &#123; // We can skip creating a MethodInvocation: just invoke the target directly. // Note that the final invoker must be an InvokerInterceptor, so we know // it does nothing but a reflective operation on the target, and no hot // swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); //如果没有拦截器链，直接执行目标方法; retVal = methodProxy.invoke(target, argsToUse); &#125; else &#123; //如果有拦截器链，把需要执行的目标对象，目标方法，拦截器链等信息传入创建一个 CglibMethodInvocation 对象 //并调用 Object retVal = CglibMethodInvocation.proceed(); // We need to create a method invocation... retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); &#125; retVal = processReturnType(proxy, target, method, retVal); return retVal; &#125; finally &#123; if (target != null &amp;&amp; !targetSource.isStatic()) &#123; targetSource.releaseTarget(target); &#125; if (setProxyContext) &#123; // Restore old proxy. AopContext.setCurrentProxy(oldProxy); &#125; &#125;&#125; 看看他是怎么调用方法生成拦截器链的 12345678910public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(Method method, @Nullable Class&lt;?&gt; targetClass) &#123; MethodCacheKey cacheKey = new MethodCacheKey(method); List&lt;Object&gt; cached = this.methodCache.get(cacheKey); if (cached == null) &#123; cached = this.advisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice( this, method, targetClass); this.methodCache.put(cacheKey, cached); &#125; return cached;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Overridepublic List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice( Advised config, Method method, @Nullable Class&lt;?&gt; targetClass) &#123; // This is somewhat tricky... We have to process introductions first, // but we need to preserve order in the ultimate list. AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance(); //能够应用在目标方法的增强器（而不是容器中的所有增强器） Advisor[] advisors = config.getAdvisors(); //创建一个List保存目标方法的所有拦截器，为它赋予初始化长度：5 //一个默认的ExposeInvocationInterceptor 和 （LogAspects）4个自定义增强器； List&lt;Object&gt; interceptorList = new ArrayList&lt;&gt;(advisors.length); Class&lt;?&gt; actualClass = (targetClass != null ? targetClass : method.getDeclaringClass()); Boolean hasIntroductions = null; //遍历增强器，将其转为Interceptor； for (Advisor advisor : advisors) &#123; if (advisor instanceof PointcutAdvisor) &#123; // Add it conditionally. PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor; if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) &#123; MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher(); boolean match; if (mm instanceof IntroductionAwareMethodMatcher) &#123; if (hasIntroductions == null) &#123; hasIntroductions = hasMatchingIntroductions(advisors, actualClass); &#125; match = ((IntroductionAwareMethodMatcher) mm).matches(method, actualClass, hasIntroductions); &#125; else &#123; match = mm.matches(method, actualClass); &#125; if (match) &#123; MethodInterceptor[] interceptors = registry.getInterceptors(advisor); if (mm.isRuntime()) &#123; // Creating a new object instance in the getInterceptors() method // isn't a problem as we normally cache created chains. for (MethodInterceptor interceptor : interceptors) &#123; interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm)); &#125; &#125; else &#123; interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; &#125; &#125; else if (advisor instanceof IntroductionAdvisor) &#123; IntroductionAdvisor ia = (IntroductionAdvisor) advisor; if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; else &#123; Interceptor[] interceptors = registry.getInterceptors(advisor); interceptorList.addAll(Arrays.asList(interceptors)); &#125; &#125; return interceptorList;&#125; 可以看到，生成了一条拦截器链（每一个通知方法又被包装为方法拦截器，利用MethodInterceptor机制） 1234567891011121314151617181920@Overridepublic MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException &#123; List&lt;MethodInterceptor&gt; interceptors = new ArrayList&lt;&gt;(3); Advice advice = advisor.getAdvice(); //如果是MethodInterceptor，直接加入到集合中 if (advice instanceof MethodInterceptor) &#123; interceptors.add((MethodInterceptor) advice); &#125; for (AdvisorAdapter adapter : this.adapters) &#123; if (adapter.supportsAdvice(advice)) &#123; //如果不是，使用AdvisorAdapter将增强器转为MethodInterceptor； interceptors.add(adapter.getInterceptor(advisor)); &#125; &#125; if (interceptors.isEmpty()) &#123; throw new UnknownAdviceTypeException(advisor.getAdvice()); &#125; //转换完成返回MethodInterceptor数组； return interceptors.toArray(new MethodInterceptor[0]);&#125; 最终可以看到如上图，有5个拦截器，其中一个是spring自带的ExposeInvocationInterceptor，而AspectJAfterAdvice和AspectJAfterThrowingAdvice是MethodInterceptor接口，直接添加到了拦截器中，剩下的则被AdvisorAdapter转换成MethodInterceptor。 以上就是拦截器链链的创建过程，回到intercept方法，当拦截器链创建成功之后，若存在拦截器链，将调用CglibMethodInvocation.proceed()方法。 123456789101112131415161718192021222324252627282930313233343536private int currentInterceptorIndex = -1;@Override@Nullablepublic Object proceed() throws Throwable &#123; //如果没有拦截器执行执行目标方法，或者拦截器的索引和拦截器数组-1大小一样（指定到了最后一个拦截器）执行目标方法； // We start with an index of -1 and increment early. if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; //利用反射执行目标方法 return invokeJoinpoint(); &#125; //按照索引自增先获取第【0】个拦截器ExposeInvocationInterceptor，然后调用拦截器的invoke方法 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; // Evaluate dynamic method matcher here: static part will already have // been evaluated and found to match. InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice; Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass()); if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123; return dm.interceptor.invoke(this); &#125; else &#123; // Dynamic matching failed. // Skip this interceptor and invoke the next in the chain. return proceed(); &#125; &#125; else &#123; // It's an interceptor, so we just invoke it: The pointcut will have // been evaluated statically before this object was constructed. return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this); &#125;&#125; 根据逻辑分析，最开始的时候currentInterceptorIndex= -1，然后执行++currentInterceptorIndex = 0，并获取下标【0】的拦截器，也就是ExposeInvocationInterceptor，并执行它的invoke方法 1234567891011121314//ExposeInvocationInterceptor类@Overridepublic Object invoke(MethodInvocation mi) throws Throwable &#123; //invocation是一个ThreadLocal对象，用于多个线程共享同一个【MethodInvocation】对象 MethodInvocation oldInvocation = invocation.get(); invocation.set(mi); try &#123; //再次调用MethodInvocation.proceed()方法 return mi.proceed(); &#125; finally &#123; invocation.set(oldInvocation); &#125;&#125; 这时候，再次调用了proceed方法，由于currentInterceptorIndex = 0，再次执行++currentInterceptorIndex，所以将获取下标【1】的拦截器MethodBeforeAdviceInterceptor并执行它的invoke方法 1234567//MethodBeforeAdviceInterceptor@Overridepublic Object invoke(MethodInvocation mi) throws Throwable &#123; //先调用Before增强器 this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed();&#125; 123456789101112//AspectJAfterAdvice@Overridepublic Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; //先接着链式调用拦截器链 return mi.proceed(); &#125; finally &#123; //不管是否返回异常，调用After增强器 invokeAdviceMethod(getJoinPointMatch(), null, null); &#125;&#125; 123456789//AfterReturningAdviceInterceptor@Overridepublic Object invoke(MethodInvocation mi) throws Throwable &#123; ////先接着链式调用拦截器链 Object retVal = mi.proceed(); //获取返回值，调用return增强器 this.advice.afterReturning(retVal, mi.getMethod(), mi.getArguments(), mi.getThis()); return retVal;&#125; 123456789101112131415//AspectJAfterThrowingAdvice@Overridepublic Object invoke(MethodInvocation mi) throws Throwable &#123; try &#123; //这时候调用proceed时，将满足currentInterceptorIndex = interceptors.size - 1,调用目标方法 return mi.proceed(); &#125; catch (Throwable ex) &#123; //trycatch中处理Exception增强器 if (shouldInvokeOnThrowing(ex)) &#123; invokeAdviceMethod(getJoinPointMatch(), null, ex); &#125; throw ex; &#125;&#125; 以上就是Spring的Aop工作原理过程，具体调用链如下图： 流程 AOP的切入过程： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#1.传入配置类，创建IOC容器#2.注册配置类，调用refresh() 刷新容器AbstractApplicationContext.refresh() #3.注册Bean的后置处理器来方便拦截bean的创建-&gt; registerBeanPostProcessors(beanFactory) #3.1 获取IOC容器已经定义了的需要创建对象的所有BeanPostProcessor -&gt; beanFactory.getBeanNamesForType(BeanPostProcessor) #3.2 给容器中加别的BeanPostProcessor -&gt; beanFactory.addBeanPostProcessor(BeanPostProcessor) #3.3 优先注册实现了PriorityOrdered接口的BeanPostProcessor #3.4 再给容器中注册实现了Ordered接口的BeanPostProcessor（AnnotationAwareAspectJAutoProxyCreator） # 实际上就是创建BeanPostProcessor对象，保存在容器中； -&gt; beanFactory.getBean() -&gt; doGetBean() -&gt; createBean() -&gt; doCreateBean() #3.4.1 创建Bean的实例 -&gt; createBeanInstance() #3.4.2 给bean的各种属性赋值 -&gt; populateBean() #3.4.3 初始化bean -&gt; initializeBean() #3.4.3.1 处理Aware接口的方法回调，回调实现BeanFactoryAware类的setBeanFactory方法 -&gt; invokeAwareMethods() #回调AbstractAdvisorAutoProxyCreator实现的setBeanFactory方法 -&gt; AbstractAdvisorAutoProxyCreator.setBeanFactory(beanFactory) #调用子类重写的initBeanFactory方法 -&gt; AnnotationAwareAspectJAutoProxyCreator.initBeanFactory(beanFactory) #3.4.3.2 执行后置处理器的postProcessBeforeInitialization() -&gt; applyBeanPostProcessorsBeforeInitialization() -&gt; BeanPostProcessor.postProcessBeforeInitialization() #3.4.3.3 执行自定义的初始化方法 如：@PostConstruct、@Init -&gt; invokeInitMethods() #3.4.3.4 执行后置处理器的postProcessAfterInitialization() -&gt; applyBeanPostProcessorsAfterInitialization() -&gt; BeanPostProcessor.postProcessAfterInitialization() #3.5 把创建成功的BeanPostProcessor注册到BeanFactory中 -&gt; beanFactory.addBeanPostProcessor(postProcessor) #3.6 注册没实现优先级接口的BeanPostProcessor #4.完成BeanFactory初始化工作；创建剩下的单实例bean-&gt; finishBeanFactoryInitialization(beanFactory) -&gt; preInstantiateSingletons() #4.1 遍历获取容器中所有定义的的Bean信息 -&gt; beanNames.iterator() #4.2 创建容器中未被创建的Bean对象 -&gt; beanFactory.getBean() -&gt; doGetBean() #4.2.1 先从缓存中获取当前bean，如果能获取到，说明bean是之前被创建过的，直接使用，否则调用createBean()创建 # Spring就是在这里保证了单实例的Bean只被创建一次，只要创建好的Bean都会被缓存起来 -&gt; getSingleton(beanName) #4.2.2 真正创建一个Bean -&gt; createBean() #【AnnotationAwareAspectJAutoProxyCreator】会在这个方法对所有bean创建之前有一个拦截,尝试返回代理对象 #解析BeforeInstantiation，给后置处理器一个机会来创建一个代理对象替代目标实例 #如果能返回代理对象就使用，如果不能就将调用doCreateBean创建Bean实例 -&gt; resolveBeforeInstantiation(beanName, mbdToUse) #后置处理器先尝试返回代理对象 -&gt; applyBeanPostProcessorsBeforeInstantiation(targetType, beanName) #拿到所有后置处理器，如果是InstantiationAwareBeanPostProcessor; #就执行postProcessBeforeInstantiation #【AnnotationAwareAspectJAutoProxyCreator】的父类【AbstractAutoProxyCreator】实现了该方法 -&gt; InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation() #返回的代理对象不为空，则调用 -&gt; applyBeanPostProcessorsAfterInitialization(bean, beanName) -&gt; BeanPostProcessor.postProcessAfterInitialization() #3.3.x 流程相同 -&gt; doCreateBean() 动态代理对象的创建过程： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556createBean():-&gt; resolveBeforeInstantiation(beanName, mbdToUse) -&gt; applyBeanPostProcessorsBeforeInstantiation(targetType, beanName) #【AbstractAutoProxyCreator】实现该方法，尝试拦截失败则将调用【doCreateBean】 -&gt; InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation() #1.判断当前bean是否在advisedBeans中（保存了所有需要增强bean） #2.判断当前bean是否是基础类型的Advice、Pointcut、Advisor、AopInfrastructureBean 或者是否是切面（@Aspect） # 实际上是调用了【AnnotationAwareAspectJAutoProxyCreator.isInfrastructureClass()】 -&gt; isInfrastructureClass() -&gt; AbstractAutoProxyCreator.isInfrastructureClass() -&gt; AspectJAdvisorFactory.isAspect() #3.是否需要跳过 实际上调用【AspectJAwareAdvisorAutoProxyCreator.shouldSkip()】 -&gt; shouldSkip() #获取候选的增强器（切面里面的通知方法）【List&lt;Advisor&gt; candidateAdvisors】 #每一个封装的通知方法的增强器是 【InstantiationModelAwarePointcutAdvisor】 #判断每一个增强器是否是 AspectJPointcutAdvisor 类型的；返回true -&gt; findCandidateAdvisors(); -&gt; super.shouldSkip() #尝试拦截失败，调用【创建普通对象实例】的方法-&gt; doCreateBean() -&gt; createBeanInstance() -&gt; populateBean() -&gt; initializeBean() -&gt; invokeAwareMethods() -&gt; applyBeanPostProcessorsBeforeInitialization() -&gt; BeanPostProcessor.postProcessBeforeInitialization() -&gt; invokeInitMethods() -&gt; applyBeanPostProcessorsAfterInitialization() #执行【AbstractAutoProxyCreator】实现的postProcessAfterInitialization() -&gt; BeanPostProcessor.postProcessAfterInitialization() #在需要的时候进行包装 -&gt; wrapIfNecessary(bean, beanName, cacheKey) #获取当前bean的所有增强器（通知方法） Object[] specificInterceptors -&gt; getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); -&gt; findEligibleAdvisors() #找到候选的所有的增强器 -&gt; findCandidateAdvisors(); #找到可以应用在当前Bean的增强器（找哪些通知方法是需要切入当前bean方法的） -&gt; findAdvisorsThatCanApply() #给增强器排序 -&gt; sortAdvisors() #保存当前bean在advisedBeans中； #如果当前bean需要增强，创建当前bean的代理对象； -&gt; createProxy() #获取所有应用在当前Bean的增强器（通知方法） -&gt; buildAdvisors() #保存到proxyFactory -&gt; proxyFactory.addAdvisors() #用代理工厂创建对象 -&gt; proxyFactory.getProxy(getProxyClassLoader()); #创建代理对象，Spri oxy(config);jdk动态代理; #ObjenesisCglibAopProxy(config);cglib的动态代理； -&gt; createAopProxy(AdvisedSupport config) #给容器中返回当前组件使用cglib增强了的代理对象； #以后容器中获取到的就是这个组件的代理对象，执行目标方法的时候，代理对象就会执行通知方法的流程； 动态代理的拦截（目标方法执行）过程： 123456789101112131415161718192021222324252627282930313233343536373839#容器中保存了组件的代理对象（cglib增强后的对象），这个对象里面保存了详细信息（比如增强器，目标对象，xxx）；#1.通过调用CglibAopProxy.intercept()拦截目标方法的执行CglibAopProxy.intercept() #2.根据ProxyFactory对象获取将要执行的目标方法拦截器链；-&gt; ProxyFactory.getInterceptorsAndDynamicInterceptionAdvice() -&gt; AdvisorChainFactory.getInterceptorsAndDynamicInterceptionAdvice() #2.1 获取应用在目标方法的所有增强器 #2.2 创建拦截器集合【List&lt;Object&gt; interceptorList】并赋予长度 #2.3 遍历所有增强器，将其转化为【Interceptor】 #2.4 如果是【MethodInterceptor】，直接加入到集合中 # 如果不是，使用【AdvisorAdapter】将增强器转为MethodInterceptor； -&gt; AdvisorAdapterRegistry.getInterceptors(advisor); #3.如果没有拦截器链，直接执行目标方法;-&gt; methodProxy.invoke(target, argsToUse); #4.如果有拦截器链，把需要执行的目标对象，目标方法， # 拦截器链等信息传入创建一个 CglibMethodInvocation 对象 #【拦截器链的触发过程】;-&gt; CglibMethodInvocation.proceed() #获取index=【0】的拦截器 -&gt; ExposeInvocationInterceptor.invoke() #获取index=【1】的拦截器 -&gt; MethodBeforeAdviceInterceptor.invoke() #调用before增强器 -&gt; MethodBeforeAdvice.before() #获取index=【2】的拦截器 -&gt; AspectJAfterAdvice.invoke() #获取index=【3】的拦截器 -&gt; AfterReturningAdviceInterceptor.invoke() #获取Index=【4】的拦截器 -&gt; AspectJAfterThrowingAdvice.invoke() #执行目标方法 -&gt; invokeJoinpoint() #如果抛异常，则调用exception增强器 -&gt; invokeAdviceMethod() #如果不抛异常，调用return增强器 -&gt; AfterReturningAdvice.afterReturning() #调用after增强器 -&gt; invokeAdviceMethod() 总结123456789101112131415161718191.@EnableAspectJAutoProxy 开启AOP功能2.@EnableAspectJAutoProxy 会给容器中注册一个组件AnnotationAwareAspectJAutoProxyCreator3.AnnotationAwareAspectJAutoProxyCreator是一个后置处理器；4.容器的创建流程： 1.registerBeanPostProcessors（）注册后置处理器；创建AnnotationAwareAspectJAutoProxyCreator对象 2.finishBeanFactoryInitialization（）初始化剩下的单实例bean 1.创建业务逻辑组件和切面组件 2.AnnotationAwareAspectJAutoProxyCreator拦截组件的创建过程 3.组件创建完之后，判断组件是否需要增强 是：切面的通知方法，包装成增强器（Advisor）;给业务逻辑组件创建一个代理对象（cglib）； 否：创建普通Bean实例5.执行目标方法： 1.代理对象执行目标方法 2.CglibAopProxy.intercept()； 1.得到目标方法的拦截器链（增强器包装成拦截器MethodInterceptor） 2.利用拦截器的链式机制，依次进入每一个拦截器进行执行； 3.效果： 正常执行：前置通知-》目标方法-》后置通知-》返回通知 出现异常：前置通知-》目标方法-》后置通知-》异常通知 “本篇文章主要摘自参考资料”","categories":[{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/tags/Spring/"}]},{"title":"'JDK1.8 HashMap和ConcurrentHashMap 源码和实现'","slug":"jdk8-hashmap","date":"2020-09-28T14:31:00.000Z","updated":"2020-10-22T16:13:42.264Z","comments":true,"path":"2020/09/28/jdk8-hashmap/","link":"","permalink":"https://midkuro.gitee.io/2020/09/28/jdk8-hashmap/","excerpt":"","text":"HashMap的源码和分析JDK1.8HashMap AVL树： 在计算机科学中，AVL树是最先发明的自平衡二叉查找树。在AVL树中任何节点的两个子树的高度最大差别为1，所以它也被称为高度平衡树。增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。 特点： 1.本身首先是一棵二叉搜索树。 2.带有平衡条件：每个结点的左右子树的高度之差的绝对值（平衡因子）最多为1。 也就是说，AVL树，本质上是带了平衡功能的二叉查找树（二叉排序树，二叉搜索树）。 树的左旋：绕着子结点逆时针转动，如下图： 树的右旋：绕着子结点顺时针转动，如下图 红黑树： 是一种自平衡二叉查找树，是一种特化的AVL树，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。 它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，插入和删除，这里的n 是树中元素的数目。 若一棵二叉查找树是红黑树，则它的任一子树必为红黑树。红黑树是一种平衡二叉查找树的变体，它的左右子树高差有可能大于 1，所以红黑树不是严格意义上的平衡二叉树（AVL），但 对之进行平衡的代价较低， 其平均统计性能要强于 AVL 。 红黑树的实际应用非常广泛，比如Linux内核中的完全公平调度器、高精度计时器、ext3文件系统等等，各种语言的函数库如Java的TreeMap和TreeSet。 红黑树的定义如下： 1.每个结点是红的或者黑的 2.根结点是黑的 3.每个叶结点是黑的（每个结点有默认的黑色的NULL结点） 4.如果一个结点是红的，则它的两个儿子都是黑的（父子结点之间不能出现两个连续的红结点） 5.对每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑结点（黑色平衡） 在算法导论中，新插入的结点优先默认是红色的，优先满足第五条定义，再满足其他定义。 案例 1.假设现在插入一个根结点（10） 123步骤：1.先插入一个红色的结点，满足第五条定义2.不满足第二条定义---&gt;变色 2.再插入一个结点（20） 123步骤：1.先和根节点比大小，判断要落在根节点的右边2.校验是否满足所有定义---&gt;满足 这是一颗正常的红黑树。因为每个节点，它的末尾节点都有隐藏的黑色空节点，所以满足第三条定义。 再插入一个结点（30） 1234步骤：1.插入节点后判断是否满足第五定义---&gt;左旋2.左旋后判断是否满足第二定义---&gt;需要变色3.旋转的结点和中心结点进行变色 再插入一个结点（40） 12345步骤：1.插入结点后判断是否满足第四定义---&gt;变色2.判断是否满足第二定义---&gt;变色结论：父节点是黑色的，则不需要调整 再插入两个结点（5）（25） 12步骤：父节点是黑色的，不需要调整 再插入一个结点（50） 1234步骤：1.父节点和叔叔节点变色2.祖父节点变色结论：父节点是红色时，叔叔节点也是红色时，则父节点和叔叔节点变色，祖父节点变色。 再插入两个结点（35）（60） 123步骤：1.先保证红框中的子树是一颗红黑树2.按照上文案例的结论，父节点和叔叔节点变色，祖父节点变色 12345步骤：1.在上面步骤的基础上，达到了子树是一颗红黑树2.然后把变色的结点（40）当做是一个新节点，插入到红框中的树中3.在这种情况下进行红框树的调整4.先左旋，结点重连，然后旋转的节点和中心节点变色 再插入个结点（6） 12步骤：1.(5)结点以(6)为中心，进行左旋 123步骤：2.然后就和上文插入(60)结点步骤相同3.先进行右旋，然后变色 总结当插入一个新节点（红色）时： 父节点是黑色的，不用进行调整 父节点是红色的，并且 1.叔叔是空的，旋转+变色 2.叔叔是红色，父节点+叔叔节点变黑色，祖父节点变红色 3.叔叔是黑色，旋转+变色 源码123456//当链表长度达到阈值8时，转换成红黑树static final int TREEIFY_THRESHOLD = 8;//满足树化的最小数组长度static final int MIN_TREEIFY_CAPACITY = 64;//当扩容红黑树拆分链表后判断其数量是否大于6，大于则重组红黑树static final int UNTREEIFY_THRESHOLD = 6; 123456789101112131415161718192021222324252627282930//红黑树存储结构对象static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; //父节点 TreeNode&lt;K,V&gt; parent; // red-black tree links //左子节点 TreeNode&lt;K,V&gt; left; //右子节点 TreeNode&lt;K,V&gt; right; //双向链表的前一个结点 TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion //颜色 boolean red; //继承Node得到，双向链表的下一个结点 //Node&lt;K,V&gt; next;&#125;//TreeNode继承的LinkedHashMap.Entrystatic class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125;//LinkedHashMap.Entry继承Map.Entry&lt;K,V&gt;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next;&#125; 所以说，上文TreeNode实际上是Node的子类，它有着两个属性，一个next，一个prev，也就是说，TreeNode还是一个双向链表。 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 由于JDK1.8的HashMap有了红黑树的保障，所以相对于计算Hash值没有JDK1.7那么复杂。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) //对数组初始化或扩容 n = (tab = resize()).length; //(n - 1) &amp; hash 计算数组下标 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //如果头结点的key等于插入的key，赋值给e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果P是个红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //如果P是个链表，HashMap默认 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; //使用尾插法插入链表尾部 p.next = newNode(hash, key, value, null); //当插入第九个元素时，调用树化方法 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //当插入的数据刚好落在链表中时 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //判断是否要更新，并且返回旧值 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //自增size后判断是否超过扩容因子（JDK1.7时还有判断当前链表是否有元素） if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 在JDK1.7中，采用头插法插入到链表的头部，而在JDK1.8中，采用的是尾插法插入到链表中，并且当链表的数量大于8时，也就是添加第九个元素时，会调用树化方法treeifyBin，根据条件将链表转换成红黑树。 12345678910111213141516171819202122232425262728//链表树化红黑树final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //如果当前数组为空 或者 数组长度小于64时 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) //对数组进行扩容 resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; //遍历链表 do &#123; //把Node类型转换成红黑树的TreeNode类型 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); //缓存头结点 if (tl == null) hd = p; else &#123; //建立双向链表关系 p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) //hd作为链表的头结点，也是红黑树的根节点，遍历链表把其他数值逐个插入到红黑树中 hd.treeify(tab); &#125;&#125; 1234//把Node类型转换成TreeNode类型TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);&#125; 接下来是真正的将链表树化的逻辑方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859final void treeify(Node&lt;K,V&gt;[] tab) &#123; TreeNode&lt;K,V&gt; root = null; //this（链表的头结点），开始遍历 for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123; //获取链表的下一个结点 next = (TreeNode&lt;K,V&gt;)x.next; //设置结点左右子结点都是NULL x.left = x.right = null; //如果root根节点对象等于null，则赋值root根节点对象，并且变黑色 if (root == null) &#123; x.parent = null; x.red = false; root = x; &#125; else &#123; //新增结点的Key的值 K k = x.key; //新增结点的hash值 int h = x.hash; //Key的数据类型 Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; //根节点的key值 K pk = p.key; //如果根结点的hash值大于新增结点的hash值，则放在左树上（dir = -1）代表左边 if ((ph = p.hash) &gt; h) dir = -1; //否则放在右边 else if (ph &lt; h) dir = 1; //如果hash值相同，获取key的数据类型，判断是否实现Comparable接口，则调用实现的compareTo方法 //如果compareTo还相同或者没实现Compareable接口，则调用tieBreakOrder else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) //比较getClass().getName() 和 System.identityHashCode dir = tieBreakOrder(k, pk); //一直遍历直到想放的位置没有结点，等于 null TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; //赋值新节点x的父节点 x.parent = xp; //如果左边放左边，如果右边放右边 if (dir &lt;= 0) xp.left = x; else xp.right = x; //执行插入红黑树过程 root = balanceInsertion(root, x); break; &#125; &#125; &#125; &#125; //把根节点存储到数组中,并且把红黑树的根节点设置成双向链表的根节点 moveRootToFront(tab, root);&#125; 123456789101112131415161718192021222324252627static &lt;K,V&gt; void moveRootToFront(Node&lt;K,V&gt;[] tab, TreeNode&lt;K,V&gt; root) &#123; int n; if (root != null &amp;&amp; tab != null &amp;&amp; (n = tab.length) &gt; 0) &#123; int index = (n - 1) &amp; root.hash; TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index]; if (root != first) &#123; Node&lt;K,V&gt; rn; //把红黑树的根节点赋值在数组上 tab[index] = root; //获取红黑树的根节点在双向链表中的前一个结点rp TreeNode&lt;K,V&gt; rp = root.prev; //如果红黑树根节点在双线链表中的下一个结点rn不为空 if ((rn = root.next) != null) //下一个结点的prev指向rp（等于跳过了root） ((TreeNode&lt;K,V&gt;)rn).prev = rp; //如果上一个结点rp不为空，它的next指向rn（等于跳过了root） if (rp != null) rp.next = rn; //如果原数组中的存储的链表头结点不为空，则通过头插法，把root插入到first之上 if (first != null) first.prev = root; root.next = first; root.prev = null; &#125; assert checkInvariants(root); &#125;&#125; 上文的方法主要是分析当插入新节点时，链表结构转换成红黑树的行为，如果插入新节点时，红黑树已经存在，则将调用putTreeVal方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; //查找key是否属于红黑树中 if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/* 红黑树的插入逻辑 @Params root 根节点 x 即将插入的结点*/static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceInsertion(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; x) &#123; //新节点默认为红色 x.red = true; //xp表示父节点，xpp表示x的祖父节点，xppl表示xpp的左孩子结点，xppr表示xpp的右孩子结点 for (TreeNode&lt;K,V&gt; xp, xpp, xppl, xppr;;) &#123; //如果x没有父节点，则表示x是第一个结点，自动成为根节点，根节点为黑色 if ((xp = x.parent) == null) &#123; x.red = false; return x; &#125; //如果父节点是黑色的，不需要做调整 else if (!xp.red || (xpp = xp.parent) == null) return root; //上面逻辑已经处理了父节点是黑色的情况，所以下面的逻辑父节点一定是红色的 //当新节点的父节点是xpp的左叶子节点时 if (xp == (xppl = xpp.left)) &#123; //叔叔节点不为空 且 叔叔节点等于红色 if ((xppr = xpp.right) != null &amp;&amp; xppr.red) &#123; //叔叔节点变黑色 xppr.red = false; //父节点变黑色 xp.red = false; //祖父节点变红色 xpp.red = true; //子树调整完成，可能需要递归调整，把祖父节点赋值给x，递归调整 x = xpp; &#125; //进入else语句 叔叔节点为空或者等于黑色 else &#123; //当新节点落在父节点的右边时 if (x == xp.right) &#123; root = rotateLeft(root, x = xp); //重新赋值xp 和xpp的值 xpp = (xp = x.parent) == null ? null : xp.parent; &#125; //如果xp（也就是之前插入的新节点）不为null if (xp != null) &#123; //把xp变成黑色 xp.red = false; //祖父节点不为null时，变成红色 if (xpp != null) &#123; xpp.red = true; //进行右旋 root = rotateRight(root, xpp); &#125; &#125; &#125; &#125; else &#123; //当新节点的父节点是xpp的右叶子节点，且它的叔叔节点不为空且红色 if (xppl != null &amp;&amp; xppl.red) &#123; xppl.red = false; xp.red = false; xpp.red = true; x = xpp; &#125; else &#123; if (x == xp.left) &#123; root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &#125; if (xp != null) &#123; xp.red = false; if (xpp != null) &#123; xpp.red = true; root = rotateLeft(root, xpp); &#125; &#125; &#125; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132//左旋static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateLeft(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; r, pp, rl; //如果新增的父节点p不等于null且 p的右子结点（新增节点） 不等于null //1.r = p.right （把新增节点赋值给 r） if (p != null &amp;&amp; (r = p.right) != null) &#123; //2.p.right = r.left解释： //新增的节点r.left默认为null ，将null 赋值给 p.right，等于取消p对r的指针 //rl != null 时主要用于递归父树左旋 if ((rl = p.right = r.left) != null) rl.parent = p; //3.r.parent = p.parent //将新增的节点r.parent指向p.parent上，也就是新增节点的祖父节点pp if ((pp = r.parent = p.parent) == null) //如果等于根节点，赋值黑色 (root = r).red = false; //用于定位p节点处于pp节点的左侧还是右侧，然后断开pp对p的指向，修改成pp对r的指向 //如果父节点落在祖父节点的左边 else if (pp.left == p) //把r当做pp的左叶子节点 pp.left = r; //如果父节点落在祖父节点的右边 else //把r当做pp右叶子节点 pp.right = r; //把p当做r的左叶子节点 r.left = p; p.parent = r; &#125; return root;&#125; 完成左旋之后进行变色，变完色之后右旋 1234567891011121314151617181920212223//通过调用 root = rotateLeft(root, xpp); 所以参数 p = xppstatic &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateRight(TreeNode&lt;K,V&gt; root, TreeNode&lt;K,V&gt; p) &#123; TreeNode&lt;K,V&gt; l, pp, lr; //祖父节点p和它的左子节点l不为空 if (p != null &amp;&amp; (l = p.left) != null) &#123; //用于右旋之后节点分配 if ((lr = p.left = l.right) != null) lr.parent = p; //如果祖父节点p是根节点，则p.parent等于null，右旋之后，l将作为根节点，所以变色黑色 if ((pp = l.parent = p.parent) == null) (root = l).red = false; //如果祖父节点p不是根节点，则获取p的父节点pp，右旋之后，pp指向l else if (pp.right == p) pp.right = l; else pp.left = l; //把p作为l的右结点 l.right = p; p.parent = l; &#125; return root;&#125; 再看一下扩容方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //扩容，长度左移 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; //新数组的大小乘以扩容因子 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //如果老数组不为空，也就是扩容逻辑 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //如果链表上只有一个元素，直接移动过去并且赋值到数组中 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果数组上的是红黑树 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //如果是链表，则先计算链表中的，应该落在原Index或者新Index（原index+原数组size）的 //拆分成两个链表，分别塞到数组两个下标中 do &#123; next = e.next; //hash值和原数组长度相与，等于0原数组 if ((e.hash &amp; oldCap) == 0) &#123; //赋值低位index的头结点 if (loTail == null) loHead = e; else //链接低位index的结点 loTail.next = e; //更新末尾结点 loTail = e; &#125; else &#123; //赋值高位index的头结点 if (hiTail == null) hiHead = e; else //链接高位index的结点 hiTail.next = e; //更新末尾结点 hiTail = e; &#125; &#125; while ((e = next) != null); //链表赋值到数组的低位index中 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //链表赋值到数组的高位index中 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 红黑树的扩容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; //数组上的红黑树根节点 TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; //遍历红黑树的双向链表 for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; //计数低位index的链表的个数 ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; //计数高位index的链表的个数 ++hc; &#125; &#125; //拆分成两个链表之后，比较 if (loHead != null) &#123; //如果链表长度&lt;=6 if (lc &lt;= UNTREEIFY_THRESHOLD) //退化成链表赋值到数组中 tab[index] = loHead.untreeify(map); else &#123; //当hiHead == null时，则等于红黑树不需要拆分，直接把整棵树（也就是根节点）移动到数组上 tab[index] = loHead; //hiHead不为空时，对低位链表进行树化，整个链表重新创建红黑树 if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; //以下逻辑和低位链表逻辑相同 if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) //新数组下标 = 原数组下标 + 原数组长度 tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125; 12345678910111213//遍历双向链表，把TreeNode类型转换成Node类型，建立单向链表，返回头结点final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125; HashMap的get方法： 1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 12345678910111213141516171819202122final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node //如果刚好等于根节点，返回 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; //如果它是红黑树，则调用红黑树的查找算法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; //否则循环链表查找 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 123final TreeNode&lt;K,V&gt; getTreeNode(int h, Object k) &#123; return ((parent != null) ? root() : this).find(h, k, null);&#125; 12345678910111213141516171819202122232425262728293031323334353637/** h: get的Key的hash值* k: get的key*/final TreeNode&lt;K,V&gt; find(int h, Object k, Class&lt;?&gt; kc) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right, q; //判断hash在左边 if ((ph = p.hash) &gt; h) p = pl; //在右边 else if (ph &lt; h) p = pr; //相等且key相同，返回节点 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; //如果左边等于null直接找右边 else if (pl == null) p = pr; //如果右边等于null直接找右边 else if (pr == null) p = pl; //如果key自定义了比较算法，compare之类的判断走哪一边 else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; //否则递归查询 else if ((q = pr.find(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); return null;&#125; ConcurrentHashMap1234//表示当前的整个ConcurrentHashMap正在扩容static final int MOVED = -1;//创建数组时用于Cas操作private transient volatile int sizeCtl; 123456789101112//把整个红黑树结构封在TreeBin对象中static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;\\ //红黑树的根节点 TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock&#125; ConcurrentHashMap的数组中将存储Node类型和``TreeBin类型，TreeBin用于承载红黑树的整个结构，其中有一个root`属性存储红黑树的根节点。 这样做的目的是为了后面对红黑树根节点加锁时，直接对TreeBin对象加锁，可以不用考虑在加锁的过程中，红黑树的根节点变化情况。 123public V put(K key, V value) &#123; return putVal(key, value, false);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //初始化数组 if (tab == null || (n = tab.length) == 0) tab = initTable(); //获取数组下标的Node对象并赋值到f中，并判断是否为空 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //通过cas操作赋值到数组下标中，如果失败则重新循环（就不会再进到这个条件了，因为数组下标内容已经不为空） if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //如果ConcurrentHashMap正在扩容，则帮助它进行扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; //对链表/红黑树的头节点加锁 synchronized (f) &#123; //判断加完锁之后头结点是否还是f（避免加锁时被修改了） if (tabAt(tab, i) == f) &#123; //如果是链表 if (fh &gt;= 0) &#123; //统计链表长度 binCount = 1; //遍历链表，插入 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //尾插法 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //如果链表长度大于8，则进行树化 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; //添加元素，总元素数量加1 addCount(1L, binCount); return null;&#125; 1234567891011121314151617181920212223242526private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) //放弃对CPU资源的控制，再和其他线程竞争CPU资源 Thread.yield(); // lost initialization race; just spin //CAS对sizeCtl减1，如果成功则创建tab数组 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // 16 - 4 = 12 扩容阈值 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; //赋值扩容阈值 sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 1234567891011121314151617181920212223242526272829private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; //树化前加锁链表头结点 synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; //改成双向链表 for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) //链表头结点 hd = p; else tl.next = p; tl = p; &#125; //通过TreeBin的构造方法创建红黑树并赋值到数组上 setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; “本篇文章主要摘自参考资料”","categories":[{"name":"HashMap","slug":"HashMap","permalink":"https://midkuro.gitee.io/categories/HashMap/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"HashMap","slug":"HashMap","permalink":"https://midkuro.gitee.io/tags/HashMap/"}]},{"title":"'JDK1.7 HashMap和ConcurrentHashMap 源码和实现'","slug":"jdk7-hashmap","date":"2020-09-28T14:30:00.000Z","updated":"2020-09-29T11:28:25.684Z","comments":true,"path":"2020/09/28/jdk7-hashmap/","link":"","permalink":"https://midkuro.gitee.io/2020/09/28/jdk7-hashmap/","excerpt":"","text":"HashMap的源码和分析JDK1.7HashMap 问题：JDK1.7中，HashMap是通过什么原理实现的呢？ 答案：数组+链表 问题：什么叫哈希碰撞（哈希冲突）？ 不同的键值通过哈希函数运算得到相同的哈希值，解决哈希冲突的方式有开放寻址法和链表法，ThreadLocalMap由于其元素个数较少，采用的是开放寻址法，而HashMap采用的是链表法来解决哈希冲突，即所有散列值相同的元素都放在相同槽对应的链表中（也就是数组+链表的方式）。 先分析一下HashMap的关键属性： 12345/*** The default initial capacity - MUST be a power of two.*///HashMap初始化容量大小，默认是16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 1234567/*** The maximum capacity, used if a higher value is implicitly specified* by either of the constructors with arguments.* MUST be a power of two &lt;= 1&lt;&lt;30.*///HashMap最大的容量大小static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; 12345/*** The load factor used when none specified in constructor.*///HashMap的扩容因子，默认是0.75static final float DEFAULT_LOAD_FACTOR = 0.75f; 12345678910/*** The next size value at which to resize (capacity * load factor).* @serial*/// If table == EMPTY_TABLE then this is the initial capacity at which the// table will be created when inflated.//阈值，当table == &#123;&#125;时，该值为初始容量（初始容量默认为16）；//当table被填充了，也就是为table分配内存空间后，threshold一般为 capacity*loadFactory。//HashMap在进行扩容时需要参考thresholdint threshold; 12345/*** The number of key-value mappings contained in this map.*///当前HashMap存储的键值对数量transient int size; 123456789/*** The number of times this HashMap has been structurally modified* Structural modifications are those that change the number of mappings in* the HashMap or otherwise modify its internal structure (e.g.,* rehash). This field is used to make iterators on Collection-views of* the HashMap fail-fast. (See ConcurrentModificationException).*///用于计算链表中的修改次数transient int modCount; 12345/*** An empty table instance to share when the table is not inflated.*///HashMap内部的存储结构是一个数组，此处数组为空，即没有初始化之前的状态 static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;; 12345/*** The table, resized as necessary. Length MUST Always be a power of two.*///HashMap的主干数组，就是一个Entry数组，初始值为空数组&#123;&#125;，主干数组的长度一定是2的次幂transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，Entry是一个链表，每一个Entry包含一个key-value键值对，每一个Entry都有一个next属性指向下一个Entry对象。 Entry是HashMap中的一个静态内部类。代码如下： 12345678910111213141516static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next;//存储指向下一个Entry的引用，单链表结构 int hash;//对key的hashcode值进行hash运算后得到的值，存储在Entry，避免重复计算 /** * Creates new entry. */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; &#125; 可以看到，Entry有一个构造函数，该构造函数第三个参数是Entry&lt;K,V&gt; n，主要用于链表的头插入，传入链表的链表头，将新生成的Entry对象作为链表的头部，next属性指向原链表头。 接着看一下HashMap的构造函数： 1234567891011121314151617181920212223242526public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);&#125;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap(int initialCapacity, float loadFactor) &#123; //当初始化的容量小于0时抛出异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); //当初始化容量大于最大值时，修改成最大值 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; //这里先把初始化的容量大小赋值给 threshold阈值 threshold = initialCapacity; //LinkedHashMap初始化的使用，HashMap类是个空方法 init();&#125; 在看HashMap的put方法之前，先看一个例子： 12345678public class Demo &#123; public static void main(String[] args) &#123; HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(\"1\", \"2\"); String a = map.put(\"1\", \"3\"); System.out.println(a); //输出结果：2 &#125;&#125; 为什么会输出结果是【2】呢？来HashMap的put方法： 12345678910111213141516171819202122232425262728public V put(K key, V value) &#123; //采用了懒加载，初始化HashMap对象时并未真正赋予其数组大小 if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; //当Key等于null时，默认其存储的数组下标是0 if (key == null) return putForNullKey(value); //计算Key的Hash值 int hash = hash(key); //将Hash值进行算法计算，得出存储的数组下标 int i = indexFor(hash, table.length); //遍历寻找key值是否存在于链表中，存在则替换value成新值，并且返回旧值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; //修改次数++ modCount++; //不存在于链表中，执行添加操作 addEntry(hash, key, value, i); return null;&#125; 接着解析一下put方法的逻辑，可以看到它懒加载时调度了inflateTable方法： 1234567891011121314151617181920/*** Inflates the table. * 初始化table数组大小*/private void inflateTable(int toSize) &#123; // Find a power of 2 &gt;= toSize // 用于获取toSize 大于或等于的 2的次方数 HashMap规定了容量大小必须是2个次方倍 int capacity = roundUpToPowerOf2(toSize); threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity);&#125;private static int roundUpToPowerOf2(int number) &#123; // assert number &gt;= 0 : \"number must be non-negative\"; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1;&#125; 1234567891011//int java.lang.Integer.highestOneBit(int i) //返回小于等于i的2的次方数public static int highestOneBit(int i) &#123; // HD, Figure 3-1 比如：i=10 binary（10）= 0000 1010 i |= (i &gt;&gt; 1); //0000 1010 | 0000 0101 = 0000 1111 i |= (i &gt;&gt; 2); //0000 1111 | 0000 0011 = 0000 1111 i |= (i &gt;&gt; 4); //以下也如此，主要是为了把后面的位数都填充为1 i |= (i &gt;&gt; 8); i |= (i &gt;&gt; 16); return i - (i &gt;&gt;&gt; 1); //0000 1111 - 0000 0111 = 0000 1000&#125; 关注代码：Integer.highestOneBit((number - 1) &lt;&lt; 1)1、highestOneBit获取的是小于等于i的2次方数，而这里需要获取大于等于i的2次方数 2、通过向左位移一位，将数字扩大，如number=10，需要将它扩大区间，让它落在【16 - 32】之间 3、（number - 1）是为了兼容特殊场景，如number等于2的次方数 思考：HashMap的采用的数组+链表的存储方式，那么当一个键值对put进来时，它的下标是怎么计算的呢？ 思考：为什么HashMap规定了其容量的大小必须是2个次方数？其原因是什么？ put方法接着往下看，可以看到，它把Key值拿去做了HashCode运算，并调用indexFor，根据返回的HashCode值计算该键值对应该存放的Entry数组下标 1234567/*** Returns index for hash code h.*/static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h &amp; (length-1);&#125; 举个例子： 意义 二进制 十进制 length 0001 0000 16 length-1 0000 1111 15 HashCode 1010 1010 hashCode &amp; (length-1) 0000 1010 可以看到下标的结果将落在了【0 - 15】 中，通过length -1，将低位全部变成1，进行与运算后，下标必定落在其范围中，这也是为什么规定了HashMap的容量必须是2的次方数。 细心的同学可以发现，这里参与计算的只有HashCode的地位，而HashCode的高位并没有参与计算，那么就会导致数据分散在数组中会很不均匀，这时候回过头再来看上一行的hash方法： 1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; //当hashSeed!=0时，计算时hash值将加入哈希种子打散hash值的分布 h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 可以看到，当取到了hashCode之后，对hashCode进行了右移的异或运算，再将得出的结果拿去计算数组下标，这是为了让hashcode的高位也能参与到数组下标的计算过程当中，解决数据分布不均匀的问题。 再接着往下看put方法的执行，定位到数组下标后遍历其链表，判断链表是否存在相同的key值，如果找到，新值覆盖旧值，并且返回旧值。这也是为什么上文例子中，输出的结果是【2】的原因。 接着详细看看put方法中执行的addEntry方法： 12345678910111213141516171819202122232425/*** int hash: 当前Key的Hash值* bucketIndex: 数组下标*/void addEntry(int hash, K key, V value, int bucketIndex) &#123; //判断是否需要扩容 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; //需要扩容时，传参传入了table.length的长度的两倍 resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; //获取当前链表的表头 Entry&lt;K,V&gt; e = table[bucketIndex]; //将key-value键值对赋予到新Entry对象中，并通过头插入法，其Entry的next属性指向原链表表头 //则新的Entry对象成为了链表的新表头，并将该表头存储在table数组中。 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); //添加新元素，hashMap的元素数量++ size++;&#125; 注意：根据源码可以得出，JDK1.7的HashMap插入链表采用的是“头插入”法。 问题：为什么采用头插法呢？ 答案：因为头插法效率高，不需要遍历链表。 问题：在添加新的键值对的时候，需要判断是否需要扩容，那么它什么情况下需要扩容？ 答案： 1.当前HashMap的键值对数量（size）&gt;= threshold【threshold=capacity（当前数组容量）*loadFactory（扩容因子）】 2.Entry数组上的元素不为空 问题：HashMap为什么需要扩容？ 答案：初始化的Entry数组容量是16，元素过多会导致链表过长，当调用get方法遍历链表时会增加耗时，所以需要通过扩容，将一条链表的数据内容分散成多条链表，添加到扩容数组的新下标中。 接下来看看他的扩容逻辑，当满足扩容条件时，调度了resize方法： 1234567891011121314151617181920212223242526272829303132333435363738void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;/*** Transfers all entries from current table to newTable.*/void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; //遍历原Entry数组 for (Entry&lt;K,V&gt; e : table) &#123; //遍历链表中的每一个非空Entry while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; //重新计算该Entry需要存储的数组下标 int i = indexFor(e.hash, newCapacity); //将next属性指向原链表头 e.next = newTable[i]; //替换数组中的链表头位置 newTable[i] = e; //将e元素指向下一个链表中的Entry e = next; &#125; &#125;&#125; key的rehash是有条件的，需要根据参数的布尔值决定它是否需要重新计算hash值，并不是所有扩容都需要重新计算key的Hash值。 假设链表中有三个元素，分别是【1、2、3】，具体行为如下： 在遍历过程中，由于数组下标没有发生变化，其Entry对象依旧将指向新数组的同一个下标，接着循环遍历链表的第二个元素。 遍历第二个元素时，通过表头插入法，其next指向原链表表头，并将自身作为Entry数组的链表头，最终得出的结果如下： 可以看到，在扩容过程中，计算出来的数组下标没有发生变化时，链表被反序存储了。 问题：怎么将一条链表的数据内容分散成多条链表，添加到扩容数组的新下标中？新下标满足什么规律？ 假设原数组长度是16，那么扩容后则等于32，看看其计算下标的变化： 意义 二进制 十进制 length 0010 0000 32 length-1 0001 1111 31 Akey：HashCode 1010 1010 hashCode &amp; (length-1) 0000 1010 index=10 Bkey：HashCode 1011 1010 hashCode &amp; (length-1) 0001 1010 index=26 可以看到，当Akey=HashCode=1010 1010时，计算的数组下标未发生变化，而当Bkey=HashCode=1011 1010时，计算的等于26，也就是说，通过这种方式，就能够将属于同一个链表的元素，在重新计算下标的过程中，将链表元素分配到其他新的链表中。 在Hash值未被重新计算的前提下，若链表元素被分配到其他新链表时，其新链表的下标=原下标+原数组长度。 问题：HashMap为什么在多线程并发的情况下会出现问题？著名的HashMap死锁问题原因是什么？ 假设现在有两条线程同时对同一个HashMap操作，执行put方法，而且刚好满足扩容条件时，假设这时候两条线程都运行到了transfer方法的循环语句，如下： 1234567891011121314151617void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; //假设两条多线程都运行到该行位置 if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 由于代码中遍历的table数组是一个成员变量，是共享的，所以循环到该点时的指向如下图： 由于Java的多线程并发是通过CPU上下文切换交替执行的，假设这时候线程2被CPU挂起了，线程1执行完扩容操作，线程2再恢复执行，那么当线程1执行完扩容后，其对应的table数组内容已经发生改变，当线程2被CPU唤醒继续执行扩容时，其结构图如下： 按照代码的流程走向，经过一次while循环以后，值得注意的是，其e对象指向Entry对象（1），其next对象指向Entry（2），得到如下： 再经过一次while循环以后，其原本的Entry对象（2）的next属性指向Entry对象（1），所以其next对象将会重新指向Entry对象（1），将得到下图： 再经过一次while循环以后，其next对象将会指向null值，而Entry对象（1）的next属性将会指向原表头Entry对象（2），将得到下图： 从逻辑上可以看出，在多线程情况下造成了循环链表，由于最后的循环中的next对象指向了null，所以线程2的扩容是可以执行的，但是当有其他线程遍历该循环链表时，将会造成死循环，耗尽CPU资源，这就是HashMap在多线程并发情况下造成的死锁问题。 问题：如何在多线程情况下避免HashMap的死锁问题？ 答案：如果已知了数据长度时，可以使用public HashMap(int initialCapacity, float loadFactor)构造函数设置其大小以及扩容因子，使得size &gt;= threshold条件不成立，避免造成扩容。 接着再回去看看resize和transfer方法，通过源码得知，initHashSeedAsNeeded方法是控制是否需要重算hash值，在它在什么情况下需要重算key的hash值呢？ 123456789101112131415final boolean initHashSeedAsNeeded(int capacity) &#123; //初始条件下 哈希种子hashSeed=0，所以currentAltHashing = false; boolean currentAltHashing = hashSeed != 0; //具体逻辑：当capacity 大于 Holder.ALTERNATIVE_HASHING_THRESHOLD时，才可能重算Hash boolean useAltHashing = sun.misc.VM.isBooted() &amp;&amp; (capacity &gt;= Holder.ALTERNATIVE_HASHING_THRESHOLD); //取异或 不相等才返回true boolean switching = currentAltHashing ^ useAltHashing; if (switching) &#123; hashSeed = useAltHashing ? sun.misc.Hashing.randomHashSeed(this) : 0; &#125; return switching;&#125; 最后跟踪源码得知，在默认情况下，无论怎么扩容都不会造成重算Hash值，除非配置了JVM启动参数jdk.map.althashing.threshold。这里哈希种子的目的就是为了打散链表的hash值，使得每次扩容时，各链表分布更加均匀，这里就不再详细讨论了。 在HashMap的属性中，定义了一个transient int modCount;，用来记录该对象的修改次数，是hashMap提供的一种快速失败机制（fast fail），用于迭代遍历时校验对象是否被修改，当集合在迭代过程中对象被其他线程并发修改时，将会抛出ConcurrentModificationException异常。 12345678910111213141516final Entry&lt;K,V&gt; nextEntry() &#123; //在遍历集合之前会将modCount赋值给expectedModCount，接着遍历过程中会不断验证modCount是否发生变化 if (modCount != expectedModCount) throw new ConcurrentModificationException(); Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); if ((next = e.next) == null) &#123; Entry[] t = table; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; &#125; current = e; return e;&#125; 问题：那想要在遍历集合的过程中删除集合的元素，该如何实现？ 答案：通过使用Iterator迭代器遍历集合，调用迭代器的remove方法删除元素，该方法在删除元素的时候会重新对expectedModCount赋值，保证了modCount == expectedModCount。 ConcurrentHashMap众做周知，HashMap就算避免了死锁问题，也不是一个线程安全的集合，而HashTable类就是达到通过对HashMap里的各个方法加synchronized锁实现HashMap集合的线程安全，HashTable是一个同步容器类。 而ConcurrentHashMap是一个并发容器类，底层使用了Segment分段锁的原理，先从源码中看看它和HashMap相比，属性上的区别： 123456/*** The default concurrency level for this table, used when not* otherwise specified in a constructor.*///并发级别，用于计算一个Segment负责管理多少个Entry数组static final int DEFAULT_CONCURRENCY_LEVEL = 16; 1234567/*** The minimum capacity for per-segment tables. Must be a power* of two, at least two to avoid immediate resizing on next use* after lazy construction.*///规定了segment中的HashEntry数组最小容量，数组容量必须是2的次方数static final int MIN_SEGMENT_TABLE_CAPACITY = 2; 12345678910/*** The maximum number of times to tryLock in a prescan before* possibly blocking on acquire in preparation for a locked* segment operation. On multiprocessors, using a bounded* number of retries maintains cache acquired while locating* nodes.*///获取锁失败时，tryLock循环的最大次数，获取当前CPU核数，大于1则设置成64static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; 123456/*** The maximum number of segments to allow; used to bound* constructor arguments. Must be power of two less than 1 &lt;&lt; 24.*///规定了segment数组的最大值不能超过2的16次方static final int MAX_SEGMENTS = 1 &lt;&lt; 16; // slightly conservative 123456/*** Mask value for indexing into segments. The upper bits of a* key's hash code are used to choose the segment.*///segmentMask = segment[].length - 1 用来执行【haschCode &amp; segmentMask】计算Hash值final int segmentMask; 12345/*** The segments, each of which is a specialized hash table.*///ConcurrentHashMap的分段锁对象，自身带了一把锁且存储了链表结构final Segment&lt;K,V&gt;[] segments; 在HashEntry类ConcurrentHashMap是的基础单元(节点)，是实际数据的载体，等同于HashMap中的Entry。 123456static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;&#125; Segment 继承 ReentrantLock 锁,用于存放数组 HashEntry[]。 1234567891011121314151617181920212223242526272829303132/*** Segments are specialized versions of hash tables. This* subclasses from ReentrantLock opportunistically, just to* simplify some locking and avoid separate construction.*/static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; /** * The maximum number of times to tryLock in a prescan before * possibly blocking on acquire in preparation for a locked * segment operation. On multiprocessors, using a bounded * number of retries maintains cache acquired while locating * nodes. */ static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; //HashEntry数组，ConcurrentHashMap数据的存储的载体 transient volatile HashEntry&lt;K,V&gt;[] table; /** * The number of elements. Accessed only either within locks * or among other volatile reads that maintain visibility. */ //HashEntry的数组中的所有HashEntry大小（包括链表） transient int count; //HashEntry数组的变化次数 transient int modCount; //扩容阈值 transient int threshold; //扩容因子 final float loadFactor;&#125; 在看看ConcurrentHashMap的构造函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Creates a new, empty map with a default initial capacity (16), * load factor (0.75) and concurrencyLevel (16). */public ConcurrentHashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);&#125;public ConcurrentHashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);&#125;public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL);&#125;@SuppressWarnings(\"unchecked\")public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); //规定了不能大于2的16次方 if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments //该值用于存储segment数组容量的次方数 int sshift = 0; int ssize = 1; //该循环主要是找大于等于concurrencyLevel的2的次方数 //默认的concurrencyLevel=16，循环4次后，sshift=4,ssize=16 while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; this.segmentShift = 32 - sshift; //计算hash值= hashCode &amp; (segment.length -1) ，这里segmentMask=segment.length-1 this.segmentMask = ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //计算的segment对象的HashEntry数组大小=初始容量大小/并发级别 int c = initialCapacity / ssize; //由于是向上取整，所以如果segment所有HashEntry数组之和小于初始容量大小，则自增数组大小 if (c * ssize &lt; initialCapacity) ++c; //规定最小的HashEntry数组大小=2 int cap = MIN_SEGMENT_TABLE_CAPACITY; //规定HashEntry数组必须是2的次方数，所以循环获取大于等于计算的HashEntry数组大小的2的次方数 while (cap &lt; c) cap &lt;&lt;= 1; // create segments and segments[0] //在初始化Segment数组时默认初始化segment[0]，主要是为了生成原型，当初始化其他segment对象时无需再计算HashEntry数组大小 Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0] this.segments = ss;&#125; 可以看到其构造函数相比HashMap，多了一个concurrencyLevel参数，该参数主要是用来设置并发级别，用于 计算每个segment的HashEntry数组大小，ConcurrentHashMap规定了segment数组和HashEntry数组的大小必须是2的次方数，其缘由与HashMap一致。 ConcurrentHashMap构造方法的执行步骤： 1.判断参数的范围合法性 2.计算concurrencyLevel大于等于2的次方数 3.设置segmentMask的值 4.计算segment对象的HashEntry数组长度 5.设置HashEntry数组长度的合理长度（2&lt;=计算的HashEntry数组长度&lt;=合理长度=2的次方数） 6.根据合理的segment数组长度及HashEntry数组长度初始化Segment[]和Segment[0] 接着看ConcurrentHashMap的put方法： 12345678910111213141516public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; //concurrentHashMap规定了Key和Value不能为NULL if (value == null) throw new NullPointerException(); //计算Key的Hash值 int hash = hash(key); //计算需要存储的segment数组中的下标 int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; //获取segment数组中的第j个位置的segment对象并赋值给对象s，如果为null，则初始化segment对象并存储进数组中 if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); //将key-value键值对存储到segment中的HashEntry数组中 return s.put(key, hash, value, false);&#125; 上文中通过调用UNSAFE.getObject(segments, (j &lt;&lt; SSHIFT) + SBASE)获取Segment数组中的第j个下标的segment对象，因为通过这种偏移量获取对象效率会高很多。 问题：在计算segment数组下标时，为什么需要执行(hash &gt;&gt;&gt; segmentShift)向右位移呢？ 123456//通过观察ConcurrentHashMap的构造函数，其中有部分代码如下：while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1;&#125;this.segmentShift = 32 - sshift; 上文分析了构造函数，该循环用于计算大于等于concurrencyLevel的2的次方数，假设concurrencyLevel=16，那么通过循环得知sshift=4，segmentShift = 32 - sshift = 28。 如上图，其向右无符号位移28（segmentShift=28）位，最后将保留HashCode的高4（sshift=4）位，并使用HashCode的高位和segmentMark相与计算所在的segment数组下标。 总而言之，就是取了HashCode的高位，和segmentMask计算数组下标，向右偏移获取HashCode高位的数量取决于初始化的concurrencyLevel的值，是2的几次方。 当put方法执行计算Segment[]下标后，获取的segment对象有可能尚未初始化，根据逻辑会调度ensureSegment方法： 123456789101112131415161718192021222324252627282930private Segment&lt;K,V&gt; ensureSegment(int k) &#123; final Segment&lt;K,V&gt;[] ss = this.segments; long u = (k &lt;&lt; SSHIFT) + SBASE; // raw offset Segment&lt;K,V&gt; seg; //进入方法后重新判断是否被其他线程初始化，若被初始化，则直接赋值seg对象并返回 if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; //获取segment[0]对象，以它为原型初始化segment对象 Segment&lt;K,V&gt; proto = ss[0]; // use segment 0 as prototype //获取原型的HashEntry数组长度 int cap = proto.table.length; //获取扩容因子 float lf = proto.loadFactor; //计算阈值 int threshold = (int)(cap * lf); HashEntry&lt;K,V&gt;[] tab = (HashEntry&lt;K,V&gt;[])new HashEntry[cap]; //double Check，再次判断是否已被其他线程初始化 if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // recheck //创建Segment对象 Segment&lt;K,V&gt; s = new Segment&lt;K,V&gt;(lf, threshold, tab); //采用CAS自旋，将新生成的Segment对象塞进数组中，若失败，则获取数组对象返回 while ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s)) break; &#125; &#125; &#125; return seg;&#125; 通过分析，当有多个线程同时并发执行创建同一个数组下标的segment对象时，由于CAS自旋机制，最终只会有一个线程创建成功，其他线程将获取数组对象并返回，从而达到在并发情况下的线程安全。 创建完segment对象后，将调用Segment.put()方法，添加key-value键值对到Segment对象中，我们来看看Segment类的put方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; //尝试加锁 tryLock不阻塞 HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; //计算存储的HashEntry数组下标 int index = (tab.length - 1) &amp; hash; //获取HashEntry数组中的index下标，这里命名的first指的是HashEntry中的链表的头结点 HashEntry&lt;K,V&gt; first = entryAt(tab, index); //遍历链表 for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; //如果是ifAbsent,则不更新值，直接返回旧值 if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; //假设遍历到最后节点均未匹配到相同的key由于它是最后的链表节点，e.next==null //再次循环时，将会运行到下面的else条件新建节点 e = e.next; &#125; else &#123; //当获取锁失败时，会调用scanAndLockForPut提前生成node对象，这里只需设置链表头即可 if (node != null) node.setNext(first); else //创建HashEntry对象，采用头插法，新的HashEntry对象的next属性指向first node = new HashEntry&lt;K,V&gt;(hash, key, value, first); //HashEntry总数+1 int c = count + 1; //如果数量达到了扩容的阈值，则进行扩容 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else //添加HashEntry对象到数组中，并替换数组中的链表头（替换成新创建的HashEntry对象） setEntryAt(tab, index, node); //Setment中累加变化次数 ++modCount; //赋值新计算的count值 count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; //解锁ReentrantLock unlock(); &#125; return oldValue;&#125; 由于Segment继承了ReentrantLock，当它在插入元素时会调用tryLock非阻塞尝试获取锁，当获取锁失败时，调用scanAndLockForPut方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/*** Scans for a node containing given key while trying to* acquire lock, creating and returning one if not found. Upon* return, guarantees that lock is held. UNlike in most* methods, calls to method equals are not screened: Since* traversal speed doesn't matter, we might as well help warm* up the associated code and accesses as well.** @return a new node if key not found, else null*/private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) &#123; //根据Hash值计算数组下标并获取链表的表头 HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; HashEntry&lt;K,V&gt; node = null; //用这个变量来控制循环的逻辑 int retries = -1; // negative while locating node //循环尝试获取锁 while (!tryLock()) &#123; HashEntry&lt;K,V&gt; f; // to recheck first below if (retries &lt; 0) &#123; //当链表的表头 == null 或者遍历链表后未匹配到元素时，创建HashEntry对象 if (e == null) &#123; if (node == null) // speculatively create node node = new HashEntry&lt;K,V&gt;(hash, key, value, null); //设置retries=0用以下次循环时调用其他逻辑 retries = 0; &#125; //当链表表头不为空时，遍历链表，寻址到链表元素时设置retries=0调用其他逻辑 else if (key.equals(e.key)) retries = 0; else //当链表遍历到最后一个节点，e.next=null,当再次循环时，会调用创建HashEntry对象的逻辑 e = e.next; &#125; //当重试次数大于一定的次数时，直接调用阻塞的Lock方法 else if (++retries &gt; MAX_SCAN_RETRIES) &#123; lock(); break; &#125; //(retries &amp; 1) == 0 ：当retries是偶数时，返回true，表示每隔一次才去判断链表表头是否发生变化 //重新获取链表表头，当链表表头与原来获取的first不同时，设置retries=-1，重新遍历 else if ((retries &amp; 1) == 0 &amp;&amp; (f = entryForHash(this, hash)) != first) &#123; e = first = f; // re-traverse if entry changed retries = -1; &#125; &#125; return node;&#125; 说白了，当尝试获取锁失败而调度scanAndLockForPut方法，其目的是为了在无法获取锁的时候能够提前创建HashEntry对象并返回。 回头接着看Segment的put方法的步骤： 1.当Segment获取到锁之后，先进行遍历，判断HashEntry是否有同样的key值存在 2.若key值存在，根据参数onlyIfAbsent判断是否覆盖value值，并返回旧值 3.若key值不存在，则创建HashEntry对象并设置链表头（有可能在获取锁时创建） 4.判断其扩容条件，若需要扩容，则进行链表重排 5.若不需要扩容，则添加HashEntry对象到数组中，并替换数组中的链表头 6.更新count值和modCount值 接着来看看其扩容的方法，当满足count + 1 &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY条件时，将调用rehash扩容方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960//注意：这里传的参数是新的HashEntry对象，其next属性指向原链表的头部private void rehash(HashEntry&lt;K,V&gt; node) &#123; HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; //向左偏移1位，扩容一倍大小 int newCapacity = oldCapacity &lt;&lt; 1; //重新计算阈值 threshold = (int)(newCapacity * loadFactor); //初始化新的HashEntry数组 HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; //HashEntry[].length - 1 用于计算Hash值 int sizeMask = newCapacity - 1; for (int i = 0; i &lt; oldCapacity ; i++) &#123; //遍历旧的HashEntry数组 HashEntry&lt;K,V&gt; e = oldTable[i]; if (e != null) &#123; HashEntry&lt;K,V&gt; next = e.next; //计算出新的HashEntry数组下标 int idx = e.hash &amp; sizeMask; //当链表中只有一个元素时，直接将该元素赋值到数组中 if (next == null) // Single node on list newTable[idx] = e; else &#123; // Reuse consecutive sequence at same slot HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; //该循环的目的是从链表尾部截取出一条与链表末尾节点的新数组下标相同，并且相连的链表 //并存储该截取链表的头对象到lastRun对象，存储新数组下标到lastIdx中 for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; lastIdx = k; lastRun = last; &#125; &#125; //直接移动尾部截取的链表到新的数组下标中 newTable[lastIdx] = lastRun; // Clone remaining nodes //重新顺着从原链表头开始遍历，遍历到lastRun，也就是链表截取处时，跳出循环 for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; //采用头插法讲一个个元素分别插入到链表头中，并赋值给HashEntry数组 newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); &#125; &#125; &#125; &#125; //对原链表扩容完成之后，计算新的HashEntry的下标 int nodeIndex = node.hash &amp; sizeMask; // add the new node //替换链表头 node.setNext(newTable[nodeIndex]); //赋值到HashEntry数组中 newTable[nodeIndex] = node; table = newTable;&#125; 这里的扩容逻辑和HashMap不太一样，HashMap存在逻辑判断可能会重新计算key的hash值，而ConcurrentHashMap并没有，所以它的必定满足新数组下标=原下标+原数组长度。 它的扩容并非直接遍历整张链表，而是先遍历一次链表，计算每个元素的新数组下标，如果从某个A元素开始，一直到链表遍历完成，他们计算的新数组下标均相同，意味着可以直接截取该链表，从A元素开始一致到末尾，整条迁移到新节点上，如下图： 当迁截取部分链表赋值到新数组之后，遍历原链表，采用头插法插入链表，并赋值到新数组中，一直遍历到截取的A元素位置时挑出循环。最后才将新增的元素对象插入到扩容的数组中。 最后看看Segment类中的put方法中调用的setEntryAt方法： 12345678/** * Sets the ith element of given table, with volatile write * semantics. (See above about use of putOrderedObject.) */static final &lt;K,V&gt; void setEntryAt(HashEntry&lt;K,V&gt;[] tab, int i, HashEntry&lt;K,V&gt; e) &#123; UNSAFE.putOrderedObject(tab, ((long)i &lt;&lt; TSHIFT) + TBASE, e);&#125; 通过使用UNSAFE调用CPU指令，意思是将HashEntry对象赋值到HashEntry数组的index下标中。 接着看看ConcurrentHashMap的size方法，它的设计思想可以在编码中借鉴： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647static final int RETRIES_BEFORE_LOCK = 2; public int size() &#123; // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try &#123; for (;;) &#123; //当重试次数超过2次时，开启加锁计算 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; //累加各个segment的修改次数 sum += seg.modCount; //累加各个segment的元素数量 int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; //第一次循环：当ConcurrentHashMap的modCount=0时，代表没元素，跳出循环 //第二次循环：和上一次循环计算的元素总数量数比较，如果相同返回，不同则加锁 if (sum == last) break; //第一次循环计算的元素总数量赋值给last last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size; &#125; 其实它的实现逻辑很简单，先在不加锁的情况下，进行计算，第一次计算的结果和第二次计算的结果相同时，就认为这个结果是稳定的，直接返回，当两次计算的结果不相同时，则进行加锁计算。 “本篇文章主要摘自参考资料”","categories":[{"name":"HashMap","slug":"HashMap","permalink":"https://midkuro.gitee.io/categories/HashMap/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"HashMap","slug":"HashMap","permalink":"https://midkuro.gitee.io/tags/HashMap/"}]},{"title":"'字节顺序'","slug":"binary-endian","date":"2020-09-23T04:20:00.000Z","updated":"2020-12-06T06:18:54.105Z","comments":true,"path":"2020/09/23/binary-endian/","link":"","permalink":"https://midkuro.gitee.io/2020/09/23/binary-endian/","excerpt":"","text":"字节序了解什么是字节顺序前，先复习一下单位换算的基本概念。 位(bit)：计算机中的最小数据单位，计算机存储的都是二进制0和1这两个鬼。 字节(Byte)：字节是存储空间的基本计量单位，也是内存的基本单位，也是编址单位。例如，一个计算机的内存是4GB，就是该计算机的内存中共有4×1024×1024×1024个字节，意味着它有4G的内存寻址空间。 换算关系： 1 GB = 1024 MB 1 MB = 1024 KB 1 KB = 1024 Bytes 1 Byte = 8 bits 思考个问题，通常描述32位二进制数据，为什么是用8个十六进制数呢？如0x1A2B3C4D 4个二进制bit 表示的数值范围是从【0000 - 1111】，即【0 - 15】, 刚好等同于 一位 16进制数的数值范围0~F(15)，也就是说，4个二进制位(bit) = 1个十六进制(Hex)，8个二进制位(bit) = 一个字节(Byte) = 2个十六进制(hex)，32个二进制位(bit) = 四个字节(Byte) = 8个十六进制(hex)。 所以针对一个32位的二进制数值，通常十六进制来表示，如0x1A2B3C4D，总共四个字节，两个十六进制数表示一个字节，高位字节为0x1A，低位字节为0x4D；中间两个字节分别为0x2B和0x3C； 数值0x1A2B3C4D想要在计算机中正确使用，就必须要考虑在内存中将其对应的四个字节合理存储。假设内存的地址都是从低到高分配的，那么对于一个数值多个字节顺序存储就有两种存储方式： 方式一：数值的高位字节存放在内存的低地址端，低位字节存放在内存的高地址端： 内存低地址 ——————–&gt; 内存高地址 0x1A | 0x2B | 0x3C | 0x4D 高位字节 &lt;——————– 低位字节 方式二、数值的低位字节存放在内存的低地址端，高位字节存放在内存的高地址端： 内存低地址 ——————–&gt; 内存高地址 0x4D | 0x3C | 0x2B | 0x1A 低位字节 ——————–&gt; 高位字节 方式一 ，我们就称之为 大端（Big endian）模式；即数值高位字节放在内存的低地址端，低位字节放在内存的高地址端。 方式二 ，我们就称之为 小端（Little endian）模式；即数值低位字节放在内存的低地址端，高位字节放在内存的高地址端。 画图更直观理解一下： 总结大端小端是不同的字节顺序存储方式，统称为字节序； 大端模式，是指数据的高字节位 保存在 内存的低地址中，而数据的低字节位 保存在 内存的高地址中。这样的存储模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，而数据从高位往低位放。和我们”从左到右“阅读习惯一致。 小端模式，是指数据的高字节位 保存在 内存的高地址中，而数据的低字节位 保存在 内存的低地址中。这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低，和我们的逻辑方法一致。 优缺点Big-Endian 优点：靠首先提取高位字节，你总是可以由看看在偏移位置为0的字节来确定这个数字是正数还是负数。你不必知道这个数值有多长，或者你也不必过一些字节来看这个数值是否含有符号位。这个数值是以它们被打印出来的顺序存放的，所以从二进制到十进制的函数特别有效。因而，对于不同要求的机器，在设计存取方式时就会不同。 Little-Endian 优点：提取一个，两个，四个或者更长字节数据的汇编指令以与其他所有格式相同的方式进行：首先在偏移地址为0的地方提取最低位的字节，因为地址偏移和字节数是一对一的关系，多重精度的数学函数就相对地容易写了。 如果你增加数字的值，你可能在左边增加数字（高位非指数函数需要更多的数字）。因此，经常需要增加两位数字并移动存储器里所有Big-endian顺序的数字，把所有数向右移，这会增加计算机的工作量。不过，使用Little- Endian的存储器中不重要的字节可以存在它原来的位置，新的数可以存在它的右边的高位地址里。这就意味着计算机中的某些计算可以变得更加简单和快速。 网络字节顺序1、字节内的比特位不受这种顺序的影响比如一个字节 1000 0000 （或表示为十六进制 80H)不管是什么顺序其内存中的表示法都是这样。 2、大于1个字节的数据类型才有字节顺序问题比如 Byte A，这个变量只有一个字节的长度，所以根据上一条没有字节顺序问题。所以字节顺序是“字节之间的相对顺序”的意思。 3、大于1个字节的数据类型的字节顺序有两种比如 short B，这是一个两字节的数据类型，这时就有字节之间的相对顺序问题了。网络字节顺序是“所见即所得”的顺序。而Intel类型的CPU的字节顺序与此相反。比如上面的 short B=0102H(十六进制，每两位表示一个字节的宽度）。所见到的是“0102”，按一般数学常识，数轴从左到右的方向增加，即内存地址从左到右增加的话，在内存中这个 short B的字节顺序是：01 02这就是网络字节顺序。所见到的顺序和在内存中的顺序是一致的！假设通过抓包得到网络数据的两个字节流为：01 02 *而相反的字节顺序就不同了，其在内存中的顺序为：02 01*如果这表示两个 Byte类型的变量，那么自然不需要考虑字节顺序的问题。如果这表示一个 short 变量，那么就需要考虑字节顺序问题。根据网络字节顺序“所见即所得”的规则，这个变量的值就是：0102 假设本地主机是Intel类型的，那么要表示这个变量，有点麻烦：定义变量 short X，字节流地址为：pt，按顺序读取内存是为x=((short)pt);那么X的内存顺序当然是 01 02按非 “所见即所得” 的规则，这个内存顺序和看到的一样显然是不对的，所以要把这两个字节的位置调换。调换的方法可以自己定义，但用已经有的API还是更为方便。 网络字节顺序与主机字节顺序 网络字节顺序NBO（Network Byte Order）：按从高到低的顺序存储，在网络上使用统一的网络字节顺序，可以避免兼容性问题。 主机字节顺序（HBO，Host Byte Order）：不同的机器HBO不相同，与CPU设计有关计算机数据存储有两种字节优先顺序：高位字节优先和低位字节优先。Internet上数据以高位字节优先顺序在网络上传输，所以对于在内部是以低位字节优先方式存储数据的机器，在Internet上传输数据时就需要进行转换。 “本篇文章主要摘自参考资料”","categories":[{"name":"binary","slug":"binary","permalink":"https://midkuro.gitee.io/categories/binary/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"https://midkuro.gitee.io/tags/Linux/"}]},{"title":"'锁升级的过程'","slug":"synchronized-process","date":"2020-09-22T04:20:00.000Z","updated":"2020-12-14T01:07:02.598Z","comments":true,"path":"2020/09/22/synchronized-process/","link":"","permalink":"https://midkuro.gitee.io/2020/09/22/synchronized-process/","excerpt":"","text":"锁升级的过程Cache Line存储器是分层次的，离CPU越近的存储器，速度越快，每字节的成本越高，同时容量也因此越小。寄存器速度最快，离CPU最近，成本最高，所以个数容量有限，其次是高速缓存（缓存也是分级，有L1，L2等缓存），再次是主存（普通内存），再次是本地磁盘。 比如这时候有个应用程序xxx.exe，这时候启动该程序，操作系统的加载步骤如下： 1、程序指令加载到内存当中 2、PC指令寄存器存储了下一条即将运行的指令地址，根据地址从内存中读取一条一条的计算机指令到Registers寄存器组中进行运算 3、通过ALU运算逻辑单元进行运算 4、将结果回写到内存中 一个CPU在同一个时刻只能运行一个线程的指令，当有另外一条线程申请时，它会将之前的线程运行的相关数据保存起来，然后运行另外一条线程，来回交替执行，这种行为叫做线程上下文切换（Context Switch）。 而一个CPU中有多个PC指令寄存器时，也就等于CPU可以通过在CPU内部切换不同的PC指令寄存器来切换线程交替运行，能够更有效的提高CPU的速度。 其中的ALU交替的进行多个PC寄存器的工作时，叫做超线程，即一个ALU对应多个PC|Registers，如所谓的四核八线程。 而这时候涉及到了一个概念，Cache，CPU到内存之间的缓存分为三层： CPU的运行周期是内存的100倍，所以需要进行缓存来让CPU进行更高效的工作，以下是三层缓存的结构图： 局部性原理是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中，因为如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。 CPU到内存之间有很多层的内存，如图所示，CPU需要经过L1，L2，L3及主内存才能读到数据。从主内存读取数据时的过程如下： 1、当我左侧的CPU读取x的值的时候，首先会去L1缓存中去找x的值，如果没有，那么取L2，L3依次去找。 2、最后从主内存读入的时候，首先将内存数据读入L3，然后L2最后L1，然后再进行运算。 3、但是读取的时候，并不是只读一个X的值，而是按块去读取（跟电脑的总线宽度有关，一次读取一块的数据，效率更高）。 4、CPU读取X后，很可能会用到相邻的数据，所以在读X的时候，会把同一块中的Y数据也读进来。这样在用Y的时候，直接从L1中取数据就可以了。 读取的块就叫做缓存行cache line 。缓存行越大，局部性空间效率越高，但读取时间慢。缓存行越小，局部性空间效率越低，但读取时间快。目前多取一个平衡的值，64字节。 高速缓存其实就是一组缓存行(cache line)的固定大小的数据块，其大小是以突发读或者突发写周期的大小为基础的。 每个高速缓存行完全是在一个突发读操作周期中进行填充或者下载的。即使处理器只存取一个字节的存储器，高速缓存控制器也启动整个存取器访问周期并请求整个数据块。缓存行第一个字节的地址总是突发周期尺寸的倍数。缓存行的起始位置总是与突发周期的开头保持一致。 缓存对齐在java中，jdk一些涉及到多线程的类，有时候会看到类似于public volatile long p1,p2,p3,p4,p5,p6,p7;这样的代码，有的就是做的缓存行对齐。 我们设计一个实验去验证缓存行对齐的导致的性能问题，及相关的解决后的效率问题。这里的思路是，首先，我们写一个类T，这个类里面有一个用volatile修饰的long属性的值，这个值占用8个字节。然后声明一个静态数组，包含两个元素，分别T的两个对象。然后开启两个线程，让两个线程分别给数组的第一个值和第二个值赋值，执行一百万次，看执行的耗时。 1234567891011121314151617181920212223public class T01_CacheLinePadding &#123; public static volatile long[] orr = new long[2]; public static void main(String[] args) throws Exception &#123; Thread t1 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_000L; i++) &#123; orr[0] = i; &#125; &#125;); Thread t2 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_000L; i++) &#123; orr[1] = i; &#125; &#125;); final long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); //200ms左右 System.out.println((System.nanoTime()-start)/100_000); &#125;&#125; 假设数组中第一个值为X，第二个值为Y。左侧框内为第一个线程，执行修改X值的操作，右侧框内为第二个线程，修改Y的值。因为两个值在同一个缓存行中，所以在X值在读取的时候，同时将X值和Y值一起读入缓存。第二个线程只修改Y的值，但是同样将XY全部读入缓存。 线程1中X值发生修改后，由于使用了volatile关键字保证了线程的可见性，第二个线程中的X值需要进行更新。而线程2修改Y的值后也需要同样的操作，但是这个更新不是必要的，而且会影响执行的效率。 所以要避免在同一个缓存行中使用多个volatile关键字。 我们给第T的long值之前加入8个long值，由于一个缓存行的大小是64byte，8个long值刚好是64byte大小，这样Y值就会被挤到其他缓存行，这样彼此修改的时候就不会产生干扰，提高代码执行效率。 1234567891011121314151617181920212223242526/** * 缓存行对齐问题代码 */public class T02_CacheLinePadding &#123; public static volatile long[] orr = new T[16]; public static void main(String[] args) throws Exception &#123; Thread t1 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_000L; i++) &#123; orr[0] = i; &#125; &#125;); Thread t2 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_000L; i++) &#123; orr[8] = i; &#125; &#125;); final long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); //80ms左右 System.out.println((System.nanoTime()-start)/100_000); &#125;&#125; 两个需要同步的volatile值不处于同一块缓存行，所以强制更新时不会互相影响，执行后可以看出，第二套代码在执行的时候，代码要优于第一套代码的执行。 在单机的Disruptor缓存行对其中，采用这种方式保证该数据cursor一定能独自存储在一块缓存行中。 123public long p1, p2, p3, p4, p5, p6, p7; // cache line paddingprivate volatile long cursor = INITIAL_CURSOR_VALUE;public long p8, p9, p10, p11, p12, p13, p14; // cache line padding 在JDK1.8中，加入了@Contended注解，通过使用注解标识这个属性用于独立的缓存行中，若要其生效需要在程序启动时加入-XX:-RestrictContended参数。 12@Contendedprivate long l; 合并写当CPU执行一个写操作到内存屎，它将会把数据写到离CPU最近的L1的数据缓存，如果这个时候的L1缓存没有命中（数据没缓存在L1里）, 则CPU将会去L2缓存。 但是由于L2速度比较慢，有可能在写的过程中值又发生了变化，所以引入了一个Write Combining Buffer缓冲区，Intel的CPU中，它只有4个字节。 当L1缓存没有命中时，WC 可以把多个对同一缓存行Store操作的数据放在WC中，在程序对相应缓存行（或者理解为这些数据）读之前先合并，等到需要读取时再一次性写入来减少写的次数和总线的压力。此时，CPU可以在把数据放入WC后继续执行指令，减少了很多时钟周期的浪费。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public final class WriteCombining &#123; private static final int ITERATIONS = Integer.MAX_VALUE; private static final int ITEMS = 1 &lt;&lt; 24; private static final int MASK = ITEMS - 1; private static final byte[] arrayA = new byte[ITEMS]; private static final byte[] arrayB = new byte[ITEMS]; private static final byte[] arrayC = new byte[ITEMS]; private static final byte[] arrayD = new byte[ITEMS]; private static final byte[] arrayE = new byte[ITEMS]; private static final byte[] arrayF = new byte[ITEMS]; public static void main(final String[] args) &#123; for (int i = 1; i &lt;= 3; i++) &#123; System.out.println(i + \" SingleLoop duration (ns) = \" + runCaseOne()); System.out.println(i + \" SplitLoop duration (ns) = \" + runCaseTwo()); &#125; &#125; public static long runCaseOne() &#123; long start = System.nanoTime(); int i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayA[slot] = b; arrayB[slot] = b; arrayC[slot] = b; arrayD[slot] = b; arrayE[slot] = b; arrayF[slot] = b; &#125; return System.nanoTime() - start; &#125; public static long runCaseTwo() &#123; long start = System.nanoTime(); int i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayA[slot] = b; arrayB[slot] = b; arrayC[slot] = b; &#125; i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayD[slot] = b; arrayE[slot] = b; arrayF[slot] = b; &#125; return System.nanoTime() - start; &#125;&#125; 第一个while循环时，WC Buffer一次性写入7个字节，无法一次写入，所以需要写两次，而由于WC buffer中的4个字节填充满了后才会一次性写到L2中，所以需要一直等待下一次循环的4个字节填充。 第二个while循环是一次写入一个WC Buffer的大小，无需等待，所以效率更快。 volatilevolatile关键字有两个作用： 1、确保一个变量的更新对其他线程可见性 2、禁止指令重排序 1234567891011121314151617181920public class HelloVolatile &#123; boolean flag = true; void circle() &#123; System.out.println(\"start\"); while(flag) &#123; &#125; System.out.println(\"end\"); &#125; public static void main(String[] args) &#123; HelloVolatile helloVolatile = new HelloVolatile(); new Thread(helloVolatile::circle, \"t1\").start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; helloVolatile.flag = false; &#125;&#125; 12输出结果：start 代码通过一个flag表示来控制循环是否停止，按我们理解主线程flag变为true之后，应该循环停止，会打印出end出来，可是事实没有打印？为什么？ 计算机 CPU 与 主存 交互的逻辑大致如图，CPU 的运算速度是 主存 的 100 倍左右，为了避免 CPU 被主存拖慢速度。当CPU 需要一个数据的时候： 1、会先从 L1 找，找到直接使用； 2、L1 中未找到，会去 L2 中，L2 中找不到会去 L3 ，L3 找不到再去主存加载到 L3； 3、再从 L3加载到 L2 ，再从 L2 加载到 L1； 这样提高的计算速度，同时也面临数据不一致问题。 如上例子，主存中现在有一个变量 flag = true，CPU1 修改flag = false 之后，将结果放入到 L1 去，但是后续代码计算还会用到 flag，这时 CPU1 不会将flag = false 同步到主存中去。之后 CPU2 也从主存中取出变量 flag（flag = true），CPU2 将自己计算的结果放入到 L1 中。这样就造成了数据不一致问题。MESI缓存一致性协议就是为了解决这个问题的。 以上是计算机底层的实现原理，JAVA 在自己的虚拟机中执行，也有自己的内存模型，但不管怎么样，底层还是依靠的 CPU 指令集达到缓存一致性。JAVA 的内存模型屏蔽了不同平台缓存一致性协议的不同实现细节，定义了一套自己的内存模型。 java 虚拟机中的变量全部储存在主存中，每个线程都有自己的工作内存，工作内存中的变量是主存变量的副本拷贝（使用那些变量，拷贝那些），每个线程只会操作工作内存的变量，当需要保存数据一致性的时候，线程会将工作内存中的变量同步到主存中去。volatile 就是让线程改变了 flag 之后，回写到主存中，以达到缓存一致。 保证修改的值会立即被更新到主存； 一个处理器的缓存回写到内存会导致其他处理器的缓存失效； 当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值； 在多线程情况下，CPU为了提高效率，会从多个线程中读取数据到CPU的缓存Cache中，而Volatile确保了线程的可见性，当CPU修改了该值之后，回写到内存后，会马上通知其他线程内存读取。 volatile的可见性只会影响修饰的对象，并不会影响修饰对象中的属性。 代码修改后： 1234567891011121314151617181920public class HelloVolatile &#123; volatile boolean flag = true; void circle() &#123; System.out.println(\"start\"); while(flag) &#123; &#125; System.out.println(\"end\"); &#125; public static void main(String[] args) &#123; HelloVolatile helloVolatile = new HelloVolatile(); new Thread(helloVolatile::circle, \"t1\").start(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; helloVolatile.flag = false; &#125;&#125; 123输出结果：startend CPU为什么会指令重排？ CPU为了提高指令执行效率，会在一条指令执行的过程中（如去内存读数据），去同时执行另一条指令，前提是两条指令没有依赖关系。 java 中的字节码最终都会编译成机器码（CPU 指令）执行，CPU 在保证单线程中执行结果不变的情况下，可以对指令进行指令重排已达到提高执行效率。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class T04_Disorder &#123; private static int x = 0, y = 0; private static int a = 0, b =0; public static void main(String[] args) throws InterruptedException &#123; int i = 0; for(;;) &#123; i++; x = 0; y = 0; a = 0; b = 0; Thread one = new Thread(new Runnable() &#123; public void run() &#123; //由于线程one先启动，下面这句话让它等一等线程two. 读着可根据自己电脑的实际性能适当调整等待时间. //shortWait(100000); a = 1; x = b; &#125; &#125;); Thread other = new Thread(new Runnable() &#123; public void run() &#123; b = 1; y = a; &#125; &#125;); one.start();other.start(); one.join();other.join(); String result = \"第\" + i + \"次 (\" + x + \",\" + y + \"）\"; if(x == 0 &amp;&amp; y == 0) &#123; System.err.println(result); break; &#125; else &#123; //System.out.println(result); &#125; &#125; &#125; public static void shortWait(long interval)&#123; long start = System.nanoTime(); long end; do&#123; end = System.nanoTime(); &#125;while(start + interval &gt;= end); &#125;&#125; 12345上述代码指令重排执行顺序的可能：x &#x3D; bb &#x3D; 1y &#x3D; aa &#x3D; 1 假设指令重排不会发生，那么 result 将不会打印，实际循环一定次数之后会打印 result。 volatile 可以禁止指令重排，对volatile修饰变量的读写访问，都不可以重排序。 volatile为什么可以禁止重排序呢？通过修饰volatile关键字后，其字节码会增加ACC_VOLATILE标志，当JVM检测到时，会在执行指令的过程中增加内存屏障，内存屏障能够保证屏障两边的指令不可以重排！保障有序！ 如图所示JSR内存屏障有四种，其中Store指的是写操作，Load指的是读操作，而LoadLoad屏障表示在屏障之前的读数据指令和之后的读数据指令必须有序，不能重排。 而在JVM层面，要求Volatile在读操作和写操作需要增加以下屏障： 在写操作之前，要求把上文的写操作执行完毕，然后执行写操作，接着才可以执行读操作。 在读操作之前，要求上文的读操作执行完毕后，然后执行读操作，接着才可以执行写操作。 而在操作系统级别，提供了内存屏障sfence、mfence、lfence等系统原语，但是由于不具备可移植性，所以Hotspot底层是通过执行CPU的lock的相关指令锁总线实现。 问题：在懒汉式的单例模式下，需要用volatile修饰符吗？ 答案：需要 饿汉式的单例模式是天生的线程安全，可以直接用于多线程而不会出现问题，但是懒汉式本身非线程安全，需要人为实现线程安全。 123456789101112131415public class LazySingleton &#123; private volatile static LazySingleton instance = null; private LazySingleton() &#123; &#125; public static LazySingleton getInstance() &#123; if(instance == null) &#123; synchronized(LazySingleton.class) &#123; if(instance == null) &#123; instance = new LazySingleton(); &#125; &#125; &#125; return instance; &#125;&#125; instant = new LazySingleton()在操作编译器编译成指令后分为三步： 1、申请内存空间，这时候成员变量均是默认值 2、调用构造方法，初始化成员变量值 3、建立栈上和堆内存对象的关联关系 123456//当我们调用构造方法时，java的底层的字节码指令如下：0: new #2 // class java/lang/Object 申请内存空间3: dup4: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 调用构造方法7: astore_1 // Object o 指向开辟的内存地址8: return 如果没有使用volatile修饰符修饰，那么在这段过程中，可能出现指令重排序，也就是说可能先执行了步骤3的指令，再执行了步骤2的指令。那么在多线程情况下，这种情况可能会将未完全初始化的对象的作用域暴露给其他线程，其他线程使用了未完全初始化的对象时将产生问题。 锁的运用在Java中说到锁，肯定熟悉Synchronized关键字，synchronized关键字最主要有以下3种应用方式，下面分别介绍 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 在非静态方法中加锁同步代码块，比如加锁this对象，如下： 12345public void lockTest() &#123; synchronized (this) &#123; System.out.println(\"加锁this对象\"); &#125;&#125; 也可以加锁new出来的对象，如下： 1234567891011public class LockDemo &#123; static L l = new L(); public static void lockTest() &#123; synchronized (l) &#123; System.out.println(\"锁 l 对象\"); &#125; &#125;&#125;public class L &#123;&#125; 当然在Java中，JUC并发工具包也提供了ReentrantLock锁，如下： 123456789public class LockDemo &#123; static ReentrantLock lock = new ReentrantLock(); public static void lockTest() &#123; lock.lock(); System.out.println(\"ReentrantLock加锁\"); lock.unlock(); &#125;&#125; 那么ReentrantLock锁，它是通过锁什么呢？可以跟踪ReentrantLock的源码看看： 123456789101112131415161718192021222324252627282930/** * The synchronization state. */private volatile int state;/** * Atomically sets synchronization state to the given updated * value if the current state value equals the expected value. * This operation has memory semantics of a &#123;@code volatile&#125; read * and write. * * @param expect the expected value * @param update the new value * @return &#123;@code true&#125; if successful. False return indicates that the actual * value was not equal to the expected value. */protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125;/** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; 可以看到ReentrantLock主要是通过设置了一个volatile关键字的state属性，通过CAS机制去申请获得锁，修改state属性。 那么synchronized是锁的是什么呢？又是通过什么来标示锁状态呢？ 对象组成想要了解synchronized锁的原理，需要先了解在JVM虚拟机中Java对象的结构 如上图所示，java对象都是存储在堆中，一个java对象分为三个部分：对象头、实例数据、填充数据。 实例变量：指的就是对象的实例数据，数据占用的字节数不固定。如下，实例数据就在对象中占了5个字节大小。 1234public class Demo &#123; boolean flag = false; //boolean类型占1个字节 int k = 0; //int类型占4个字节&#125; 填充数据：在64位的虚拟机中，规定了java对象大小要求必须是8个字节的整数倍，所以当大小不满足8个字节的整数倍时，会自动填充。比如上图实例变量占用了5个字节，那么为了对齐数据，该对象可能需要填充3个字节数据。 对象头：对象头是对象的第一部分且是所有对象公共部分，对象头由两部分组成，分别是Mark Word和Klass Pointer（或者叫做Class Metadata Address、Class Pointer），如果对象是数组，则由三部分组成，将会多出一部分记录数组长度。 因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中无法确定数组的大小。 案例分析 本文如无特殊说明时，对象均指普通对象，如果是数组对象，会特别指出。 先回顾一下，八大基础数据类型的内存占用情况： Primitive Type Memory Required(bytes) boolean 1 byte 1 short 2 char 2 int 4 float 4 long 8 double 8 然后通过引入jol-core（jol=java object layout）依赖，输出对象的字节存储结构，用以分析对象头的组成情况 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.13&lt;/version&gt;&lt;/dependency&gt; 1234567891011public class LockDemo &#123; static L l = new L(); public static void main(String[] args) &#123; System.out.println(ClassLayout.parseInstance(l).toPrintable()); &#125;&#125;public class L &#123; boolean flag = false;&#125; 输出结果： 123456789cn.mastercom.lock.L object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 43 c0 00 20 (01000011 11000000 00000000 00100000) (536920131) 12 1 boolean L.flag false 13 3 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 3 bytes external &#x3D; 3 bytes total 由上述案例可以看到，对象头作为一个对象的开头存储结构，在64位的虚拟机中，对象头object header占用了96bit（位）=12byte（字节）。 其中OFFSET代表字节的偏移量，并且可以看到，对象头之后存储了实例数据，从偏移量OFFSET=12开始，boolean类型占用了SIZE=1(byte)。 从OFFSET=13开始，SIZE=3(byte)属于填充数据，用于补齐对象字节大小是8的整数倍，也就是说，当对象刚好等于8的整数倍时，则不需要填充补齐。 举个例子，将L类里的boolean类型(1byte)改成int(4byte)类型，则对象大小=对象头(12byte)+实例数据Int类型(4byte)=16byte，这时候已经是8的整数倍了，则不需要填充数据对齐。 一个（非数组）java对象中，一定会具备12B大小的对象头，实例数据或填充数据均可以是0B，比如： 12B对象头+4B实例数据=16B=8的整数倍 12B对象头+4B填充数据=16B=8的整数倍 如果该对象是一个数组对象的话，那么它的对象头由三部分组成：分别是Mark Word和Klass Pointer和数组长度。 12345public class LockDemo &#123; public static void main(String[] args) &#123; System.out.println(ClassLayout.parseInstance(new int[] &#123; 15, 11 &#125;).toPrintable()); &#125;&#125; 输出结果： 123456789[Ljava.lang.Object; object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) f5 22 00 20 (11110101 00100010 00000000 00100000) (536879861) 12 4 (object header) 02 00 00 00 (00000010 00000000 00000000 00000000) (2) 16 8 java.lang.Object Object;.&lt;elements&gt; N&#x2F;AInstance size: 24 bytesSpace losses: 0 bytes internal + 0 bytes external &#x3D; 0 bytes total 可以看到，当对象是一个数组时，对象头将会多出4个字节用于存储数组的长度，也就是说，对象头占了16个byte的大小。 申明在64位的虚拟机中： 1、普通对象的对象头占用了96bit（位）= 12byte（字节） 2、对象头大小 = Mark Word(64bit) + Klass Pointer(32bit) = 96bit = 12byte 3、数组对象的对象头占用了128bit(位) = 16byte（字节） 4、数组对象头大小 = Mark Word(64bit) + Klass Pointer(32bit) + 数组长度(32bit) = 128bit = 16byte 。 5、其中Klass Pointer和数组长度实际上均是占用了64bit大小，由于虚拟机默认开启了指针压缩，在存储时，分别将64bit的Klass Pointer和64bit的数组长度均压缩成32bit，所以Klass Pointer和数组长度的实际存储空间均是32bit。 6、一个对象占用的最小内存是16byte。 7、静态属性不算在对象大小内 在32位的虚拟机中： 1、在32位的虚拟机中，普通对象的对象头占用了64bit（位）=8byte（字节）。 2、对象头大小 = Mark Word(32bit) + Klass Pointer(32bit) = 64bit = 8byte 3、数组对象的对象头占用了96bit（位） = 12byte（字节） 4、数组对象头大小=Mark Word(32bit) + Klass Pointer(32bit) + 数组长度(32bit) = 128bit = 12byte 通过执行以下命令输出java的默认运行参数： 其中能够看到JDK在运行时默认开启了UseCompressedClassPointers和UseCompressedOops指针压缩，即最终存储Klass Pointer时将会压缩成4个字节。 其中上文的Oops全称是Ordinary Object Pointers，即普通对象指针，比如当一个对象成员变量是一个引用数据类型，其指针指向另外一个对象时，该指针的大小，默认也是压缩成4个字节。 对象头在JVM虚拟机规范中规范了对象头的定义： 每个GC管理的堆对象开头的公共结构。（每一个oop指针都指向一个对象头。）包括对象的布局、类型、GC状态、同步状态和标识哈希码的基本信息，由两个词组成（在Hotspot虚拟机中，分别是Mark Word和Klass Pointer），在数组中，他后面紧跟着一个长度字段，Java对象和VM内部对象都有一个通用的对象头格式。 Klass Pointer存储的是一个指针，描述的是该对象属于哪一个类的相关信息。 Mark Word在存储格式如下： 由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间。 对象拥有五种状态：无锁、偏向锁、轻量级锁，重量级锁、GC标志。 其中不同的状态分别对应不同的锁标识位，如下： 锁状态 是否偏向锁 锁标志位 无锁 0 01 偏向锁 1 01 轻量级锁 00 重量级锁 10 GC标志 11 无锁和偏向锁的锁标识位均是01，通过是否偏向锁的信息判断锁的状态。 其中偏向锁和轻量级锁是JDK 1.6 对synchronized锁进行优化后新增的，这里面的重量级锁也通常说的是synchronized的对象锁。 在JDK 1.6以后的版本中，处理同步锁时存在锁升级的概念，JVM对同步锁的处理是从偏向锁开始的，随着竞争越来越激烈，处理方式从偏向锁升级到轻量级锁、最终升级到重量级锁。 这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 无锁状态当一个对象被创建时，它将处于无锁状态： 32位虚拟机： 锁状态 25bit 4bit 1bit是否偏向锁 2bit锁标志位 无锁 对象HashCode 对象分代年龄 0 01 64位虚拟机： 锁状态 25bit 31bit 1bit 4bit 1bit是否偏向锁 2bit锁标志位 无锁 unused 对象HashCode unsused 对象分代年龄 0 01 可以看到，在32位虚拟机中，无锁状态的对象，前25bit存储了对象的HashCode，跟着4bit存储了对象的分代年龄，接着1bit存储偏向锁信息，最后2bit存储锁标志位信息。 在64位虚拟机中，无锁状态的对象，前25bit未被使用，跟着31bit存储了对象的HashCode，接着1bit未被使用（某种场景下被用作cms_free），之后的存储同上。 对象HashCode（identitry_hashcode）：是当前对象存储在内存地址中的值 对象分代年龄（age）：在常规的策略中，一个对象创建后将存放在新生代中，度过了15次Young GC之后，将会存储到老年代中，而对象分代年龄则标记着当前对象经历过几次GC。由于对象分代年龄占了4bit，其范围是【0000 - 1111】，也就是【0 -15】，也正是如此，新生代升级老年代的默认年龄由此得来。 是否偏向锁（biased_lock）：对象是否启用偏向锁标记，为1时表示对象启用偏向锁，为0时表示对象没有偏向锁。lock 和 biased_lock共同表示对象处于什么锁状态 锁标志位（lock）：由于希望用尽可能少的二进制位表示尽可能多的信息，所以设置了 lock标记。该标记的值不同，整个 Mark Word表示的含义不同。biased_lock 和 lock一起，表达的锁状态含义。 在上文中解释了定义好的Mark Word格式，在64位虚拟机的环境中，我们通过代码输出对象头来分析一下是否与之一致。 1234567public class LockDemo &#123; static L l = new L(); public static void main(String[] args) &#123; System.out.println(ClassLayout.parseInstance(l).toPrintable()); &#125;&#125; 123456789输出结果：cn.mastercom.lock.L object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 43 c0 00 20 (01000011 11000000 00000000 00100000) (536920131) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 可以看到，前8个字节的数据，分别占了两行，但是结果集和预想的不太一样，如果按照格式规定，应该有31位的HashCode，但是从结果上都是0，并没有发现所谓的HashCode，这是为什么呢？ 因为HashCode存储的是地址，地址需要通过计算得出，通过观察hashCode方法，发现是个public native int hashCode();本地方法，底层通过C++实现计算出来的。 我们通过调度hashCode()方法计算对象的Hashcode后，才会将Hashcode存储在对象头中，这时候再观看一下对象头的变化 12345678public class LockDemo &#123; static L l = new L(); public static void main(String[] args) &#123; System.out.println(\"HashCode：\" + Integer.toHexString(l.hashCode())); System.out.println(ClassLayout.parseInstance(l).toPrintable()); &#125;&#125; 可以很明显得看到了数据发生了变化，但是怎么去观看这些二进制数据呢？ 这里需要引入一个字节顺序的概念，它和操作系统有关，在Linux操作系统上，它的字节顺序是是大端存储，在Windows中，它的字节顺序是小端存储，本案例处于Windows操作系统中。 如 二进制数值【10000000 00010000】，在小端存储中，低位（值）对低位（地址），高位对高位，也就是变成 【00010000 10000000】，换句话说，上文输出的对象头格式，应该倒过来看。 从偏移量OFFSET=8，SIZE=4的信息，表示的是Klass Pointer的信息，VALUE列下方的数值输出的是十六进制的数据，我们代码输出的HashCode也转成十六进制，接着倒着看OFFSET=4的信息，有25bit未被使用，接着可以看到选中区域就是存储了HashCode。如图所示。 最开始的【00000001】，也正如上图Mark Word格式所描述相同，如下： 1bit 4bit 1bit 2bit unused age biased_lock lock 也正是这样，可以看到，当前对象处于无锁状态，其对应的锁标志位是【01】。 12345678910public class LockDemo &#123; static L l = new L(); public static void main(String[] args) &#123; System.out.println(ClassLayout.parseInstance(l).toPrintable()); synchronized (l) &#123; System.out.println(ClassLayout.parseInstance(l).toPrintable()); &#125; &#125;&#125; 输出： 1234567891011121314151617cn.mastercom.sync.L object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 43 c0 00 20 (01000011 11000000 00000000 00100000) (536920131) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes totalcn.mastercom.sync.L object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 58 f3 67 02 (01011000 11110011 01100111 00000010) (40366936) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 43 c0 00 20 (01000011 11000000 00000000 00100000) (536920131) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 通过输出加锁前和加锁后的对象信息，观察其锁变化，能够发现，加了锁之后，它的锁标志位指向的是轻量级锁，那么偏向锁哪里去了呢？ 是因为JVM在启动的时候默认前四秒钟不启动偏向锁，通过BiasedLockingStartupDelay参数控制，其默认值是4秒。 12345678910public class LockDemo &#123; public static void main(String[] args) throws InterruptedException &#123; Thread.sleep(5000); L l = new L(); synchronized (l) &#123; System.out.println(ClassLayout.parseInstance(l).toPrintable()); &#125; &#125;&#125; 12345678cn.mastercom.sync.L object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 38 54 03 (00000101 00111000 01010100 00000011) (55851013) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 43 c0 00 20 (01000011 11000000 00000000 00100000) (536920131) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external &#x3D; 4 bytes total 通过线程休眠了5秒之后，就能看到创建的对象采用了偏向锁。 CASCAS：Compare and Swap，即比较再交换。 jdk5增加了并发包java.util.concurrent.*,其下面的类使用CAS算法实现了区别于synchronouse同步锁的一种乐观锁。JDK 5之前Java语言是靠synchronized关键字保证同步的，这是一种独占锁，也是是悲观锁。 CAS是一种无锁算法，CAS执行CPU指令的过程时是一个原子操作，CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 多线程情况下，通常使用AtomicInteger来计算自增操作，其中就使用了CAS算法进行实现。 123456789/** * Atomically increments by one the current value. * * @return the previous value */public final int getAndIncrement() &#123; //this表示当前AtomicInteger对象，valueOffset表示int值的偏移量，1表示增加数 return unsafe.getAndAddInt(this, valueOffset, 1);&#125; 123456789101112//Unsafe类//CAS有3个操作数，内存值V(var5)，旧的预期值A(var2)，要修改的新值B(var5+var4)public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; //死循环CAS操作 do &#123; //通过对象和偏移量获取主内存中，该属性的的值 var5 = this.getIntVolatile(var1, var2); //当线程中旧值var2和主内存中的var5相同时，才执行修改操作 &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; AtomicInteger.incrementAndGet的实现用了乐观锁技术，调用了类sun.misc.Unsafe库里面的 CAS算法，该方法是一个本地方法，由C++实现的逻辑，通过调用CPU（lock_cmpxchg）指令来实现无锁自增。所以，AtomicInteger.incrementAndGet的自增效率很高。 12345//expect 期望的旧值//update 更新的新值public final boolean compareAndSet(V expect, V update) &#123; return unsafe.compareAndSwapObject(this, valueOffset, expect, update);&#125; ABA问题12345678//原子引用类 用于对象的CAS操作AtomicReference&lt;Object&gt; atomicReference = new AtomicReference&lt;&gt;();//设置值Object o = new Object();atomicReference.set(o);Object o2 = new Object();atomicReference.compareAndSet(o,o2); 在基础数据类型中，发生ABA问题是可以忽略的，因为基础数据类型是无状态的，而一个对象，解决ABA问题的关键，在于对CAS的对象进行标识版本号，而JUC包提供了一个类AtomicStampedReference&lt;V&gt; 12345//initialRef 初始值//initialStamp 初始版本public AtomicStampedReference(V initialRef, int initialStamp) &#123; pair = Pair.of(initialRef, initialStamp);&#125; 123456Object o = new Object();AtomicStampedReference&lt;Object&gt; atomicStampedReference = new AtomicStampedReference&lt;&gt;(o, 1);int stamp = atomicStampedReference.getStamp();Object o2 = new Object();//旧对象 新对象 旧版本号 新版本号atomicStampedReference.compareAndSet(o,o2, stamp,stamp + 1); 锁的升级过程偏向锁初次执行到synchronized代码块的时候，锁对象变成偏向锁（通过CAS修改对象头里的锁标志位），字面意思是“偏向于第一个获得它的线程”的锁。执行完同步代码块后，线程并不会主动释放偏向锁。当第二次到达同步代码块时，线程会判断此时持有锁的线程是否就是自己（持有锁的线程ID也在对象头里），如果是则正常往下执行。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。 偏向锁是指当一段同步代码一直被同一个线程所访问时，即不存在多个线程的竞争时，那么该线程在后续访问时便会自动获得锁，从而降低获取锁带来的消耗，即提高性能。 当一个线程访问同步代码块并获取锁时，会在 Mark Word 里存储锁偏向的线程 ID。在线程进入和退出同步块时不再通过 CAS 操作来加锁和解锁，而是检测 Mark Word 里是否存储着指向当前线程的偏向锁。轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 ThreadID 的时候依赖一次 CAS 原子指令即可。 偏向锁的加锁步骤： Load-and-test，也就是简单判断一下当前线程id是否与Markword当中的线程id是否一致. 如果一致，则说明此线程已经成功获得了锁，继续执行下面的代码. 如果不一致，则要检查一下对象是否还是可偏向，即“是否偏向锁”标志位的值。 如果还未偏向，则利用CAS操作来竞争锁，也即是第一次获取锁时的操作。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程是不会主动释放偏向锁的。 关于偏向锁的撤销，需要等待全局安全点，即在某个时间点上没有字节码正在执行时，它会先暂停拥有偏向锁的线程，然后判断锁对象是否处于被锁定状态。如果线程不处于活动状态，则将对象头设置成无锁状态，并撤销偏向锁，恢复到无锁（标志位为01）或轻量级锁（标志位为00）的状态。 当发生锁竞争时，偏向锁会变为轻量级锁，这时需要先将偏向锁进行锁撤销，这一步骤也会消耗不少的性能，轻量级锁的Mark Word中，lock标志位为00，其余内容被替换为一个指针，指向了栈里面的锁记录。 锁撤销的过程如下： 在一个安全点停止拥有锁的线程。 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Markword，使其变成无锁状态。 唤醒当前线程，将当前锁升级成轻量级锁。 如果计算过对象的hashCode，则对象无法进入偏向状态！ 轻量级锁重量级锁的hashCode存在与什么地方？ 答案：线程的栈帧中，轻量级锁的LockRecord中，或是代表重量级锁的ObjectMonitor的成员中 关于epoch: (不重要) 批量重偏向与批量撤销渊源：从偏向锁的加锁解锁过程中可看出，当只有一个线程反复进入同步块时，偏向锁带来的性能开销基本可以忽略，但是当有其他线程尝试获得锁时，就需要等到safe point时，再将偏向锁撤销为无锁状态或升级为轻量级，会消耗一定的性能，所以在多线程竞争频繁的情况下，偏向锁不仅不能提高性能，还会导致性能下降。于是，就有了批量重偏向与批量撤销的机制。 原理以class为单位，为每个class维护解决场景批量重偏向（bulk rebias）机制是为了解决：一个线程创建了大量对象并执行了初始的同步操作，后来另一个线程也来将这些对象作为锁对象进行操作，这样会导致大量的偏向锁撤销操作。批量撤销（bulk revoke）机制是为了解决：在明显多线程竞争剧烈的场景下使用偏向锁是不合适的。 一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器+1，当这个值达到重偏向阈值（默认20）时，JVM就认为该class的偏向锁有问题，因此会进行批量重偏向。每个class对象会有一个对应的epoch字段，每个处于偏向锁状态对象的Mark Word中也有该字段，其初始值为创建该对象时class中的epoch的值。每次发生批量重偏向时，就将该值+1，同时遍历JVM中所有线程的栈，找到该class所有正处于加锁状态的偏向锁，将其epoch字段改为新值。下次获得锁时，发现当前对象的epoch值和class的epoch不相等，那就算当前已经偏向了其他线程，也不会执行撤销操作，而是直接通过CAS操作将其Mark Word的Thread Id 改成当前线程Id。当达到重偏向阈值后，假设该class计数器继续增长，当其达到批量撤销的阈值后（默认40），JVM就认为该class的使用场景存在多线程竞争，会标记该class为不可偏向，之后，对于该class的锁，直接走轻量级锁的逻辑。 轻量级锁 轻量级锁是指当锁是偏向锁的时候，却被另外的线程所访问，此时偏向锁就会升级为轻量级锁，其他线程会通过自旋（关于自旋的介绍见文末）的形式尝试获取锁，线程不会阻塞，从而提高性能。 轻量级锁的获取主要由两种情况：① 当关闭偏向锁功能时；② 由于多个线程竞争偏向锁导致偏向锁升级为轻量级锁。 一旦有第二个线程加入锁竞争，偏向锁就升级为轻量级锁（自旋锁）。这里要明确一下什么是锁竞争：如果多个线程轮流获取一个锁，但是每次获取锁的时候都很顺利，没有发生阻塞，那么就不存在锁竞争。只有当某线程尝试获取锁的时候，发现该锁已经被占用，只能等待其释放，这才发生了锁竞争。 在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。 长时间的自旋操作是非常消耗资源的，一个线程持有锁，其他线程就只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做忙等（busy-waiting）。如果多个线程用一个锁，但是没有发生锁竞争，或者发生了很轻微的锁竞争，那么synchronized就用轻量级锁，允许短时间的忙等现象。这是一种折衷的想法，短时间的忙等，换取线程在用户态和内核态之间切换的开销。 轻量级锁也被称为自旋锁或无锁，原因在于它在循环等待获得锁的线程释放该锁。 轻量级锁的加锁步骤： 线程在自己的栈桢中创建锁记录LockRecord。 将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。 将锁记录中的Owner指针指向锁对象。 将锁对象的对象头的MarkWord替换为指向锁记录的指针。 轻量级锁主要有两种：自旋锁和自适应自旋锁。自旋锁会导致空耗CPU且很可能锁不公平；自适应是指根据上一次该线程是否成功或者多久获取过该锁设置旋转次数，若上次失败很可能直接进入重量级锁。 重量级锁重量级锁显然，此忙等是有限度的（有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改）。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁，也称为阻塞同步、悲观锁、互斥锁。其lock标志位为10，Mark Word其余内容被替换为一个指向对象监视器Monitor的指针。特殊的是，如果此对象已经被GC标记过，lock会变为11，不含其余内容。 当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起（而不是忙等），等待将来被唤醒。 偏向锁、轻量级锁都是JVM在用户态上进行资源分配的一种手段，而当申请了重量级锁，代表着JVM虚拟机向操作系统的内核态申请了加锁，将控制权都交给了操作系统，由操作系统来负责线程间的调度和线程的状态变更。而这样会出现频繁地对线程运行状态的切换，线程的挂起和唤醒，从而消耗大量的系统资源。 Monitor当发生重量级锁（synchronized）时，Mark Word其余内容被替换为一个指向对象监视器Monitor的指针。而Monitor其实是一种同步工具，也可以说是一种同步机制，它通常被描述为一个对象，主要特点是： 对象的所有方法都被“互斥”的执行。好比一个Monitor只有一个运行“许可”，任一个线程进入任何一个方法都需要获得这个“许可”，离开时把许可归还。 通常提供singal机制：允许正持有“许可”的线程暂时放弃“许可”，等待某个谓词成真（条件变量），而条件成立后，当前进程可以“通知”正在等待这个条件变量的线程，让他可以重新去获得运行许可。 在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的） 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125; 每个对象都有一个Monitor对象相关联，Monitor对象中记录了持有锁的线程信息、等待队列等。Monitor对象中有几个关键属性： _owner：记录当前持有锁的线程 _EntryList：存放处于等待锁block状态的线程队列 _WaitSet：存放处于wait状态的线程队列 _recursions：锁的重入次数 _count：用来记录该线程获取锁的次数 1、当一个线程需要获取 Object 的锁时，会被放入 EntrySet 中进行等待，如果该线程获取到了锁，成为当前锁的 owner。其余线程会进入阻塞队列EntryList中。 2、如果根据程序逻辑，一个已经获得了锁的线程缺少某些外部条件，而无法继续进行下去（例如生产者发现队列已满或者消费者发现队列为空），那么该线程可以通过调用 wait 方法将锁释放，进入WaitSet队列中阻塞进行等待。 3、当线程释放锁时，Owner会被置空，公平锁条件下，EntryList中的线程会竞争锁其它线程在这个时候有机会获得锁，去干其它的事情，从而使得之前不成立的外部条件成立，这样先前被阻塞的线程就可以重新进入 EntryList 去竞争锁。这个外部条件在 monitor 机制中称为条件变量。 锁代码块Monitor可以存储在任意一个Java对象的对象头Mark Word中，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因。 123456789public class SyncCodeBlock &#123; public int i; public void syncTask()&#123; synchronized (this)&#123; i++; &#125; &#125;&#125; 编译上述代码并使用javap反编译后得到字节码如下(这里我们省略一部分没有必要的信息)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class com.concurrencys.SyncCodeBlock minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: //........省略常量池中数据 //构造函数 public com.zejian.concurrencys.SyncCodeBlock(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return LineNumberTable: line 7: 0 //===========主要看看syncTask方法实现================ public void syncTask(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter //注意此处，进入同步方法 4: aload_0 5: dup 6: getfield #2 // Field i:I 9: iconst_1 10: iadd 11: putfield #2 // Field i:I 14: aload_1 15: monitorexit //注意此处，退出同步方法 16: goto 24 19: astore_2 20: aload_1 21: monitorexit //注意此处，退出同步方法 22: aload_2 23: athrow 24: return Exception table: //省略其他字节码.......&#125;SourceFile: \"SyncCodeBlock.java\" 主要关注字节码中的如下代码： 1234563: monitorenter //进入同步方法//..........省略其他 15: monitorexit //退出同步方法16: goto 24//省略其他.......21: monitorexit //退出同步方法 Java虚拟机的指令集中有monitorenter和monitorexit两条指令来支持synchronized关键字的语义。方法中调用过的每条monitorenter指令都必须执行其对应的monitorexit指令，无论这个方法是正常结束还是异常结束。 1、执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权。 2、当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。 3、如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor，重入时计数器的值也会加 1。 4、倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。 为了保证方法异常时monitorenter和monitorexit指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器生命可处理所有的异常，它的目的就是用来执行monitorexit指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。 锁方法方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。JVM可以从方法常量池中的方法表结构中的 ACC_SYNCHRONIZED 访问标志区分一个方法是否同步方法。 当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。 在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。 123456public class SyncMethod &#123; public int i; public synchronized void syncTask()&#123; i++; &#125;&#125; 1234567891011121314151617181920212223242526public class com.zejian.concurrencys.SyncMethod minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool; //省略没必要的字节码 //==================syncTask方法====================== public synchronized void syncTask(); descriptor: ()V //方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法 flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 12: 0 line 13: 10&#125;SourceFile: \"SyncMethod.java\" synchronized修饰的方法并没有monitorenter指令和monitorexit指令，取得代之的确实是ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法，JVM通过该ACC_SYNCHRONIZED访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。这便是synchronized锁在同步代码块和同步方法上实现的基本原理。 锁消除消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间。 123456public void add(String str1, String str2) &#123; //StringBuffer是线程安全,由于sb只会在append方法中使用,不可能被其他线程引用 //因此sb属于不可能共享的资源,JVM会自动消除内部的锁 StringBuffer sb = new StringBuffer(); sb.append(str1).append(str2); &#125; 如StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。 锁粗化通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽可能短，但是大某些情况下，一个程序对同一个锁不间断、高频地请求、同步与释放，会消耗掉一定的系统资源，因为锁的讲求、同步与释放本身会带来性能损耗，这样高频的锁请求就反而不利于系统性能的优化了，虽然单次同步操作的时间可能很短。锁粗化就是告诉我们任何事情都有个度，有些情况下我们反而希望把很多次锁的请求合并成一个请求，以降低短时间内大量锁请求、同步、释放带来的性能损耗。 123456789public void doSomethingMethod()&#123; synchronized(lock)&#123; //do some thing &#125; //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕 synchronized(lock)&#123; //do other thing &#125;&#125; 12345678public void doSomethingMethod()&#123; //进行锁粗化：整合成一次锁请求、同步、释放 synchronized(lock)&#123; //do some thing //做其它不需要同步但能很快执行完的工作 //do other thing &#125;&#125; 可重入性从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。 需要特别注意另外一种情况，当子类继承父类时，子类也是可以通过可重入锁调用父类的同步方法。由于synchronized是基于monitor实现的，因此每次重入，monitor中的计数器仍会加1。 线程中断12345678/中断线程（实例方法）public void Thread.interrupt();//判断线程是否被中断（实例方法）public boolean Thread.isInterrupted();//判断是否被中断并清除当前中断状态（静态方法）public static boolean Thread.interrupted(); 一个线程处于被阻塞状态或者试图执行一个阻塞操作时，使用Thread.interrupt()方式中断该线程，注意此时将会抛出一个InterruptedException的异常，同时中断状态将会被复位(由中断状态改为非中断状态)，如下代码将演示该过程： 12345678910111213141516171819202122232425262728293031public class InterruputSleepThread3 &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; //while在try中，通过异常中断就可以退出run循环 try &#123; while (true) &#123; //当前线程处于阻塞状态，异常必须捕捉处理，无法往外抛出 TimeUnit.SECONDS.sleep(2); &#125; &#125; catch (InterruptedException e) &#123; System.out.println(\"Interruted When Sleep\"); boolean interrupt = this.isInterrupted(); //中断状态被复位 System.out.println(\"interrupt:\"+interrupt); &#125; &#125; &#125;; t1.start(); TimeUnit.SECONDS.sleep(2); //中断处于阻塞状态的线程 t1.interrupt(); /** * 输出结果: Interruted When Sleep interrupt:false */ &#125;&#125; 如上述代码所示，我们创建一个线程，并在线程中调用了sleep方法从而使用线程进入阻塞状态，启动线程后，调用线程实例对象的interrupt方法中断阻塞异常，并抛出InterruptedException异常，此时中断状态也将被复位。除了阻塞中断的情景，我们还可能会遇到处于运行期且非阻塞的状态的线程，这种情况下，直接调用Thread.interrupt()中断线程是不会得到任响应的，如下代码，将无法中断非阻塞状态下的线程： 1234567891011121314151617181920212223public class InterruputThread &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1=new Thread()&#123; @Override public void run()&#123; while(true)&#123; System.out.println(\"未被中断\"); &#125; &#125; &#125;; t1.start(); TimeUnit.SECONDS.sleep(2); t1.interrupt(); /** * 输出结果(无限执行): 未被中断 未被中断 未被中断 ...... */ &#125;&#125; 虽然我们调用了interrupt方法，但线程t1并未被中断，因为处于非阻塞状态的线程需要我们手动进行中断检测并结束程序，改进后代码如下： 123456789101112131415161718192021222324252627public class InterruputThread &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1=new Thread()&#123; @Override public void run()&#123; while(true)&#123; //判断当前线程是否被中断 if (this.isInterrupted())&#123; System.out.println(\"线程中断\"); break; &#125; &#125; System.out.println(\"已跳出循环,线程中断!\"); &#125; &#125;; t1.start(); TimeUnit.SECONDS.sleep(2); t1.interrupt(); /** * 输出结果: 线程中断 已跳出循环,线程中断! */ &#125;&#125; 代码中使用了实例方法isInterrupted判断线程是否已被中断，如果被中断将跳出循环以此结束线程,注意非阻塞状态调用interrupt()并不会导致中断状态重置。 综合所述，可以简单总结一下中断两种情况： 一种当线程处于阻塞状态或者试图执行一个阻塞操作时，我们可以使用实例方法interrupt()进行线程中断，执行中断操作后将会抛出interruptException异常(该异常必须捕捉无法向外抛出)并将中断状态复位。 另外一种是当线程处于运行状态时，我们也可调用实例方法interrupt()进行线程中断，但同时必须手动判断中断状态，并编写中断线程的代码。 事实上线程的中断操作对于正在等待获取的锁对象的synchronized方法或者代码块并不起作用，也就是对于synchronized来说，如果一个线程在等待锁，那么结果只有两种，要么它获得这把锁继续执行，要么它就保存等待，即使调用中断线程的方法，也不会生效。 本篇文章主要参考： 对象头的概念 多线程并发编程讲解 偏向锁轻量锁获取流程 深入理解Java并发之synchronized实现原理 volatile关键字","categories":[{"name":"Synchronized","slug":"Synchronized","permalink":"https://midkuro.gitee.io/categories/Synchronized/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.gitee.io/tags/Thread/"}]},{"title":"'SpringMVC 工作原理'","slug":"springmvc-model","date":"2020-09-11T04:20:00.000Z","updated":"2020-11-05T10:43:20.424Z","comments":true,"path":"2020/09/11/springmvc-model/","link":"","permalink":"https://midkuro.gitee.io/2020/09/11/springmvc-model/","excerpt":"","text":"SpringMVC工作原理SpringMVC简单介绍什么是MVC？​ MVC是模型(Model)、视图(View)、控制器(Controller)的简写，是一种软件设计规范。就是将业务逻辑、数据、显示分离的方法来组织代码。MVC主要作用是降低了视图与业务逻辑间的双向偶合。MVC不是一种设计模式，MVC是一种架构模式。当然不同的MVC存在差异。 ​ Model（模型）：数据模型，提供要展示的数据，因此包含数据和行为，可以认为是领域模型或JavaBean组件（包含数据和行为），不过现在一般都分离开来：Value Object（数据Dao） 和 服务层（行为Service）。也就是模型提供了模型数据查询和模型数据的状态更新等功能，包括数据和业务。 ​ View（视图）：负责进行模型的展示，一般就是我们见到的用户界面，客户想看到的东西。 ​ Controller（控制器）：接收用户请求，委托给模型进行处理（状态改变），处理完毕后把返回的模型数据返回给视图，由视图负责展示。 也就是说控制器做了个调度员的工作。 最典型的MVC就是JSP + servlet + javabean的模式。 SpringMVC简而言之，springMVC是Spring框架的一部分，是基于java实现的一个轻量级web框架。 学习SpringMVC框架最核心的就是DispatcherServlet的设计，掌握好DispatcherServlet是掌握SpringMVC的核心关键。 12345678910111、DispatcherServlet表示前置控制器，是整个SpringMVC的控制中心。用户发出请求，DispatcherServlet接收请求并拦截请求。2、HandlerMapping为处理器映射。DispatcherServlet调用HandlerMapping,HandlerMapping根据请求url查找Handler。3、返回处理器执行链，根据url查找控制器，并且将解析后的信息传递给DispatcherServlet4、HandlerAdapter表示处理器适配器，其按照特定的规则去执行Handler。5、执行handler找到具体的处理器6、Controller将具体的执行信息返回给HandlerAdapter,如ModelAndView。7、HandlerAdapter将视图逻辑名或模型传递给DispatcherServlet。8、DispatcherServlet调用视图解析器(ViewResolver)来解析HandlerAdapter传递的逻辑视图名。9、视图解析器将解析的逻辑视图名传给DispatcherServlet。10、DispatcherServlet根据视图解析器解析的视图结果，调用具体的视图，进行试图渲染11、将响应数据返回给客户端 基于XML的Hello_SpringMVC1.添加pom依赖 1234567891011121314151617181920&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-webmvc --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.3.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.编写web.xml文件 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"&gt; &lt;!--配置DispatcherServlet--&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 关联springmvc的配置文件 此配置文件的属性可以不添加，但是需要在WEB-INF的目录下创建 前端控制器名称-servlet.xml文件 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;!--匹配servlet的请求， /：标识匹配所有请求，但是不会jsp页面 /*：拦截所有请求，拦截jsp页面 但是需要注意的是，当配置成index.html的时候，会发现请求不到 原因在于，tomcat下也有一个web.xml文件，所有的项目下web.xml文件都需要继承此web.xml 在服务器的web.xml文件中有一个DefaultServlet用来处理静态资源，但是url-pattern是/ 而我们在自己的配置文件中如果添加了url-pattern=/会覆盖父类中的url-pattern，此时在请求的时候 DispatcherServlet会去controller中做匹配，找不到则直接报404 而在服务器的web.xml文件中包含了一个JspServlet的处理，所以不过拦截jsp请求 --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 3、编写springmvc需要的spring配置文件，applicationContext.xml 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--处理映射器--&gt; &lt;bean class=\"org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping\"&gt;&lt;/bean&gt; &lt;!--处理器适配器--&gt; &lt;bean class=\"org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter\"&gt;&lt;/bean&gt; &lt;!--视图解析器--&gt; &lt;bean id=\"internalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!--配置前缀--&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\"&gt;&lt;/property&gt; &lt;!--配置后缀--&gt; &lt;property name=\"suffix\" value=\".jsp\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"/hello\" class=\"com.controller.HelloController\"&gt;&lt;/bean&gt;&lt;/beans&gt; 4.HelloController.java 1234567891011121314151617import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.mvc.Controller;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class HelloController implements Controller &#123; public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception &#123; //创建模型和视图对象 ModelAndView mv = new ModelAndView(); //将需要的值传递到model中 mv.addObject(\"msg\",\"helloSpringMVC\"); //设置要跳转的视图， mv.setViewName(\"hello\"); return mv; &#125;&#125; 基于注解的Hello_SpringMVC12345678910111213@Controllerpublic class HelloController&#123; /* * @RequestMapping就是用来标识此方法用来处理什么请求，其中的/可以取消 * 取消后默认也是从当前项目的根目录开始查找，一般在编写的时候看个人习惯 * 同时，@RequestMapping也可以用来加在类上， */ @RequestMapping(\"/hello\") public String hello(Model model)&#123; model.addAttribute(\"msg\",\"hello,SpringMVC\"); return \"hello\"; &#125;&#125; 12345678具体的运行流程：1、客户端发送请求http:&#x2F;&#x2F;localhost:8080&#x2F;hello2、由tomcat接受到对应的请求3、SpringMVC的前端控制器DispatcherServlet接收到所有的请求4、查看请求地址和@RequestMapping注解的哪个匹配，来找到具体的类的处理方法5、前端控制器找到目标处理类和方法之后，执行目标方法6、方法执行完成之后会有一个返回值，SpringMVC会将这个返回值用视图解析器进行解析拼接成完整的页面地址7、DispatcherServlet拿到页面地址之后，转发到具体的页面 @RequestMapping123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@RequestMapping(\"/kuro\")public class HelloController&#123; /* * @RequestMapping就是用来标识此方法用来处理什么请求，其中的/可以取消 * 取消后默认也是从当前项目的根目录开始查找，一般在编写的时候看个人习惯 * 同时，@RequestMapping也可以用来加在类上， * */ @RequestMapping(\"/hello\") public String hello(Model model)&#123; model.addAttribute(\"msg\",\"hello,SpringMVC\"); return \"hello\"; &#125; /** * Request的其他属性值 * value:要匹配的请求 * method:限制发送请求的方式： POST GET * params:表示请求要接受的参数,如果定义了这个属性，那么发送的时候必须要添加参数 * params有几种匹配规则 * 1、直接写参数的名称，param1,param2 * params = &#123;\"username\"&#125; * 2、表示请求不能包含的参数，!param1 * params = &#123;\"!username\"&#125; * 3、表示请求中需要要包含的参数但是可以限制值 param1=values param1!=value * params = &#123;\"username=123\",\"age\"&#125; * params = &#123;\"username!=123\",\"age\"&#125; * headers:填写请求头信息 * chrome：User-Agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.79 Safari/537.36 * firefox:User-Agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0 * * consumers:只接受内容类型是哪种的请求，相当于指定Content-Type * produces:返回的内容类型 Content-Type：text/html;charset=utf-8 * * @return */ @RequestMapping(value = \"/hello2\",method = RequestMethod.POST) public String hello2()&#123; return \"hello\"; &#125; @RequestMapping(value = \"/hello3\",params = &#123;\"username!=123\",\"age\"&#125;) public String hello3(String username)&#123; return \"hello\"; &#125; @RequestMapping(value = \"/hello4\",headers = &#123;\"User-Agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0\"&#125;) public String hello4()&#123; return \"hello\"; &#125; /** * @Request包含三种模糊匹配的方式，分别是： * ？：能替代任意一个字符 * *: 能替代任意多个字符和一层路径 * **：能代替多层路径 * @return */ @RequestMapping(value = \"/**/h*llo?\") public String hello5()&#123; return \"hello\"; &#125;&#125; @PathVariable如果需要在请求路径中的参数像作为参数应该怎么使用呢？可以使用@PathVariable注解，此注解就是提供了对占位符URL的支持，就是将URL中占位符参数绑定到控制器处理方法的参数中。 123456789@Controller@RequestMapping(\"/kuro\")public class HelloController&#123; @RequestMapping(value = \"/pathVariable/&#123;name&#125;\") public String pathVariable(@PathVariable(\"name\") String name)&#123; return \"hello\"; &#125;&#125; REST12345GET：获取资源 &#x2F;book&#x2F;1POST：新建资源 &#x2F;bookPUT：更新资源 &#x2F;book&#x2F;1DELETE：删除资源 &#x2F;book&#x2F;1一切看起来都非常美好，但是大家需要注意了，我们在发送请求的时候只能发送post或者get，没有办法发送put和delete请求，那么应该如何处理呢？ 1234567891011121314151617181920212223@Controllerpublic class RestController &#123; @RequestMapping(value = \"/user\",method = RequestMethod.POST) public String add()&#123; return \"success\"; &#125; @RequestMapping(value = \"/user/&#123;id&#125;\",method = RequestMethod.DELETE) public String delete(@PathVariable(\"id\") Integer id)&#123; return \"success\"; &#125; @RequestMapping(value = \"/user/&#123;id&#125;\",method = RequestMethod.PUT) public String update(@PathVariable(\"id\") Integer id)&#123; return \"success\"; &#125; @RequestMapping(value = \"/user/&#123;id&#125;\",method = RequestMethod.GET) public String query(@PathVariable(\"id\") Integer id)&#123; return \"success\"; &#125;&#125; 1234567891011121314public class MyFilter implements Filter &#123; public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; servletRequest.setCharacterEncoding(\"UTF-8\"); servletResponse.setCharacterEncoding(\"UTF-8\"); //过滤器链--传递 filterChain.doFilter(servletRequest,servletResponse); &#125; public void destroy() &#123; &#125;&#125; 12345678910111213141516171819202122package org.springframework.web.filter;public class HiddenHttpMethodFilter extends OncePerRequestFilter &#123; private String methodParam = \"_method\"; protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; HttpServletRequest requestToUse = request; //如果是个Post请求 if (\"POST\".equals(request.getMethod()) &amp;&amp; request.getAttribute(\"javax.servlet.error.exception\") == null) &#123; //获取\"key=_method\"的value值， String paramValue = request.getParameter(this.methodParam); if (StringUtils.hasLength(paramValue)) &#123; String method = paramValue.toUpperCase(Locale.ENGLISH); if (ALLOWED_METHODS.contains(method)) &#123; //并把它的value当做请求参数转换成对应的请求方式 requestToUse = new HiddenHttpMethodFilter.HttpMethodRequestWrapper(request, method); &#125; &#125; &#125; //过滤器链继续 filterChain.doFilter((ServletRequest)requestToUse, response); &#125;&#125; 123456789&lt;!-- web.xml--&gt;&lt;filter&gt; &lt;filter-name&gt;hiddenFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;hiddenFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 1234567891011121314&lt;body&gt; &lt;form action=\"/user\" method=\"post\"&gt; &lt;input type=\"submit\" value=\"增加\"&gt; &lt;/form&gt; &lt;form action=\"/user/1\" method=\"post\"&gt; &lt;input name=\"_method\" value=\"delete\" type=\"hidden\"&gt; &lt;input type=\"submit\" value=\"删除\"&gt; &lt;/form&gt; &lt;form action=\"/user/1\" method=\"post\"&gt; &lt;input name=\"_method\" value=\"put\" type=\"hidden\"&gt; &lt;input type=\"submit\" value=\"修改\"&gt; &lt;/form&gt; &lt;a href=\"/user/1\"&gt;查询&lt;/a&gt;&lt;br/&gt;&lt;/body&gt; @RequestParam12345678910111213141516171819202122232425@Controllerpublic class RequestController &#123; /** * 如何获取SpringMVC中请求中的信息 * 默认情况下，可以直接在方法的参数中填写跟请求一样的名称，此时会默认接受参数 * 如果有值，直接赋值，如果没有，那么直接给空值 * * @RequestParam:获取请求中的参数值,使用此注解之后，参数的名称不需要跟请求的名称一致，但是必须要写 * public String request(@RequestParam(\"user\") String username)&#123; * * 此注解还包含三个参数： * value:表示要获取的参数值 * required：表示此参数是否必须，默认是true，如果不写参数那么会报错，如果值为false，那么不写参数不会有任何错误 * defaultValue:如果在使用的时候没有传递参数，那么定义默认值即可 * * * @param username * @return */ @RequestMapping(\"/request\") public String request(@RequestParam(value = \"user\",required = false,defaultValue = \"hehe\") String username)&#123; return \"success\"; &#125;&#125; @RequestHeader123456789101112131415161718192021@Controllerpublic class RequestController &#123; /** * 如果需要获取请求头信息该如何处理呢？ * 可以使用@RequestHeader注解， * public String header(@RequestHeader(\"User-Agent\") String agent)&#123; * 相当于 request.getHeader(\"User-Agent\") * * 如果要获取请求头中没有的信息，那么此时会报错，同样，此注解中也包含三个参数,跟@RequestParam一样 * value * required * defalutValue * @param agent * @return */ @RequestMapping(\"/header\") public String header(@RequestHeader(\"User-Agent\") String agent)&#123; return \"success\"; &#125;&#125; @CookieValue123456789101112131415161718192021222324@Controllerpublic class RequestController &#123; /** * 如果需要获取cookie信息该如何处理呢？ * 可以使用@CookieValue注解， * public String cookie(@CookieValue(\"JSESSIONID\") String id)&#123; * 相当于 * Cookie[] cookies = request.getCookies(); * for(Cookie cookie : cookies)&#123; * cookie.getValue(); * &#125; * 如果要获取cookie中没有的信息，那么此时会报错，同样，此注解中也包含三个参数,跟@RequestParam一样 * value * required * defalutValue * @param id * @return */ @RequestMapping(\"/cookie\") public String cookie(@CookieValue(\"JSESSIONID\") String id)&#123; return \"success\"; &#125;&#125; 乱码问题GET请求：在tomcat的server.xml文件中，添加URIEncoding=“UTF-8” POST请求：编写过滤器进行实现。 123456789101112131415161718&lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!--解决post请求乱码--&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--解决响应乱码--&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 如果配置了多个过滤器，那么字符编码过滤器一定要在最前面，否则失效。 使用原生API1234567891011121314151617181920212223242526272829 /** * SpringMVC也可以在参数上使用原生的Servlet API * * HttpSession * HttpServletRequest * HttpServletResponse * * java.security.Principal 安全协议相关 * Locale：国际化相关的区域信息对象 * InputStream: * ServletInputStream inputStream = request.getInputStream(); * OutputStream: * ServletOutputStream outputStream = response.getOutputStream(); * Reader: * BufferedReader reader = request.getReader(); * Writer: * PrintWriter writer = response.getWriter(); * @param session * @param request * @param response * @return */@RequestMapping(\"api\")public String api(HttpSession session, HttpServletRequest request, HttpServletResponse response)&#123; request.setAttribute(\"requestParam\",\"request\"); session.setAttribute(\"sessionParam\",\"session\"); return \"success\";&#125; 响应数据使用Model，Map，ModelMap、ModelAndView传输数据到页面 12345678910111213141516171819202122232425@RequestMapping(\"output1\")public String output1(Model model)&#123; model.addAttribute(\"msg\",\"hello,Springmvc\"); return \"output\";&#125;@RequestMapping(\"output2\")public String output2(ModelMap model)&#123; model.addAttribute(\"msg\",\"hello,Springmvc\"); return \"output\";&#125;@RequestMapping(\"output3\")public String output1(Map map)&#123; map.put(\"msg\",\"hello,Springmvc\"); return \"output\";&#125;@RequestMapping(\"mv\")public ModelAndView mv()&#123; ModelAndView mv = new ModelAndView(); mv.setViewName(\"output\"); mv.addObject(\"msg\",\"hello.modelAndView\"); return mv;&#125; 所有的参数值都设置到了request作用域中 @SessionAttribute此注解可以表示，当向request作用域设置数据的时候同时也要向session中保存一份,此注解有两个参数，一个value（表示将哪些值设置到session中），另外一个type（表示按照类型来设置数据，一般不用，因为有可能会将很多数据都设置到session中，导致session异常）。 12345678910@Controller@SessionAttributes(value = \"msg\")public class OutputController &#123; @RequestMapping(\"output1\") public String output1(Model model)&#123; model.addAttribute(\"msg\",\"hello,Springmvc\"); return \"output\"; &#125;&#125; @ModelAttribute会在请求执行前先调用MyModelAttribute方法，在模板的基础上写入请求参数的值，使用都是的同一个Model对象，ModelAttribute除了可以使用设置值到model中之外，还可以利用返回值。 12345678910@RequestMapping(\"update\")public String update(@ModelAttribute(\"user\") User user,Model model)&#123;&#125;@ModelAttributepublic void MyModelAttribute(Model model)&#123; User user = new User(); model.addAttribute(\"user\",user);&#125; forward12345678910111213141516/** * 当使用转发的时候可以添加前缀forward:index.jsp,此时是不会经过视图解析器的，所以要添加完整的名称 * * forward:也可以由一个请求跳转到另外一个请求 * * @return */@RequestMapping(\"/forward01\")public String forward()&#123; return \"forward:/index.jsp\";&#125;@RequestMapping(\"/forward02\")public String forward2()&#123; return \"forward:/forward01\";&#125; redirect123456789101112131415/** * redirect :重定向的路径 * 相当于 response.sendRedirect(\"index.jsp\") * 跟视图解析器无关 * @return */@RequestMapping(\"redirect\")public String redirect()&#123; return \"redirect:/index.jsp\";&#125;@RequestMapping(\"/redirect2\")public String redirect2()&#123; return \"redirect:/redirect\";&#125; 123456789101112131415转发： 由服务器的页面进行跳转，不需要客户端重新发送请求： 特点如下： 1、地址栏的请求不会发生变化，显示的还是第一次请求的地址 2、请求的次数，有且仅有一次请求 3、请求域中的数据不会丢失 4、根目录：localhost:8080&#x2F;项目地址&#x2F;,包含了项目的访问地址重定向： 在浏览器端进行页面的跳转，需要发送两次请求（第一次是人为的，第二次是自动的） 特点如下： 1、地址栏的地址发生变化，显示最新发送请求的地址 2、请求次数：2次 3、请求域中的数据会丢失，因为是不同的请求 4、根目录：localhost:8080&#x2F; 不包含项目的名称 静态资源由于DispatcherServlet会拦截所有的请求，而此时我们没有对应图片的请求处理方法，所以此时报错了，想要解决的话非常简单，只需要添加一个配置即可 12345&lt;!--此配置表示 我们自己配置的请求由controller来处理，但是不能请求的处理交由tomcat来处理静态资源可以访问，但是动态请求无法访问--&gt;&lt;mvc:default-servlet-handler/&gt; 但是加上此配置之后，大家又发现此时除了静态资源无法访问之外，我们正常的请求也无法获取了，因此还需要再添加另外的配置： 12&lt;!--保证静态资源和动态请求都能够访问--&gt;&lt;mvc:annotation-driven/&gt; 组件说明：以下组件通常使用框架提供实现： DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。 HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。 ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。 组件：1、前端控制器DispatcherServlet（不需要工程师开发）,由框架提供作用：接收请求，响应结果，相当于转发器，中央处理器。有了dispatcherServlet减少了其它组件之间的耦合度。用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性。 2、处理器映射器HandlerMapping(不需要工程师开发),由框架提供作用：根据请求的url查找HandlerHandlerMapping负责根据用户请求找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 3、处理器适配器HandlerAdapter作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。 4、处理器Handler(需要工程师开发)注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行HandlerHandler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要工程师根据业务需求开发Handler。 5、视图解析器View resolver(不需要工程师开发),由框架提供作用：进行视图解析，根据逻辑视图名解析成真正的视图（view）View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 springmvc框架提供了很多的View视图类型，包括：jstlView、freemarkerView、pdfView等。一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由工程师根据业务需求开发具体的页面。 6、视图View(需要工程师开发jsp…)View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…） 核心架构的具体流程步骤如下：1、首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；2、DispatcherServlet——&gt;HandlerMapping， HandlerMapping 将会把请求映射为HandlerExecutionChain 对象（包含一个Handler 处理器（页面控制器）对象、多个HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新的映射策略；3、DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；4、HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个ModelAndView 对象（包含模型数据、逻辑视图名）；5、ModelAndView的逻辑视图名——&gt; ViewResolver， ViewResolver 将把逻辑视图名解析为具体的View，通过这种策略模式，很容易更换其他视图技术；6、View——&gt;渲染，View会根据传进来的Model模型数据进行渲染，此处的Model实际是一个Map数据结构，因此很容易支持其他视图技术；7、返回控制权给DispatcherServlet，由DispatcherServlet返回响应给用户，到此一个流程结束。 下边两个组件通常情况下需要开发： Handler：处理器，即后端控制器用controller表示。 View：视图，即展示给用户的界面，视图中通常需要标签语言展示模型数据。 “本篇文章主要摘自参考资料”","categories":[{"name":"springMVC","slug":"springMVC","permalink":"https://midkuro.gitee.io/categories/springMVC/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://midkuro.gitee.io/tags/SpringMVC/"}]},{"title":"'MySql 高级 '","slug":"mysql-index","date":"2020-09-08T15:00:00.000Z","updated":"2020-11-23T00:50:39.566Z","comments":true,"path":"2020/09/08/mysql-index/","link":"","permalink":"https://midkuro.gitee.io/2020/09/08/mysql-index/","excerpt":"","text":"MySql 高级Show profile1234567891011121314151617181920212223242526272829303132333435363738394041424344454647mysql&gt; set profiling&#x3D;1;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; select * from um_user;+----------+----------+--------------+| username | password | userInfo |+----------+----------+--------------+| admin | admin | aasa || test | test | aaaaaaaaaaaa || guest | guest | ddddd |+----------+----------+--------------+3 rows in set (0.00 sec)mysql&gt; select * from emp;Empty set (0.00 sec)mysql&gt; show profiles;+----------+------------+-----------------------+| Query_ID | Duration | Query |+----------+------------+-----------------------+| 1 | 0.00028200 | set profiling&#x3D;1 || 2 | 0.00087525 | select * from um_user || 3 | 0.00037500 | select * from emp |+----------+------------+-----------------------+3 rows in set, 1 warning (0.00 sec)mysql&gt; show profile for query 2;+----------------------+----------+| Status | Duration |+----------------------+----------+| starting | 0.000185 || checking permissions | 0.000015 || Opening tables | 0.000025 || init | 0.000106 || System lock | 0.000016 || optimizing | 0.000007 || statistics | 0.000018 || preparing | 0.000017 || executing | 0.000007 || Sending data | 0.000365 || end | 0.000016 || query end | 0.000014 || closing tables | 0.000012 || freeing items | 0.000054 || cleaning up | 0.000021 |+----------------------+----------+15 rows in set, 1 warning (0.00 sec) show processlist1234567891011mysql&gt; show processlist;+----+------+---------------------+------+---------+------+----------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+---------------------+------+---------+------+----------+------------------+| 3 | root | localhost | kuro | Query | 0 | starting | show processlist || 4 | root | 192.168.163.1:10542 | NULL | Sleep | 2430 | | NULL || 5 | root | 192.168.163.1:10543 | kuro | Sleep | 2420 | | NULL || 6 | root | 192.168.163.1:10548 | kuro | Sleep | 2425 | | NULL || 7 | root | 192.168.163.1:10549 | kuro | Sleep | 2420 | | NULL |+----+------+---------------------+------+---------+------+----------+------------------+5 rows in set (0.00 sec) performance schema 详细文档 逻辑架构和其他数据库相比，Mysql有点与众不同，他的架构在多种不同场景中应用并发挥良好作用。主要体现在存储引擎的架构上。插入式的存储引擎架构将查询处理和其他的系统任务以及数据的存储提取相分离。这种架构可以根据业务的需求和实际需要选择合适的存储引擎。 连接层 最上层是一些客户端和连接服务，包含本地sock通信和大多数基于客户端/服务端工具实现的类似于tcp/ip的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。 服务层 第二层架构主要完成大多少的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析和优化及部分内置函数的执行，所有跨存储引擎的功能也在这一层实现，如过程、函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化，如确定查询表的顺序、是否利用索引等，最后生成相应的执行操作。 如果是select语句，服务器还会查询内部的缓存。这样在解决大量读操作的环境中能够很好的提升系统的性能。 引擎层 存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信，不同的存储引擎具有的功能不通，这样我们可以根据自己的实际需要进行选取。 存储层 数据存储层，主要是将数据存储在运行于裸设备的文件系统之上，并完成与存储引擎的交互。 首先，我们对该图中的各个模块做一简单介绍：1、Connectors 指的是不同语言中与SQL的交互。 2、Connection Pool 管理缓冲用户连接，线程处理等需要缓存的需求。负责监听对 MySQL Server 的各种请求，接收连接请求，转发所有连接请求到线程管理模块。每一个连接上 MySQL Server 的客户端请求都会被分配（或创建）一个连接线程为其单独服务。而连接线程的主要工作就是负责 MySQL Server 与客户端的通信，接受客户端的命令请求，传递 Server 端的结果信息等。线程管理模块则负责管理维护这些连接线程。包括线程的创建，线程的 cache 等。 ３、 Management Serveices &amp; Utilities 系统管理和控制工具。 4、 SQL Interface 接受用户的SQL命令，并且返回用户需要查询的结果。 5、 Parser SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。在 MySQL中我们习惯将所有 Client 端发送给 Server 端的命令都称为 query ，在 MySQL Server 里面，连接线程接收到客户端的一个 Query 后，会直接将该 query 传递给专门负责将各种 Query 进行分类然后转发给各个对应的处理模块。主要功能： a 、 将SQL语句进行语义和语法的分析，分解成数据结构，然后按照不同的操作类型进行分类，然后做出针对性的转发到后续步骤，以后SQL语句的传递和处理就是基于这个结构的； b、 如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的。 6、 Optimizer 查询优化器：SQL语句在查询之前会使用查询优化器对查询进行优化。就是优化客户端请求query，根据客户端请求的 query 语句，和数据库中的一些统计信息，在一系列算法的基础上进行分析，得出一个最优的策略，告诉后面的程序如何取得这个 query 语句的结果。 使用的是“选取-投影-联接”策略进行查询：用一个例子就可以理解： select uid,name from user where gender = 1;这个select 查询先根据where 语句进行选取，而不是先将表全部查询出来以后再进行gender过滤；然后根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤。最后将这两个查询条件联接起来生成最终查询结果。 7 、Cache和Buffer 查询缓存：主要功能是将客户端提交 给MySQL 的 Select 类 query 请求的返回结果集 cache 到内存中，与该 query 的一个 hash 值 做一个对应。该 query 所取数据的基表发生任何数据的变化之后， MySQL 会自动使该 query 的Cache 失效。在读写比例非常高的应用系统中， Query Cache 对性能的提高是非常显著的。当然它对内存的消耗也是非常大的。 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。 8 、存储引擎接口 MySQL区别于其他数据库的最重要的特点就是其插件式的表存储引擎。MySQL插件式的存储引擎架构提供了一系列标准的管理和服务支持，这些标准与存储引擎本身无关，可能是每个数据库系统本身都必需的，如SQL分析器和优化器等，而存储引擎是底层物理结构的实现，每个存储引擎开发者都可以按照自己的意愿来进行开发。注意：存储引擎是基于表的，而不是数据库。 查看命令1234#查看mysql提供什么存储引擎show engines;#查看当前默认的存储引擎show variables like &#39;%storage_engine%&#39;; MyISAM和InnoDB对比 索引优化分析SQL执行顺序 手写顺序： 机器顺序： Join查询 索引简介MySQL官方对索引的定义为：索引(Index)是帮助MySQL高校获取数据的数据结构。 可以得到索引的本质：索引是数据结构。索引的目的在提高查询效率，可以类比字典。可以简单理解为”排好序的快速查找数据结构”。 数据本身之外,数据库还维护着一个满足特定查找算法的数据结构，这些数据结构以某种方式指向数据，这样就可以在这些数据结构的基础上实现高级查找算法,这种数据结构就是索引。 一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往以文件形式存储在硬盘上。 我们平时所说的索引，如果没有特别指明，都是指B树(多路搜索树，并不一定是二叉树)结构组织的索引。其中聚集索引，次要索引，覆盖索引，复合索引，前缀索引，唯一索引默认都是使用B+树索引，统称索引。当然,除了B+树这种类型的索引之外，还有哈希索引(hash index)等。 优势： 1.类似大学图书馆建书目索引，提高数据检索效率，降低数据库的IO成本 2.通过索引列对数据进行排序，降低数据排序成本，降低了CPU的消耗 劣势： 1.实际上索引也是一张表，该表保存了主键和索引字段，并指向实体表的记录,所以索引列也是要占用空间的 2.虽然索引大大提高了查询速度，同时却会降低更新表的速度,如果对表INSERT,UPDATE和DELETE。因为更新表时，MySQL不仅要不存数据，还要保存一下索引文件每次更新添加了索引列的字段，都会调整因为更新所带来的键值变化后的索引信息。 3.索引只是提高效率的一个因素，如果你的MySQL有大数据量的表，就需要花时间研究建立优秀的索引，或优化查询语句。 索引分类单值索引：即一个索引只包含单个列，一个表可以有多个单列索引 唯一索引：索引列的值必须唯一，但允许有空值 复合索引：即一个索引包含多个列 创建索引的基本语法 索引结构BTree索引 初始化介绍： 浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。 真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 查找过程： 如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。 真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 Btree索引(或Balanced Tree)，是一种很普遍的数据库索引结构，oracle默认的索引类型（本文也主要依据oracle来讲）。其特点是定位高效、利用率高、自我平衡，特别适用于高基数字段，定位单条或小范围数据非常高效。理论上，使用Btree在亿条数据与100条数据中定位记录的花销相同。 mysql支持其他索引结构，如Hash索引、full-text全文索引，R-Tree索引。 哪些情况需要创建索引？ 1234567891011121314151.主键自动建立唯一索引2.频繁作为查询的条件的字段应该创建索引3.查询中与其他表关联的字段，外键关系建立索引4.频繁更新的字段不适合创建索引，因为每次更新不单单是更新了记录还会更新索引，加重IO负担5.Where条件里用不到的字段不创建索引6.单间&#x2F;组合索引的选择问题，who？（在高并发下倾向创建组合索引）7.查询中排序的字段，排序字段若通过索引去访问将大大提高排序的速度8.查询中统计或者分组字段 哪些情况不需要创建索引？ 1234561.表记录太少2.经常增删改的表3.数据重复且分布平均的表字段，因此应该只为经常查询和经常排序的数据列建立索引。注意，如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。如性别：男&#x2F;女 性能分析MySQL Query Optimizermysql中有专门负责优化 select 语句的优化器模块，主要功能：通过计算分析系统中收集到的统计信息，为窗户端请求的query提供它认为最优的执行计划（不一定是DBA认为最优的，这部分最耗费时间）。 当客户端向mysql发送一条query，命令解析器模块完成请求分类，区别出是select并转发给 mysql query optimizer时，mysql query optimizer首先会对整条query进行优化，处理掉一些常量表达式的预算，直接换算成常量值。并对query中的查询条件进行简化和调整，如去掉一些无用或显而易见的条件、结构调整等。 然后分析query中的hint信息（如果有），看显示hint信息是否可以完全确定该query的执行计划。如果没有hint或hint信息还不足以完全确定执行计划，则会读取所涉及对象的统计信息，根据query进行写相应的计算分析，然后再得出最后的执行计划。 常见瓶颈 CPU : CPU在饱和的时候一般发生在数据装入内存或从磁盘上读取数据的时候 IO : 磁盘I/O瓶颈发生在装入数据远大于内存容量的时候 服务器硬件的性能瓶颈 : top,free,iostat和vmstat来查看系统的性能状态 Explain 使用EXPLAIN关键字可以模拟优化器执行SQL语句，从而知道MySQL是如何处理你的SQL语句的。分析你的查询语句或是结构的性能瓶颈。 它能够看到表的读取顺序、数据读取操作的操作类型、哪些索引可以使用、哪些索引被实际使用、表之间的引用、每张表有多少行被优化器查询。 idselect查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序 三种情况： 第一种：id相同，执行顺序由上至下 第二种：id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 第三种：id相同不同，同时存在 select_type查询的类型，主要用于区别，普通查询、联合查询、子查询等的复杂查询 123456781.SIMPLE : 简单的select查询，查询中不包含子查询或者UNION2.PRIMARY : 查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY3.SUBQUERY : 在SELECT或者WHERE列表中包含了子查询4.DERIVED : 在FROM列表中包含的子查询被标记为DERIVED（衍生） MySQL会递归执行这些子查询，把结果放在临时表里。5.UNION : 若第二个SELECT出现在UNION之后，则被标记为UNION; 若UNION包含在FROM子句的子查询中，外层SELECT将被标记为：DERIVED6.UNION RESULT : 从UNION表获取结果的SELECT table显示这一行的数据是关于哪张表的 type显示查询使用了何种类型，从最好到最差依次是：system&gt;const&gt;eq_ref&gt;ref&gt;range&gt;index&gt;ALL system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现，这个也可以忽略不计 const：表示通过索引一次就找到了，const用于比较primary key或者unique索引。因为只匹配一行数据，所以很快。如将主键至于where列表中，MySQL就能将该查询转换为一个常量 eq_ref：唯一性索引，对于每个索引键，表中只有一条记录与之匹配，常见于主键或唯一索引扫描 ref：非唯一索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体 range： 只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引 一般就是在你的where语句中出现了between、&lt;、&gt;、in等的查询 这种范围扫描索引扫描比全表扫描要好，因为他只需要开始索引的某一点，而结束语另一点，不用扫描全部索引 index： Full Index Scan,index与ALL区别为index类型只遍历索引树。这通常比ALL快，因为索引文件通常比数据文件小。（也就是说虽然all和index都是读全表，但index是从索引中读取的，而all是从硬盘中读的） all：FullTable Scan,将遍历全表以找到匹配的行 一般来说，得保证查询只是达到range级别，最好达到ref possible_keys显示可能应用在这张表中的索引,一个或多个。查询涉及的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用。 key实际使用的索引。如果为null则没有使用索引，查询中若使用了覆盖索引，则索引和查询的select字段重叠。 key_len表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好。 key_len显示的值为索引最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。 ref显示索引那一列被使用了，如果可能的话，是一个常数。那些列或常量被用于查找索引列上的值 rows根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数 Extra包含不适合在其他列中显示但十分重要的额外信息 Using filesort： 说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL中无法利用索引完成排序操作成为“文件排序” Using temporary： 使用了临时表保存中间结果，MySQL在对查询结果排序时使用临时表。常见于排序order by 和分组查询 group by Using Index： 表示相应的select操作中使用了覆盖索引（Coveing Index）,避免访问了表的数据行，效率不错！如果同时出现using where，表明索引被用来执行索引键值的查找；如果没有同时出现using where，表面索引用来读取数据而非执行查找动作。 impossible where： where子句的值总是false，不能用来获取任何元组 Using where：表示使用了 where 过滤 using join buffer：使用了连接缓存 distinct：优化distinct，在找到第一匹配的元组后即停止找同样值的工作 select tables optimized away： 在没有GROUPBY子句的情况下，基于索引优化MIN/MAX操作或者对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。 案例 索引优化 1.最佳全值匹配 2.最佳左前缀法则 如果索引了多例，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。 3.不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描 4.存储引擎不能使用索引中范围条件右边的列 5.尽量使用覆盖索引（只访问索引的查询（索引列和查询列一致）），减少select* 6.mysql在使用不等于（！=或者&lt;&gt;）的时候无法使用索引会导致全表扫描 7.is null,is not null 也无法使用索引 8.like以通配符开头（’$abc…’）mysql索引失效会变成全表扫描操作 问题：解决like’%字符串%’索引不被使用的方法？？ 1、可以使用主键索引2、使用覆盖索引，查询字段必须是建立覆盖索引字段3、当覆盖索引指向的字段是varchar(380)及380以上的字段时，覆盖索引会失效！ 9.字符串不加单引号索引失效 10.少用or,用它连接时会索引失效 小总结 like KK%相当于=常量 %KK和%KK% 相当于范围 一般性建议： 对于单键索引，尽量选择针对当前query过滤性更好的索引 在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠前越好 在选择组合索引的时候，尽量选择可以能包含当前query中的where子句中更多字段的索引 尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的 查询截取分析查询优化永远小表驱动大表，类似嵌套循环Nested Loop 相关： 尽可能减少Join语句中的NestedLoop的循环总次数：“永远用小结果集驱动大的结果集” 优先优化NestedLoop的内层循环： 保证Join语句中被驱动表上Join条件字段已经被索引 当无法保证被驱动表的Join条件字段被索引且内存资源充足的前提下，不要太吝啬JoinBuffer的设置； Order by优化MySQL支持二种方式的排序，FileSort和Index,Index效率高。它指MySQL扫描索引本身完成排序。FileSort方式效率较低。 ORDER BY子句，尽量使用Index方式排序，避免使用FileSort方式排序。 ORDER BY满足两情况，会使用Index方式排序： ORDER BY语句使用索引最左前列 使用where子句与OrderBy子句条件列组合满足索引最左前列 尽可能在索引列上完成排序操作，遵照索引建的最佳左前缀，如果不在索引列上，filesort有两种算法：mysql就要启动双路排序和单路排序。 双路排序： MySQL4.1之前是使用双路排序，字面意思是两次扫描磁盘，最终得到数据。 读取行指针和orderby列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据传输。 从磁盘取排序字段，在buffer进行排序，再从磁盘取其他字段。 取一批数据，要对磁盘进行两次扫描，众所周知，I\\O是很耗时的，所以在mysql4.1之后，出现了第二张改进的算法，就是单路排序。 单路排序： 从磁盘读取查询需要的所有列，按照orderby列在buffer对它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据，并且把随机IO变成顺序IO，但是它会使用更多的空间，因为它把每一行都保存在内存中了。 总体而言，单路排序好过双路排序，但是单路排序也有一定的问题： 可以通过增大sort_buffer_size参数的设置、增大max_length_for_sort_data参数的设置来进行优化。 总结 Group by优化1.group by 实质是先排序后进行分组，遵照索引建的最佳左前缀 2.当无法使用索引列，增大max_length_for_sort_data参数的设置+增大sort_buffer_size参数的设置 3.where高于having,能写在where限定的条件就不要去having限定了。 主从复制原理 每个slave只有一个master，每个slave只能有一个唯一的服务器ID，每个master可以有多个salve。 锁机制锁的分类 从数据操作的类型分： 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响 写锁（排它锁）：当前写操作没有完成前，它会阻断其他写锁和读锁。 从对数据操作的颗粒度： 表锁 行锁 表锁（偏读）特点：偏向MyISAM存储引擎，开销小，加锁快，无死锁，锁定粒度大，发生锁冲突的概率最高，并发最低。 加读锁： 加写锁： 结论： 简而言之，就是读锁会阻塞写，但是不会阻塞读，而写锁则会把读和写都堵塞。 表锁分析： 此外，Myisam的读写锁调度是写优先，这也是myisam不适合做写为主表的引擎。因为写锁后，其他线程不能做任何操作，大量更新回事查询很难得到锁，从而造成永远阻塞。 行锁（偏写）特点：偏向InnoDB存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB与MyISAM的最大不同有两点：一是支持事务（TRANSACTION）;二是采用了行级锁。 行锁基本演示： 无索引行锁升级为表锁：varchar 不用 ‘ ‘ 导致系统自动转换类型, 行锁变表锁 间隙锁的危害： 间隙锁一个比较致命的弱点，就是当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据。在某些场景下这可能会对性能造成很大的危害。 面试题：常考如何锁定一行 结论： 行锁分析： 优化建议： 123451.尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁2.合理设计索引，尽量缩小锁的范围3.尽可能较少检索条件，避免间隙锁4.尽量控制事务大小，减少锁定资源量和时间长度5.尽可能低级别事务隔离 bin_log、redo_log、undo_log","categories":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://midkuro.gitee.io/categories/MYSQL/"}],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://midkuro.gitee.io/tags/MYSQL/"}]},{"title":"'MYSQL performance schema详解'","slug":"mysql-performanceSchema","date":"2020-09-08T06:00:00.000Z","updated":"2020-11-15T15:08:02.370Z","comments":true,"path":"2020/09/08/mysql-performanceSchema/","link":"","permalink":"https://midkuro.gitee.io/2020/09/08/mysql-performanceSchema/","excerpt":"","text":"MYSQL performance schema详解performance_schema的介绍​ MySQL的performance schema 用于监控MySQL server在一个较低级别的运行过程中的资源消耗、资源等待等情况。 ​ 特点如下： ​ 1、提供了一种在数据库运行时实时检查server的内部执行情况的方法。performance_schema 数据库中的表使用performance_schema存储引擎。该数据库主要关注数据库运行过程中的性能相关的数据，与information_schema不同，information_schema主要关注server运行过程中的元数据信息 ​ 2、performance_schema通过监视server的事件来实现监视server内部运行情况， “事件”就是server内部活动中所做的任何事情以及对应的时间消耗，利用这些信息来判断server中的相关资源消耗在了哪里？一般来说，事件可以是函数调用、操作系统的等待、SQL语句执行的阶段（如sql语句执行过程中的parsing 或 sorting阶段）或者整个SQL语句与SQL语句集合。事件的采集可以方便的提供server中的相关存储引擎对磁盘文件、表I/O、表锁等资源的同步调用信息。​ 3、performance_schema中的事件与写入二进制日志中的事件（描述数据修改的events）、事件计划调度程序（这是一种存储程序）的事件不同。performance_schema中的事件记录的是server执行某些活动对某些资源的消耗、耗时、这些活动执行的次数等情况。​ 4、performance_schema中的事件只记录在本地server的performance_schema中，其下的这些表中数据发生变化时不会被写入binlog中，也不会通过复制机制被复制到其他server中。​ 5、 当前活跃事件、历史事件和事件摘要相关的表中记录的信息。能提供某个事件的执行次数、使用时长。进而可用于分析某个特定线程、特定对象（如mutex或file）相关联的活动。​ 6、PERFORMANCE_SCHEMA存储引擎使用server源代码中的“检测点”来实现事件数据的收集。对于performance_schema实现机制本身的代码没有相关的单独线程来检测，这与其他功能（如复制或事件计划程序）不同​ 7、收集的事件数据存储在performance_schema数据库的表中。这些表可以使用SELECT语句查询，也可以使用SQL语句更新performance_schema数据库中的表记录（如动态修改performance_schema的setup_*开头的几个配置表，但要注意：配置表的更改会立即生效，这会影响数据收集）​ 8、performance_schema的表中的数据不会持久化存储在磁盘中，而是保存在内存中，一旦服务器重启，这些数据会丢失（包括配置表在内的整个performance_schema下的所有数据）​ 9、MySQL支持的所有平台中事件监控功能都可用，但不同平台中用于统计事件时间开销的计时器类型可能会有所差异。 performance schema入门​ 在mysql的5.7版本中，性能模式是默认开启的，如果想要显式的关闭的话需要修改配置文件，不能直接进行修改，会报错Variable ‘performance_schema’ is a read only variable。 123456789101112131415161718192021222324252627282930--查看performance_schema的属性mysql&gt; SHOW VARIABLES LIKE 'performance_schema';+--------------------+-------+| Variable_name | Value |+--------------------+-------+| performance_schema | ON |+--------------------+-------+1 row in set (0.01 sec)--在配置文件中修改performance_schema的属性值，on表示开启，off表示关闭[mysqld]performance_schema=ON--切换数据库use performance_schema;--查看当前数据库下的所有表,会看到有很多表存储着相关的信息show tables;--可以通过show create table tablename来查看创建表的时候的表结构mysql&gt; show create table setup_consumers;+-----------------+---------------------------------| Table | Create Table +-----------------+---------------------------------| setup_consumers | CREATE TABLE `setup_consumers` ( `NAME` varchar(64) NOT NULL, `ENABLED` enum('YES','NO') NOT NULL ) ENGINE=PERFORMANCE_SCHEMA DEFAULT CHARSET=utf8 | +-----------------+---------------------------------1 row in set (0.00 sec) ​ 想要搞明白后续的内容，同学们需要理解两个基本概念： ​ instruments: 生产者，用于采集mysql中各种各样的操作产生的事件信息，对应配置表中的配置项我们可以称为监控采集配置项。 ​ consumers:消费者，对应的消费者表用于存储来自instruments采集的数据，对应配置表中的配置项我们可以称为消费存储配置项。 performance_schema表的分类​ performance_schema库下的表可以按照监视不同的纬度就行分组。 1234567891011121314151617181920--语句事件记录表，这些表记录了语句事件信息，当前语句事件表events_statements_current、历史语句事件表events_statements_history和长语句历史事件表events_statements_history_long、以及聚合后的摘要表summary，其中，summary表还可以根据帐号(account)，主机(host)，程序(program)，线程(thread)，用户(user)和全局(global)再进行细分)show tables like '%statement%';--等待事件记录表，与语句事件类型的相关记录表类似：show tables like '%wait%';--阶段事件记录表，记录语句执行的阶段事件的表show tables like '%stage%';--事务事件记录表，记录事务相关的事件的表show tables like '%transaction%';--监控文件系统层调用的表show tables like '%file%';--监视内存使用的表show tables like '%memory%';--动态对performance_schema进行配置的配置表show tables like '%setup%'; performance_schema的简单配置与使用​ 数据库刚刚初始化并启动时，并非所有instruments(事件采集项，在采集项的配置表中每一项都有一个开关字段，或为YES，或为NO)和consumers(与采集项类似，也有一个对应的事件类型保存表配置项，为YES就表示对应的表保存性能数据，为NO就表示对应的表不保存性能数据)都启用了，所以默认不会收集所有的事件，可能你需要检测的事件并没有打开，需要进行设置，可以使用如下两个语句打开对应的instruments和consumers（行计数可能会因MySQL版本而异)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253--打开等待事件的采集器配置项开关，需要修改setup_instruments配置表中对应的采集器配置项UPDATE setup_instruments SET ENABLED = 'YES', TIMED = 'YES'where name like 'wait%';--打开等待事件的保存表配置开关，修改setup_consumers配置表中对应的配置项UPDATE setup_consumers SET ENABLED = 'YES'where name like '%wait%';--当配置完成之后可以查看当前server正在做什么，可以通过查询events_waits_current表来得知，该表中每个线程只包含一行数据，用于显示每个线程的最新监视事件select * from events_waits_current\\G*************************** 1. row *************************** THREAD_ID: 11 EVENT_ID: 570 END_EVENT_ID: 570 EVENT_NAME: wait/synch/mutex/innodb/buf_dblwr_mutex SOURCE: TIMER_START: 4508505105239280 TIMER_END: 4508505105270160 TIMER_WAIT: 30880 SPINS: NULL OBJECT_SCHEMA: NULL OBJECT_NAME: NULL INDEX_NAME: NULL OBJECT_TYPE: NULLOBJECT_INSTANCE_BEGIN: 67918392 NESTING_EVENT_ID: NULL NESTING_EVENT_TYPE: NULL OPERATION: lock NUMBER_OF_BYTES: NULL FLAGS: NULL/*该信息表示线程id为11的线程正在等待buf_dblwr_mutex锁，等待事件为30880属性说明： id:事件来自哪个线程，事件编号是多少 event_name:表示检测到的具体的内容 source:表示这个检测代码在哪个源文件中以及行号 timer_start:表示该事件的开始时间 timer_end:表示该事件的结束时间 timer_wait:表示该事件总的花费时间注意：_current表中每个线程只保留一条记录，一旦线程完成工作，该表中不会再记录该线程的事件信息*//*_history表中记录每个线程应该执行完成的事件信息，但每个线程的事件信息只会记录10条，再多就会被覆盖，*_history_long表中记录所有线程的事件信息，但总记录数量是10000，超过就会被覆盖掉*/select thread_id,event_id,event_name,timer_wait from events_waits_history order by thread_id limit 21;/*summary表提供所有事件的汇总信息，该组中的表以不同的方式汇总事件数据（如：按用户，按主机，按线程等等）。例如：要查看哪些instruments占用最多的时间，可以通过对events_waits_summary_global_by_event_name表的COUNT_STAR或SUM_TIMER_WAIT列进行查询（这两列是对事件的记录数执行COUNT（*）、事件记录的TIMER_WAIT列执行SUM（TIMER_WAIT）统计而来）*/SELECT EVENT_NAME,COUNT_STAR FROM events_waits_summary_global_by_event_name ORDER BY COUNT_STAR DESC LIMIT 10;/*instance表记录了哪些类型的对象会被检测。这些对象在被server使用时，在该表中将会产生一条事件记录，例如，file_instances表列出了文件I/O操作及其关联文件名*/select * from file_instances limit 20; 常用配置项的参数说明1、启动选项 1234567891011121314151617181920212223242526272829303132333435363738394041424344performance_schema_consumer_events_statements_current=TRUE是否在mysql server启动时就开启events_statements_current表的记录功能(该表记录当前的语句事件信息)，启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新setup_consumers配置表中的events_statements_current配置项，默认值为TRUEperformance_schema_consumer_events_statements_history=TRUE与performance_schema_consumer_events_statements_current选项类似，但该选项是用于配置是否记录语句事件短历史信息，默认为TRUEperformance_schema_consumer_events_stages_history_long=FALSE与performance_schema_consumer_events_statements_current选项类似，但该选项是用于配置是否记录语句事件长历史信息，默认为FALSE除了statement(语句)事件之外，还支持：wait(等待)事件、state(阶段)事件、transaction(事务)事件，他们与statement事件一样都有三个启动项分别进行配置，但这些等待事件默认未启用，如果需要在MySQL Server启动时一同启动，则通常需要写进my.cnf配置文件中performance_schema_consumer_global_instrumentation=TRUE是否在MySQL Server启动时就开启全局表（如：mutex_instances、rwlock_instances、cond_instances、file_instances、users、hostsaccounts、socket_summary_by_event_name、file_summary_by_instance等大部分的全局对象计数统计和事件汇总统计信息表 ）的记录功能，启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新全局配置项默认值为TRUEperformance_schema_consumer_statements_digest=TRUE是否在MySQL Server启动时就开启events_statements_summary_by_digest 表的记录功能，启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新digest配置项默认值为TRUEperformance_schema_consumer_thread_instrumentation=TRUE是否在MySQL Server启动时就开启events_xxx_summary_by_yyy_by_event_name表的记录功能，启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新线程配置项默认值为TRUEperformance_schema_instrument[=name]是否在MySQL Server启动时就启用某些采集器，由于instruments配置项多达数千个，所以该配置项支持key-value模式，还支持%号进行通配等，如下:# [=name]可以指定为具体的Instruments名称（但是这样如果有多个需要指定的时候，就需要使用该选项多次），也可以使用通配符，可以指定instruments相同的前缀+通配符，也可以使用%代表所有的instruments## 指定开启单个instruments--performance-schema-instrument= 'instrument_name=value'## 使用通配符指定开启多个instruments--performance-schema-instrument= 'wait/synch/cond/%=COUNTED'## 开关所有的instruments--performance-schema-instrument= '%=ON'--performance-schema-instrument= '%=OFF'注意，这些启动选项要生效的前提是，需要设置performance_schema=ON。另外，这些启动选项虽然无法使用show variables语句查看，但我们可以通过setup_instruments和setup_consumers表查询这些选项指定的值。 2、系统变量 1234567891011121314151617181920212223242526272829303132333435show variables like '%performance_schema%';--重要的属性解释performance_schema=ON/*控制performance_schema功能的开关，要使用MySQL的performance_schema，需要在mysqld启动时启用，以启用事件收集功能该参数在5.7.x之前支持performance_schema的版本中默认关闭，5.7.x版本开始默认开启注意：如果mysqld在初始化performance_schema时发现无法分配任何相关的内部缓冲区，则performance_schema将自动禁用，并将performance_schema设置为OFF*/performance_schema_digests_size=10000/*控制events_statements_summary_by_digest表中的最大行数。如果产生的语句摘要信息超过此最大值，便无法继续存入该表，此时performance_schema会增加状态变量*/performance_schema_events_statements_history_long_size=10000/*控制events_statements_history_long表中的最大行数，该参数控制所有会话在events_statements_history_long表中能够存放的总事件记录数，超过这个限制之后，最早的记录将被覆盖全局变量，只读变量，整型值，5.6.3版本引入 * 5.6.x版本中，5.6.5及其之前的版本默认为10000，5.6.6及其之后的版本默认值为-1，通常情况下，自动计算的值都是10000 * 5.7.x版本中，默认值为-1，通常情况下，自动计算的值都是10000*/performance_schema_events_statements_history_size=10/*控制events_statements_history表中单个线程（会话）的最大行数，该参数控制单个会话在events_statements_history表中能够存放的事件记录数，超过这个限制之后，单个会话最早的记录将被覆盖全局变量，只读变量，整型值，5.6.3版本引入 * 5.6.x版本中，5.6.5及其之前的版本默认为10，5.6.6及其之后的版本默认值为-1，通常情况下，自动计算的值都是10 * 5.7.x版本中，默认值为-1，通常情况下，自动计算的值都是10除了statement(语句)事件之外，wait(等待)事件、state(阶段)事件、transaction(事务)事件，他们与statement事件一样都有三个参数分别进行存储限制配置，有兴趣的同学自行研究，这里不再赘述*/performance_schema_max_digest_length=1024/*用于控制标准化形式的SQL语句文本在存入performance_schema时的限制长度，该变量与max_digest_length变量相关(max_digest_length变量含义请自行查阅相关资料)全局变量，只读变量，默认值1024字节，整型值，取值范围0~1048576*/performance_schema_max_sql_text_length=1024/*控制存入events_statements_current，events_statements_history和events_statements_history_long语句事件表中的SQL_TEXT列的最大SQL长度字节数。 超出系统变量performance_schema_max_sql_text_length的部分将被丢弃，不会记录，一般情况下不需要调整该参数，除非被截断的部分与其他SQL比起来有很大差异全局变量，只读变量，整型值，默认值为1024字节，取值范围为0~1048576，5.7.6版本引入降低系统变量performance_schema_max_sql_text_length值可以减少内存使用，但如果汇总的SQL中，被截断部分有较大差异，会导致没有办法再对这些有较大差异的SQL进行区分。 增加该系统变量值会增加内存使用，但对于汇总SQL来讲可以更精准地区分不同的部分。*/ 重要配置表的相关说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/*performance_timers表中记录了server中有哪些可用的事件计时器字段解释： timer_name:表示可用计时器名称，CYCLE是基于CPU周期计数器的定时器 timer_frequency:表示每秒钟对应的计时器单位的数量,CYCLE计时器的换算值与CPU的频率相关、 timer_resolution:计时器精度值，表示在每个计时器被调用时额外增加的值 timer_overhead:表示在使用定时器获取事件时开销的最小周期值*/select * from performance_timers;/*setup_timers表中记录当前使用的事件计时器信息字段解释： name:计时器类型，对应某个事件类别 timer_name:计时器类型名称*/select * from setup_timers;/*setup_consumers表中列出了consumers可配置列表项字段解释： NAME：consumers配置名称 ENABLED：consumers是否启用，有效值为YES或NO，此列可以使用UPDATE语句修改。*/select * from setup_consumers;/*setup_instruments 表列出了instruments 列表配置项，即代表了哪些事件支持被收集：字段解释： NAME：instruments名称，instruments名称可能具有多个部分并形成层次结构 ENABLED：instrumetns是否启用，有效值为YES或NO，此列可以使用UPDATE语句修改。如果设置为NO，则这个instruments不会被执行，不会产生任何的事件信息 TIMED：instruments是否收集时间信息，有效值为YES或NO，此列可以使用UPDATE语句修改，如果设置为NO，则这个instruments不会收集时间信息*/SELECT * FROM setup_instruments;/*setup_actors表的初始内容是匹配任何用户和主机，因此对于所有前台线程，默认情况下启用监视和历史事件收集功能字段解释： HOST：与grant语句类似的主机名，一个具体的字符串名字，或使用“％”表示“任何主机” USER：一个具体的字符串名称，或使用“％”表示“任何用户” ROLE：当前未使用，MySQL 8.0中才启用角色功能 ENABLED：是否启用与HOST，USER，ROLE匹配的前台线程的监控功能，有效值为：YES或NO HISTORY：是否启用与HOST， USER，ROLE匹配的前台线程的历史事件记录功能，有效值为：YES或NO*/SELECT * FROM setup_actors;/*setup_objects表控制performance_schema是否监视特定对象。默认情况下，此表的最大行数为100行。字段解释： OBJECT_TYPE：instruments类型，有效值为：“EVENT”（事件调度器事件）、“FUNCTION”（存储函数）、“PROCEDURE”（存储过程）、“TABLE”（基表）、“TRIGGER”（触发器），TABLE对象类型的配置会影响表I/O事件（wait/io/table/sql/handler instrument）和表锁事件（wait/lock/table/sql/handler instrument）的收集 OBJECT_SCHEMA：某个监视类型对象涵盖的数据库名称，一个字符串名称，或“％”(表示“任何数据库”) OBJECT_NAME：某个监视类型对象涵盖的表名，一个字符串名称，或“％”(表示“任何数据库内的对象”) ENABLED：是否开启对某个类型对象的监视功能，有效值为：YES或NO。此列可以修改 TIMED：是否开启对某个类型对象的时间收集功能，有效值为：YES或NO，此列可以修改*/SELECT * FROM setup_objects;/*threads表对于每个server线程生成一行包含线程相关的信息，字段解释： THREAD_ID：线程的唯一标识符（ID） NAME：与server中的线程检测代码相关联的名称(注意，这里不是instruments名称) TYPE：线程类型，有效值为：FOREGROUND、BACKGROUND。分别表示前台线程和后台线程 PROCESSLIST_ID：对应INFORMATION_SCHEMA.PROCESSLIST表中的ID列。 PROCESSLIST_USER：与前台线程相关联的用户名，对于后台线程为NULL。 PROCESSLIST_HOST：与前台线程关联的客户端的主机名，对于后台线程为NULL。 PROCESSLIST_DB：线程的默认数据库，如果没有，则为NULL。 PROCESSLIST_COMMAND：对于前台线程，该值代表着当前客户端正在执行的command类型，如果是sleep则表示当前会话处于空闲状态 PROCESSLIST_TIME：当前线程已处于当前线程状态的持续时间（秒） PROCESSLIST_STATE：表示线程正在做什么事情。 PROCESSLIST_INFO：线程正在执行的语句，如果没有执行任何语句，则为NULL。 PARENT_THREAD_ID：如果这个线程是一个子线程（由另一个线程生成），那么该字段显示其父线程ID ROLE：暂未使用 INSTRUMENTED：线程执行的事件是否被检测。有效值：YES、NO HISTORY：是否记录线程的历史事件。有效值：YES、NO * THREAD_OS_ID：由操作系统层定义的线程或任务标识符（ID）：*/select * from threads 注意：在performance_schema库中还包含了很多其他的库和表，能对数据库的性能做完整的监控，大家需要参考官网详细了解。 performance_schema实践操作​ 基本了解了表的相关信息之后，可以通过这些表进行实际的查询操作来进行实际的分析。 12345678910111213141516171819202122232425262728--1、哪类的SQL执行最多？SELECT DIGEST_TEXT,COUNT_STAR,FIRST_SEEN,LAST_SEEN FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC--2、哪类SQL的平均响应时间最多？SELECT DIGEST_TEXT,AVG_TIMER_WAIT FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC--3、哪类SQL排序记录数最多？SELECT DIGEST_TEXT,SUM_SORT_ROWS FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC--4、哪类SQL扫描记录数最多？SELECT DIGEST_TEXT,SUM_ROWS_EXAMINED FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC--5、哪类SQL使用临时表最多？SELECT DIGEST_TEXT,SUM_CREATED_TMP_TABLES,SUM_CREATED_TMP_DISK_TABLES FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC--6、哪类SQL返回结果集最多？SELECT DIGEST_TEXT,SUM_ROWS_SENT FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC--7、哪个表物理IO最多？SELECT file_name,event_name,SUM_NUMBER_OF_BYTES_READ,SUM_NUMBER_OF_BYTES_WRITE FROM file_summary_by_instance ORDER BY SUM_NUMBER_OF_BYTES_READ + SUM_NUMBER_OF_BYTES_WRITE DESC--8、哪个表逻辑IO最多？SELECT object_name,COUNT_READ,COUNT_WRITE,COUNT_FETCH,SUM_TIMER_WAIT FROM table_io_waits_summary_by_table ORDER BY sum_timer_wait DESC--9、哪个索引访问最多？SELECT OBJECT_NAME,INDEX_NAME,COUNT_FETCH,COUNT_INSERT,COUNT_UPDATE,COUNT_DELETE FROM table_io_waits_summary_by_index_usage ORDER BY SUM_TIMER_WAIT DESC--10、哪个索引从来没有用过？SELECT OBJECT_SCHEMA,OBJECT_NAME,INDEX_NAME FROM table_io_waits_summary_by_index_usage WHERE INDEX_NAME IS NOT NULL AND COUNT_STAR = 0 AND OBJECT_SCHEMA &lt;&gt; 'mysql' ORDER BY OBJECT_SCHEMA,OBJECT_NAME;--11、哪个等待事件消耗时间最多？SELECT EVENT_NAME,COUNT_STAR,SUM_TIMER_WAIT,AVG_TIMER_WAIT FROM events_waits_summary_global_by_event_name WHERE event_name != 'idle' ORDER BY SUM_TIMER_WAIT DESC--12-1、剖析某条SQL的执行情况，包括statement信息，stege信息，wait信息SELECT EVENT_ID,sql_text FROM events_statements_history WHERE sql_text LIKE '%count(*)%';--12-2、查看每个阶段的时间消耗SELECT event_id,EVENT_NAME,SOURCE,TIMER_END - TIMER_START FROM events_stages_history_long WHERE NESTING_EVENT_ID = 1553;--12-3、查看每个阶段的锁等待情况SELECT event_id,event_name,source,timer_wait,object_name,index_name,operation,nesting_event_id FROM events_waits_history_longWHERE nesting_event_id = 1553; 注：本文转载自他人，只做笔记查阅用途","categories":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://midkuro.gitee.io/categories/MYSQL/"}],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://midkuro.gitee.io/tags/MYSQL/"}]},{"title":"'MySql 核心技术 '","slug":"mysql-technology","date":"2020-09-08T04:00:00.000Z","updated":"2020-11-23T00:51:05.186Z","comments":true,"path":"2020/09/08/mysql-technology/","link":"","permalink":"https://midkuro.gitee.io/2020/09/08/mysql-technology/","excerpt":"","text":"MySql 核心技术基本概念启动和停止方式一：计算机——右击管理——服务 方式二：通过管理员身份运行 12net start 服务名（启动服务）net stop 服务名（停止服务） 登录和退出登录：mysql 【-h主机名 -P端口号 】-u用户名 -p密码 退出：exit或 ctrl+C 常见命令12345678910111213141516171.查看当前所有的数据库show databases;2.打开指定的库use 库名3.查看当前库的所有表show tables;4.查看其它库的所有表show tables from 库名;5.查看表结构desc 表名;6.查看服务器的版本方式一：登录到mysql服务端select version();方式二：没有登录到mysql服务端mysql --version或mysql --V 语法规范 不区分大小写,但建议关键字大写，表名、列名小写 每条命令最好用分号结尾 每条命令根据需要，可以进行缩进 或换行 注释： 单行注释：#注释文字单行注释：– 注释文字多行注释：/* 注释文字 */ 语言分类DQL（Data Query Language）：数据查询语言（select） DML (Data Manipulate Language):数据操作语言（insert 、update、delete） DDL（Data Define Languge）：数据定义语言（create、drop、alter） TCL（Transaction Control Language）：事务控制语言（commit、rollback） DQL语言基础查询语法： 1select 查询列表 from 表名; 特点： 1、查询列表可以是：表中的字段、常量值、表达式、函数2、查询的结果是一个虚拟的表格 加号+作用：做加法运算 123select 数值+数值; 直接运算select 字符+数值;先试图将字符转换成数值，如果转换成功，则继续运算；否则转换成0，再做运算select null+值;结果都为null 条件查询语法： 123select 查询列表from 表名where 筛选条件 分类： 简单条件运算符：&gt; &lt; = != &lt;&gt; &gt;= &lt;= 逻辑运算符：&amp;&amp; / and、|| / or、! / not 模糊查询：like、between and、in、is null /is not null通配符：%任意多个字符，_任意单个字符 is null 和 &lt;=&gt; 比较： 普通类型的数值 null值 可读性 is null × √ √ &lt;=&gt; √ √ × 排序查询语法： 1234select 查询列表from 表where 筛选条件order by 排序列表 【asc&#x2F;desc】 特点：1、asc ：升序，如果不写默认升序，desc：降序 2、排序列表 支持 单个字段、多个字段、函数、表达式、别名 3、order by的位置一般放在查询语句的最后（除limit语句之外） 常见函数单行函数字符函数123456789101112131415161718192021222324252627282930313233#1.length 获取参数值的字节个数SELECT LENGTH(&#39;john&#39;);#2.concat 拼接字符串SELECT CONCAT(last_name,&#39;_&#39;,first_name) 姓名 FROM employees;#3.upper 变大写 lower 变小写SELECT UPPER(&#39;john&#39;);SELECT LOWER(&#39;joHn&#39;);#4.substr、substring 截取字符串 注意：索引从1开始#截取从指定索引处后面所有字符SELECT SUBSTR(&#39;李莫愁爱上了陆展元&#39;,7) out_put;#截取从指定索引处指定字符长度的字符SELECT SUBSTR(&#39;李莫愁爱上了陆展元&#39;,1,3) out_put;#5.instr 返回子串第一次出现的索引，如果找不到返回0SELECT INSTR(&#39;杨不殷六侠悔爱上了殷六侠&#39;,&#39;殷八侠&#39;) AS out_put;#6.trim 去空格&#x2F;指定字符SELECT LENGTH(TRIM(&#39; 张翠山 &#39;)) AS out_put;#去除指定字符SELECT TRIM(&#39;aa&#39; FROM &#39;aaaaaaaaa张aaaaaaaaaaaa翠山aaaaa&#39;) AS out_put;#7.lpad 用指定的字符实现左填充指定长度SELECT LPAD(&#39;殷素素&#39;,2,&#39;*&#39;) AS out_put;#8.rpad 用指定的字符实现右填充指定长度SELECT RPAD(&#39;殷素素&#39;,12,&#39;ab&#39;) AS out_put;#9.replace 替换SELECT REPLACE(&#39;周芷若周芷若张无忌爱上了周芷若&#39;,&#39;周芷若&#39;,&#39;赵敏&#39;) AS out_put; 数学函数1234567891011121314151617181920#round 四舍五入SELECT ROUND(-1.55);SELECT ROUND(1.567,2);#ceil 向上取整,返回&gt;&#x3D;该参数的最小整数SELECT CEIL(-1.02);#floor 向下取整，返回&lt;&#x3D;该参数的最大整数SELECT FLOOR(-9.99); #truncate 截断SELECT TRUNCATE(1.69999,1); #1.6#mod取余&#x2F;*mod(a,b) ： a-a&#x2F;b*bmod(-10,-3):-10- (-10)&#x2F;(-3)*（-3）&#x3D;-1*&#x2F;SELECT MOD(10,-3);SELECT 10%3; 日期函数12345678910111213141516171819202122#now 返回当前系统日期+时间SELECT NOW();#curdate 返回当前系统日期，不包含时间SELECT CURDATE();#curtime 返回当前时间，不包含日期SELECT CURTIME();#可以获取指定的部分，年、月、日、小时、分钟、秒SELECT YEAR(NOW()) 年;SELECT YEAR(&#39;1998-1-1&#39;) 年;SELECT YEAR(hiredate) 年 FROM employees;SELECT MONTH(NOW()) 月;SELECT MONTHNAME(NOW()) 月;#str_to_date 将字符通过指定的格式转换成日期SELECT STR_TO_DATE(&#39;1998-3-2&#39;,&#39;%Y-%c-%d&#39;) AS out_put;#date_format 将日期转换成字符SELECT DATE_FORMAT(NOW(),&#39;%y年%m月%d日&#39;) AS out_put; 其他函数123SELECT VERSION();SELECT DATABASE();SELECT USER(); 流程控制函数123456789101112131415161718192021222324252627282930313233343536#1.if(条件表达式，表达式1，表达式2)：如果条件表达式成立，返回表达式1，否则返回表达式2SELECT IF(10&lt;5,&#39;大&#39;,&#39;小&#39;);#2.case情况1case 变量或表达式或字段when 常量1 then 值1when 常量2 then 值2...else 值nend#案例：SELECT salary 原始工资,department_id,CASE department_idWHEN 30 THEN salary*1.1WHEN 40 THEN salary*1.2WHEN 50 THEN salary*1.3ELSE salaryEND AS 新工资FROM employees;#case情况2case when 条件1 then 值1when 条件2 then 值2...else 值nend#案例：SELECT salary,CASE WHEN salary&gt;20000 THEN &#39;A&#39;WHEN salary&gt;15000 THEN &#39;B&#39;WHEN salary&gt;10000 THEN &#39;C&#39;ELSE &#39;D&#39;END AS 工资级别FROM employees; 分组函数功能：用作统计使用，又称为聚合函数或统计函数或组函数 分类：sum 求和、avg 平均值、max 最大值 、min 最小值 、count 计算个数 特点：1、sum、avg一般用于处理数值型、max、min、count可以处理任何类型 2、以上分组函数都忽略null值 3、可以和distinct搭配实现去重的运算 4、一般使用count(*)用作统计行数 5、和分组函数一同查询的字段要求是group by后的字段 效率上：MyISAM存储引擎，count(*)最高InnoDB存储引擎，count(*)和count(1)效率&gt;count(字段) 12345SELECT SUM(salary) FROM employees;SELECT AVG(salary) FROM employees;SELECT MIN(salary) FROM employees;SELECT MAX(salary) FROM employees;SELECT COUNT(salary) FROM employees; 分组查询语法： 12345select 查询列表from 表【where 筛选条件】group by 分组的字段【order by 排序的字段】; 特点：1、和分组函数一同查询的字段必须是group by后出现的字段 2、筛选分为两类：分组前筛选和分组后筛选 3、分组可以按单个字段也可以按多个字段 4、可以搭配着排序使用 问题：分组函数做筛选能不能放在where后面答：不能 问题：where——group by——having 一般来讲，能用分组前筛选的，尽量使用分组前筛选，提高效率 使用关键字 筛选的表 位置 分组前筛选 where 原始表 group by前 分组后筛选 having 分组后的结果 group by后 1234567#案例：每个工种有奖金的员工的最高工资&gt;6000的工种编号和最高工资,按最高工资升序SELECT job_id,MAX(salary) mFROM employeesWHERE commission_pct IS NOT NULLGROUP BY job_idHAVING m&gt;6000ORDER BY m ; 连接查询含义：又称多表查询，当查询的字段来自于多个表时，就会用到连接查询 笛卡尔乘积现象：表1 有m行，表2有n行，结果=m*n行 发生原因：没有有效的连接条件如何避免：添加有效的连接条件 分类： 按年代分类： sql92标准:仅仅支持内连接 sql99标准【推荐】：支持内连接+外连接（左外和右外）+交叉连接 按功能分类： 内连接： 等值连接 非等值连接 自连接 外连接： 左外连接 右外连接 全外连接 交叉连接SQL92语法等值连接语法： 1234567select 查询列表from 表1 别名,表2 别名where 表1.key&#x3D;表2.key【and 筛选条件】【group by 分组字段】【having 分组后的筛选】【order by 排序字段】 特点： ① 一般为表起别名 ②多表的顺序可以调换 ③n表连接至少需要n-1个连接条件 ④等值连接的结果是多表的交集部分 非等值连接语法： 1234567select 查询列表from 表1 别名,表2 别名where 非等值的连接条件【and 筛选条件】【group by 分组字段】【having 分组后的筛选】【order by 排序字段】 自连接语法： 1234567select 查询列表from 表 别名1,表 别名2where 等值的连接条件【and 筛选条件】【group by 分组字段】【having 分组后的筛选】【order by 排序字段】 SQL99语法内连接语法： 1234567891011121314select 查询列表from 表1 别名【inner】 join 表2 别名 on 连接条件where 筛选条件group by 分组列表having 分组后的筛选order by 排序列表limit 子句;#案例SELECT last_name,department_nameFROM departments dJOIN employees eON e.&#96;department_id&#96; &#x3D; d.&#96;department_id&#96;; 特点：①表的顺序可以调换②内连接的结果=多表的交集③n表连接至少需要n-1个连接条件 分类：等值连接、非等值连接、自连接 外连接语法： 123456789101112131415select 查询列表from 表1 别名left|right|full【outer】 join 表2 别名 on 连接条件where 筛选条件group by 分组列表having 分组后的筛选order by 排序列表limit 子句;#案例SELECT b.*,bo.*FROM boys boLEFT OUTER JOIN beauty bON b.&#96;boyfriend_id&#96; &#x3D; bo.&#96;id&#96;WHERE b.&#96;id&#96; IS NULL; 特点：①查询的结果=主表中所有的行，如果从表和它匹配的将显示匹配行，如果从表没有匹配的则显示null②left join 左边的就是主表，right join 右边的就是主表， full join 两边都是主表③一般用于查询除了交集部分的剩余的不匹配的行 交叉连接语法： 123select 查询列表from 表1 别名cross join 表2 别名; 子查询含义：嵌套在其他语句内部的select语句称为子查询或内查询，外面的语句可以是insert、update、delete、select等，一般select作为外面语句较多外面如果为select语句，则此语句称为外查询或主查询 分类：1、按出现位置select后面：仅仅支持标量子查询 from后面：表子查询 where或having后面：标量子查询、列子查询、行子查询 exists后面：标量子查询、列子查询、行子查询、表子查询 2、按结果集的行列标量子查询（单行子查询）：结果集为一行一列列子查询（多行子查询）：结果集为多行一列行子查询：结果集为多行多列表子查询：结果集为多行多列 分页查询语法： 12345678910111213141516171819select 查询列表from 表【join type】 join 表2on 连接条件where 筛选条件group by 分组字段having 分组后的筛选order by 排序的字段】limit 【offset,】size;offset要显示条目的起始索引（起始索引从0开始）size 要显示的条目个数#案例1：查询前五条员工信息SELECT * FROM employees LIMIT 0,5;SELECT * FROM employees LIMIT 5;#案例2：查询第11条——第25条SELECT * FROM employees LIMIT 10,15; 特点： limit语句放在查询语句的最后，假如要显示的页数为page，每一页条目数为size 123select 查询列表from 表limit (page-1)*size,size; 联合查询union 联合 合并：将多条查询语句的结果合并成一个结果 语法： 12345678910查询语句1union 【all】查询语句2union 【all】...#案例：查询部门编号&gt;90或邮箱包含a的员工信息SELECT * FROM employees WHERE email LIKE &#39;%a%&#39;UNIONSELECT * FROM employees WHERE department_id&gt;90; 应用场景：要查询的结果来自于多个表，且多个表没有直接的连接关系，但查询的信息一致时 特点：1、要求多条查询语句的查询列数是一致的！2、要求多条查询语句的查询的每一列的类型和顺序最好一致3、union关键字默认去重，如果使用union all 可以包含重复项 查询总结执行顺序： 123456789select 查询列表 7from 表1 别名 1连接类型 join 表2 2on 连接条件 3where 筛选 4group by 分组列表 5having 筛选 6order by排序列表 8limit 起始条目索引，条目数; 9 DML语言插入语句语法： 123insert into 表名(字段名,...) values(值,...);或insert into 表名 set 字段&#x3D;值,字段&#x3D;值,...; 特点：1、要求值的类型和字段的类型要一致或兼容2、字段的个数和顺序不一定与原始表中的字段个数和顺序一致但必须保证值和字段一一对应3、假如表中有可以为null的字段，注意可以通过以下两种方式插入null值①字段和值都省略②字段写上，值使用null4、字段和值的个数必须一致5、字段名可以省略，默认所有列 两种方式 的区别：1.方式一支持一次插入多行，语法如下： 1insert into 表名【(字段名,..)】 values(值，..),(值，...),...; 2.方式一支持子查询，语法如下： 1insert into 表名 查询语句; 修改语句语法： 1234567891011121314151617181920212223update 表名set 列&#x3D;新值,列&#x3D;新值,...where 筛选条件;#修改多表的记录【补充】sql92语法：update 表1 别名,表2 别名set 列&#x3D;值,...where 连接条件and 筛选条件;sql99语法：update 表1 别名inner|left|right join 表2 别名on 连接条件set 列&#x3D;值,...where 筛选条件;#案例 修改多表的记录UPDATE boys boINNER JOIN beauty b ON bo.&#96;id&#96;&#x3D;b.&#96;boyfriend_id&#96;SET b.&#96;phone&#96;&#x3D;&#39;119&#39;,bo.&#96;userCP&#96;&#x3D;1000WHERE bo.&#96;boyName&#96;&#x3D;&#39;张无忌&#39;; 删除语句语法： 123456789101112131415161718方式一：deletedelete from 表名 where 筛选条件#多表的删除【补充】sql92语法：delete 表1的别名,表2的别名from 表1 别名,表2 别名where 连接条件and 筛选条件;sql99语法：delete 表1的别名,表2的别名from 表1 别名inner|left|right join 表2 别名 on 连接条件where 筛选条件;方式二：truncatetruncate table 表名; delete和truncate的区别： 1.delete 可以加where 条件，truncate不能加 2.truncate删除，效率高一丢丢 3.假如要删除的表中有自增长列，如果用delete删除后，再插入数据，自增长列的值从断点开始，而truncate删除后，再插入数据，自增长列的值从1开始。 4.truncate删除没有返回值，delete删除有返回值 5.truncate删除不能回滚，delete删除可以回滚. DDL语言库的管理1234567891011121314#库的创建create database 【if not exists】库名 库名【 character set 字符集名】;#案例：创建库BooksCREATE DATABASE IF NOT EXISTS books ;#库的修改RENAME DATABASE books TO 新库名;#更改库的字符集ALTER DATABASE books CHARACTER SET gbk;#库的删除DROP DATABASE IF EXISTS books; 表的管理表的创建1234567891011121314151617create table 表名( 列名 列的类型【(长度) 约束】, 列名 列的类型【(长度) 约束】, 列名 列的类型【(长度) 约束】, ... 列名 列的类型【(长度) 约束】)#案例：创建表BookCREATE TABLE book( id INT,#编号 bName VARCHAR(20),#图书名 price DOUBLE,#价格 authorId INT,#作者编号 publishDate DATETIME#出版日期); 表的修改12345678910111213141516alter table 表名 add|drop|modify|change column 列名 【列类型 约束】;#添加列alter table 表名 add column 列名 类型 【first|after 字段名】;#修改列的类型或约束alter table 表名 modify column 列名 新类型 【新约束】;#修改列名alter table 表名 change column 旧列名 新列名 类型;#删除列alter table 表名 drop column 列名;#修改表名alter table 表名 rename 【to】 新表名; 表的删除1drop table【if exists】 表名; 表的复制12345#复制表的结构create table 表名 like 旧表;#复制表的结构+数据create table 表名 select 查询列表 from 旧表【where 筛选】; 数据类型数值型整型 tinyint smallint mediumint int bigint 字节 1 2 3 4 8 特点：①都可以设置无符号和有符号，默认有符号，通过unsigned设置无符号 ②如果超出了范围，会报out or range异常，插入临界值 ③长度可以不指定，默认会有一个长度，长度代表显示的最大宽度，如果不够则左边用0填充，但需要搭配zerofill，并且默认变为无符号整型 1234#如何设置无符号CREATE TABLE tab_int( t1 INT(7) ZEROFILL); 浮点型定点数：decimal(M,D)浮点数： float(M,D) double(M,D) 字节 4 8 特点：①M代表整数部位+小数部位的个数，D代表小数部位 ②如果超出范围，则报out or range异常，并且插入临界值 ③M和D都可以省略，但对于定点数，M默认为10，D默认为0 ④如果精度要求较高，则优先考虑使用定点数 字符型较短的文本：char、varchar 其他：binary和varbinary用于保存较短的二进制，enum用于保存枚举，set用于保存集合 较长的文本：text、blob(较大的二进制) 特点： char varchar 写法 char(M) varchar(M) M的意思 最大的字符数，可以省略，默认为1 最大的字符数，不可以省略 特点 固定长度的字符 可变长度的字符 空间的耗费 比较耗费 比较节省 效率 高 低 日期型 分类 特点 date 只保存日期 time 只保存时间 year 只保存年 datetime 日期+时间 timestamp 日期+时间 字节 范围 时区影响 datetime 8 1000-9999 不受 timestamp 4 1970-2038 受 12345678910111213#案例CREATE TABLE tab_date( t1 DATETIME, t2 TIMESTAMP);INSERT INTO tab_date VALUES(NOW(),NOW());SELECT * FROM tab_date;SHOW VARIABLES LIKE &#39;time_zone&#39;;SET time_zone&#x3D;&#39;+9:00&#39;; 常见约束含义：一种限制，用于限制表中的数据，为了保证表中的数据的准确和可靠性 分类： 特点 NOT NULL 非空，用于保证该字段的值不能为空 DEFAULT 默认，用于保证该字段有默认值 PRIMARY KEY 主键，用于保证该字段的值具有唯一性，并且非空 UNIQUE 唯一，用于保证该字段的值具有唯一性，可以为空 CHECK 检查约束【mysql中不支持】 FOREIGN KEY 外键，用于限制两个表的关系，用于保证该字段的值必须来自于主表的关联列的值，在从表添加外键约束，用于引用主表中某列的值 添加约束的时机：创建表时、修改表时 约束的添加分类： 列级约束： 六大约束语法上都支持，但外键约束没有效果 表级约束： 除了非空、默认，其他的都支持 主键和唯一的区别： 保证唯一性 是否允许为空 一个表中可以有多少个 是否允许组合 主键 √ 至多一个 √，但不推荐 唯一 √ √ 可以多个 √，但不推荐 外键： 1、要求在从表设置外键关系 2、从表的外键列的类型和主表的关联列的类型要求一致或兼容，名称无要求 3、主表的关联列必须是一个key（一般是主键或唯一） 4、插入数据时，先插入主表，再插入从表。删除数据时，先删除从表，再删除主表 123456可以通过以下两种方式来删除主表的记录#方式一：级联删除ALTER TABLE stuinfo ADD CONSTRAINT fk_stu_major FOREIGN KEY(majorid) REFERENCES major(id) ON DELETE CASCADE;#方式二：级联置空ALTER TABLE stuinfo ADD CONSTRAINT fk_stu_major FOREIGN KEY(majorid) REFERENCES major(id) ON DELETE SET NULL; 创建表时添加约束添加列级约束 1234567#只支持：默认、非空、主键、唯一create table 表名( 字段名 字段类型 not null,#非空 字段名 字段类型 primary key,#主键 字段名 字段类型 unique,#唯一 字段名 字段类型 default 值,#默认) 添加表级约束 1234create table 表名( 字段名 字段类型 constraint 约束名 foreign key(字段名) references 主表（被引用列）) 支持类型 起约束名 列级约束 除了外键 不可以 表级约束 除了非空和默认 可以，但是对主键无效 12345678910#案例CREATE TABLE IF NOT EXISTS stuinfo( id INT PRIMARY KEY, stuname VARCHAR(20), sex CHAR(1), age INT DEFAULT 18, seat INT UNIQUE, majorid INT, CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorid) REFERENCES major(id)); 修改表约束12345678#添加&#x2F;删除列级约束alter table 表名 modify column 字段名 字段类型 新约束;#添加表级约束alter table 表名 add 【constraint 约束名】 约束类型(字段名) 【外键的引用】;#删除列级约束ALTER TABLE 表名 DROP 约束类型 字段名; 1234567891011121314151617181920212223242526添加非空alter table 表名 modify column 字段名 字段类型 not null;删除非空alter table 表名 modify column 字段名 字段类型 ;2、默认添加默认alter table 表名 modify column 字段名 字段类型 default 值;删除默认alter table 表名 modify column 字段名 字段类型 ;3、主键添加主键alter table 表名 add【 constraint 约束名】 primary key(字段名);删除主键alter table 表名 drop primary key;4、唯一添加唯一alter table 表名 add【 constraint 约束名】 unique(字段名);删除唯一alter table 表名 drop index 索引名;5、外键添加外键alter table 表名 add【 constraint 约束名】 foreign key(字段名) references 主表（被引用列）;删除外键alter table 表名 drop foreign key 约束名; 自增长列123456789101112131415#创建表时设置自增长列create table 表( 字段名 字段类型 约束 auto_increment)#修改表时设置自增长列alter table 表 modify column 字段名 字段类型 约束 auto_increment#删除自增长列alter table 表 modify column 字段名 字段类型 约束 #相关知识SHOW VARIABLES LIKE &#39;%auto_increment%&#39;;SET auto_increment_increment&#x3D;3; 特点：1、不用手动插入值，可以自动提供序列值，默认从1开始，步长为1auto_increment_increment，如果要更改起始值：手动插入值，如果要更改步长：更改系统变量，set auto_increment_increment=值; 2、一个表至多有一个自增长列 3、自增长列只能支持数值型 4、自增长列必须为一个key 索引123456789ALTER TABLE table_name ADD INDEX index_name (column_list)ALTER TABLE table_name ADD UNIQUE (column_list)ALTER TABLE table_name ADD PRIMARY KEY (column_list)CREATE INDEX index_name ON table_name (column_list)CREATE UNIQUE INDEX index_name ON table_name (column_list) 12345DROP INDEX index_name ON talbe_nameALTER TABLE table_name DROP INDEX index_nameALTER TABLE table_name DROP PRIMARY KEY TCL语言事务含义：一条或多条sql语句组成一个执行单位，一组sql语句要么都执行要么都不执行特点（ACID） A 原子性：一个事务是不可再分割的整体，要么都执行要么都不执行 C 一致性：一个事务可以使数据从一个一致状态切换到另外一个一致的状态 I 隔离性：一个事务不受其他事务的干扰，多个事务互相隔离的 D 持久性：一个事务一旦提交了，则永久的持久化到本地 隐式（自动）事务：没有明显的开启和结束，本身就是一条事务可以自动提交，比如insert、update、delete 123456789101112131415#显式事务：具有明显的开启和结束#步骤1：开启事务set autocommit&#x3D;0;start transaction; #可省略#步骤2：编写事务中的sql语句(select insert update delete)语句1;语句2;...#可以设置保存点savepoint 回滚点名;#步骤3：结束&#x2F;回滚事务commit;提交事务rollback;回滚事务rollback to 回滚点名; 并发事务多个事务同时操作同一个数据库的相同数据时，并发问题都有哪些？ 脏读：一个事务读取了其他事务还没有提交的数据，读到的是其他事务“更新”的数据 不可重复读：一个事务多次读取，结果不一样 幻读：一个事务读取了其他事务还没有提交的数据，只是读到的是 其他事务“插入”的数据 可以通过设置事务的隔离级别来解决以上的问题。 脏读 不可重复读 幻读 read uncommitted:读未提交 × × × read committed：读已提交 √ × × repeatable read：可重复读 √ √ × serializable：串行化 √ √ √ 123456#mysql中默认 第三个隔离级别 repeatable read#oracle中默认第二个隔离级别 read committed#查看隔离级别select @@tx_isolation;#设置隔离级别set session|global transaction isolation level 隔离级别; 其他视图mysql5.1版本出现的新特性，本身是一个虚拟表，它的数据来自于表，通过执行时动态生成。好处：1、简化sql语句2、提高了sql的重用性3、保护基表的数据，提高了安全性 12345678910111213141516171819202122#创建create view 视图名as查询语句;#修改#方式一：create or replace view 视图名as查询语句;#方式二：alter view 视图名as查询语句#删除drop view 视图1，视图2,...;#查看desc 视图名;show create view 视图名; 注意：视图一般用于查询的，而不是更新的，所以具备以下特点的视图都不允许更新①包含分组函数、group by、distinct、having、union、②join③常量视图④where后的子查询用到了from中的表⑤用到了不可更新的视图 关键字 是否占用物理空间 使用 视图 view 占用较小，只保存sql逻辑 一般用于查询 表 table 保存实际的数据 增删改查 变量系统变量变量由系统提供的，不用自定义语法： 12345678910111213#查看系统变量show 【global|session 】variables like &#39;&#39;; 如果没有显式声明global还是session，则默认是session#查看指定的系统变量的值select @@【global|session】.变量名; 如果没有显式声明global还是session，则默认是session#为系统变量赋值#方式一：set 【global|session 】 变量名&#x3D;值; 如果没有显式声明global还是session，则默认是session#方式二：set @@global.变量名&#x3D;值;set @@变量名&#x3D;值； 全局变量服务器层面上的，必须拥有super权限才能为系统变量赋值，作用域为整个服务器，也就是针对于所有连接（会话）有效 123456789#查看所有全局变量SHOW GLOBAL VARIABLES;#查看满足条件的部分系统变量SHOW GLOBAL VARIABLES LIKE &#39;%char%&#39;;#查看指定的系统变量的值SELECT @@global.autocommit;#为某个系统变量赋值SET @@global.autocommit&#x3D;0;SET GLOBAL autocommit&#x3D;0; 会话变量服务器为每一个连接的客户端都提供了系统变量，作用域为当前的连接（会话） 12345678910#查看所有会话变量SHOW SESSION VARIABLES;#查看满足条件的部分会话变量SHOW SESSION VARIABLES LIKE &#39;%char%&#39;;#查看指定的会话变量的值SELECT @@autocommit;SELECT @@session.tx_isolation;#为某个会话变量赋值SET @@session.tx_isolation&#x3D;&#39;read-uncommitted&#39;;SET SESSION tx_isolation&#x3D;&#39;read-committed&#39;; 自定义变量用户变量作用域：针对于当前连接（会话）生效位置：begin end里面，也可以放在外面 12345678910111213141516#赋值操作符：&#x3D;或:&#x3D;#声明并赋值：set @变量名&#x3D;值;或set @变量名:&#x3D;值;或select @变量名:&#x3D;值;#更新值#方式一：set @变量名&#x3D;值; 或set @变量名:&#x3D;值; 或select @变量名:&#x3D;值;#方式二：select xx into @变量名 from 表;#使用select @变量名; 局部变量作用域：仅仅在定义它的begin end中有效位置：只能放在begin end中，而且只能放在第一句 1234567891011#声明declare 变量名 类型 【default 值】;#赋值或更新#方式一：set 变量名&#x3D;值;或set 变量名:&#x3D;值;或select @变量名:&#x3D;值;#方式二：select xx into 变量名 from 表;#使用select 变量名; 作用域 定义位置 语法 用户变量 当前会话 会话的任何地方 加@符号，不用指定类型 局部变量 定义它的BEGIN END中 BEGIN END的第一句话 一般不用加@,需要指定类型 存储过程创建1234567create procedure 存储过程名(参数模式 参数名 参数类型)begin 存储过程体end注意：1.参数模式：in、out、inout，其中in可以省略2.存储过程体的每一条sql语句都需要用分号结尾 注意：1、参数列表包含三部分：参数模式 参数名 参数类型举例：in stuname varchar(20) 参数模式：in：该参数可以作为输入，也就是该参数需要调用方传入值out：该参数可以作为输出，也就是该参数可以作为返回值inout：该参数既可以作为输入又可以作为输出，也就是该参数既需要传入值，又可以返回值 2、如果存储过程体仅仅只有一句话，begin end可以省略存储过程体中的每条sql语句的结尾要求必须加分号。存储过程的结尾可以使用 delimiter 重新设置 1234#语法delimiter 结束标记#案例：delimiter $ 调用1234567891011call 存储过程名(实参列表)#举例：#调用in模式的参数：call sp1（‘值’）;#调用out模式的参数：set @name; call sp1(@name);select @name;#调用inout模式的参数：set @name&#x3D;值; call sp1(@name); select @name; 123456789101112131415#案例CREATE PROCEDURE myp7(IN beautyName VARCHAR(20),OUT boyName VARCHAR(20),OUT usercp INT) BEGIN SELECT boys.boyname ,boys.usercp INTO boyname,usercp FROM boys RIGHT JOIN beauty b ON b.boyfriend_id &#x3D; boys.id WHERE b.name&#x3D;beautyName ; END $#多个out参数用into，逗号隔开#调用CALL myp7(&#39;小昭&#39;,@name,@cp)$SELECT @name,@cp$ 查看1show create procedure 存储过程名; 删除1drop procedure 存储过程名; 函数","categories":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://midkuro.gitee.io/categories/MYSQL/"}],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://midkuro.gitee.io/tags/MYSQL/"}]},{"title":"'Netty（二）编码 '","slug":"netty-source","date":"2020-08-04T04:00:00.000Z","updated":"2020-09-08T14:22:31.650Z","comments":true,"path":"2020/08/04/netty-source/","link":"","permalink":"https://midkuro.gitee.io/2020/08/04/netty-source/","excerpt":"","text":"Netty服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;public class NettyServer &#123; public static void main(String[] args) throws Exception &#123; //创建BossGroup 和 WorkerGroup //说明 //1. 创建两个线程组 bossGroup 和 workerGroup //2. bossGroup 只是处理连接请求 , 真正的和客户端业务处理，会交给 workerGroup完成 //3. 两个都是无限循环 //4. bossGroup 和 workerGroup 含有的子线程(NioEventLoop)的个数 // 默认实际 cpu核数 * 2 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); //8 try &#123; //创建服务器端的启动对象，配置参数 ServerBootstrap bootstrap = new ServerBootstrap(); //使用链式编程来进行设置 bootstrap.group(bossGroup, workerGroup) //设置两个线程组 .channel(NioServerSocketChannel.class) //使用NioSocketChannel 作为服务器的通道实现 .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列得到连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动连接状态 //.handler(null) // 该 handler对应 bossGroup , childHandler 对应 workerGroup .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;//创建一个通道初始化对象(匿名对象) //给pipeline 设置处理器 @Override protected void initChannel(SocketChannel ch) throws Exception &#123; System.out.println(\"客户socketchannel hashcode=\" + ch.hashCode()); //可以使用一个集合管理 SocketChannel， 再推送消息时，可以将业务加入到各个channel 对应的 NIOEventLoop 的 taskQueue 或者 scheduleTaskQueue ch.pipeline().addLast(new NettyServerHandler()); &#125; &#125;); // 给我们的workerGroup 的 EventLoop 对应的管道设置处理器 System.out.println(\".....服务器 is ready...\"); //绑定一个端口并且同步, 生成了一个 ChannelFuture 对象 //启动服务器(并绑定端口) ChannelFuture cf = bootstrap.bind(6668).sync(); //给cf 注册监听器，监控我们关心的事件 cf.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (cf.isSuccess()) &#123; System.out.println(\"监听端口 6668 成功\"); &#125; else &#123; System.out.println(\"监听端口 6668 失败\"); &#125; &#125; &#125;); //对关闭通道进行监听 cf.channel().closeFuture().sync(); &#125;finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.Channel;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.channel.ChannelPipeline;import io.netty.util.CharsetUtil;import java.util.concurrent.TimeUnit;/*说明1. 我们自定义一个Handler 需要继续netty 规定好的某个HandlerAdapter(规范)2. 这时我们自定义一个Handler , 才能称为一个handler */public class NettyServerHandler extends ChannelInboundHandlerAdapter &#123; //读取数据实际(这里我们可以读取客户端发送的消息) /* 1. ChannelHandlerContext ctx:上下文对象, 含有 管道pipeline , 通道channel, 地址 2. Object msg: 就是客户端发送的数据 默认Object */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println(\"服务器读取线程 \" + Thread.currentThread().getName() + \" channle =\" + ctx.channel()); System.out.println(\"server ctx =\" + ctx); Channel channel = ctx.channel(); ChannelPipeline pipeline = ctx.pipeline(); //本质是一个双向链表, 出栈入栈 //将 msg 转成一个 ByteBuf //ByteBuf 是 Netty 提供的，不是 NIO 的 ByteBuffer. ByteBuf buf = (ByteBuf) msg; System.out.println(\"客户端发送消息是:\" + buf.toString(CharsetUtil.UTF_8)); System.out.println(\"客户端地址:\" + channel.remoteAddress()); &#125; //数据读取完毕 @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; //writeAndFlush 是 write + flush //将数据写入到缓存，并刷新 //一般讲，我们对这个发送的数据进行编码 ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(&gt;^ω^&lt;)喵1\", CharsetUtil.UTF_8)); &#125; //处理异常, 一般是需要关闭通道 @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; ctx.close(); &#125;&#125; 客户端1234567891011121314151617181920212223242526272829303132333435363738394041import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;public class NettyClient &#123; public static void main(String[] args) throws Exception &#123; //客户端需要一个事件循环组 EventLoopGroup group = new NioEventLoopGroup(); try &#123; //创建客户端启动对象 //注意客户端使用的不是 ServerBootstrap 而是 Bootstrap Bootstrap bootstrap = new Bootstrap(); //设置相关参数 bootstrap.group(group) //设置线程组 .channel(NioSocketChannel.class) // 设置客户端通道的实现类(反射) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new NettyClientHandler()); //加入自己的处理器 &#125; &#125;); System.out.println(\"客户端 ok..\"); //启动客户端去连接服务器端 //关于 ChannelFuture 要分析，涉及到netty的异步模型 ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 6668).sync(); //给关闭通道进行监听 channelFuture.channel().closeFuture().sync(); &#125;finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.util.CharsetUtil;public class NettyClientHandler extends ChannelInboundHandlerAdapter &#123; //当通道就绪就会触发该方法 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"client \" + ctx); ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, server: (&gt;^ω^&lt;)喵\", CharsetUtil.UTF_8)); &#125; //当通道有读取事件时，会触发 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf buf = (ByteBuf) msg; System.out.println(\"服务器回复的消息:\" + buf.toString(CharsetUtil.UTF_8)); System.out.println(\"服务器的地址： \"+ ctx.channel().remoteAddress()); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; 运行","categories":[{"name":"Netty","slug":"Netty","permalink":"https://midkuro.gitee.io/categories/Netty/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://midkuro.gitee.io/tags/NIO/"},{"name":"Netty","slug":"Netty","permalink":"https://midkuro.gitee.io/tags/Netty/"}]},{"title":"'Netty（一）Netty简介 与 零拷贝 '","slug":"netty-model","date":"2020-08-03T04:00:00.000Z","updated":"2020-09-08T14:22:23.254Z","comments":true,"path":"2020/08/03/netty-model/","link":"","permalink":"https://midkuro.gitee.io/2020/08/03/netty-model/","excerpt":"","text":"Netty简介与零拷贝零拷贝我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的（只有 kernel buffer 有一份数据），也就是说，是没有CPU拷贝的。 零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的 CPU 缓存伪共享以及无 CPU 校验和计算。 在 Java 程序中，常用的零拷贝有 mmap(内存映射) 和 sendFile。 传统IO 传统的IO模型，从数据传输到客户端需要经过3次上下文切换,4次数据拷贝。 上下文切换：从用户态–&gt;内核态–&gt;用户态–&gt;内核态 数据拷贝：DMA–&gt;内核态-&gt;用户态–&gt;Socket缓冲区–&gt;TCP协议(网卡) mmap mmap通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户控件的拷贝次数。 mmap实现了3次上下文切换，3次数据拷贝。 sendFile Linux 2.1 版本 提供了 sendFile 函数，其基本原理如下：数据根本不经过用户态，直接从内核缓冲区进入到 Socket Buffer，同时，由于和用户态完全无关，就减少了一次上下文切换。 Linux 在 2.4 版本中，做了一些修改，避免了从内核缓冲区拷贝到 Socket buffer 的操作，直接拷贝到协议栈，从而再一次减少了数据拷贝。 这里其实有 一次cpu 拷贝： 内核态–&gt; socket buffer，但是，拷贝的信息很少，比如lenght ,offset, 消耗低，可以忽略。 区别mmap 适合小数据量读写，sendFile 适合大文件传输。 mmap 需要 3 次上下文切换，3 次数据拷贝；sendFile 需要 2 次上下文切换，最少 2 次数据拷贝。 sendFile 可以利用DMA 方式，减少 CPU 拷贝，mmap 则不能（必须从内核拷贝到 Socket 缓冲区）。 Netty介绍Netty 是由 JBOSS 提供的一个 Java 开源框架。Netty 提供异步的、基于事件驱动的网络应用程序框架，用以快速开发高性能、高可靠性的网络 IO 程序 Netty 可以帮助你快速、简单的开发出一个网络应用，相当于简化和流程化了 NIO 的开发过程 Netty 是目前最流行的 NIO 框架，Netty 在互联网领域、大数据分布式计算领域、游戏行业、通信行业等获得了广泛的应用，知名的 Elasticsearch 、Dubbo 框架内部都采用了 Netty。 NIO存在的问题NIO 的类库和 API 繁杂，使用麻烦：需要熟练掌握 Selector、ServerSocketChannel、SocketChannel、ByteBuffer 等。需要具备其他的额外技能：要熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，你必须对多线程和网络编程非常熟悉，才能编写出高质量的 NIO 程序。 开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常流的处理等等。 JDK NIO 的 Bug：例如臭名昭著的 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%。直到 JDK 1.7 版本该问题仍旧存在，没有被根本解决。 Netty的优点Netty 对 JDK 自带的 NIO 的 API 进行了封装，解决了上述问题。 设计优雅：适用于各种传输类型的统一 API 阻塞和非阻塞 Socket；基于灵活且可扩展的事件模型，可以清晰地分离关注点；高度可定制的线程模型 - 单线程，一个或多个线程池. 使用方便：详细记录的 Javadoc，用户指南和示例；没有其他依赖项，JDK 5（Netty 3.x）或 6（Netty 4.x）就足够了。高性能、吞吐量更高：延迟更低；减少资源消耗；最小化不必要的内存复制。 安全：完整的 SSL/TLS 和 StartTLS 支持。社区活跃、不断更新：社区活跃，版本迭代周期短，发现的 Bug 可以被及时修复，同时，更多的新功能会被加入。 Netty版本说明netty版本分为 netty3.x 和 netty4.x、netty5.x因为Netty5出现重大bug，已经被官网废弃了，目前推荐使用的是Netty4.x的稳定版本。下载地址 线程模型不同的线程模式，对程序的性能有很大影响，为了搞清Netty 线程模式，我们来系统的讲解下 各个线程模式， 最后看看Netty 线程模型有什么优越性. 目前存在的线程模型有：传统阻塞 I/O 服务模型 和Reactor 模式。 根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现： 单 Reactor 单线程 单 Reactor 多线程 主从 Reactor 多线程 Netty 线程模式：基于主从 Reactor 多线程模型做了一定的改进，其中主从 Reactor 多线程模型有多个 Reactor。 传统阻塞 I/O 服务模型 工作原理图黄色的框表示对象， 蓝色的框表示线程，白色的框表示方法(API)。 模型特点采用阻塞IO模式获取输入的数据，每个连接都需要独立的线程完成数据的输入，业务处理和数据返回。 问题分析当并发数很大，就会创建大量的线程，占用很大系统资源，连接创建后，如果当前线程暂时没有数据可读，该线程会阻塞在read操作，造成线程资源浪费。 Reactor 模式针对传统阻塞 I/O 服务模型的 2 个缺点，解决方案： 基于 I/O 复用模型：多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。 Reactor对应的叫法: 反应器模式 分发者模式(Dispatcher) 通知者模式(notifier) 基于线程池复用线程资源：不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。 Reactor 模式，通过一个或多个输入同时传递给服务处理器的模式(基于事件驱动)。 服务器端程序处理传入的多个请求，并将它们同步分派到相应的处理线程， 因此Reactor模式也叫 Dispatcher模式。 Reactor 模式使用IO复用监听事件， 收到事件后，分发给某个线程(进程), 这点就是网络服务器高并发处理关键。 核心组成Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。 它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人； Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。 单 Reactor 单线程方案说明： Select 是前面 I/O 复用模型介绍的标准网络编程 API，可以实现应用程序通过一个阻塞对象监听多路连接请求。 Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发。 如果是建立连接请求事件，则由Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理。 如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应，Handler 会完成 Read–&gt;业务处理–&gt;Send 的完整业务流程 结合实例：服务器端用一个线程通过多路复用搞定所有的 IO 操作（包括连接，读、写等），编码简单，清晰明了，但是如果客户端连接数量较多，将无法支撑。 方案优缺点分析： 优点：模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成 缺点：性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈缺点：可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。 使用场景：客户端的数量有限，业务处理非常快速，比如 Redis在业务处理的时间复杂度 O(1) 的情况。 单Reactor多线程 方案说明：Reactor 对象通过select 监控客户端请求事件, 收到事件后，通过dispatch进行分发。 如果建立连接请求, 则由Acceptor 通过accept 处理连接请求, 然后创建一个Handler对象处理完成连接后的各种事件。 如果不是连接请求，则由reactor分发调用连接对应的handler 来处理。 handler 只负责响应事件，不做具体的业务处理, 通过read 读取数据后，会分发给后面的worker线程池的某个线程处理业务。 worker 线程池会分配独立线程完成真正的业务，并将结果返回给handler。 handler收到响应后，通过send 将结果返回给client。 方案优缺点分析： 优点：可以充分的利用多核cpu 的处理能力 缺点：多线程数据共享和访问比较复杂，reactor 处理所有的事件的监听和响应，在单线程运行， 在高并发场景容易出现性能瓶颈。 主从 Reactor 多线程 针对单 Reactor 多线程模型中，Reactor 在单线程中运行，高并发场景下容易成为性能瓶颈，可以让 Reactor 在多线程中运行。 方案说明： Reactor主线程 MainReactor 对象通过select 监听连接事件, 收到事件后，通过Acceptor 处理连接事件。 当 Acceptor 处理连接事件后，MainReactor 将连接分配给SubReactor。 Subreactor 将连接加入到连接队列进行监听,并创建handler进行各种事件处理。 当有新事件发生时， Subreactor 就会调用对应的handler处理。 handler 通过read 读取数据，分发给后面的worker 线程处理。 worker 线程池分配独立的worker 线程进行业务处理，并返回结果。 handler 收到响应的结果后，再通过send 将结果返回给client。 Reactor 主线程可以对应多个Reactor 子线程, 即MainRecator 可以关联多个SubReactor。 方案优缺点说明： 优点：父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。 缺点：编程复杂度较高。 结合实例：这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。 总结3 种模式用生活案例来理解：单 Reactor 单线程，前台接待员和服务员是同一个人，全程为顾客服 单 Reactor 多线程，1 个前台接待员，多个服务员，接待员只负责接待 主从 Reactor 多线程，多个前台接待员，多个服务生 Reactor 模式具有如下的优点： 响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的。 可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销。 扩展性好，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源。 复用性好，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。 Netty模型 Netty 主要基于主从Reactor 多线程模型（如图）做了一定的改进，其中主从 Reactor 多线程模型有多个Reactor。 BossGroup 线程维护Selector , 只关注Accept。 当接收到Accept事件，获取到对应的SocketChannel, 封装成 NIOScoketChannel并注册到Worker 线程(事件循环), 并进行维护 当Worker线程监听到Selector 中通道发生自己感兴趣的事件后，就由handler进行处理， 注意handler 已经加入到通道。 工作原理 Netty抽象出两组线程池BossGroup专门负责接收客户端的连接,WorkerGroup 专门负责网络的读写。 BossGroup 和 WorkerGroup 类型都是 NioEventLoopGroup。 NioEventLoopGroup 相当于一个事件循环组, 这个组中含有多个事件循环 ，每一个事件循环是 NioEventLoop。 NioEventLoop 表示一个不断循环的执行处理任务的线程， 每个NioEventLoop 都有一个selector , 用于监听绑定在其上的socket的网络通讯。 NioEventLoopGroup 可以有多个线程, 即可以含有多个NioEventLoop。 每个BossGroup的NioEventLoop 循环执行的步骤有3步： 轮询accept 事件。 处理accept 事件，与client建立连接 , 生成NioScocketChannel , 并将其注册到某个workerGroup的NIOEventLoop 上的 selector中。 处理任务队列的任务 ， 即runAllTasks。 每个WorkerGroup的NIOEventLoop 处理业务时，会使用pipeline(管道)，pipeline 中包含了 channel , 即通过pipeline 可以获取到对应通道, 管道中维护了很多的处理器。","categories":[{"name":"Netty","slug":"Netty","permalink":"https://midkuro.gitee.io/categories/Netty/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://midkuro.gitee.io/tags/NIO/"},{"name":"Netty","slug":"Netty","permalink":"https://midkuro.gitee.io/tags/Netty/"}]},{"title":"'RocketMQ（三）整合springBoot '","slug":"rocketmq-springboot","date":"2020-07-20T04:00:00.000Z","updated":"2020-12-01T07:37:30.235Z","comments":true,"path":"2020/07/20/rocketmq-springboot/","link":"","permalink":"https://midkuro.gitee.io/2020/07/20/rocketmq-springboot/","excerpt":"","text":"RocketMQ 4.x生产者12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt;&lt;/dependency&gt; 123# application.propertiesrocketmq.name-server=192.168.1.131:9876rocketmq.producer.group=my-group 123456@SpringBootApplicationpublic class MQProducerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MQSpringBootApplication.class); &#125;&#125; 123456789101112@RunWith(SpringRunner.class)@SpringBootTest(classes = &#123;MQSpringBootApplication.class&#125;)public class ProducerTest &#123; @Autowired private RocketMQTemplate rocketMQTemplate; @Test public void test1()&#123; rocketMQTemplate.convertAndSend(\"springboot-mq\",\"hello springboot rocketmq\"); &#125;&#125; 消费者12345678910@Slf4j@Component@RocketMQMessageListener(topic = \"springboot-mq\",consumerGroup = \"springboot-mq-consumer-1\")public class Consumer implements RocketMQListener&lt;String&gt; &#123; @Override public void onMessage(String message) &#123; log.info(\"Receive message：\"+message); &#125;&#125; 事务消息123456789101112131415161718192021//绑定rocketMQ的bean@RocketMQTransactionListener(rocketMQTemplateBeanName = \"rocketMQTemplate\")public class MyTransactionListener implements RocketMQLocalTransactionListener &#123; // arg 是调用时传递的参数 @Override public RocketMQLocalTransactionState executeLocalTransaction(Message message, Object arg) &#123; try &#123; //业务逻辑 return RocketMQLocalTransactionState.COMMIT; &#125; catch (Exception e) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125; &#125; @Override public RocketMQLocalTransactionState checkLocalTransaction(Message message) &#123; return RocketMQLocalTransactionState.ROLLBACK; &#125;&#125; 通过实现RocketMQLocalTransactionListener类，触发调度事务消息发送成半消息时，回调接口。 123456789101112131415@Servicepublic class ProducerServiceImpl&#123; @Autowired private RocketMQTemplate rocketMQTemplate; public void sendMessage(String message) &#123; Map&lt;String, Object&gt; headers = new HashMap&lt;&gt;(); headers.put(\"myHeader\", \"myHeader\"); Message&lt;String&gt; message = MessageBuilder.withPayload(message).copyHeaders(headers).build(); rocketMQTemplate.sendMessageInTransaction(\"myDestnation\", message, basic); &#125;&#125; 参考资料","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.gitee.io/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.gitee.io/tags/RocketMQ/"}]},{"title":"'RocketMQ（二）消息类型 '","slug":"rocketmq-message","date":"2020-07-17T04:00:00.000Z","updated":"2020-11-12T04:20:09.317Z","comments":true,"path":"2020/07/17/rocketmq-message/","link":"","permalink":"https://midkuro.gitee.io/2020/07/17/rocketmq-message/","excerpt":"","text":"RocketMQ 4.x12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.4.0&lt;/version&gt;&lt;/dependency&gt; 消息发送者步骤分析 1234561.创建消息生产者producer，并制定生产者组名2.指定Nameserver地址3.启动producer4.创建消息对象，指定主题Topic、Tag和消息体5.发送消息6.关闭生产者producer 消息消费者步骤分析 123451.创建消费者Consumer，制定消费者组名2.指定Nameserver地址3.订阅主题Topic和Tag4.设置回调函数，处理消息5.启动消费者consumer 生产者发送同步消息这种可靠性同步地发送方式使用的比较广泛，比如：重要的消息通知，短信通知。 1234567891011121314151617181920212223public class SyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送消息到一个Broker SendResult sendResult = producer.send(msg); // 通过sendResult返回消息是否成功送达 System.out.printf(\"%s%n\", sendResult); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 发送异步消息异步消息通常用在对响应时间敏感的业务场景，即发送端不能容忍长时间地等待Broker的响应。 12345678910111213141516171819202122232425262728293031323334public class AsyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); producer.setRetryTimesWhenSendAsyncFailed(0); for (int i = 0; i &lt; 100; i++) &#123; final int index = i; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); // SendCallback接收异步返回结果的回调 producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; System.out.printf(\"%-10d OK %s %n\", index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; System.out.printf(\"%-10d Exception %s %n\", index, e); e.printStackTrace(); &#125; &#125;); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 发送单向消息这种方式主要用在不特别关心发送结果的场景，例如日志发送。 12345678910111213141516171819202122public class OnewayProducer &#123; public static void main(String[] args) throws Exception&#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送单向消息，没有任何返回结果 producer.sendOneway(msg); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 消费者负载均衡模式消费者采用负载均衡方式消费消息，多个消费者共同消费队列消息，每个消费者处理的消息不同. 1234567891011121314151617181920212223public static void main(String[] args) throws Exception &#123; // 实例化消息生产者,指定组名 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group1\"); // 指定Namesrv地址信息. consumer.setNamesrvAddr(\"localhost:9876\"); // 订阅Topic consumer.subscribe(\"Test\", \"*\"); //负载均衡模式消费 consumer.setMessageModel(MessageModel.CLUSTERING); // 注册回调函数，处理消息 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); //启动消息者 consumer.start(); System.out.printf(\"Consumer Started.%n\");&#125; 广播模式消费者采用广播的方式消费消息，每个消费者消费的消息都是相同的. 1234567891011121314151617181920212223public static void main(String[] args) throws Exception &#123; // 实例化消息生产者,指定组名 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group1\"); // 指定Namesrv地址信息. consumer.setNamesrvAddr(\"localhost:9876\"); // 订阅Topic consumer.subscribe(\"Test\", \"*\"); //广播模式消费 consumer.setMessageModel(MessageModel.BROADCASTING); // 注册回调函数，处理消息 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); //启动消息者 consumer.start(); System.out.printf(\"Consumer Started.%n\");&#125; 顺序消息RocketMQ每个主题都会有若干个队列，分布于集群中各个broker上，分布规律如下： 每个queue存储了主题Topic的消息，在默认的情况下，消息发送会采取Round Robin轮询方式把消息发送到不同的queue（分区队列）中，而消费消息的时候，从多个queue上拉取消息，这种情况发送和消费是不能保证顺序的，因为消费者在处于多线程的情况下，无法完全地按照发送消息的queue顺序消费消息。 举个例子：一个订单的顺序流程是：创建(A)、付款(B)、推送(C)、完成(D)。在业务上，需要保证相同订单号，他们消费消息的顺序严格一致，而在默认的情况下，由于多线程地从不同的queue中消费消息，顺序就无法与 A、B、C、D保持一致。 消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。 如何保证消息顺序： 如果控制发送的顺序消息依次发送到同一个queue中，消费的时候只从这个queue上依次拉取，则就保证了顺序。 一个主题中，它只使用一个queue，发送和消费的策略均使用同一个queue，则表示是全局有序。一般情况下，不需要使用全局有序，因为一个主题只使用一个queue的情况下，会严重降低了系统的并发度。 一个主题中，有多个queue参与，同一个业务编号的消息需要被发送到同一个queue中，不同业务编号可以使用不同的queue，则为分区有序，即相对每个queue，消息都是有序的。 如何实现消息顺序： 第一点，消息顺序发送，多线程发送的消息无法保证有序性，因此，需要业务方在发送时，针对同一个业务编号(如同一笔订单)的消息需要保证在一个线程内顺序发送，在上一个消息发送成功后，在进行下一个消息的发送。对应到mq中，消息发送方法就得使用同步发送，异步发送无法保证顺序性 第二点，消息顺序存储，Topic主题下会存在多个queue，要保证消息的顺序存储，同一个业务编号的消息需要被发送到一个queue中。对应到编码中，需要使用MessageQueueSelector来选择要发送的queue，即对业务编号进行hash，然后根据队列数量对hash值取余，将消息发送到一个queue中 第三点，消息顺序消费，要保证消息顺序消费，同一个queue就只能被一个消费者所消费，因此对broker中消费队列加锁是无法避免的。同一时刻，一个消费队列只能被一个消费者消费，消费者内部，也只能有一个消费线程来消费该队列。即，同一时刻，一个消费队列只能被一个消费者中的一个线程消费。 下面用订单进行分区有序的示例。订单号相同的消息会被先后发送到同一个队列中，消费时，同一个OrderId获取到的肯定是同一个队列。 顺序消息生产123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/*** Producer，发送顺序消息*/public class Producer &#123; public static void main(String[] args) throws Exception &#123; DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); producer.setNamesrvAddr(\"127.0.0.1:9876\"); producer.start(); String[] tags = new String[]&#123;\"TagA\", \"TagC\", \"TagD\"&#125;; // 订单列表 List&lt;OrderStep&gt; orderList = new Producer().buildOrders(); Date date = new Date(); SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String dateStr = sdf.format(date); for (int i = 0; i &lt; 10; i++) &#123; // 加个时间前缀 String body = dateStr + \" Hello RocketMQ \" + orderList.get(i); Message msg = new Message(\"TopicTest\", tags[i % tags.length], \"KEY\" + i, body.getBytes()); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Long id = (Long) arg; //根据订单id选择发送queue long index = id % mqs.size(); return mqs.get((int) index); &#125; &#125;, orderList.get(i).getOrderId());//订单id System.out.println(String.format(\"SendResult status:%s, queueId:%d, body:%s\", sendResult.getSendStatus(), sendResult.getMessageQueue().getQueueId(), body)); &#125; producer.shutdown(); &#125; /** * 订单的步骤 */ private static class OrderStep &#123; private long orderId; private String desc; public long getOrderId() &#123; return orderId; &#125; public void setOrderId(long orderId) &#123; this.orderId = orderId; &#125; public String getDesc() &#123; return desc; &#125; public void setDesc(String desc) &#123; this.desc = desc; &#125; @Override public String toString() &#123; return \"OrderStep&#123;\" + \"orderId=\" + orderId + \", desc='\" + desc + '\\'' + '&#125;'; &#125; &#125; /** * 生成模拟订单数据 */ private List&lt;OrderStep&gt; buildOrders() &#123; List&lt;OrderStep&gt; orderList = new ArrayList&lt;OrderStep&gt;(); OrderStep orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"推送\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); return orderList; &#125;&#125; 顺序消费消息123456789101112131415161718192021222324252627282930313233343536373839404142434445/*** 顺序消息消费，带事务方式（应用可控制Offset什么时候提交）*/public class ConsumerInOrder &#123; public static void main(String[] args) throws Exception &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_3\"); consumer.setNamesrvAddr(\"127.0.0.1:9876\"); /** * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt; * 如果非第一次启动，那么按照上次消费的位置继续消费 */ consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\"); consumer.registerMessageListener(new MessageListenerOrderly() &#123; Random random = new Random(); @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; //重点设置 自动提交，否则无法清空本地消费过的mapTemp缓存，以及无法更新偏移量到broker context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序 System.out.println(\"consumeThread=\" + Thread.currentThread().getName() + \"queueId=\" + msg.getQueueId() + \", content:\" + new String(msg.getBody())); &#125; try &#123; //模拟业务逻辑处理中... TimeUnit.SECONDS.sleep(random.nextInt(10)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125; &#125;); consumer.start(); System.out.println(\"Consumer Started.\"); &#125;&#125; 延时消息123456789101112131415161718public class ScheduledMessageProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化一个生产者来产生延时消息 DefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\"); // 启动生产者 producer.start(); int totalMessagesToSend = 100; for (int i = 0; i &lt; totalMessagesToSend; i++) &#123; Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes()); // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel) message.setDelayTimeLevel(3); // 发送消息 producer.send(message); &#125; // 关闭生产者 producer.shutdown(); &#125;&#125; 12// org/apache/rocketmq/store/config/MessageStoreConfig.javaprivate String messageDelayLevel = \"1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\"; 现在RocketMQ并不支持任意时间的延时，需要设置几个固定的延时等级，从1s到2h分别对应着等级1到18 批量消息批量发送消息能显著提高传递小消息的性能。限制是这些批量消息应该有相同的topic，相同的waitStoreMsgOK，而且不能是延时消息。此外，这一批消息的总大小不应超过4MB。 如果您每次只发送不超过4MB的消息，则很容易使用批处理，样例如下： 1234567891011String topic = \"BatchTest\";List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, \"TagA\", \"OrderID001\", \"Hello world 0\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID002\", \"Hello world 1\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID003\", \"Hello world 2\".getBytes()));try &#123; producer.send(messages);&#125; catch (Exception e) &#123; e.printStackTrace(); //处理error&#125; 如果消息的总长度可能大于4MB时，这时候最好把消息进行分割 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123; private final int SIZE_LIMIT = 1024 * 1024 * 4; private final List&lt;Message&gt; messages; private int currIndex; public ListSplitter(List&lt;Message&gt; messages) &#123; this.messages = messages; &#125; @Override public boolean hasNext() &#123; return currIndex &lt; messages.size(); &#125; @Override public List&lt;Message&gt; next() &#123; int nextIndex = currIndex; int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) &#123; Message message = messages.get(nextIndex); int tmpSize = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123; tmpSize += entry.getKey().length() + entry.getValue().length(); &#125; tmpSize = tmpSize + 20; // 增加日志的开销20字节 if (tmpSize &gt; SIZE_LIMIT) &#123; //单个消息超过了最大的限制 //忽略,否则会阻塞分裂的进程 if (nextIndex - currIndex == 0) &#123; //假如下一个子列表没有元素,则添加这个子列表然后退出循环,否则只是退出循环 nextIndex++; &#125; break; &#125; if (tmpSize + totalSize &gt; SIZE_LIMIT) &#123; break; &#125; else &#123; totalSize += tmpSize; &#125; &#125; List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); currIndex = nextIndex; return subList; &#125;&#125;//把大的消息分裂成若干个小的消息ListSplitter splitter = new ListSplitter(messages);while (splitter.hasNext()) &#123; try &#123; List&lt;Message&gt; listItem = splitter.next(); producer.send(listItem); &#125; catch (Exception e) &#123; e.printStackTrace(); //处理error &#125;&#125; 过滤消息在大多数情况下，TAG是一个简单而有用的设计，其可以来选择您想要的消息。例如： 12DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"CID_EXAMPLE\");consumer.subscribe(\"TOPIC\", \"TAGA || TAGB || TAGC\"); 消费者将接收包含TAGA或TAGB或TAGC的消息。但是限制是一个消息只能有一个标签，这对于复杂的场景可能不起作用。在这种情况下，可以使用SQL表达式筛选消息。SQL特性可以通过发送消息时的属性来进行计算。在RocketMQ定义的语法下，可以实现一些简单的逻辑。下面是一个例子： 1234567891011121314------------| message ||----------| a &gt; 5 AND b &#x3D; &#39;abc&#39;| a &#x3D; 10 | --------------------&gt; Gotten| b &#x3D; &#39;abc&#39;|| c &#x3D; true |------------------------| message ||----------| a &gt; 5 AND b &#x3D; &#39;abc&#39;| a &#x3D; 1 | --------------------&gt; Missed| b &#x3D; &#39;abc&#39;|| c &#x3D; true |------------ SQL基本语法RocketMQ只定义了一些基本语法来支持这个特性。你也可以很容易地扩展它。 数值比较，比如：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，=； 字符比较，比如：=，&lt;&gt;，IN； IS NULL 或者 IS NOT NULL； 逻辑符号 AND，OR，NOT； 常量支持类型为： 数值，比如：123，3.1415； 字符，比如：‘abc’，必须用单引号包裹起来； NULL，特殊的常量 布尔值，TRUE 或 FALSE 只有使用push模式的消费者才能用使用SQL92标准的sql语句，接口如下： 1public void subscribe(finalString topic, final MessageSelector messageSelector) 消息生产者发送消息时，你能通过putUserProperty来设置消息的属性 1234567891011DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");producer.start();Message msg = new Message(\"TopicTest\", tag, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) );// 设置一些属性msg.putUserProperty(\"a\", String.valueOf(i));SendResult sendResult = producer.send(msg);producer.shutdown(); 消息消费者用MessageSelector.bySql来使用sql筛选消息 12345678910DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_4\");// 只有订阅的消息有这个属性a, a &gt;=0 and a &lt;= 3consumer.subscribe(\"TopicTest\", MessageSelector.bySql(\"a between 0 and 3\"); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start(); 事务消息流程分析 上图说明了事务消息的大致方案，其中分为两个流程：正常事务消息的发送及提交、事务消息的补偿流程。 事务消息发送及提交(1) 发送消息（half消息）。 (2) 服务端响应消息写入结果。 (3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。 (4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见） 事务补偿(1) 对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查” (2) Producer收到回查消息，检查回查消息对应的本地事务的状态 (3) 根据本地事务状态，重新Commit或者Rollback 其中，补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。 事务消息状态事务消息共有三种状态，提交状态、回滚状态、中间状态： TransactionStatus.CommitTransaction: 提交事务，它允许消费者消费此消息。 TransactionStatus.RollbackTransaction: 回滚事务，它代表该消息将被删除，不允许被消费。 TransactionStatus.Unknown: 中间状态，它代表需要检查消息队列来确定状态。 发送事务消息创建事务性生产者使用 TransactionMQProducer类创建生产者，并指定唯一的 ProducerGroup，就可以设置自定义线程池来处理这些检查请求。执行本地事务后、需要根据执行结果对消息队列进行回复。回传的事务状态在请参考前一节。 1234567891011121314151617181920212223242526public class Producer &#123; public static void main(String[] args) throws MQClientException, InterruptedException &#123; //创建事务监听器 TransactionListener transactionListener = new TransactionListenerImpl(); //创建消息生产者 TransactionMQProducer producer = new TransactionMQProducer(\"group6\"); producer.setNamesrvAddr(\"192.168.25.135:9876;192.168.25.138:9876\"); //生产者这是监听器 producer.setTransactionListener(transactionListener); //启动消息生产者 producer.start(); String[] tags = new String[]&#123;\"TagA\", \"TagB\", \"TagC\"&#125;; for (int i = 0; i &lt; 3; i++) &#123; try &#123; Message msg = new Message(\"TransactionTopic\", tags[i % tags.length], \"KEY\" + i, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(\"%s%n\", sendResult); TimeUnit.SECONDS.sleep(1); &#125; catch (MQClientException | UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; //producer.shutdown(); &#125;&#125; 实现事务的监听接口当发送半消息成功时，我们使用 executeLocalTransaction 方法来执行本地事务。它返回前一节中提到的三个事务状态之一。checkLocalTranscation 方法用于检查本地事务状态，并回应消息队列的检查请求。它也是返回前一节中提到的三个事务状态之一。 123456789101112131415161718192021public class TransactionListenerImpl implements TransactionListener &#123; @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; System.out.println(\"执行本地事务\"); if (StringUtils.equals(\"TagA\", msg.getTags())) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.equals(\"TagB\", msg.getTags())) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; System.out.println(\"MQ检查消息Tag【\"+msg.getTags()+\"】的本地事务执行结果\"); return LocalTransactionState.COMMIT_MESSAGE; &#125;&#125; 使用限制 事务消息不支持延时消息和批量消息。 为了避免单个消息被检查太多次而导致半队列消息累积，我们默认将单个消息的检查次数限制为 15 次，但是用户可以通过 Broker 配置文件的 transactionCheckMax参数来修改此限制。如果已经检查某条消息超过 N 次的话（ N = transactionCheckMax ） 则 Broker 将丢弃此消息，并在默认情况下同时打印错误日志。用户可以通过重写 AbstractTransactionCheckListener 类来修改这个行为。 事务消息将在 Broker 配置文件中的参数 transactionMsgTimeout 这样的特定时间长度之后被检查。当发送事务消息时，用户还可以通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制，该参数优先于 transactionMsgTimeout 参数。 事务性消息可能不止一次被检查或消费。 提交给用户的目标主题消息可能会失败，目前这依日志的记录而定。它的高可用性通过 RocketMQ 本身的高可用性机制来保证，如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制。 事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享。与其他类型的消息不同，事务消息允许反向查询、MQ服务器能通过它们的生产者 ID 查询到消费者。 参考资料","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.gitee.io/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.gitee.io/tags/RocketMQ/"}]},{"title":"'RocketMQ（一）基础概念 '","slug":"rocketmq-install","date":"2020-07-08T04:00:00.000Z","updated":"2020-11-12T04:20:05.019Z","comments":true,"path":"2020/07/08/rocketmq-install/","link":"","permalink":"https://midkuro.gitee.io/2020/07/08/rocketmq-install/","excerpt":"","text":"RocketMQ 4.x 基础概念安装下载地址 官方文档 启动NameServer 1234#进入rocketMQ的目录nohup sh bin/mqnamesrv &amp;#查看日志tail -f ~/logs/rocketmqlogs/namesrv.log 启动Broker 123nohup sh bin/mqbroker -n localhost:9876 autoCreateTopicEnable=true &amp;#查看日志tail -f ~/logs/rocketmqlogs/broker.log 关闭 1234#关闭Nameserversh bin/mqshutdown namesrv#关闭Brokersh bin/mqshutdown broker 启动遇见的问题 RocketMQ默认的虚拟机内存比较大，启动的时候如果启动失败，可能是机器内存不够，需要编辑启动文件 12vi runbroker.shvi runserver.sh 参考配置： 1JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms512m -Xmx512m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\" 5.磁盘空间不足的问题 rocketMQ默认需要的磁盘空间较大，当磁盘空间不足时，生产者无法写入消息，需要再runbroker.sh中的内存配置里增加启动参数： 1JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms1g -Xmx1g -Xmn512m -Drocketmq.broker.diskSpaceWarningLevelRatio=0.98\" 测试发送消息 1234# 1.设置环境变量export NAMESRV_ADDR=localhost:9876# 2.使用安装包的Demo发送消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer 接收消息 1234# 1.设置环境变量export NAMESRV_ADDR=localhost:9876# 2.接收消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 集群 Producer：消息的发送者；举例：发信者 Consumer：消息接收者；举例：收信者 Broker：暂存和传输消息；举例：邮局 NameServer：管理Broker；举例：各个邮局的管理机构 Topic：区分消息的种类；一个发送者可以发送消息给一个或者多个Topic；一个消息的接收者可以订阅一个或者多个Topic消息 Message Queue：相当于是Topic的分区；用于并行发送和接收消息 集群特点 NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。 集群模式单Master模式这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用,可以用于本地测试。 多Master模式一个集群无Slave，全是Master，例如2个Master或者3个Master，这种模式的优缺点如下： 优点：配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高； 缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。 多Master多Slave模式（异步）每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下： 优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样； 缺点：Master宕机，磁盘损坏情况下会丢失少量消息。 多Master多Slave模式（同步）每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功，才向应用返回成功，这种模式的优缺点如下： 优点：数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高； 缺点：性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。 单机模式在正常情况下，如果broker和nameserver在同一台机器中访问，并且服务不开放给其他机器使用时，可以直接使用-n localhost:9876作为broker的启动参数。 但是在需要指定具体机器IP的情况下，则会出现broker无法找到对应nameserver的情况，需要自行编写配置文件作为启动参数。 12#假设这里的rocketmq的目录是 /home/local/rocketMQ/rocketmq-all-4.7.1-bin-release/vi ./conf/broker.conf 1234567891011121314151617181920#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-midkuro#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址 分号';'分割namesrvAddr=192.168.1.131:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#检测物理文件磁盘空间，太小会导致无法使用消息队列diskMaxUsedSpaceRatio=90#多网卡时配置，需要外网访问则配置外网IPbrokerIP1=192.168.1.131 启动Broker命令： 1nohup sh bin/mqbroker -n 192.168.1.131:9876 -c ./conf/broker.conf &amp; 双主双从 序号 IP 角色 架构模式 1 192.168.1.131 nameserver、brokerserver Master1、Slave2 2 192.168.1.131 nameserver、brokerserver Master2、Slave1 Host添加信息1vim &#x2F;etc&#x2F;hosts 配置如下: 12345678# nameserver192.168.1.131 rocketmq-nameserver1192.168.1.134 rocketmq-nameserver2# broker192.168.1.131 rocketmq-master1192.168.1.131 rocketmq-slave2192.168.1.134 rocketmq-master2192.168.1.134 rocketmq-slave1 配置完成后, 重启网卡 1systemctl restart network 防火墙配置宿主机需要远程访问虚拟机的rocketmq服务和web服务，需要开放相关的端口号，简单粗暴的方式是直接关闭防火墙 123456# 关闭防火墙systemctl stop firewalld.service # 查看防火墙的状态firewall-cmd --state # 禁止firewall开机启动systemctl disable firewalld.service 或者为了安全，只开放特定的端口号，RocketMQ默认使用3个端口：9876 、10911 、11011 。如果防火墙没有关闭的话，那么防火墙就必须开放这些端口： nameserver 默认使用 9876 端口 master 默认使用 10911 端口 slave 默认使用11011 端口 执行以下命令： 12345678# 开放name server默认端口firewall-cmd --remove-port=9876/tcp --permanent# 开放master默认端口firewall-cmd --remove-port=10911/tcp --permanent# 开放slave默认端口 (当前集群模式可不开启)firewall-cmd --remove-port=11011/tcp --permanent # 重启防火墙firewall-cmd --reload 环境变量配置1vim /etc/profile 在profile文件的末尾加入如下命令 1234#set rocketmqROCKETMQ_HOME=/home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasePATH=$PATH:$ROCKETMQ_HOME/binexport ROCKETMQ_HOME PATH 输入:wq! 保存并退出， 并使得配置立刻生效： 1source /etc/profile 创建消息存储路径1234mkdir &#x2F;home&#x2F;local&#x2F;rocketMQ&#x2F;storemkdir &#x2F;home&#x2F;local&#x2F;rocketMQ&#x2F;commitlogmkdir &#x2F;home&#x2F;local&#x2F;rocketMQ&#x2F;consumequeuemkdir &#x2F;home&#x2F;local&#x2F;rocketMQ&#x2F;index broker配置文件当前目录：/home/local/rocketMQ/rocketmq-all-4.7.1-bin-release/ master1服务器：192.168.1.131 1vi .&#x2F;conf&#x2F;2m-2s-sync&#x2F;broker-a.properties 注释掉原来的配置，并修改配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#网卡IPbrokerIP1=192.168.1.131#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址 分号';'分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/home/local/rocketMQ/broker-a/store#commitLog 存储路径storePathCommitLog=/home/local/rocketMQ/broker-a/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/home/local/rocketMQ/broker-a/consumequeue#消息索引存储路径storePathIndex=/home/local/rocketMQ/broker-a/store/index#checkpoint 文件存储路径storeCheckpoint=/home/local/rocketMQ/broker-a/store/checkpoint#abort 文件存储路径abortFile=/home/local/rocketMQ/broker-a/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=SYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128 slave2服务器：192.168.1.131 1vi .&#x2F;conf&#x2F;2m-2s-sync&#x2F;broker-b-s.properties 拷贝上面的broker-a.properties内容，并修改相关配置，如下： 12345brokerName=broker-bbrokerId=1#Broker 对外服务的监听端口listenPort=11011brokerRole=SLAVE master2服务器：192.168.1.134 1vi .&#x2F;conf&#x2F;2m-2s-sync&#x2F;broker-b.properties 拷贝上面的broker-a.properties内容，并修改相关配置，如下： 1brokerName=broker-b slave1服务器：192.168.1.134 1vi .&#x2F;conf&#x2F;2m-2s-sync&#x2F;broker-a-s.properties 拷贝上面的broker-a.properties内容，并修改相关配置，如下： 1234567brokerIP1=192.168.1.131brokerName=broker-abrokerId=1#Broker 对外服务的监听端口listenPort=11011brokerRole=SLAVE#以及修改各个路径配置 修改启动脚本文件如果机器内存首先，则需要先修改runbroker.sh和runserver.sh的启动内存大小。 服务启动启动NameServe集群分别在192.168.1.131和192.168.1.134启动NameServer 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqnamesrv &amp; 启动Broker集群192.168.1.131 master1： 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqbroker -c ./conf/2m-2s-sync/broker-a.properties &amp; 192.168.1.131 slave2： 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqbroker -c ./conf/2m-2s-sync/broker-b-s.properties &amp; 192.168.1.134 master2： 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqbroker -c ./conf/2m-2s-sync/broker-b.properties &amp; 192.168.1.134 slave1： 12cd /home/local/rocketMQ/rocketmq-all-4.7.1-bin-releasenohup sh bin/mqbroker -c ./conf/2m-2s-sync/broker-a-s.properties &amp; 查看进程状态启动后通过JPS查看启动进程 查看日志1234# 查看nameServer日志tail -500f ~/logs/rocketmqlogs/namesrv.log# 查看broker日志tail -500f ~/logs/rocketmqlogs/broker.log 遇见的问题项目中的配置使用： 12rocketmq: name-server: 192.168.1.132:9876;192.168.1.134:9876 连接消息队列时发现日志输出： 1closeChannel: close the connection to remote address[] result: true 其原因是brokerIP是服务器的内网IP导致producer无法与之建立连接导致。 需要broker-xxx.conf配置文件中增加以下配置 1brokerIP1=192.168.1.131 参考资料","categories":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.gitee.io/categories/RocketMQ/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.gitee.io/tags/RocketMQ/"}]},{"title":"'Spring Cloud Seata '","slug":"springcloud-seata","date":"2020-06-29T04:00:00.000Z","updated":"2020-11-12T04:13:44.114Z","comments":true,"path":"2020/06/29/springcloud-seata/","link":"","permalink":"https://midkuro.gitee.io/2020/06/29/springcloud-seata/","excerpt":"","text":"Spring Cloud Seata是什么Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。 官方文档 下载地址 术语TC - 事务协调者 维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM - 事务管理器 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM - 资源管理器 管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 一次分布式事务处理过程是由一个XID和三个组件模型（TC、TM、RM）组成。 处理过程 TM向TC申请开启一个全局事务，全局事务创建成功并声称一个全局唯一的XID; XID在微服务调用链路的上下文中传播； RM向TC注册分支事务，将其纳入XID对应全局事务的管辖； TM向TC发起针对XID的全局提交或回滚决议； TC调度XID下管辖的全部分支事务完成提交或回滚请求。 安装下载seata推荐使用带GA标签的版本，表示是官方推荐的稳定版，截止2020年7月，下载的是v1.0.0-GA版本。 然后备份并修改file.conf配置文件，主要修改：自定义事务组名字、事务日志存储模式（DB）、数据库连接信息。 12345678910111213service &#123; vgroup_mapping.my_test_tx_group = \"midkuro_tx_group\"&#125;store &#123; mode = \"db\"&#125;db &#123; url = \"jdbc:mysql://127.0.0.1:3306/seata\" user = \"账号\" password = \"密码\"&#125; 创建seata库，建表语句db_store.sql在安装目录\\seata\\conf里。 修改registry.conf配置文件，指明注册中心是nacos，并修改其配置信息： 123456789registry &#123; type = \"nacos\" nacos &#123; serveAddr = \"localhost\" namespace = \"\" cluster = \"default\" &#125;&#125; 通过执行bin目录下的seata-server.bat启动程序。 用例用户购买商品的业务逻辑。整个业务逻辑由3个微服务提供支持： 仓储服务：对给定的商品扣除仓储数量。 订单服务：根据采购需求创建订单。 帐户服务：从用户帐户中扣除余额。 架构图 在spring中使用@Transactional注解标记本地事务，而在seata中使用的是@GolbalTransactional注解，我们只需要使用一个 @GlobalTransactional 注解在业务方法上。 编码假设有三个系统，订单系统、库存系统、支付系统，操作流程是【下订单-&gt;减库存-&gt;扣余额-&gt;改订单状态】 1234567891011121314151617&lt;!--pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;!--如果客户端和pom依赖版本不一致，需要排除依赖自行引入--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112#application.ymlserver: port: 2001spring: application: name: seata-order-service cloud: alibaba: seata: #自定义事务组名称需要和seata-server中对应 tx-server-group: midkuro-tx-group 123456789101112131415161718192021222324252627282930@Service@Slf4jpublic class OrderServiceImpl implements OrderService &#123; @Resource private OrderDao orderDao; @Resource private StorageService storageService; @Resource private AccountService accountService; @GlobalTransactional(name = \"midkuro-create-order\",rollbackFor = Exception.class) @Override public void create(Order order) &#123; log.info(\"--------&gt;开始创建新订单\"); orderDao.create(order); log.info(\"--------订单微服务开始调用库存,做扣减\"); storageService.decrease(order.getProductId(),order.getCount()); log.info(\"-------订单微服务开始调用库存，做扣减end\"); log.info(\"-------订单微服务开始调用账户，做扣减\"); accountService.decrease(order.getUserId(),order.getMoney()); log.info(\"-------订单微服务开始调用账户，做扣减end\"); log.info(\"-------修改订单状态\"); orderDao.update(order.getUserId(),0); log.info(\"-------修改订单状态结束\"); log.info(\"--------下订单结束了，哈哈哈哈\"); &#125;&#125; 通过在微服务的调用链上增加注解实现分布式事务全局回滚操作。 原理分布式事务的执行流程： TM开启分布式事务（TM向TC注册全局事务记录）； 按业务场景编排数据库，服务等事务内资源（RM向TC汇报资源准备状态）； TM结束分布式事务，事务一阶段结束（TM通知TC提交/回滚分布式事务）； TC汇总事务信息，决定分布式事务是提交还是回滚； TC通知所有RM提交/回滚资源，事务二阶段结束。 Seata提供了 AT、TCC、SAGA 和 XA 事务模式，默认使用AT模式。 AT模式两阶段提交协议的演变： 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。 二阶段： 提交异步化，非常快速地完成。 回滚通过一阶段的回滚日志进行反向补偿。 Seata的AT模式实现了对业务的无入侵，它是怎么做到的呢？ 一阶段在一阶段，Seata会拦截业务SQL： 解析SQL语义，找到业务SQL要更新的业务数据，在业务数据被更新前，将其保存成before image 执行业务SQL更新业务数据，在业务数据更新后 将其保存成after image，最后生成行锁 以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。 二阶段提交因为业务SQL在一阶段已经提交至数据库，所以二阶段如果是顺利提交的话，seata框架只需异步得将一阶段保存的快照数据和行锁删掉，完成数据清理即可。 二阶段回滚当二阶段是回滚的话，seata就需要回滚一阶段已经执行的业务SQL，还原业务数据。 回滚方式便是用before image还原业务数据；但是在还原前要首先校验脏写，对比数据库当前业务数据和after image，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。 总结","categories":[{"name":"Seata","slug":"Seata","permalink":"https://midkuro.gitee.io/categories/Seata/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Cloud Stream '","slug":"springcloud-stream","date":"2020-06-28T05:00:00.000Z","updated":"2020-11-12T04:21:27.729Z","comments":true,"path":"2020/06/28/springcloud-stream/","link":"","permalink":"https://midkuro.gitee.io/2020/06/28/springcloud-stream/","excerpt":"","text":"Spring Cloud Stream是什么Spring Cloud Stream是一个构件消息驱动微服务的框架。 应用程序通过inputs或者outputs来与Spring Cloud Stream中的binder对象交互。通过我们配置binding，Spring Cloud Stream的binder对象负责与消息中间件交互。 通过使用Spring Integration来链接消息代理中间件以实现消息事件驱动。Spring Cloud Stream为一些供应商的消息中间件产品提供了个性化的自动化配置实现，引用了发布-订阅、消费组、分区的三个核心概念。 官方文档 在没有绑定器这个概念的情况下，SpringBoot应用要直接与消息中间件进行信息交互的时候，由于各个消息中间件构建的初衷不同，他们的实现细节会有较大的差异，通过定义绑定器作为中间件，完美地实现了应用程序与消息中间件细节之间的隔离，通过向应用程序暴露统一的Channel通道，使得应用程序不需要再考虑各种不同的消息中间件实现。 spring官方目前只支持RabbitMQ和Kafka，rocketMQ的由alibaba研发支持。 设计思想 Binder ：很方便的链接中间件，屏蔽差异 Channel：通道，是队列queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过Cahnnel对队列进行配置。 Source和Sink：参照对象是Spring Cloud Stream自身，从Stream发布消息就是输出，接受消息就是输入。 组成 说明 Middleware 中间件，目前只支持RabbitMQ和Kafka Binder Binder是应用与消息中间件之间的封装，目前实行了Kafka和RabbitMQ的Binder，通过Binder可以很方便的连接中间件，可以动态的改变消息类型(对应于Kafka的topic，RabbitMQ的exchange)，这些都可以通过配置文件来实现 @Input 注解标识输入通道，通过该输入通道接收到的消息进入应用程序 @Output 注解标识输出通道，发布的消息将通过该通道离开应用程序 @StreamListener 监听队列，用于消费者的队列的消息接收 @EnableBinding 指信道channel和exchange绑定在一起 生产者新建springBoot工程cloud-stream-privider 12345&lt;!--pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt;&lt;/dependency&gt; 12345678910111213141516171819202122server: port: 8801spring: application: name: cloud-stream-rocketmq-provider cloud: nacos: discovery: server-addr: localhost:8848 config: #配置中心地址 server-addr: localhost:8848 #指定配置文件后缀 file-extension: yaml stream: rocketmq: binder: #RocketMQ需要配置name-server name-server: localhost:9876 bindings: #服务的整合处理 output: #生产者默认绑定器名称 destination: testChannel #表示要使用的目的地名称 1234package cn.midkuro.com.service;public interface ProviderService &#123; void send(String message);&#125; 123456789101112131415161718import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.messaging.Source;import org.springframework.messaging.MessageChannel;import org.springframework.messaging.support.MessageBuilder;@EnableBinding(Source.class) //定义消息推送通道public class ProviderServiceImpl implements ProviderService &#123; @Autowired private MessageChannel output; //消息发送通道 @Override public String send() &#123; String serial = UUID.randomUUID().toString(); output.send(MessageBuilder.withPayload(serial).build()); System.out.println(\"***********serial:\"+serial); return serial; &#125;&#125; 12345678910@RestController@RefreshScopepublic class ProviderController &#123; @Autowired private ProviderService service; @GetMapping(\"/sendMessage\") public void sendMessage() &#123; service.send(); &#125;&#125; 消费者1234567891011121314151617181920212223server: port: 8802spring: application: name: cloud-stream-rocketmq-consumer cloud: nacos: discovery: server-addr: localhost:8848 config: #配置中心地址 server-addr: localhost:8848 #指定配置文件后缀 file-extension: yaml stream: rocketmq: binder: name-server: localhost:9876 bindings: input: #消费者默认绑定器名称 destination: testChannel #与生产者相同的目的地名称 group: cloud-stream-rocketmq-consumer #rocketMQ要求消费者必须配置分组 123456789101112131415161718192021package cn.midkuro.com.Service;import org.springframework.beans.factory.annotation.Value;import org.springframework.cloud.stream.annotation.EnableBinding;import org.springframework.cloud.stream.annotation.StreamListener;import org.springframework.cloud.stream.messaging.Sink;import org.springframework.messaging.Message;import org.springframework.stereotype.Component;@Component@EnableBinding(Sink.class)public class ConsumerService &#123; @Value(\"$&#123;server.port&#125;\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) &#123; System.out.println(\"我是消费者1号，-----》接受到的消息是：\" + message.getPayload() + \"\\t\" + serverPort); &#125;&#125; 自定义Bindingorg.springframework.cloud.stream.binder.Binder是Spring Cloud对消息容器的抽象，不同的消息容器有不同的实现，通过它可以屏蔽各消息容器的内部细节。 1234567public interface Binder&lt;T, C extends ConsumerProperties, P extends ProducerProperties&gt; &#123; Binding&lt;T&gt; bindConsumer(String name, String group, T inboundBindTarget, C consumerProperties); Binding&lt;T&gt; bindProducer(String name, T outboundBindTarget, P producerProperties);&#125; Binder可以生成Binding，Binding用来绑定消息容器的生产者和消费者。 它有两种类型，INPUT和OUTPUT，INPUT对应于消费者，OUTPUT对应于生产者。 可以通过在配置类上使用@EnableBinding指定需要使用的Binding，它指定的是一个接口，在对应接口中会定义一些标注了@Input或@Output的方法，它们就对应一个Binding了。 Spring提供了两个内置的接口，Source和Sink，Source对应的是OUTPUT生产者，Sink对应的是INPUT消费者。 1234567891011public interface Source &#123; /** * Name of the output channel. */ String OUTPUT = \"output\"; /** * @return output channel */ @Output(Source.OUTPUT) MessageChannel output();&#125; 1234567891011public interface Sink &#123; /** * Input channel name. */ String INPUT = \"input\"; /** * @return input channel. */ @Input(Sink.INPUT) SubscribableChannel input();&#125; 在一个EnableBinding注解中可以同时定义多个Binding，如下： 123@EnableBinding(value = &#123; Source.class, Sink.class &#125;) //或者@EnableBinding(Processor.class) 12public interface Processor extends Source, Sink &#123; //spring内置提供&#125; 默认情况下，它的内置binding是input和output，也就是我们配置文件配置的： 12345spring: cloud: stream: bindings: output: #生产者默认绑定器名称 如果自定义了一个binding配置，如下： 12345spring: cloud: stream: bindings: mybinding: #自定义绑定器名称 12345public interface MyBinding &#123; @Output(\"mybinding\") // 通过@Output指定绑定器名称mybinding MessageChannel output(); // 使用@Output注解标注的输入管道需要使用MessageChannel来订阅通道&#125; 123456@EnableBinding(MyBinding.class)public class ProviderServiceImpl implements ProviderService &#123; @Autowired @Qualifier(\"mybinding\") private MessageChannel output;&#125; 若是消费者频道，则是在方法上通过@StreamListener进行标注，表示它将监听消费某个Binding的消息。 1@StreamListener(\"mybinding\") 当有多个Binding时，可以通过进行组合，并在使用注入时通过@Qualifier进行区分即可，如下： 1234567public interface MutipleMyBinding &#123; @Output(\"mybinding1\") MessageChannel output1(); @Output(\"mybinding2\") MessageChannel output2();&#125; 重复消费比如在如下场景中，订单系统做集群部署，都会从消息队列中获取订单信息，那如果一个订单同时被两个服务获取到，就会造成数据错误，得避免这种情况，这时候需要使用stream中的消息分组来解决。 在stream中处于同一个group中的多个消费者是竞争关系，就能保证消息只会被其中一个应用消费一次。不同组是可以全面消费的(重复消费)。 微服务应用放置于同一个group中，就能够保证消息只会被其中一个应用消费一次。不同的组是可以重复消费的，同一个组内会发生竞争关系，只有一个可以消费。 通过在配置文件配置分组配置实现 123456spring: cloud: stream: bindings: input: group: myGroupName 持久化配置了分组名称的消费者，在程序重新启动时，会接着消费未消费的消息，而没有配置分组的，则会丢失之前未消费的消息。","categories":[{"name":"Stream","slug":"Stream","permalink":"https://midkuro.gitee.io/categories/Stream/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Cloud Sentinel '","slug":"springcloud-sentinel","date":"2020-06-28T04:00:00.000Z","updated":"2020-11-12T04:24:16.514Z","comments":true,"path":"2020/06/28/springcloud-sentinel/","link":"","permalink":"https://midkuro.gitee.io/2020/06/28/springcloud-sentinel/","excerpt":"","text":"Spring Cloud Sentinel是什么随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Sentinel 具有以下特征: 丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。 完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。 Sentinel 的主要特性： Sentinel 的开源生态： 安装Sentinel 分为两个部分: 核心库（Java 客户端）不依赖任何框架/库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持。 控制台（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器。 官方介绍文档 下载地址 环境配置：Java环境必须是JDK1.8及以上，并且8080端口不能被占用！ 下载当前时间对应的最新版本sentinel-dashboard-1.7.2.jar，并通过命令java -jar sentinel-dashboard-1.7.2.jar启动。 通过访问sentinel管理界面http://localhost:8080，如下： 能够看到以上界面则代表sentinel启动成功，默认的账号密码是sentinel，登录进去后能够看到如下界面： 编码新建项目cloudalibba-sentinel-service 1234567891011121314151617&lt;!--pom.xml 引入相关依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- sentinel-datasource-nacos 用于持久化--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324#application.ymlserver: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: #nacos服务注册中心地址 server-addr: localhost:8848 sentinel: transport: #配置sentinel dashboard地址 dashboard: localhost:8080 #默认8719端口。假如端口被占用会自动从8719依次+1扫描，直到找到未被占用的端口 port: 8719 management: endpoints: web: exposure: include: '*' 12345678910111213@RestControllerpublic class FlowLimitController &#123; @GetMapping(\"/testA\") public String testA() &#123; return \"------testA\"; &#125; @GetMapping(\"/testB\") public String testB() &#123; return \"------testB\"; &#125;&#125; 通过启动项目注册到nacos和sentinel中，并登陆sentinel页面查看是否注册成功，结果如下： 界面空空如也的原因是因为sentlnel默认采用的是懒加载机制，需要先触发一次接口：http://localhost:8401/testA和http://localhost:8401/testB。 再次查看sentinel控制台，结果如下：","categories":[{"name":"Sentinel","slug":"Sentinel","permalink":"https://midkuro.gitee.io/categories/Sentinel/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Cloud Nacos '","slug":"springcloud-nacos","date":"2020-06-28T03:00:00.000Z","updated":"2020-11-17T12:01:04.322Z","comments":true,"path":"2020/06/28/springcloud-nacos/","link":"","permalink":"https://midkuro.gitee.io/2020/06/28/springcloud-nacos/","excerpt":"","text":"Spring Cloud Nacos简介Nacos：前四个字母分别为Naming和Configuration的前两个字母，最后s为Service。 Nacos(Dynamic Naming and Configuration Service)是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Nacos就是注册中心 + 配置中心的组合， Nacos = Eureka + Config + Bus。 Spring Cloud Alibaba文档 安装下载地址 帮助文档 从官网下载Nacos，解压压缩包，进入bin目录运行start.cmd，linux环境则运行sh startup.sh -m standalone。 命令运行成功后直接访问http://localhost:8848/nacos，默认的账号密码都是nacos。 看到上述页面则表示安装成功。 服务提供者新建项目nacos-provider，引入服务发现及alibaba依赖： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;!--pom.xml--&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;nacos-provider&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;nacos-provider&lt;/name&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;maven-jar-plugin.version&gt;2.6&lt;/maven-jar-plugin.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring.cloud.version&gt;Hoxton.SR1&lt;/spring.cloud.version&gt; &lt;spring.cloud.alibaba.version&gt;2.1.0.RELEASE&lt;/spring.cloud.alibaba.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.cloud.alibaba.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 1234567891011121314151617#application.ymlserver: port: 8081spring: application: name: nacos-provider cloud: nacos: discovery: server-addr: 127.0.0.1:8848 management: endpoints: web: exposure: include: '*' 12345678910@RestControllerpublic class TestController &#123; @Value(\"$&#123;server.port&#125;\") private String port; @GetMapping(\"/port\") public String port() &#123; return \"My Port : \" + port; &#125;&#125; 12345678@EnableDiscoveryClient@SpringBootApplicationpublic class NacosProdiverApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(NacosProdiverApplication.class, args); &#125;&#125; 通过引入springCloud及alibaba依赖，并编写相关配置文件，并在启动类上增加注解@EnableDiscoveryClient，启动即可注册到nacos中。 nacos天生支持负载均衡，因为nacos集成了netfilx的ribbon依赖。 在启动多个相同实例时，如下： 服务消费者新建nacos-consumer项目，pom.xml与上文nacos-provider项目相同。 1234567891011121314#application.ymlserver: port: 8083spring: application: name: nacos-cunsumer cloud: nacos: discovery: server-addr: 127.0.0.1:8848 service: provider-url: http://nacos-provider/ 123456789@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced //注意必须配置负载均衡注解 public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 12345678910111213@RestControllerpublic class TestController &#123; @Value(\"$&#123;service.provider-url&#125;\") private String serviceURL; @Autowired private RestTemplate restTemplate; @GetMapping(\"/consumer/port\") public String port() &#123; return restTemplate.getForObject(serviceURL + \"/port\", String.class); &#125;&#125; 这时候启动nacos-consumer项目，并且运行两个nacos-provider项目，用以测试负载均衡。 通过使用RestTemplate以及@LoadBalanced请求访问nacos-provider服务，达到负载均衡的目的。 配置中心新建nacos-config-client项目，并且新建两个配置文件application.yml和bootstrap.yml。 Nacos和Spring-cloud-config一样，在项目初始化时，要保证先从配置中心进行配置拉取，拉取配置之后，才能保证项目的正常启动。 SpringBoot中配置文件的加载是存在优先顺序的，bootstrap优先级高于application。 1234567891011121314#bootstrap.yamlserver: port: 3377spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: 127.0.0.1:8848 config: server-addr: 127.0.0.1:8848 #配置中心地址 file-extension: yaml #指定配置文件后缀 将主体配置放在bootstrap.yml中。 1234#application.ymlspring: profiles: active: dev #表示开发环境 环境配置放在application.yml中。 在 Nacos Spring Cloud 中，dataId 的完整格式如下： 1$&#123;prefix&#125;-$&#123;spring.profile.active&#125;.$&#123;file-extension&#125; prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix来配置。 也就是说，默认情况是： 1$&#123;spring.application.name&#125;-$&#123;spring.profile.active&#125;.$&#123;file-extension&#125; 例如上述的nacos-config-client的配置文件，则产生的对应的dataId则为：nacos-config-client-dev.yaml。 切记nacos只支持yaml后缀格式，暂不兼容yml，所以在编写的过程中需要注意不要写错。 spring.profile.active 即为当前环境对应的 profile，详情可以参考 Spring Boot文档。 注意：当 spring.profile.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 ${prefix}.${file-extension} file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。 通过 Spring Cloud 原生注解 @RefreshScope 实现配置自动更新。 1234567891011@RestController@RefreshScope // 支持nasos的动态刷新工能public class TestController &#123; @Value(\"$&#123;config.info&#125;\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo() &#123; return configInfo; &#125;&#125; 通过在nacos界面上新建配置，新建``nacos-config-client-dev.yaml的dataId`。 点击右下角的发布保存之后就能够在列表中看到： 通过访问之前编写的Controller能够看到获取得到配置： 自动刷新： 通过在nacos界面上进行调整编辑配置文件，将version = 1改成version = 2，在不重启mtex-config-client的情况下，能够看到配置已经刷新。 命名空间 命名空间类似于java里面的package名和类名，最外层的namespace是可以用于区分部署环境的，Group和DataID逻辑上区分两个目标对象。 默认情况下： 123Namespace=publicGroup=DEFAULT_GROUPCluster=DEFAULT Nacos默认的命名空间是public，Namespace主要用来实现隔离。比方说现在有三个环境：开发、测试、生产环境，我们可以创建三个Namespace，不同的Namespace之间是隔离的。 Group默认是DEFAULT_GROUP，Group可以把不同的微服务划分到同一个分组里面去。 Service就是微服务，一个Service可以包含多个Cluster（集群），Nacos默认Cluster是DEFAULT，Cluster是对指定微服务的一个虚拟划分。 比放说为了容灾，将Service微服务分别部署在杭州机房和广州机房，这时候就可以给杭州机房的Service微服务起一个集群名称，给广州机房的Service微服务起另一个集群名称，还可以尽量让同一个机房的微服务互相调用，以提升性能。 最后Instance，指的是微服务的实例。 DataID 通过在同个分组里，编写不同的运行环境后缀的配置文件 12345spring: profiles: #表示开发环境 active: dev #active:pro 并通过修改application.yml的相关配置切换环境。 Group 通过新建同名称的文件，所属不同分组，以切换分组的形式切换相关配置运行环境。 123spring: profiles: active: info NameSpace 新建命名空间，会生成一个唯一的命名空间ID。 点击切换命名空间，并且在bootstrap.yml中namespace属性配置相关的命名空间ID。 持久化默认Nacos使用嵌入式数据库实现数据的存储，所以，如果启动多个默认配置下的Nacos节点，数据存储是存在一致性问题的，为了解决这个问题，Nacos采用了集中式存储的方式来支持集群化部署，目前只支持Mysql的存储。 Nacos支持三种部署模式： 单机模式 - 用于测试和单机试用。 集群模式 - 用于生产环境，确保高可用。 多集群模式 - 用于多数据中心场景。 单机模式支持mysql： 在0.7版本之前，在单机模式时nacos使用嵌入式数据库实现数据的存储，不方便观察数据存储的基本情况。0.7版本增加了支持mysql数据源能力，具体的操作步骤： 1.安装数据库，版本要求：5.6.5+ 2.初始化mysql数据库，数据库初始化文件：nacos-mysql.sql，拷贝文件内容到mysql中执行。 3.修改conf/application.properties文件，增加支持mysql数据源配置（目前只支持mysql），添加mysql数据源的url、用户名和密码。 123456spring.datasource.platform=mysqldb.num=1db.url.0=jdbc:mysql://127.0.0.1:3306/nacos_devtest?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=nacos_devtestdb.password=youdontknow 再以单机模式启动nacos，nacos所有写嵌入式数据库的数据都写到了mysql。 集群启动模式单机模式 1sh startup.sh -m standalone 集群模式 使用内嵌数据源 1sh startup.sh -p embedded 使用外置数据源 1sh startup.sh 如果启动失败，可以查看和bin目录同级的logs文件夹中的start.out日志，看看是否是由于无法识别到JAVA_HOME导致的，如果是，则编辑startup.sh，在第一行中增加JAVA_HOME配置 1JAVA_HOME=/home/local/java/jdk1.8.0_191 Cluster配置以linux环境为例，在已经配置好mysql作为持久化的前提下，拷贝cluster.conf.example文件，将新文件重命名为cluster.conf。 并编辑文件配置集群IP和端口 123192.168.1.131:3333192.168.1.131:4444192.168.1.131:5555 这个IP必须是linux命令hostname -i能够识别到的IP。 动态端口在nacos V1.3.0及以上版本中，支持了内嵌式关系型分布式数据库，其默认的startup.sh部分内容如下： 123456789101112131415161718while getopts \":m:f:s:c:p:\" optdo case $opt in m) MODE=$OPTARG;; f) FUNCTION_MODE=$OPTARG;; s) SERVER=$OPTARG;; c) MEMBER_LIST=$OPTARG;; p) EMBEDDED_STORAGE=$OPTARG;; ?) echo \"Unknown parameter\" exit 1;; esacdone 123echo \"$JAVA $&#123;JAVA_OPT&#125;\" &gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp;nohup $JAVA $&#123;JAVA_OPT&#125; nacos.nacos &gt;&gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp;echo \"nacos is starting，you can check the $&#123;BASE_DIR&#125;/logs/start.out\" 可以看到相比之前版本，新增了-p参数，用来提供集群部署时可以不依赖Mysql，以便降低中小用户的集群运维部署成本（大客户，生产环境依然建议依赖Mysql，以便有更高的性能）。 备份startup.sh，并修改startup.sh，达到通过启动命令参数配置启动端口。 12345678910111213141516171819202122#增加 o: 选择while getopts \":m:f:s:c:p:o:\" optdo case $opt in m) MODE=$OPTARG;; f) FUNCTION_MODE=$OPTARG;; s) SERVER=$OPTARG;; c) MEMBER_LIST=$OPTARG;; p) EMBEDDED_STORAGE=$OPTARG;; #增加 o参数配置 o) PORT=$OPTARG;; ?) echo \"Unknown parameter\" exit 1;; esacdone 1234echo \"$JAVA $&#123;JAVA_OPT&#125;\" &gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp;#增加 启动端口参数传递nohup $JAVA -Dserver.port=$&#123;PORT&#125; $&#123;JAVA_OPT&#125; nacos.nacos &gt;&gt; $&#123;BASE_DIR&#125;/logs/start.out 2&gt;&amp;1 &amp;echo \"nacos is starting，you can check the $&#123;BASE_DIR&#125;/logs/start.out\" 则可以通过在sh startup.sh命令后面增加-o端口参数，如下： 1sh startup.sh -o 8848 -m standalone 集群启动： 123sh startup.sh -o 3333 -p embeddedsh startup.sh -o 4444 -p embeddedsh startup.sh -o 5555 -p embedded 启动成功后，需要通过配置Nginx负载均衡三台nacos，并且在各个微服务的配置文件中改成Nginx的负载均衡端口即可。 1234567891011121314#Nginx.conf部分配置upstream cluster&#123; server 192.168.1.131:3333; server 192.168.1.131:4444; server 192.168.1.131:5555;&#125;server&#123; listen 1111; server_name localhost; location /&#123; proxy_pass http://cluster; &#125;&#125; 123456789101112131415server: port: 3377spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: 192.168.1.131:1111 config: #配置中心地址 server-addr: 192.168.1.131:1111 #指定配置文件后缀 file-extension: yaml","categories":[{"name":"Nacos","slug":"Nacos","permalink":"https://midkuro.gitee.io/categories/Nacos/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Cloud Zuul'","slug":"springcloud-zuul","date":"2020-06-27T04:03:00.000Z","updated":"2020-11-12T12:40:31.261Z","comments":true,"path":"2020/06/27/springcloud-zuul/","link":"","permalink":"https://midkuro.gitee.io/2020/06/27/springcloud-zuul/","excerpt":"","text":"Spring Cloud Zuul网关是介于客户端（外部调用方比如app，h5）和微服务的中间层。 Zuul是Netflix开源的微服务网关，核心是一系列过滤器。这些过滤器可以完成以下功能。 是所有微服务入口，进行分发。 身份认证与安全。识别合法的请求，拦截不合法的请求。 监控。在入口处监控，更全面。 动态路由。动态将请求分发到不同的后端集群。 压力测试。可以逐渐增加对后端服务的流量，进行测试。 负载均衡。也是用ribbon。 限流（望京超市）。比如我每秒只要1000次，10001次就不让访问了。 服务熔断 zuul默认集成了：ribbon和hystrix。 基本使用12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 1234567@EnableZuulProxy@SpringBootApplicationpublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ApplicationTest.class, args); &#125;&#125; 123eureka.client.service-url.defaultZone=http://euk1.com:7001/eureka/spring.application.name=zuulserverserver.port=80 通过http://localhost:80/consumer/alive就能够达到负载均衡Consumer微服务的作用，其中consumer是注册eureka的服务名，alive是Controller的接口。 相关配置123456789101112131415161718192021222324#修改consumer的负载均衡策略，consumer是注册微服务的名称#xxxxxxx.ribbon.NFLoadBalancerRuleClassNameconsumer.ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RandomRulemanagement.endpoints.web.exposure.include=*management.endpoint.health.show-details=alwaysmanagement.endpoint.health.enabled=truemanagement.endpoint.routes.enabled=true#配置consumer微服务前缀zuul.routes.consumer=/xxoo/**#类似nginx转发 zuul.routes.xx.path=/xx/**zuul.routes.xx.url=http://mashibing.com#忽略微服务zuul.ignored-services=consumer#所有微服务前缀指定zuul.prefix=/api/v1#是否带上前缀转发zuul.strip-prefix=false 链路追踪sleuth用来收集分布式微服务的调用链。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt; sleuth收集跟踪信息通过http请求发送给zipkin server，zipkin将跟踪信息存储，以及提供RESTful API接口，zipkin ui通过调用api进行数据展示，Zipkin内部集成了sleuth。 默认内存存储，可以用mysql，ES等存储。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; 12345678spring: #zipkin zipkin: base-url: http://localhost:9411/ #采样比例1 代表100%的请求都采集 sleuth: sampler: rate: 1 官网下载zipkin的服务端后启动，默认端口就是9411，通过访问http://localhost:9411/即可。 Spring Cloud Admin采集日志默认使用logback。 服务端12345678910&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Admin 界面 --&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt;&lt;/dependency&gt; 12345678@SpringBootApplication@EnableAdminServerpublic class AdminApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AdminApplication.class, args); &#125;&#125; 客户端12345678910&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 123management.endpoints.web.exposure.include=*management.endpoint.health.show-details=alwaysspring.boot.admin.client.url=http://localhost:8080 邮件通知1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt; 123456789101112spring.mail.host=spring.mail.username=spring.mail.password=spring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=true# 发送给谁spring.boot.admin.notify.mail.to=# 是谁发送出去的spring.boot.admin.notify.mail.from=management.health.mail.enabled=false","categories":[{"name":"Zuul","slug":"Zuul","permalink":"https://midkuro.gitee.io/categories/Zuul/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Cloud Hystrix'","slug":"springcloud-hystrix","date":"2020-06-27T04:01:00.000Z","updated":"2020-11-12T08:25:39.365Z","comments":true,"path":"2020/06/27/springcloud-hystrix/","link":"","permalink":"https://midkuro.gitee.io/2020/06/27/springcloud-hystrix/","excerpt":"","text":"Spring Cloud HystrixHystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统中，许多依赖不可避免的会调用失败，超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，提高分布式系统的弹性。 熔断​ 熔断机制是应对雪崩效应的一种微服务链路保户机制，当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的相应信息。当检测当该节点微服务调用响应正常后恢复调用链路，熔断机制的注解是@HystrixCommand “熔断器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控，，某个异常条件被触发，直接熔断整个服务。，向调用方法返回一个符合预期的、可处理的备选响应(FallBack),而不是长时间的等待或者抛出吊牌用方法无法处理的异常，就保证了服务调用方的线程不会被长时间占用，避免故障在分布式系统中蔓延。 1234567第一次正常第二次提供者异常提供者多次异常后，断路器打开后续请求，则直接降级，走备用逻辑。 断路器状态转换的逻辑： 1234567关闭状态：正常情况下，断路器关闭，可以正常请求依赖的服务。打开状态：当一段时间内，请求失败率达到一定阈值，断路器就会打开。服务请求不会去请求依赖的服务。调用方直接返回。不发生真正的调用。重置时间过后，进入半开模式。半开状态：断路器打开一段时间后，会自动进入“半开模式”，此时，断路器允许一个服务请求访问依赖的服务。如果此请求成功(或者成功达到一定比例)，则关闭断路器，恢复正常访问。否则，则继续保持打开状态。断路器的打开，能保证服务调用者在调用异常服务时，快速返回结果，避免大量的同步等待，减少服务调用者的资源消耗。并且断路器能在打开一段时间后继续侦测请求执行结果，判断断路器是否能关闭，恢复服务的正常调用。 降级为了在整体资源不够的时候，适当放弃部分服务，将主要的资源投放到核心服务中，待渡过难关之后，再重启已关闭的服务，保证了系统核心服务的稳定。当服务停掉后，自动进入fallback替换主方法。 用fallback方法代替主方法执行并返回结果，对失败的服务进行降级。当调用服务失败次数在一段时间内超过了断路器的阈值时，断路器将打开，不再进行真正的调用，而是快速失败，直接执行fallback逻辑。服务降级保护了服务调用者的逻辑。 12345678910熔断和降级：共同点： 1、为了防止系统崩溃，保证主要功能的可用性和可靠性。 2、用户体验到某些功能不能用。不同点： 1、熔断由下级故障触发，主动惹祸。 2、降级由调用方从负荷角度触发，无辜被抛弃。 **Consumer调用Provider服务失败时，走备用逻辑，进行降级，让Consumer业务看起来是正常的，只是数据不完善，但是有响应。当响应的次数达到熔断的阈值时，不再真正请求Provider，而是直接执行备用逻辑，快速失败。** 整合RestTemplate1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 12//启动类添加注解@EnableCircuitBreaker 12345678910111213@HystrixCommand(fallbackMethod = \"back\")public String alive() &#123; // 自动处理URL RestTemplate restTemplate = new RestTemplate(); String url =\"http://user-provider/User/alive\"; String object = restTemplate.getForObject(url, String.class); return object;&#125;public String back() &#123; return \"请求失败~bbb...\";&#125; 整合Feign12#application.propertiesfeign.hystrix.enabled=true 12345678910@RestControllerpublic class ConsumerController &#123; @Autowired ConsumerApi consumerSrv; @GetMapping(\"/alive\") public String alive() &#123; return consumerSrv.isAlive(); &#125;&#125; 123456@FeignClient(name = \"user-provider\",fallback = AliveBack.class)public interface ConsumerApi &#123; @RequestMapping(value = \"/User/alive\",method = RequestMethod.GET) public String alive();&#125; 1234567@Componentpublic class AliveBack implements ConsumerApi&#123; @Override public String alive() &#123; return \"aaa\"; &#125;&#125; FallbackFactory降级的工厂策略。 1@FeignClient(name = \"user-provider\",fallbackFactory = WebError.class) 1234567891011121314151617181920212223import feign.hystrix.FallbackFactory;@Componentpublic class WebError implements FallbackFactory&lt;ConsumerApi&gt; &#123; @Override public ConsumerApi create(Throwable cause) &#123; return new ConsumerApi() &#123; @Override public String alive() &#123; //针对不同异常返回响应 if(cause instanceof InternalServerError) &#123; System.out.println(\"InternalServerError\"); return \"远程服务报错\"; &#125;else if(cause instanceof RuntimeException) &#123; return \"请求时异常：\" + cause; &#125;else &#123; return \"都算不上\"; &#125; &#125; &#125;; &#125;&#125; 相关配置HystrixCommandProperties 12345678910111213141516171819202122232425262728293031323334353637383940/* --------------统计相关------------------*/ // 统计滚动的时间窗口,默认:5000毫秒（取自circuitBreakerSleepWindowInMilliseconds） private final HystrixProperty metricsRollingStatisticalWindowInMilliseconds; // 统计窗口的Buckets的数量,默认:10个,每秒一个Buckets统计 private final HystrixProperty metricsRollingStatisticalWindowBuckets; // number of buckets in the statisticalWindow // 是否开启监控统计功能,默认:true private final HystrixProperty metricsRollingPercentileEnabled; /* --------------熔断器相关------------------*/ // 熔断器在整个统计时间内是否开启的阀值，默认20。也就是在metricsRollingStatisticalWindowInMilliseconds（默认10s）内至少请求20次，熔断器才发挥起作用 private final HystrixProperty circuitBreakerRequestVolumeThreshold; // 熔断时间窗口，默认:5秒.熔断器中断请求5秒后会进入半打开状态,放下一个请求进来重试，如果该请求成功就关闭熔断器，否则继续等待一个熔断时间窗口private final HystrixProperty circuitBreakerSleepWindowInMilliseconds; //是否启用熔断器,默认true. 启动 private final HystrixProperty circuitBreakerEnabled; //默认:50%。当出错率超过50%后熔断器启动private final HystrixProperty circuitBreakerErrorThresholdPercentage; //是否强制开启熔断器阻断所有请求,默认:false,不开启。置为true时，所有请求都将被拒绝，直接到fallback private final HystrixProperty circuitBreakerForceOpen; //是否允许熔断器忽略错误,默认false, 不开启 private final HystrixProperty circuitBreakerForceClosed; /* --------------信号量相关------------------*/ //使用信号量隔离时，命令调用最大的并发数,默认:10 private final HystrixProperty executionIsolationSemaphoreMaxConcurrentRequests; //使用信号量隔离时，命令fallback(降级)调用最大的并发数,默认:10 private final HystrixProperty fallbackIsolationSemaphoreMaxConcurrentRequests; /* --------------其他------------------*/ //使用命令调用隔离方式,默认:采用线程隔离,ExecutionIsolationStrategy.THREAD private final HystrixProperty executionIsolationStrategy; //使用线程隔离时，调用超时时间，默认:1秒 private final HystrixProperty executionIsolationThreadTimeoutInMilliseconds; //线程池的key,用于决定命令在哪个线程池执行 private final HystrixProperty executionIsolationThreadPoolKeyOverride; //是否开启fallback降级策略 默认:true private final HystrixProperty fallbackEnabled; // 使用线程隔离时，是否对命令执行超时的线程调用中断（Thread.interrupt()）操作.默认:true private final HystrixProperty executionIsolationThreadInterruptOnTimeout; // 是否开启请求日志,默认:true private final HystrixProperty requestLogEnabled; //是否开启请求缓存,默认:true private final HystrixProperty requestCacheEnabled; // Whether request caching is enabled. 隔离策略Hystrix提供了两种线程隔离策略：线程池（默认）、信号量。 线程隔离hystrix将使用独立的线程池对应每一个服务提供者，用于隔离和限制这些服务。在消费者调用提供者时，并发请求受线程池中线程数量的限制。 这样做的好处是严格限制了生产者中，不会因为某一个服务的高并发导致调用的执行，阻塞过长时间，使得某个服务提供者的高延迟或者资源受限只会发生在该服务提供者对应的线程池中，不会影响其他调用服务线程的执行。 HystrixCommand将会在单独的线程上执行。 信号量隔离其实就是个计数器，通过信号量限制单个服务提供者的并发量，开销相对较小（因为不用那么多线程池），并发请求受到信号量个数的限制。 HystrixCommand将会在调用线程上执行。 123456789101112131415161718192021线程隔离和信号量隔离的区别： 共同点： 都是用来阻断某个服务的请求过多导致其他服务不可用的策略。 不同点： 1.线程隔离通过线程池实现控制服务请求数量 2.信号量隔离通过计数器实现，没有开辟线程空间。线程隔离： 优点： 1.能够提供拒绝策略 2.线程池内部服务异常隔离 3.能够提供异步请求，通过异步请求服务，完成时调用Tomcat的worker线程的callBack回调，达到解放worker的线程阻塞的目的 缺点： 线程隔离会带来线程开销，比如无其他网络请求的场景，可能会因为开销换隔离得不偿失。信号量隔离： 优点： 1.不需要消耗线程切换 2.适用于没有网络请求的场景 缺点： 没办法实现拒绝策略 线程池和信号量都支持熔断和限流。相比线程池，信号量不需要线程切换，因此避免了不必要的开销。但是信号量不支持异步，也不支持超时，也就是说当所请求的服务不可用时，信号量会控制超过限制的请求立即返回，但是已经持有信号量的线程只能等待服务响应或从超时中返回，即可能出现长时间等待。线程池模式下，当超过指定时间未响应的服务，Hystrix会通过响应中断的方式通知线程立即结束并返回。 12#客户端下切换隔离策略hystrix.command.default.execution.isolation.strategy=SEMAPHORE Dashboard12//启动类添加注解@EnableHystrixDashboard 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt; spring-cloud-starter-netflix-hystrix-dashboard &lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 图形化界面：http://localhost:8080/hystrix","categories":[{"name":"Hystrix","slug":"Hystrix","permalink":"https://midkuro.gitee.io/categories/Hystrix/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Cloud Config'","slug":"springcloud-config","date":"2020-06-27T04:00:00.000Z","updated":"2020-11-12T14:47:50.800Z","comments":true,"path":"2020/06/27/springcloud-config/","link":"","permalink":"https://midkuro.gitee.io/2020/06/27/springcloud-config/","excerpt":"","text":"Spring Cloud Config基本使用服务端123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 1234567spring.application.name=config-center#git仓库地址spring.cloud.config.server.git.uri=https://github.com/midkuro/config-center.git#git分支spring.cloud.config.label=mastereureka.client.service-url.defaultZone=http://euk1.com:7002/eureka/ 12345678@EnableConfigServer@SpringBootApplicationpublic class AConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AConfigApplication.class, args); &#125;&#125; 往git远程仓库上传一个文件config-client-dev.properties 然后可以通过发送请求查看内容 1http://localhost:70/master/config-client-dev.properties 123456789101112配置文件的匹配规则：获取配置规则：根据前缀匹配/&#123;name&#125;-&#123;profiles&#125;.properties/&#123;name&#125;-&#123;profiles&#125;.yml/&#123;name&#125;-&#123;profiles&#125;.json/&#123;label&#125;/&#123;name&#125;-&#123;profiles&#125;.ymlname 服务名称profile 环境名称，开发、测试、生产：dev qa prdlable 仓库分支、默认master分支匹配原则：从前缀开始。 客户端1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt;&lt;/dependency&gt; 【application.properties】必须改名成【bootstrap.properties】，客户端启动时就可以去拉取配置， 1234567891011spring.application.name=config-client#直接URL方式查找配置中心spring.cloud.config.uri=http://localhost:9999/#通过注册中心查找#spring.cloud.config.discovery.enabled=true#注册中心的名称#spring.cloud.config.discovery.service-id=config-center#环境名称，dev环境--获取的配置：config-client-dev.propertiesspring.cloud.config.profile=dev#git分支spring.cloud.config.label=master 配置刷新手动刷新12345&lt;!-- 服务监控开启refresh 端口 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 123management.endpoints.jmx.exposure.include=*management.endpoints.web.exposure.include=*management.endpoint.health.show-details=always 添加actuator依赖并暴露refresh接口，然后在@Value需要刷新的类中增加@RefreshScope注解，最后config-client客户端发送POST请求 1http://localhost:91/actuator/refresh 这种刷新方式只能刷新一个服务。 自动刷新1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 引入依赖，安装RabbitMQ，然后在需要自动刷新的项目（config-client）中添加MQ的相关配置。 1234spring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest 然后修改git上的配置文件后，触发请求通知服务刷新配置，本地服务刷新的时候会通知给其他服务也去刷新服务。 1http://localhost:91/actuator/bus-refresh","categories":[{"name":"Config","slug":"Config","permalink":"https://midkuro.gitee.io/categories/Config/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Cloud Feign'","slug":"springcloud-feign","date":"2020-06-27T04:00:00.000Z","updated":"2020-12-09T09:48:29.842Z","comments":true,"path":"2020/06/27/springcloud-feign/","link":"","permalink":"https://midkuro.gitee.io/2020/06/27/springcloud-feign/","excerpt":"","text":"Spring Cloud FeignRestTemplate依赖注入123456@Bean// 开启负载均衡@LoadBalancedRestTemplate restTemplate() &#123; return new RestTemplate();&#125; 接下来便可以使用资源地址调用服务 12String url =\"http://provider/getHi\";String respStr = restTemplate.getForObject(url, String.class); get 请求处理getForEntitygetForEntity方法的返回值是一个ResponseEntity，ResponseEntity是Spring对HTTP请求响应的封装，包括了几个重要的元素，如响应码、contentType、contentLength、响应消息体等。 1&lt;200,Hi,[Content-Type:&quot;text&#x2F;plain;charset&#x3D;UTF-8&quot;, Content-Length:&quot;8&quot;, Date:&quot;Fri, 10 Apr 2020 09:58:44 GMT&quot;, Keep-Alive:&quot;timeout&#x3D;60&quot;, Connection:&quot;keep-alive&quot;]&gt; 返回一个Map调用方 123String url =\"http://provider/getMap\";ResponseEntity&lt;Map&gt; entity = restTemplate.getForEntity(url, Map.class);System.out.println(\"respStr: \" + entity.getBody() ); 生产方 123456@GetMapping(\"/getMap\")public Map&lt;String, String&gt; getMap() &#123; HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(\"name\", \"500\"); return map; &#125; 返回对象调用方 12ResponseEntity&lt;Person&gt; entity = restTemplate.getForEntity(url, Person.class);System.out.println(\"respStr: \" + ToStringBuilder.reflectionToString(entity.getBody() )); 生产方 1234567@GetMapping(\"/getObj\")public Person getObj() &#123; Person person = new Person(); person.setId(100); person.setName(\"xiaoming\"); return person; &#125; 1234public class Person &#123; private int id; private String name;&#125; 传参调用使用占位符 12String url =\"http://provider/getObjParam?name=&#123;1&#125;\";ResponseEntity&lt;Person&gt; entity = restTemplate.getForEntity(url, Person.class,\"hehehe...\"); 使用map 123String url =\"http://provider/getObjParam?name=&#123;name&#125;\";Map&lt;String, String&gt; map = Collections.singletonMap(\"name\", \" memeda\");ResponseEntity&lt;Person&gt; entity = restTemplate.getForEntity(url, Person.class,map); 返回对象1Person person = restTemplate.getForObject(url, Person.class,map); post 请求处理调用方 123//form表单的post请求可以用参数拼接String url =\"http://provider/getObjParam?name=admin\";ResponseEntity&lt;AdapterInfo&gt; result = restTemplate.postForEntity(url, null, AdapterInfo.class); 调用方 1234//Application-JSON的请求、@ResquestBody需要使用Map当参数,不能使用参数拼接String url =\"http://provider/postParam\";Map&lt;String, String&gt; map = Collections.singletonMap(\"name\", \" memeda\");ResponseEntity&lt;Person&gt; entity = restTemplate.postForEntity(url, map, Person.class); 生产方 12345678@PostMapping(\"/postParam\")public Person postParam(@RequestBody String name) &#123; System.out.println(\"name:\" + name); Person person = new Person(); person.setId(100); person.setName(\"xiaoming\" + name); return person; &#125; postForLocationpostForLocation也是提交新资源，提交成功之后，返回新资源的URI，postForLocation的参数和前面两种的参数基本一致，只不过该方法的返回值为Uri，这个只需要服务提供者返回一个Uri即可，该Uri表示新资源的位置。 调用方 1234String url =\"http://provider/postParam\";Map&lt;String, String&gt; map = Collections.singletonMap(\"name\", \" memeda\");URI location = restTemplate.postForLocation(url, map, Person.class);System.out.println(location); 生产方 需要设置头信息，不然返回的是null 1234public URI postParam(@RequestBody Person person,HttpServletResponse response) throws Exception &#123; URI uri = new URI(\"https://www.baidu.com/s?wd=\"+person.getName()); response.addHeader(\"Location\", uri.toString());&#125; exchange可以自定义http请求的头信息，同时保护get和post方法 拦截器需要实现ClientHttpRequestInterceptor接口 拦截器 123456789101112131415public class LoggingClientHttpRequestInterceptor implements ClientHttpRequestInterceptor &#123; @Override public ClientHttpResponse intercept(HttpRequest request, byte[] body, ClientHttpRequestExecution execution) throws IOException &#123; System.out.println(\"拦截啦！！！\"); System.out.println(request.getURI()); ClientHttpResponse response = execution.execute(request, body); System.out.println(response.getHeaders()); return response; &#125;&#125; 添加到resttemplate中 1234567@Bean@LoadBalancedRestTemplate restTemplate() &#123; RestTemplate restTemplate = new RestTemplate(); restTemplate.getInterceptors().add(new LoggingClientHttpRequestInterceptor()); return restTemplate;&#125; Ribbon两种负载均衡​ 当系统面临大量的用户访问，负载过高的时候，通常会增加服务器数量来进行横向扩展（集群），多个服务器的负载需要均衡，以免出现服务器负载不均衡，部分服务器负载较大，部分服务器负载较小的情况。通过负载均衡，使得集群中服务器的负载保持在稳定高效的状态，从而提高整个系统的处理能力。 1234567软件负载均衡：nginx,lvs硬件负载均衡：F5我们只关注软件负载均衡，第一层可以用DNS，配置多个A记录，让DNS做第一层分发。第二层用比较流行的是反向代理，核心原理：代理根据一定规则，将http请求转发到服务器集群的单一服务器上。 软件负载均衡分为：服务端（集中式），客户端。 服务端负载均衡：在客户端和服务端中间使用代理，nginx。 客户端负载均衡：根据自己的情况做负载。Ribbon就是。 客户端负载均衡和服务端负载均衡最大的区别在于 服务端地址列表的存储位置，以及负载算法在哪里。 客户端负载均衡在客户端负载均衡中，所有的客户端节点都有一份自己要访问的服务端地址列表，这些列表统统都是从服务注册中心获取的； 服务端负载均衡在服务端负载均衡中，客户端节点只知道单一服务代理的地址，服务代理则知道所有服务端的地址。 12345手写客户端负载均衡1、知道自己的请求目的地（虚拟主机名，默认是spring.application.name）2、获取所有服务端地址列表（也就是注册表）。3、选出一个地址，找到虚拟主机名对应的ip、port（将虚拟主机名 对应到 ip和port上）。4、发起实际请求(最朴素的请求)。 12345Ribbon作为Spring Cloud的负载均衡机制的实现，1. Ribbon可以单独使用，作为一个独立的负载均衡组件。只是需要我们手动配置 服务地址列表。2. Ribbon与Eureka配合使用时，Ribbon可自动从Eureka Server获取服务提供者地址列表（DiscoveryClient），并基于负载均衡算法，请求其中一个服务提供者实例。3. Ribbon与OpenFeign和RestTemplate进行无缝对接，让二者具有负载均衡的能力。OpenFeign默认集成了ribbon。 负载均衡算法默认实现： ZoneAvoidanceRule（区域权衡策略）：复合判断Server所在区域的性能和Server的可用性，轮询选择服务器。 其他规则： BestAvailableRule（最低并发策略）：会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务。逐个找服务，如果断路器打开，则忽略。 RoundRobinRule（轮询策略）：以简单轮询选择一个服务器。按顺序循环选择一个server。 RandomRule（随机策略）：随机选择一个服务器。 AvailabilityFilteringRule（可用过滤策略）：会先过滤掉多次访问故障而处于断路器跳闸状态的服务和过滤并发的连接数量超过阀值得服务，然后对剩余的服务列表安装轮询策略进行访问。 WeightedResponseTimeRule（响应时间加权策略）：据平均响应时间计算所有的服务的权重，响应时间越快服务权重越大，容易被选中的概率就越高。刚启动时，如果统计信息不中，则使用RoundRobinRule(轮询)策略，等统计的信息足够了会自动的切换到WeightedResponseTimeRule。响应时间长，权重低，被选择的概率低。反之，同样道理。此策略综合了各种因素（网络，磁盘，IO等），这些因素直接影响响应时间。 RetryRule（重试策略）：先按照RoundRobinRule(轮询)的策略获取服务，如果获取的服务失败则在指定的时间会进行重试，进行获取可用的服务。如多次获取某个服务失败，就不会再次获取该服务。主要是在一个时间段内，如果选择一个服务不成功，就继续找可用的服务，直到超时。 切换负载均衡策略注解方式12345@Beanpublic IRule myRule()&#123; //return new RoundRobinRule(); //return new RandomRule(); return new RetryRule(); 配置文件针对服务定ribbon策略： 1provider.ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RandomRule 给所有服务定ribbon策略： 1ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RandomRule 属性配置方式优先级高于Java代码。 Ribbon脱离Eureka12ribbon.eureka.enabled=falseribbon.listOfServers=localhost:80,localhost:81 Ribbon可以和服务注册中心Eureka一起工作，从服务注册中心获取服务端的地址信息，也可以在配置文件中使用listOfServers字段来设置服务端地址。 FeignOpenFeign是Netflix 开发的声明式、模板化的HTTP请求客户端。可以更加便捷、优雅地调用http api。 OpenFeign会根据带有注解的函数信息构建出网络请求的模板，在发送网络请求之前，OpenFeign会将函数的参数值设置到这些请求模板中。 feign主要是构建微服务消费端。只要使用OpenFeign提供的注解修饰定义网络请求的接口类，就可以使用该接口的实例发送RESTful的网络请求。还可以集成Ribbon和Hystrix，提供负载均衡和断路器。 英文表意为“假装，伪装，变形”， 是一个 Http 请求调用的轻量级框架，可以以 Java 接口注解的方式调用 Http 请求，而不用像 Java 中通过封装 HTTP 请求报文的方式直接调用。通过处理注解，将请求模板化，当实际调用的时候，传入参数，根据参数再应用到请求上，进而转化成真正的请求，这种请求相对而言比较直观。Feign 封装 了HTTP 调用流程，面向接口编程，回想第一节课的SOP。 Feign和OpenFeign的关系Feign本身不支持Spring MVC的注解，它有一套自己的注解 OpenFeign是Spring Cloud 在Feign的基础上支持了Spring MVC的注解，如@RequesMapping等等。OpenFeign的@FeignClient可以解析SpringMVC的@RequestMapping注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务。 公共API依赖编写公共API，并且打成Jar包（User-API），然后给生产者和消费者引用。 接口有参数时必须加@RequestParam注解标识参数名称 123456789101112@RequestMapping(\"/User\")public interface RegisterApi &#123; @GetMapping(\"/isAlive\") public String isAlive(); @GetMapping(\"/getMap\") public void getMap(@RequestParam(\"id\") Integer id); @GetMapping(\"/getMap3\") public Map&lt;Integer, String&gt; getMap3(@RequestParam Map&lt;String, Object&gt; map);&#125; 生产者创建生产者项目User-Provider，引入公共API依赖，注册eureka，生产者编写Controller时继承RegisterApi，实现方法，作为实现类 12345&lt;dependency&gt; &lt;groupId&gt;com.kuro.User-API&lt;/groupId&gt; &lt;artifactId&gt;User-API&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617@RestControllerpublic class UserController implements RegisterApi &#123; @Override public String isAlive() &#123; return \"ok\"; &#125; @GetMapping(\"/getMap\") public void map(Integer id) &#123; &#125; @GetMapping(\"/getMap3\") public Map&lt;Integer, String&gt; map3(@RequestParam Map&lt;String, Object&gt; map) &#123; return map; &#125;&#125; 消费者12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;&lt;/dependency&gt; 创建消费者项目User-Consumer，引入公共API依赖，继承RegisterApi，并添加@FeignClient，标识给feign，消费者代理和调用接口，具体实现在生产者项目中。 123@FeignClient(name = \"user-provider\")public interface UserConsumerService extends RegisterApi &#123;&#125; 12345678910@RestControllerpublic class ConsumerController &#123; @Autowired UserConsumerService consumerSrv; @GetMapping(\"/alive\") public String alive() &#123; return consumerSrv.isAlive(); &#125;&#125; 123456789@SpringBootApplication//开启feign注解@EnableFeignClientspublic class UserConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(UserConsumerApplication.class, args); &#125;&#125; Feign默认所有带参数的请求都是Post，想要使用指定的提交方式需引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt; 日志123456789//重写日志等级@Configurationpublic class FeiginConfig &#123; @Bean Logger.Level logLevel()&#123; return Logger.Level.BASIC; &#125;&#125; 12#配置日志等级logging.level.com.kuro.UserConsumer=debug 权限feign的默认配置类是：org.springframework.cloud.openfeign.FeignClientsConfiguration。默认定义了feign使用的编码器，解码器等。 允许使用@FeignClient的configuration的属性自定义Feign配置。自定义的配置优先级高于上面的FeignClientsConfiguration。 12345&lt;!-- 安全认证 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 1234567891011121314@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; // 关闭csrf http.csrf().disable(); // 表示所有的访问都必须认证，认证处理后才可以正常进行 http.httpBasic().and().authorizeRequests().anyRequest().fullyAuthenticated(); // 所有的rest服务一定要设置为无状态，以提升操作效率和性能 http.sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS); &#125;&#125; 12345spring: security: user: name: root password: root 123456public class FeignAuthConfiguration &#123; @Bean public BasicAuthRequestInterceptor basicAuthRequestInterceptor() &#123; return new BasicAuthRequestInterceptor(\"root\", \"root\"); &#125;&#125; 12//在feign上加配置@FeignClient(name = \"user-provider\",configuration = FeignAuthConfiguration.class) 1234小结：如果在配置类上添加了@Configuration注解，并且该类在@ComponentScan所扫描的包中，那么该类中的配置信息就会被所有的@FeignClient共享。最佳实践是：不指定@Configuration注解（或者指定configuration，用注解忽略），而是手动：@FeignClient(name &#x3D; &quot;user-provider&quot;,configuration &#x3D; FeignAuthConfiguration.class) 超时Feign默认支持Ribbon；Ribbon的重试机制和Feign的重试机制有冲突，所以源码中默认关闭Feign的重试机制,使用Ribbon的重试机制 1234#连接超时时间(ms)ribbon.ConnectTimeout&#x3D;1000#业务逻辑超时时间(ms)ribbon.ReadTimeout&#x3D;6000 重试123456#同一台实例最大重试次数,不包括首次调用ribbon.MaxAutoRetries&#x3D;1#重试负载均衡其他的实例最大重试次数,不包括首次调用ribbon.MaxAutoRetriesNextServer&#x3D;1#是否所有操作都重试ribbon.OkToRetryOnAllOperations&#x3D;false 使用ribbon重试机制，请求失败后，在6秒内不会再请求该失败的机器，每隔6秒会再次重新尝试该失败的机器。 拦截器1234567public class MyBasicAuthRequestInterceptor implements RequestInterceptor &#123; @Override public void apply(RequestTemplate template) &#123; //拦截处理 &#125;&#125; 123456feign: client: config: user-provider: request-interceptors: - com.kuro.interceptor.MyBasicAuthRequestInterceptor 压缩12345678910#服务端开启压缩server.compression.enabled=true#调用方压缩配置#配置请求GZIP压缩feign.compression.request.enabled=true#配置响应GZIP压缩feign.compression.response.enabled=true#单位是Bfeign.compression.request.min-request-size=100 原理123456781. 主程序入口添加@EnableFeignClients注解开启对Feign Client扫描加载处理。根据Feign Client的开发规范，定义接口并加@FeignClient注解。2. 当程序启动时，会进行包扫描，扫描所有@FeignClient注解的类，并将这些信息注入Spring IoC容器中。当定义的Feign接口中的方法被调用时，通过JDK的代理方式，来生成具体的RequestTemplate。当生成代理时，Feign会为每个接口方法创建一个RequestTemplate对象，该对象封装了HTTP请求需要的全部信息，如请求参数名、请求方法等信息都在这个过程中确定。3. 然后由RequestTemplate生成Request，然后把这个Request交给client处理，这里指的Client可以是JDK原生的URLConnection、Apache的Http Client，也可以是Okhttp。最后Client被封装到LoadBalanceClient类，这个类结合Ribbon负载均衡发起服务之间的调用。","categories":[{"name":"Feign","slug":"Feign","permalink":"https://midkuro.gitee.io/categories/Feign/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Cloud Eureka '","slug":"springcloud-eureka","date":"2020-06-27T03:00:00.000Z","updated":"2020-11-14T02:08:11.069Z","comments":true,"path":"2020/06/27/springcloud-eureka/","link":"","permalink":"https://midkuro.gitee.io/2020/06/27/springcloud-eureka/","excerpt":"","text":"Spring Cloud Eureka 服务注册与发现Eureka 单节点搭建pom.xml 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; application.yml 123456789eureka: client: #是否将自己注册到Eureka Server,默认为true，由于当前就是server，故而设置成false，表明该服务不会向eureka注册自己的信息 register-with-eureka: false #是否从eureka server获取注册信息，由于单节点，不需要同步其他节点数据，用false fetch-registry: false #设置服务注册中心的URL，用于client和server端交流 service-url: defaultZone: http://localhost:7900/eureka/ application.properties 123456#是否将自己注册到Eureka Server,默认为true，由于当前就是server，故而设置成false，表明该服务不会向eureka注册自己的信息eureka.client.register-with-eureka=false#是否从eureka server获取注册信息，由于单节点，不需要同步其他节点数据，用falseeureka.client.fetch-registry=false#设置服务注册中心的URL，用于client和server端交流eureka.client.service-url.defaultZone=http://localhost:7900/eureka/ 12345678//启动类上添加此注解标识该服务为配置中心@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; Eureka高可用高可用：可以通过运行多个Eureka server实例并相互注册的方式实现。Server节点之间会彼此增量地同步信息，从而确保节点中数据一致。 修改本机host文件，绑定一个主机名，单机部署时使用ip地址会有问题 节点 1: 123456789101112#是否将自己注册到其他Eureka Server,默认为true 需要eureka.client.register-with-eureka=true#是否从eureka server获取注册信息， 需要eureka.client.fetch-registry=true#设置服务注册中心的URL，用于client和server端交流#此节点应向其他节点发起请求eureka.client.serviceUrl.defaultZone=http://ek2.com:7902/eureka/#主机名，必填eureka.instance.hostname=ek1.commanagement.endpoint.shutdown.enabled=true#web端口，服务是由这个端口处理rest请求的server.port=7901 节点 2: 123456789101112#是否将自己注册到其他Eureka Server,默认为true 需要eureka.client.register-with-eureka=true#是否从eureka server获取注册信息， 需要eureka.client.fetch-registry=true#设置服务注册中心的URL，用于client和server端交流#此节点应向其他节点发起请求eureka.client.serviceUrl.defaultZone=http://ek1.com:7902/eureka/#主机名，必填eureka.instance.hostname=ek2.commanagement.endpoint.shutdown.enabled=true#web端口，服务是由这个端口处理rest请求的server.port=7902 两个节点的话，如下图内容 就算成功了 开启监控Spring Boot 2.0 的Actuator只暴露了health和info端点，提供的监控信息无法满足我们的需求 在1.x中有n多可供我们监控的节点，官方的回答是为了安全…. 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 123#application.properties配置中#开启所有端点management.endpoints.web.exposure.include=* 服务注册新建一个web项目，引入starterspring-cloud-starter-netflix-eureka-client pom.xml 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; application.yml 123456#注册中心eureka: client: #设置服务注册中心的URL service-url: defaultZone: http://root:root@localhost:7900/eureka/ ps:不想注册，设置成false即可，实例演示结果：注册中心没有实例信息。找控制台204信息也没有找到。 12345spring: cloud: service-registry: auto-registration: enabled: false 注册成功： 1DiscoveryClient_API-LISTEN-ORDER/api-listen-order:30.136.133.9:port - registration status: 204 Eureka Server与Eureka Client之间的联系主要通过心跳的方式实现。心跳(Heartbeat)即Eureka Client定时向Eureka Server汇报本服务实例当前的状态，维护本服务实例在注册表中租约的有效性。 Eureka Client将定时从Eureka Server中拉取注册表中的信息，并将这些信息缓存到本地，用于服务发现。 Eureka原理Register 服务注册：想要参与服务注册发现的实例首先需要向Eureka服务器注册信息，注册在第一次心跳发生时提交。 Renew 续租，心跳：Eureka客户需要每30秒发送一次心跳来续租 更新通知Eureka服务器实例仍然是活动的。如果服务器在90秒内没有看到更新，它将从其注册表中删除实例 如 [10:00 00] 第一次，[10:00 30]、[10:01 00]、[10:01:30] 最后一次，将剔除实例。 Fetch Registry Eureka客户端从服务器获取注册表信息并将其缓存在本地。 之后，客户端使用这些信息来查找其他服务。 通过获取上一个获取周期和当前获取周期之间的增量更新，可以定期(每30秒)更新此信息。 节点信息在服务器中保存的时间更长(大约3分钟)，因此获取节点信息时可能会再次返回相同的实例。Eureka客户端自动处理重复的信息。 在获得增量之后，Eureka客户机通过比较服务器返回的实例计数来与服务器协调信息，如果由于某种原因信息不匹配，则再次获取整个注册表信息。 Cancel Eureka客户端在关闭时向Eureka服务器发送取消请求。这将从服务器的实例注册表中删除实例，从而有效地将实例从通信量中取出。 Time Lag 同步时间延迟 来自Eureka客户端的所有操作可能需要一段时间才能反映到Eureka服务器上，然后反映到其他Eureka客户端上。这是因为eureka服务器上的有效负载缓存，它会定期刷新以反映新信息。Eureka客户端还定期地获取增量。因此，更改传播到所有Eureka客户机可能需要2分钟。 Communication mechanism 通讯机制：Http协议下的Rest请求，默认情况下Eureka使用Jersey和Jackson以及JSON完成节点间的通讯 客户端配置选项123456#续约发送间隔默认30秒，心跳间隔eureka.instance.lease-renewal-interval-in-seconds&#x3D;5#表示eureka client间隔多久去拉取服务注册信息，默认为30秒，对于api-gateway，如果要迅速获取服务注册状态，可以缩小该值，比如5秒eureka.client.registry-fetch-interval-seconds&#x3D;5# 续约到期时间（默认90秒）eureka.instance.lease-expiration-duration-in-seconds&#x3D;60 服务器端配置选项1234#关闭自我保护模式eureka.server.enable-self-preservation&#x3D;false#失效服务间隔eureka.server.eviction-interval-timer-in-ms&#x3D;3000 Eureka提供的API 元数据Eureka的元数据有两种：标准元数据和自定义元数据。标准元数据：主机名、IP地址、端口号、状态页和健康检查等信息，这些信息都会被发布在服务注册表中，用于服务之间的调用。自定义元数据：可以使用eureka.instance.metadata-map配置，这些元数据可以在远程客户端中访问，但是一般不改变客户端行为，除非客户端知道该元数据的含义。 可以在配置文件中对当前服务设置自定义元数据，可后期用户个性化使用，元数据可以配置在eureka服务器和eureka的客户端上。 1eureka.instance.metadata-map.dalao=kuro 自我保护机制Eureka在CAP理论当中是属于AP ， 也就说当产生网络分区时，Eureka保证系统的可用性，但不保证系统里面数据的一致性 默认开启，服务器端容错的一种方式，即短时间心跳不到达仍不剔除服务列表里的节点 1EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY&#39;RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 默认情况下，Eureka Server在一定时间内，没有接收到某个微服务心跳，会将某个微服务注销（90S）。但是当网络故障时，微服务与Server之间无法正常通信，上述行为就非常危险，因为微服务正常，不应该注销。 Eureka Server通过自我保护模式来解决整个问题，当Server在短时间内丢失过多客户端时，那么Server会进入自我保护模式，会保护注册表中的微服务不被注销掉。当网络故障恢复后，退出自我保护模式。 思想：宁可保留健康的和不健康的，也不盲目注销任何健康的服务。 客户端每分钟续约数量小于客户端总数的85%时会触发保护机制 1234567#服务端，关闭自我保护机制eureka: server: #关闭自我保护 enable-self-preservation: false #清理服务间隔时间，毫秒 eviction-interval-timer-in-ms: 5000 关闭后Eureka注册页面中会提示 多网卡选择 ip注册 1234eureka: instance: prefer-ip-address: true#表示将自己的ip注册到EurekaServer上。不配置或false，表示将操作系统的hostname注册到server 服务器有多个网卡，eh0，eh1，eh2，只有eh0可以让外部其他服务访问进来，而Eureka client将eh1和eh2注册到Eureka server上，这样其他服务就无法访问该微服务了。 指定Ip 1234eureka: instance: prefer-ip-address: true ip-address: 实际能访问到的Ip 如果设置了此时的ip-address，在元数据查看到就是此ip，其他服务也通过此ip来调用。或者使用spring.cloud.inetutils配置网卡选择 EurekaClientEurekaClient 可以在客户端获取eureka服务器上的注册者信息 org.springframework.cloud.client.discovery与com.netflix.discovery.DiscoveryClient 1234567@AutowiredDiscoveryClient discoveryClient;//DiscoveryClient的APIString description();//获取实现类的描述。List&lt;String&gt; getServices();//获取所有服务实例id。List&lt;ServiceInstance&gt; getInstances(String serviceId);//通过服务id查询服务实例信息列表。 Eureka 健康检查由于server和client通过心跳保持 服务状态，而只有状态为UP的服务才能被访问。看eureka界面中的status。 比如心跳一直正常，服务一直UP，但是此服务DB连不上了，无法正常提供服务。 此时，我们需要将 微服务的健康状态也同步到server。只需要启动eureka的健康检查就行。这样微服务就会将自己的健康状态同步到eureka。配置如下即可。 开启手动控制在client端配置：将自己真正的健康状态传播到server。 12345678910eureka: client: healthcheck: #开启健康检查，需要引入actuator enabled: true instance: #发送心跳给server的频率，每隔这个时间会主动心跳一次 lease-renewal-interval-in-seconds: 1 #Server从收到client后，下一次收到心跳的间隔时间。超过这个时间没有接收到心跳EurekaServer就会将这个实例剔除 lease-expiration-duration-in-seconds: 1 Client端配置Actuator1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 改变健康状态的Service123456789101112131415161718192021@Servicepublic class HealthStatusService implements HealthIndicator&#123; private Boolean status = true; public void setStatus(Boolean status) &#123; this.status = status; &#125; @Override public Health health() &#123; // TODO Auto-generated method stub if(status) return new Health.Builder().up().build(); return new Health.Builder().down().build(); &#125; public String getStatus() &#123; // TODO Auto-generated method stub return this.status.toString(); &#125; 测试用的Controller123456@GetMapping(\"/health\")public String health(@RequestParam(\"status\") Boolean status) &#123; healthStatusSrv.setStatus(status); return healthStatusSrv.getStatus();&#125; 安全配置1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 12spring.security.user.name=kurospring.security.user.password=123 如果服务注册报错以下错误，是默认开启了防止跨域攻击，在服务端增加配置类 1Root name &#39;timestamp&#39; does not match expected (&#39;instance&#39;) for type [simple 1234567891011@Configuration@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter&#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; // TODO Auto-generated method stub http.csrf().disable(); super.configure(http); &#125;&#125; 其他配置12345678910111213141516\"homePageUrl\": \"http://127.0.0.1:8084/\",\"statusPageUrl\": \"http://127.0.0.1:8084/actuator/info\",\"healthCheckUrl\": \"http://127.0.0.1:8084/actuator/health\",如果设置了server: servlet: path: /path需要：eureka: instance: statusPageUrlPath: $&#123;server.servlet.path&#125;/actuator/info healthCheckUrlPath: $&#123;server.servlet.path&#125;/actuator/health","categories":[{"name":"Eureka","slug":"Eureka","permalink":"https://midkuro.gitee.io/categories/Eureka/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Cloud SSO'","slug":"springcloud-sso","date":"2020-06-05T04:01:00.000Z","updated":"2020-11-15T14:23:20.739Z","comments":true,"path":"2020/06/05/springcloud-sso/","link":"","permalink":"https://midkuro.gitee.io/2020/06/05/springcloud-sso/","excerpt":"","text":"Spring Cloud SSO单机服务 在单机服务中，同一个浏览器访问系统，系统需要在登录后将用户信息存储在Session会话中，并返回一个SessionID到浏览器中，浏览器下次请求该系统时，携带SessionID到系统中，校验通过则无需再次登录。 单点登录单点登录（Single Sign On），简称为 SSO，其含义在于用户只需要登录一次就可以访问所有相互信任的应用系统。 在多个微服务的场景下，用户只要向其中一个服务发起了登录请求后，后续再访问其他微服务/子系统的时候，无需再次登录，其内部服务的流转可以通过网关进行负债均衡和流量分发。 对浏览器来说，始终使用的是同一个协议、域名、端口的网页地址，根据浏览器同源策略，用户在任意一台服务器登录成功后，服务器将返回一个【SessionID/Token】给浏览器，浏览器在下次请求中携带该信息访问任意子系统均无需登录。 共享Session 通过将多个微服务的Session会话的信息共享到Redis中，每个微服务共享份Session信息，当浏览器携带了SessionID到各个服务中时，服务均能获取到相应的会话信息。 共享Session是有状态的会话 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 12345678spring.redis.host=localhost#spring.redis.password=spring.redis.port=6379spring.security.user.name=123spring.security.user.password=123server.port=81 通过使用Security进行登录验证，使用Spring Session进行共享Session，它会自动将我们需要存储的Session会话信息持久化到Redis中，并返回一个Token令牌给浏览器。 只要浏览器在访问当前系统或子系统时，携带Token令牌，就能达到多个子系统共享Session，单点登录的功能。 JWT JWT，全称是Java Web Token，主要是通过生成Token并返回给浏览器，各个服务本地不存储会话信息，浏览器通过传递Token进行SSO单点登录。 1234567Token包含三个部分：1.头部信息：签名算法2.消息体、载荷（用户信息、唯一标识、权限、其他）3.签名签名的生成过程：签名 &#x3D; Hash（Base64(头部信息) + &#39;.&#39; + Base64(消息体) + &#39;.&#39; + 密文） Token = Base64(头部信息) + ‘.’ + Base64(消息体) + ‘.’ + 签名 ，以点号做分隔。 在这种情况下，服务器生成签名所使用的密文并没有传递到浏览器中，所以该签名无法被伪造。 而浏览器是可以将Token进行Base64解码获得其中的签名算法和消息体内容，就算他人恶意组装Token发送到服务器，由于他们无法获取生成签名的密文，最终服务器通过重新计算的签名与原签名不相同，就可以达到防篡改的目的。 12345//头部信息&#123; “alg”: “HS256”,// 签名算法 “typ”: “JWT” //token类型 &#125; 123456//消息体&#123; \"exp\"(expiration time): 过期时间, \"sub\" (subject)：主题, //一般用用户id,用来标识用户会话 \"iat\" (Issued At)：签发时间&#125; 实现12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.7.0&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.kuro.admin;import java.util.Base64;import java.util.Calendar;import java.util.Date;import io.jsonwebtoken.Claims;import io.jsonwebtoken.ExpiredJwtException;import io.jsonwebtoken.Jwts;/** * @author yueyi2019 */public class JwtUtil &#123; /** * 密钥，仅服务端存储 */ private static String secret = \"ko346134h_we]rg3in_yip1!\"; /** * * @param subject * @param issueDate 签发时间 * @return */ public static String createToken(String subject, Date issueDate) &#123; Calendar c = Calendar.getInstance(); c.setTime(issueDate); c.add(Calendar.DAY_OF_MONTH, 20); String compactJws = Jwts.builder() .setSubject(subject) .setIssuedAt(issueDate) .setExpiration(c.getTime()) .signWith(io.jsonwebtoken.SignatureAlgorithm.HS512, secret) .compact(); return compactJws; &#125; /** * 解密 jwt * @param token * @return * @throws Exception */ public static String parseToken(String token) &#123; try &#123; Claims claims = Jwts.parser().setSigningKey(secret).parseClaimsJws(token).getBody(); if (claims != null)&#123; return claims.getSubject(); &#125; &#125;catch (ExpiredJwtException e)&#123; e.printStackTrace(); System.out.println(\"jwt过期了\"); &#125; return \"\"; &#125;&#125; 123456789101112131415161718192021222324252627@WebFilter(filterName = \"authFilter\", urlPatterns = \"/**\")@Componentpublic class MyFi implements Filter &#123; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest req = (HttpServletRequest) request; String token = req.getHeader(\"token\"); if (token != null) &#123; // 判断解析token是否成功 String parseToken = JwtUtil.parseToken(token); if (!StringUtils.isEmpty(parseToken)) &#123; System.out.println(\"auth success\"); chain.doFilter(request, response); &#125; &#125; else &#123; System.out.println(\"auth failed\"); &#125; &#125; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; System.out.println(\"来了老弟\"); &#125; Oauth2OAuth（开放授权）是一个开放标准，允许用户授权第三方移动应用访问他们存储在另外的服务提供者上的信息，而不需要将用户名和密码提供给第三方移动应用或分享他们数据的所有内容，OAuth2.0是OAuth协议的延续版本，但不向后兼容OAuth 1.0。 Resource Owner 资源拥有者，对应微信的每个用户微信上设置的个人信息是属于每个用户的，不属于腾讯。 Resource Server 资源服务器，一般就是用户数据的一些操作（增删改查）的REST API，比如微信的获取用户基本信息的接口。 Client Application 第三方客户端，对比微信中就是各种微信公众号开发的应用，第三方应用经过认证服务器授权后即可访问资源服务器的REST API来获取用户的头像、性别、地区等基本信息。 Authorization Server 认证服务器，验证第三方客户端是否合法。如果合法就给客户端颁布token，第三方通过token来调用资源服务器的API。 授权类型anthorization_code 授权码类型，适用于Web Server Application。模式为：客户端先调用/oauth/authorize/进到用户授权界面，用户授权后返回code，客户端然后根据code和appSecret获取access token。 implicit 简化类型，相对于授权码类型少了授权码获取的步骤。客户端应用授权后认证服务器会直接将access token放在客户端的url。客户端解析url获取token。这种方式其实是不太安全的，可以通过https安全通道和缩短access token的有效时间来较少风险。 password 密码类型，客户端应用通过用户的username和password获access token。适用于资源服务器、认证服务器与客户端具有完全的信任关系，因为要将用户要将用户的用户名密码直接发送给客户端应用，客户端应用通过用户发送过来的用户名密码获取token，然后访问资源服务器资源。比如支付宝就可以直接用淘宝用户名和密码登录，因为它们属于同一家公司，彼此充分信任。 client_credentials 客户端类型，是不需要用户参与的一种方式，用于不同服务之间的对接。比如自己开发的应用程序要调用短信验证码服务商的服务，调用地图服务商的服务、调用手机消息推送服务商的服务。当需要调用服务是可以直接使用服务商给的appID和appSecret来获取token，得到token之后就可以直接调用服务。 微信授权参照文档 依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 服务端 服务端端口8080，客户端端口8081 认证服务器12345678910111213141516171819202122232425262728293031323334@EnableAuthorizationServer@Configurationpublic class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; //配置注册的appid=client //配置重定向的redirectUris //配置作用域和密钥 //配置对 clients.inMemory().withClient(\"client\") .redirectUris(\"http://localhost:8081/callback\") .scopes(\"read\",\"write\") .secret(\"secret\") .authorizedGrantTypes(\"authorization_code\",\"password\",\"implicit\",\"client_credentials\");&#125; @Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception &#123; //支持把secret和clientid写在url上，否则需要在头上 security.tokenKeyAccess(\"isAuthenticated()\") .checkTokenAccess(\"permitAll()\") .allowFormAuthenticationForClients(); &#125; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception &#123; endpoints.authenticationManager(authenticationManager); &#125; @Autowired @Qualifier(\"authenticationManagerBean\") private AuthenticationManager authenticationManager;&#125; security配置123456789101112131415161718192021222324252627282930313233@Configurationpublic class SecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.formLogin() .and().csrf().disable() .authorizeRequests().anyRequest().authenticated(); &#125; @Override public void configure(WebSecurity web) throws Exception &#123; super.configure(web); &#125; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication().withUser(\"111\").password(\"222\").authorities(\"user\") .and().withUser(\"admin\").password(\"admin\").authorities(\"admin\"); &#125; @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; @Bean PasswordEncoder passwordEancoder() &#123; return NoOpPasswordEncoder.getInstance(); &#125;&#125; 资源服务器12345678910111213@EnableGlobalMethodSecurity(prePostEnabled = true)@EnableResourceServer@Configurationpublic class ResourceServerConfiguration extends ResourceServerConfigurerAdapter &#123; @Override public void configure(HttpSecurity http) throws Exception &#123;//配置访问资源【/oauth2/api/read/**】需要具备[read]作用域 http.antMatcher(\"/oauth2/api/**\").authorizeRequests() .antMatchers(HttpMethod.GET, \"/oauth2/api/read/**\").access(\"#oauth2.hasScope('read')\") .antMatchers(HttpMethod.GET, \"/oauth2/api/write/**\").access(\"#oauth2.hasScope('write')\") ; &#125;&#125; 接口服务1234567891011121314151617181920@RestControllerpublic class MainController &#123; @GetMapping(\"/oauth2/api/me\") public String me() &#123; return \"这是一个匿名访问接口，无需access_token\"; &#125; @GetMapping(\"/oauth2/api/read/xxoo\") public String xxoo() &#123; return \"这是一个需要read权限的接口\"。 &#125; @GetMapping(\"/oauth2/api/write/xxoo\") public String write() &#123; return \"这是一个需要write权限的接口\"; &#125;&#125; PostMan测试 最后发送请求： 1http://localhost:8080/oauth2/api/read/xxoo?access_token=d9e2a024-14cc-4ae8-833e-998240a99f17 客户端1234567891011121314151617181920@RestControllerpublic class UserController &#123; @RequestMapping(value = \"/callback\", method = RequestMethod.GET) public String callback(@RequestParam(\"code\") String code) throws IOException &#123; ResponseEntity&lt;String&gt; response = null; System.out.println(\"Authorization code------\" + code); RestTemplate restTemplate = new RestTemplate(); String access_token_url = \"http://localhost:8080/oauth/token\"; access_token_url += \"?client_id=client&amp;code=\" + code; access_token_url += \"&amp;grant_type=authorization_code\"; access_token_url += \"&amp;redirect_uri=http://localhost:8081/callback\"; access_token_url += \"&amp;client_secret=secret\"; System.out.println(\"access_token_url \" + access_token_url); response = restTemplate.exchange(access_token_url, HttpMethod.POST, null, String.class); System.out.println(response.getBody()); JSONObject object = JSONObject.parseObject(response.getBody()); return object.getString(\"access_token\"); &#125;&#125; 在客户端中提供回调的接口callback，与服务端中的重定向接口一致，通过前端触发请求： 1http://localhost:8080/oauth/authorize?response_type=code&amp;client_id=client&amp;redirect_uri=http://localhost:8081/callback 通过登录授权之后发送code到回调接口的callback参数中，并且在接口中触发oauth/token请求获取token。 如何取舍以下两种场景？ 1.获取token之后将token返回给前端，等待前端下次请求时，再调用授权系统的相关查询信息 2.获取Token之后主动调用授权系统的相关信息，然后返回前端 微信的API接口则使用的是第一种方式，而JWT则是选择第二种。 如果是基于过滤器实现的话，切记要增加注解@ServletComponentScan 123456@WebFilter(filterName = \"oathFilter\", urlPatterns = &#123;\"/callback\"&#125;)public class Oauth2Filter implements Filter &#123; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; &#125; 12345@SpringBootApplication//开启基于Filter的注解@ServletComponentScanpublic class ClientApplication &#123;&#125; 参考资料","categories":[{"name":"SSO","slug":"SSO","permalink":"https://midkuro.gitee.io/categories/SSO/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"}]},{"title":"'Spring Boot Security'","slug":"springboot-security","date":"2020-06-05T04:00:00.000Z","updated":"2020-12-08T16:05:15.078Z","comments":true,"path":"2020/06/05/springboot-security/","link":"","permalink":"https://midkuro.gitee.io/2020/06/05/springboot-security/","excerpt":"","text":"Spring Boot Security基本使用1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 基本原理123456789101112131415org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilterorg.springframework.security.web.context.SecurityContextPersistenceFilter org.springframework.security.web.header.HeaderWriterFilterorg.springframework.security.web.csrf.CsrfFilterorg.springframework.security.web.authentication.logout.LogoutFilter org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter org.springframework.security.web.authentication.ui.DefaultLoginPageGeneratingFilter org.springframework.security.web.authentication.ui.DefaultLogoutPageGeneratingFilterorg.springframework.security.web.savedrequest.RequestCacheAwareFilterorg.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilterorg.springframework.security.web.authentication.AnonymousAuthenticationFilter org.springframework.security.web.session.SessionManagementFilter org.springframework.security.web.access.ExceptionTranslationFilter org.springframework.security.web.access.intercept.FilterSecurityInterceptor 重点看三个过滤器：FilterSecurityInterceptor：是一个方法级的权限过滤器, 基本位于过滤链的最底部。 ExceptionTranslationFilter：是个异常过滤器，用来处理在认证授权过程中抛出的异常 UsernamePasswordAuthenticationFilter ：对/login 的 POST 请求做拦截，校验表单中用户名，密码。 过滤器如何进行加载的？ 1234567891011121314//1.使用SpringSeurity配置过滤器DelegatingFilterProxypublic class DelegatingFilterProxy extends GenericFilterBean &#123; protected Filter initDelegate(WebApplicationContext wac) throws ServletException &#123; //FilterChainProxy String targetBeanName = this.getTargetBeanName(); Assert.state(targetBeanName != null, \"No target bean name set\"); Filter delegate = (Filter)wac.getBean(targetBeanName, Filter.class); if (this.isTargetFilterLifecycle()) &#123; delegate.init(this.getFilterConfig()); &#125; return delegate; &#125;&#125; 12345678910111213141516171819202122232425262728public class FilterChainProxy extends GenericFilterBean &#123; private void doFilterInternal(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; FirewalledRequest fwRequest = firewall .getFirewalledRequest((HttpServletRequest) request); HttpServletResponse fwResponse = firewall .getFirewalledResponse((HttpServletResponse) response); //获取所有的过滤器 List&lt;Filter&gt; filters = getFilters(fwRequest); if (filters == null || filters.size() == 0) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(UrlUtils.buildRequestUrl(fwRequest) + (filters == null ? \" has no matching filters\" : \" has an empty filter list\")); &#125; fwRequest.reset(); chain.doFilter(fwRequest, fwResponse); return; &#125; VirtualFilterChain vfc = new VirtualFilterChain(fwRequest, chain, filters); //执行过滤器链调度 vfc.doFilter(fwRequest, fwResponse); &#125;&#125; UserDetailsService当什么也没有配置的时候，账号和密码是由 Spring Security 定义生成的。而在实际项目中账号和密码都是从数据库中查询出来的。 所以我们要通过自定义逻辑控制认证逻辑。 如果需要自定义逻辑时，只需要实现 UserDetailsService 接口即可。接口定义如下： 123public interface UserDetailsService &#123; UserDetails loadUserByUsername(String username) throws UsernameNotFoundException;&#125; 返回值 UserDetails，这个类是系统默认的用户“主体” 12345678910111213141516public interface UserDetails extends Serializable &#123; // 表示获取登录用户所有权限 Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); // 表示获取密码 String getPassword(); // 表示获取用户名 String getUsername(); // 表示判断账户是否过期 boolean isAccountNonExpired(); // 表示判断账户是否被锁定 boolean isAccountNonLocked(); // 表示凭证&#123;密码&#125;是否过期 boolean isCredentialsNonExpired(); // 表示当前用户是否可用 boolean isEnabled();&#125; User类是UserDetails的实现类，以后我们只需要使用 User 这个实体类即可！ 1234567package org.springframework.security.core.userdetails;public class User implements UserDetails, CredentialsContainer &#123; public User(String username, String password, Collection&lt;? extends GrantedAuthority&gt; authorities) &#123; this(username, password, true, true, true, true, authorities); &#125;&#125; username表示用户名。此值是客户端表单传递过来的数据。默认情况下必须叫 username，否则无 法接收。 PasswordEncoder12345678910public interface PasswordEncoder &#123; // 表示把参数按照特定的解析规则进行解析 String encode(CharSequence rawPassword); // 表示验证从存储中获取的编码密码与编码后提交的原始密码是否匹配。如果密码匹配，则返回 true；如果不匹配，则返回 false。第一个参数表示需要被解析的密码。第二个参数表示存储的密码。 boolean matches(CharSequence rawPassword, String encodedPassword); // 表示如果解析的密码能够再次进行解析且达到更安全的结果则返回 true，否则返回false。默认返回 false。 default boolean upgradeEncoding(String encodedPassword) &#123; return false; &#125;&#125; 12BCryptPasswordEncoder 是 Spring Security 官方推荐的密码解析器，平时多使用这个解析器。BCryptPasswordEncoder 是对 bcrypt 强散列方法的具体实现。是基于 Hash 算法实现的单向加密。可以通过 strength 控制加密强度，默认 10. 12345678910111213@Testpublic void test01()&#123; // 创建密码解析器 BCryptPasswordEncoder bCryptPasswordEncoder = new BCryptPasswordEncoder(); // 对密码进行加密 String midkuro = bCryptPasswordEncoder.encode(\"midkuro\"); // 打印加密之后的数据 System.out.println(\"加密之后数据：\\t\"+midkuro); //判断原字符加密后和加密之前是否匹配 boolean result = bCryptPasswordEncoder.matches(\"midkuro\", midkuro); // 打印比较结果 System.out.println(\"比较结果：\\t\"+result);&#125; 登录设定配置文件第一种方式：通过配置文件配置固定的账号密码进行登录。 在没配置其账号密码时，默认的账号是user，密码会在控制台中输出随机密码 1Using generated security password: 6e86c6e9-d661-41ae-aabc-bea8817c4f7b 12spring.security.user.name=111spring.security.user.password=111 配置类第二种方式：通过配置类 1234567891011121314151617@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; //对密码进行加密配置 BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); String password = passwordEncoder.encode(\"123\"); //通过内存添加用户的信息，并赋予登录角色：admin auth.inMemoryAuthentication().withUser(\"lucy\").password(password).roles(\"admin\"); &#125; //需要向容器注入加密组件 @Bean PasswordEncoder password() &#123; return new BCryptPasswordEncoder(); &#125;&#125; 自定义编写实现类创建配置类，设置使用哪个UserDetailsService实现类。 1234567891011121314@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired private UserDetailsService userDetailsService; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.userDetailsService(userDetailsService).passwordEncoder(password()); &#125; @Bean PasswordEncoder password() &#123; return new BCryptPasswordEncoder(); &#125;&#125; 编写实现类，通过传入的userName查数据库并返回User对象，User对象有用户名密码和操作权限。 123456789101112131415161718192021222324@Service(\"userDetailsService\")public class MyUserDetailsService implements UserDetailsService &#123; //mybatis的Mapper @Autowired private UsersMapper usersMapper; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; //调用usersMapper方法，根据用户名查询数据库 QueryWrapper&lt;Users&gt; wrapper = new QueryWrapper(); // where username=? wrapper.eq(\"username\",username); Users users = usersMapper.selectOne(wrapper); //判断 if(users == null) &#123;//数据库没有用户名，认证失败 throw new UsernameNotFoundException(\"用户名不存在！\"); &#125; List&lt;GrantedAuthority&gt; auths = AuthorityUtils.commaSeparatedStringToAuthorityList(\"admin\"); //从查询数据库返回users对象，得到用户名和密码，返回 return new User(users.getUsername(), new BCryptPasswordEncoder().encode(users.getPassword()),auths); &#125;&#125; 12345678@Data@AllArgsConstructor@NoArgsConstructorpublic class Users &#123; private Integer id; private String username; private String password;&#125; 自定义登录页123456789101112131415161718192021@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.formLogin() //自定义自己编写的登录页面 .loginPage(\"/login.html\") //登录页面设置 .loginProcessingUrl(\"/user/login\") //登录访问路径 .defaultSuccessUrl(\"/test/index\").permitAll() //登录成功之后，跳转路径 //自定义表单的key值，默认是username和password //.usernameParameter(\"user\") //.passwordParameter(\"pwd\") .and().authorizeRequests() .antMatchers(\"/\",\"/test/hello\",\"/user/login\").permitAll() //设置哪些路径可以直接访问，不需要认证 .and().csrf().disable(); //关闭csrf防护 &#125;&#125; 1234567891011121314@RestController@RequestMapping(\"/test\")public class TestController &#123; @RequestMapping(\"hello\") public String hello() &#123; return \"hello security\"; &#125; @RequestMapping(\"index\") public String index() &#123; return \"hello index\"; &#125;&#125; 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;!-- 需要添加&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;这样在后面的th标签就不会报错 --&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head lang=\"en\"&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/&gt; &lt;title&gt;xx&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;表单提交&lt;/h1&gt;&lt;!-- 表单提交用户信息,注意字段的设置,username 和 password 不能更改 --&gt;&lt;form action=\"/user/login\" method=\"post\"&gt; &lt;input type=\"hidden\" name=\"$&#123;_csrf.parameterName&#125;\" value=\"$&#123;_csrf.token&#125;\" /&gt; &lt;input type=\"text\" name=\"username\" /&gt; &lt;input type=\"text\" name=\"password\" /&gt; &lt;input type=\"submit\" /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 用户授权1.在配置类设置当前访问地址有哪些权限 1234567891011121314151617181920@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() //1 hasAuthority方法 //当前登录用户，只有具有admins权限(并集)才可以访问这个路径 //如果当前的主题具有指定的权限，则返回true，否则返回false，没有权限403 .antMatchers(\"/test/index1\").hasAuthority(\"admins\") //2 hasAnyAuthority方法(交集) //如果当前的主体有任何提供的权限（给定的作为一个逗号分隔的字符串列表）的话，返回 true..antMatchers(\"/test/index2\").hasAnyAuthority(\"admins,manager\") //3 hasRole方法 ROLE_sale //如果用户具备给定角色就允许访问,否则出现 403。如果当前主体具有指定的角色，则返回 true .antMatchers(\"/test/index3\").hasRole(\"sale\") //4.hasAnyRole方法 表示用户具备任何一个角色就可以访问 .antMatchers(\"/test/index4\").hasAnyRole(\"sale\");&#125; 123最长匹配原则(has more characters)说明：URL请求&#x2F;app&#x2F;dir&#x2F;file.jsp，现在存在两个路径匹配模式&#x2F;**&#x2F;*.jsp和&#x2F;app&#x2F;dir&#x2F;*.jsp，那么会根据模式&#x2F;app&#x2F;dir&#x2F;*.jsp来匹配 2.在UserDetailsService，设置返回的User对象的权限 1List&lt;GrantedAuthority&gt; auths = AuthorityUtils.commaSeparatedStringToAuthorityList(\"admins,ROLE_sale\"); 值得注意的是，这里用户添加角色时，名称是Role_sale，原因在于Security会在配置类中的角色名称中自动添加前缀，权限和角色底层校验逻辑一致，而Authority并没有。 12345678910111213private static String hasAuthority(String authority) &#123; return \"hasAuthority('\" + authority + \"')\";&#125;private static String hasRole(String role) &#123; Assert.notNull(role, \"role cannot be null\"); if (role.startsWith(\"ROLE_\")) &#123; throw new IllegalArgumentException(\"role should not start with 'ROLE_' since it is automatically inserted. Got '\" + role + \"'\"); &#125; else &#123; //将我们定义的角色名称进行 \"ROLE_\" 前缀拼接 return \"hasRole('ROLE_\" + role + \"')\"; &#125;&#125; hasRole 和 hasAuthority 写代码时前缀不同，但是最终执行是一样的，功能上没什么区别；设计上来说，role 和 authority 这是两个层面的权限设计思路，一个是角色，一个是权限，角色是权限的集合。 自定义403页面12345@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; //配置没有权限访问跳转自定义页面 http.exceptionHandling().accessDeniedPage(\"/unauth.html\");&#125; 认证授权注解使用注解先要开启注解功能！ 123456@Configuration@EnableWebSecurity//开启全局注解并设置注解 @Secured、@PreAuthorize生效@EnableGlobalMethodSecurity(prePostEnabled = true,securedEnabled = true)public class SecuritySecureConfig extends WebSecurityConfigurerAdapter &#123;&#125; @Secured判断是否具有角色，另外需要注意的是这里匹配的字符串需要添加前缀“ROLE_“，必须要有ROLE_sale或者ROLE_manager的角色。 12345@GetMapping(\"update\")@Secured(&#123;\"ROLE_sale\",\"ROLE_manager\"&#125;)public String update() &#123; return \"hello update\";&#125; @PreAuthorize该注解适合进入方法前的权限验证，可以将登录用户的 roles/permissions 参数传到方法中。 1234567@GetMapping(\"update\")//同时需包含ROLE_sale和ROLE_manager角色@PreAuthorize(\"hasRole('ROLE_sale') AND hasRole('ROLE_manager')\")//@PreAuthorize(\"hasAnyAuthority('admins')\")public String update() &#123; return \"hello update\";&#125; @PostAuthorize@PostAuthorize 注解使用并不多，在方法执行后再进行权限验证，适合验证带有返回值的权限. 123456@GetMapping(\"update\")@PostAuthorize(\"hasAnyAuthority('admins')\")public String update() &#123; System.out.println(\"会执行这个输出语句....\"); return \"hello update\";&#125; @PostFilter权限验证之后对数据进行过滤，留下用户名是 admin1 的数据，表达式中的 filterObject 引用的是方法返回值 List 中的某一个元素。 12345678@RequestMapping(\"getAll\")@PostFilter(\"filterObject.username == 'admin1'\")public List&lt;UserInfo&gt; getAllUser()&#123; ArrayList&lt;UserInfo&gt; list = new ArrayList&lt;&gt;(); list.add(new Users(11,\"admin1\",\"6666\")); list.add(new Users(21,\"admin2\",\"888\")); return list;&#125; @PreFilter进入控制器之前对数据进行过滤，只保留users.id是偶数的数据。 12345678@RequestMapping(\"test\")@PreFilter(value = \"filterObject.id%2==0\")public List&lt;UserInfo&gt; getTestPreFilter(@RequestBody List&lt;Users&gt; list)&#123; list.forEach(t-&gt; &#123; System.out.println(t.getId()+\"\\t\"+t.getUsername()); &#125;); return list;&#125; 权限继承1234567@BeanRoleHierarchy roleHierarchy() &#123; //admin拥有user的权限 RoleHierarchyImpl impl = new RoleHierarchyImpl(); impl.setHierarchy(\"ROLE_admin &gt; ROLE_user\"); return impl;&#125; 用户注销123456@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; //退出 http.logout().logoutUrl(\"/logout\") //注销的URL .logoutSuccessUrl(\"/test/hello\").permitAll(); //注销后跳转的地址&#125; 自动登录 基于Cookie技术和安全框架机制实现自动登录 123456789#rememberMe中将cookie写到数据库的表，代码中粘贴出来的CREATE TABLE &#96;persistent_logins&#96; ( &#96;username&#96; varchar(64) NOT NULL, &#96;series&#96; varchar(64) NOT NULL, &#96;token&#96; varchar(64) NOT NULL, &#96;last_used&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (&#96;series&#96;)) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; 12345678910111213141516171819202122232425@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; //注入数据源 @Autowired private DataSource dataSource; //配置操作数据库的对象 @Bean public PersistentTokenRepository persistentTokenRepository() &#123; JdbcTokenRepositoryImpl jdbcTokenRepository = new JdbcTokenRepositoryImpl(); //设置数据源 jdbcTokenRepository.setDataSource(dataSource); //自动创建表 第一次执行会创建，以后要执行就要删除掉！ //jdbcTokenRepository.setCreateTableOnStartup(true); return jdbcTokenRepository; &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; //开启记住我功能 http.rememberMe().tokenRepository(persistentTokenRepository()) .tokenValiditySeconds(60)//设置有效时长，单位秒 .userDetailsService(userDetailsService);//设置使用校验的用户Service &#125;&#125; 12&lt;!--html的表单中添加 checkbox ， 此处的name值必须为 \"remember-me\" --&gt;&lt;input type=\"checkbox\" name=\"remember-me\" title=\"自动登录\"/&gt;&lt;br/&gt; 踢除其他登录最简单的原理是保存用户ID和Session的映射关系，保证只有一个机器进行登录操作，新的机器登录时会踢出旧的登录Session。 12345@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; //设置一个用户最多对应一个Session会话 http.sessionManagement().maximumSessions(1);&#125; 禁止其他登录12345@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; //设置一个用户对应一个Session会话，并且后来者无法进行登录 http.maximumSessions(1).maxSessionsPreventsLogin(true);&#125; 清理过期Session1234@BeanHttpSessionEventPublisher httpSessionEventPublisher() &#123; return new HttpSessionEventPublisher();&#125; 退出登录处理器1234567891011@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http .addLogoutHandler(new LogoutHandler() &#123; @Override public void logout(HttpServletRequest request, HttpServletResponse response, Authentication authentication) &#123; System.out.println(\"退出\"); &#125; &#125;);&#125; 登录成功处理器登录成功之后的处理操作 123456789101112131415@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http .successHandler(new AuthenticationSuccessHandler() &#123; @Override public void onAuthenticationSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException &#123; System.out.println(\"登录成功\"); // 根据权限不同，跳转到不同页面 request.getSession().getAttribute(name) request.getRequestDispatcher(\"\").forward(request, response); &#125; &#125;);&#125; 登录失败处理器1234567891011//增加了Handler之后，则默认failureUrl配置不生效.failureHandler(new AuthenticationFailureHandler() &#123; @Override public void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response, AuthenticationException exception) throws IOException, ServletException &#123; // TODO Auto-generated method stub exception.printStackTrace(); request.getRequestDispatcher(request.getRequestURL().toString()).forward(request, response); &#125;&#125;) 1234567常见登录失败异常： LockedException 账户被锁定 CredentialsExpiredException 密码过期 AccountExpiredException 账户过期 DisabledException 账户被禁用 BadCredentialsException 密码错误 UsernameNotFoundException 用户名错误 浏览器策略同源浏览器的同源策略是一种安全功能，同源策略限制了从同一个源加载的文档或脚本如何与来自另一个源的资源进行交互。这是一个用于隔离潜在恶意文件的重要安全机制。 所谓同源是指：域名、协议、端口均相同。当出现域名、协议、端口中任意一个不同时，则不是同源的。 所以就产生了在www.abc.com网站中的Ajax请求到www.bcd.com网站的跨域问题。 1234561.浏览器发送HTTP请求到服务器2.服务器发送给网关进行登录验证3.网关登录验证，创建Session会话，返回会话标识SessionID&#x2F;Token&#x2F;令牌等标记信息4.浏览器接受到SessionID&#x2F;Token后，将其存储在Cookies中5.下次发送HTTP请求时携带Cookies中的SessionID&#x2F;Token到服务器中6.定位同一个会话并访问 页面中常用的记住账号、自动登录等功能，最简单的实现就是在服务器中创建一个永不过期的会话，然后Cookies存储相关信息即可。 跨域当访问一个服务器的网页时，它的Ajax请求到了另外一个非同源的连接时，则将触发跨域请求，Cookies一般情况下是无法跨域的。 1234jsonp解决跨域：只能发起GET请求，通过jsonp发送的请求，会随带 cookie 一起发送。Cors解决跨域：在浏览器中指定Origin来源，如果在服务器接受范围，请求则成功 123456Cors解决跨域原理：1.www.bcd.com服务器需要开启允许跨域 Access-Control-Allow-Origin: http://www.abc.com 标识允许这个域名对它进行跨域请求1.www.abc.com页面中的Ajax跨域请求www.bcd.com2.Ajax在请求的过程中需要携带自身请求的Cookies信息和Origin来源：www.abc.com到www.bcd.com中3.www.bcd.com服务器校验请求的Origin来源是否处于可允许的列表中4.www.bcd.com响应请求 XSS123456789101112131415XSS攻击通常指的是通过利用网页开发时留下的漏洞，通过巧妙的方法注入恶意指令代码到网页，当用户打开网页时，服务器自动加载并执行攻击者恶意制造的网页程序。嵌入的脚本一般通过JS实现，如&lt;script src = \"www.baidu.com\"/&gt;，XSS嵌入的JS脚本攻击的只能发送get请求。APP基本没有XSS跨站点攻击。WEB解决办法：1.防止非法JS嵌入到网页中2.URL ENCODE特殊符号（%、;、&amp;等等）3.定期扫描静态资源是否匹配关键字（script、src）4.敏感资源人机交互（图形验证码、手机验证码）5.所有接口改成Post请求APP的Token丢了解决办法：1.代码混淆（编译后的文件加密，无法反编译）2.Token绑定IP地址，切换IP地址则Token失效 CSRF跨站请求攻击，简单地说，是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并运行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去运行。 这利用了 web 中用户身份验证的一个漏洞：简单的身份验证只能保证请求发自某个用户的浏览器，却不能保证请求本身是用户自愿发出的。 12345CSRF攻击原理：1.用户登录受信任网站A，并且在本地生成Cookie2.用户访问受信任网站A，浏览器自动携带Cookie，不需要再做任何验证3.用户在未登出信任网站A时，访问了危险网站B4.危险网站B通过浏览器同源，发送了一个请求到信任网站A中，以你的名义发送恶意请求 可以通过增加人为验证机制，或者每个请求动态生成Hash值解决。 Hash值放在Cookies中容易被CSRF利用进行二次请求，因为他能从Cookies中获取到Hash值，而把Hash值放在每次请求的页面中，即使用户没有退出受信任网站A，危险网站B也无法从信任网站A的页面中中获取Hash值。 从 Spring Security 4.0 开始，默认情况下会启用 CSRF 保护，以防止 CSRF 攻击应用程序，Spring Security CSRF 会针对 PATCH，POST，PUT 和 DELETE 方法进行防护。 需要在页面表单中嵌入_csrf.token的值，每次后台都会下发一个新的csrfToken 到浏览器，并将生成 csrfToken 保存到 HttpSession 或者 Cookie 中。 12345&lt;!-- html 写法--&gt;&lt;input type=\"hidden\" name=\"$&#123;_csrf.parameterName&#125;\" value=\"$&#123;_csrf.token&#125;\" /&gt;&lt;!-- thymeleaf 写法--&gt;&lt;input type=\"hidden\" th:if=\"$&#123;_csrf&#125;!=null\" th:value=\"$&#123;_csrf.token&#125;\" name=\"_csrf\"/&gt; 12345678//底层默认创建的Csrf配置类public final class CsrfConfigurer&lt;H extends HttpSecurityBuilder&lt;H&gt;&gt; extends AbstractHttpConfigurer&lt;CsrfConfigurer&lt;H&gt;, H&gt; &#123; //默认使用HttpSessionCsrfTokenRepository，也就是Session存储下发token的策略方式解决csrf攻击 //其他实现类：CookieCsrfTokenRepository private CsrfTokenRepository csrfTokenRepository = new LazyCsrfTokenRepository( new HttpSessionCsrfTokenRepository());&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//底层通过CsfrFilter过滤器对token做验证操作public final class CsrfFilter extends OncePerRequestFilter &#123; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; request.setAttribute(HttpServletResponse.class.getName(), response); //装载请求域中的token CsrfToken csrfToken = this.tokenRepository.loadToken(request); final boolean missingToken = csrfToken == null; //没token就创建token if (missingToken) &#123; csrfToken = this.tokenRepository.generateToken(request); this.tokenRepository.saveToken(csrfToken, request, response); &#125; //设置token到请求域中 request.setAttribute(CsrfToken.class.getName(), csrfToken); request.setAttribute(csrfToken.getParameterName(), csrfToken); //验证token是否匹配 if (!this.requireCsrfProtectionMatcher.matches(request)) &#123; filterChain.doFilter(request, response); return; &#125; //判断请求域的token和实际缓存的token是否一致 String actualToken = request.getHeader(csrfToken.getHeaderName()); if (actualToken == null) &#123; actualToken = request.getParameter(csrfToken.getParameterName()); &#125; if (!csrfToken.getToken().equals(actualToken)) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Invalid CSRF token found for \" + UrlUtils.buildFullRequestUrl(request)); &#125; if (missingToken) &#123; this.accessDeniedHandler.handle(request, response, new MissingCsrfTokenException(actualToken)); &#125; else &#123; this.accessDeniedHandler.handle(request, response, new InvalidCsrfTokenException(csrfToken, actualToken)); &#125; return; &#125; filterChain.doFilter(request, response); &#125;&#125; 微服务12345&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.7.0&lt;/version&gt;&lt;/dependency&gt; 单点登录跨域是不同的系统内部互相通信时的浏览器不同源问题，而单点登录是指一个浏览器在系统A登录后，当浏览器访问系统B时，不需要再次登录。 1234567单点登录过程：1.浏览器向www.abc.com发起登录HTTP请求2.不通的域名系统最终汇集到同一个网关上做鉴权操作3.通过网关上的OAuth或者第三方的CAS鉴权，产生Session会话4.持久化Session会话到Redis中，多个域名共享5.返回SessionID&#x2F;Token到浏览器中，缓存到Cookies中6.请求www.bcd.com时，发送cookies中的SessonID&#x2F;Token进行免登录。 自定义加密策略1234567891011121314@Componentpublic class DefaultPasswordEncoder implements PasswordEncoder &#123; //进行MD5加密 @Override public String encode(CharSequence charSequence) &#123; return MD5.encrypt(charSequence.toString()); &#125; //进行密码比对 @Override public boolean matches(CharSequence charSequence, String encodedPassword) &#123; return encodedPassword.equals(MD5.encrypt(charSequence.toString())); &#125;&#125; 创建Token123456789101112131415161718192021@Componentpublic class TokenManager &#123; //token有效时长 private long tokenEcpiration = 24*60*60*1000; //编码秘钥 private String tokenSignKey = \"123456\"; //1 使用jwt根据用户名生成token public String createToken(String username) &#123; String token = Jwts.builder().setSubject(username) .setExpiration(new Date(System.currentTimeMillis()+tokenEcpiration)) .signWith(SignatureAlgorithm.HS512, tokenSignKey).compressWith(CompressionCodecs.GZIP).compact(); return token; &#125; //2 根据token字符串得到用户信息 public String getUserInfoFromToken(String token) &#123; String userinfo = Jwts.parser().setSigningKey(tokenSignKey).parseClaimsJws(token).getBody().getSubject(); return userinfo; &#125; //3 删除token public void removeToken(String token) &#123; &#125;&#125; 登出处理器123456789101112131415161718192021222324public class TokenLogoutHandler implements LogoutHandler &#123; private TokenManager tokenManager; private RedisTemplate redisTemplate; public TokenLogoutHandler(TokenManager tokenManager,RedisTemplate redisTemplate) &#123; this.tokenManager = tokenManager; this.redisTemplate = redisTemplate; &#125; @Override public void logout(HttpServletRequest request, HttpServletResponse response, Authentication authentication) &#123; //1 从header里面获取token //2 token不为空，移除token，从redis删除token String token = request.getHeader(\"token\"); if(token != null) &#123; //移除 tokenManager.removeToken(token); //从token获取用户名 String username = tokenManager.getUserInfoFromToken(token); redisTemplate.delete(username); &#125; //将请求结果写到response中返回 ResponseUtil.out(response, R.ok()); &#125;&#125; 未授权处理器1234567public class UnauthEntryPoint implements AuthenticationEntryPoint &#123; @Override public void commence(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, AuthenticationException e) throws IOException, ServletException &#123; //返回error ResponseUtil.out(httpServletResponse, R.error()); &#125;&#125; 认证过滤器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class TokenLoginFilter extends UsernamePasswordAuthenticationFilter &#123; private TokenManager tokenManager; private RedisTemplate redisTemplate; private AuthenticationManager authenticationManager; public TokenLoginFilter(AuthenticationManager authenticationManager, TokenManager tokenManager, RedisTemplate redisTemplate) &#123; this.authenticationManager = authenticationManager; this.tokenManager = tokenManager; this.redisTemplate = redisTemplate; //开放POST类型限制 this.setPostOnly(false); //设置登录接口的url this.setRequiresAuthenticationRequestMatcher(new AntPathRequestMatcher(\"/admin/acl/login\",\"POST\")); &#125; //1 获取表单提交用户名和密码 @Override public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; //获取表单提交数据 try &#123; User user = new ObjectMapper().readValue(request.getInputStream(), User.class); //将用户名和密码封装成对象交给Security管理 return authenticationManager.authenticate(new UsernamePasswordAuthenticationToken(user.getUsername(),user.getPassword(), new ArrayList&lt;&gt;())); &#125; catch (IOException e) &#123; e.printStackTrace(); throw new RuntimeException(); &#125; &#125; //2 认证成功调用的方法 @Override protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authResult) throws IOException, ServletException &#123; //认证成功，得到认证成功之后用户信息 SecurityUser user = (SecurityUser)authResult.getPrincipal(); //根据用户名生成token String token = tokenManager.createToken(user.getCurrentUserInfo().getUsername()); //把用户名称和用户权限列表放到redis redisTemplate.opsForValue().set(user.getCurrentUserInfo().getUsername(),user.getPermissionValueList()); //返回token ResponseUtil.out(response, R.ok().data(\"token\",token)); &#125; //3 认证失败调用的方法 protected void unsuccessfulAuthentication(HttpServletRequest request, HttpServletResponse response, AuthenticationException failed) throws IOException, ServletException &#123; ResponseUtil.out(response, R.error()); &#125;&#125; 12345678910//\"用户实体类\"@Datapublic class User implements Serializable &#123; private static final long serialVersionUID = 1L; private String username; private String password; private String nickName; private String salt; private String token;&#125; 授权过滤器1234567891011121314151617181920212223242526272829303132333435363738394041424344public class TokenAuthFilter extends BasicAuthenticationFilter &#123; private TokenManager tokenManager; private RedisTemplate redisTemplate; public TokenAuthFilter(AuthenticationManager authenticationManager,TokenManager tokenManager,RedisTemplate redisTemplate) &#123; super(authenticationManager); this.tokenManager = tokenManager; this.redisTemplate = redisTemplate; &#125; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException &#123; //获取当前认证成功用户权限信息 UsernamePasswordAuthenticationToken authRequest = getAuthentication(request); //判断如果有权限信息，放到权限上下文中 if(authRequest != null) &#123; SecurityContextHolder.getContext().setAuthentication(authRequest); &#125; chain.doFilter(request,response); &#125; private UsernamePasswordAuthenticationToken getAuthentication(HttpServletRequest request) &#123; //从header获取token String token = request.getHeader(\"token\"); if(token != null) &#123; //从token获取用户名 String username = tokenManager.getUserInfoFromToken(token); //从redis获取对应权限列表 List&lt;String&gt; permissionValueList = (List&lt;String&gt;)redisTemplate.opsForValue().get(username); //用户具备的权限对象集合 Collection&lt;GrantedAuthority&gt; authority = new ArrayList&lt;&gt;(); for(String permissionValue : permissionValueList) &#123; //权限名称 需要使用SimpleGrantedAuthority包装成对象 SimpleGrantedAuthority auth = new SimpleGrantedAuthority(permissionValue); authority.add(auth); &#125; ////将用户名和权限信息封装成对象交给Security管理 return new UsernamePasswordAuthenticationToken(username,token,authority); &#125; return null; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//继承Security提供的用户类 UserDetails ，增加额外的属性，如 自定义的User类，权限集合@Datapublic class SecurityUser implements UserDetails &#123; //当前登录用户 private transient User currentUserInfo; //当前权限 private List&lt;String&gt; permissionValueList; public SecurityUser() &#123; &#125; public SecurityUser(User user) &#123; if (user != null) &#123; this.currentUserInfo = user; &#125; &#125; //获取权限集合 @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123; Collection&lt;GrantedAuthority&gt; authorities = new ArrayList&lt;&gt;(); for(String permissionValue : permissionValueList) &#123; if(StringUtils.isEmpty(permissionValue)) continue; SimpleGrantedAuthority authority = new SimpleGrantedAuthority(permissionValue); authorities.add(authority); &#125; return authorities; &#125; @Override public String getPassword() &#123; return currentUserInfo.getPassword(); &#125; @Override public String getUsername() &#123; return currentUserInfo.getUsername(); &#125; @Override public boolean isAccountNonExpired() &#123; return true; &#125; @Override public boolean isAccountNonLocked() &#123; return true; &#125; @Override public boolean isCredentialsNonExpired() &#123; return true; &#125; @Override public boolean isEnabled() &#123; return true; &#125;&#125; 核心配置类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)public class TokenWebSecurityConfig extends WebSecurityConfigurerAdapter &#123; private TokenManager tokenManager; private RedisTemplate redisTemplate; private DefaultPasswordEncoder defaultPasswordEncoder; //自定义用户数据查询ervice private UserDetailsService userDetailsService; @Autowired public TokenWebSecurityConfig(UserDetailsService userDetailsService, DefaultPasswordEncoder defaultPasswordEncoder, TokenManager tokenManager, RedisTemplate redisTemplate) &#123; this.userDetailsService = userDetailsService; this.defaultPasswordEncoder = defaultPasswordEncoder; this.tokenManager = tokenManager; this.redisTemplate = redisTemplate; &#125; /** * 配置设置 * @param http * @throws Exception */ //设置退出的地址和token，redis操作地址 @Override protected void configure(HttpSecurity http) throws Exception &#123; http.exceptionHandling() .authenticationEntryPoint(new UnauthEntryPoint())//没有权限访问 .and().csrf().disable()//关闭csrf .authorizeRequests() .anyRequest().authenticated() .and().logout().logoutUrl(\"/admin/acl/index/logout\")//退出路径 .addLogoutHandler(new TokenLogoutHandler(tokenManager,redisTemplate)).and() .addFilter(new TokenLoginFilter(authenticationManager(), tokenManager, redisTemplate)) .addFilter(new TokenAuthFilter(authenticationManager(), tokenManager, redisTemplate)).httpBasic(); &#125; //调用userDetailsService和密码处理 @Override public void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.userDetailsService(userDetailsService).passwordEncoder(defaultPasswordEncoder); &#125; //不进行认证的路径，可以直接访问,如静态请求 @Override public void configure(WebSecurity web) throws Exception &#123; web.ignoring().antMatchers(\"/img/**\",\"/js/**\"); &#125;&#125; 自定义实现类12345678910111213141516171819202122232425262728293031323334@Service(\"userDetailsService\")public class UserDetailsServiceImpl implements UserDetailsService &#123; //Mybatis的用户表的Mapper @Autowired private UserService userService; //Mybatis的权限表的Mapper @Autowired private PermissionService permissionService; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; //根据用户名查询数据库数据 DbUser类是对应数据库用户表的实体类 DbUser user = userService.selectByUsername(username); //判断 if(user == null) &#123; throw new UsernameNotFoundException(\"用户不存在\"); &#125; //User类是对应SecurityUser implements UserDetails中的属性类User User curUser = new User(); //通过工具类拷贝类的属性到另一个实体类中 BeanUtils.copyProperties(user,curUser); //根据用户查询数据库的用户权限列表 List&lt;String&gt; permissionValueList = permissionService.selectPermissionValueByUserId(user.getId()); //构建SecurityUser(UserDetails)对象 SecurityUser securityUser = new SecurityUser(); securityUser.setCurrentUserInfo(curUser); securityUser.setPermissionValueList(permissionValueList); return securityUser; &#125;&#125; 123456789101112131415161718用户认证流程：#1.进入到过滤器验证登录 TokenLoginFilter.attemptAuthentication#2.先通过查询数据库获取用户对象UserDetailsService.loadUserByUsername#3.验证用户通过TokenLoginFilter.successfulAuthentication#4.生成用户TokentokenManager.createToken()#5.将用户信息存储到Redis中redisTemplate.opsForValue().set()#6.response写入tokenresponse.write(token)认证成功后进入授权流程：#7.获取当前用户的token，去redis中拉取权限信息，添加到Security对象权限TokenAuthFilter.doFilterInternal() 过滤器介绍 SpringSecurity 的过滤器介绍 SpringSecurity 采用的是责任链的设计模式，它有一条很长的过滤器链。现在对这条过滤器链的 15 个过滤器进行说明: （1） WebAsyncManagerIntegrationFilter：将 Security 上下文与 Spring Web 中用于处理异步请求映射的 WebAsyncManager 进行集成。 （2） SecurityContextPersistenceFilter：在每次请求处理之前将该请求相关的安全上下文信息加载到SecurityContextHolder 中，然后在该次请求处理完成之后，将SecurityContextHolder 中关于这次请求的信息存储到一个“仓储”中，然后将SecurityContextHolder 中的信息清除，例如在 Session 中维护一个用户的安全信息就是这个过滤器处理的。 （3） HeaderWriterFilter：用于将头信息加入响应中。 （4） CsrfFilter：用于处理跨站请求伪造。 （5）LogoutFilter：用于处理退出登录。 （6）UsernamePasswordAuthenticationFilter：用于处理基于表单的登录请求，从表单中获取用户名和密码。默认情况下处理来自 /login 的请求。从表单中获取用户名和密码时，默认使用的表单 name 值为 username 和 password，这两个值可以通过设置这个过滤器的 usernameParameter 和 passwordParameter 两个参数的值进行修改。 （7）DefaultLoginPageGeneratingFilter：如果没有配置登录页面，那系统初始化时就会配置这个过滤器，并且用于在需要进行登录时生成一个登录表单页面。 （8）BasicAuthenticationFilter：检测和处理 http basic 认证。 （9）RequestCacheAwareFilter：用来处理请求的缓存。 （10）SecurityContextHolderAwareRequestFilter：主要是包装请求对象 request。 （11）AnonymousAuthenticationFilter：检测 SecurityContextHolder 中是否存在Authentication 对象，如果不存在为其提供一个匿名 Authentication。 （12）SessionManagementFilter：管理 session 的过滤器 （13）ExceptionTranslationFilter：处理 AccessDeniedException 和AuthenticationException 异常。 （14）FilterSecurityInterceptor：可以看做过滤器链的出口。 （15）RememberMeAuthenticationFilter：当用户没有登录而直接访问资源时, 从 cookie 里找出用户的信息, 如果 Spring Security 能够识别出用户提供的 remember me cookie, 用户将不必填写用户名和密码, 而是直接登录进入系统，该过滤器默认不开启。 基本流程Spring Security 采取过滤链实现认证与授权，只有当前过滤器通过，才能进入下一个过滤器： 绿色部分是认证过滤器，需要我们自己配置，可以配置多个认证过滤器。认证过滤器可以使用 Spring Security 提供的认证过滤器，也可以自定义过滤器（例如：短信验证）。认证过滤器要在 configure(HttpSecurity http)方法中配置，没有配置不生效。下面会重点介绍以下三个过滤器： UsernamePasswordAuthenticationFilter 过滤器：该过滤器会拦截前端提交的 POST 方式的登录表单请求，并进行身份认证。 ExceptionTranslationFilter 过滤器：该过滤器不需要我们配置，对于前端提交的请求会直接放行，捕获后续抛出的异常并进行处理（例如：权限访问限制）。 FilterSecurityInterceptor 过滤器：该过滤器是过滤器链的最后一个过滤器，根据资源权限配置来判断当前请求是否有权限访问对应的资源。如果访问受限会抛出相关异常，并由 ExceptionTranslationFilter 过滤器进行捕获和处理。 认证流程 当前端提交的是一个 POST 方式的登录表单请求，就会被该过滤器拦截，并进行身份认证。该过滤器的 doFilter() 方法实现在其抽象父类。 分析UsernamePasswordAuthenticationFilter 认证过滤器，一般都是查看doFilter方法，该方法是在父类中实现的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public abstract class AbstractAuthenticationProcessingFilter extends GenericFilterBean implements ApplicationEventPublisherAware, MessageSourceAware&#123; public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; //1.判断提交方式是否Post，若不是则放行 if (!requiresAuthentication(request, response)) &#123; chain.doFilter(request, response); return; &#125; if (logger.isDebugEnabled()) &#123; logger.debug(\"Request is to process authentication\"); &#125; Authentication authResult; try &#123; //2.调用子类的方法进行身份认证，认证成功之后，把认证信息封装到对象里面 authResult = attemptAuthentication(request, response); if (authResult == null) &#123; return; &#125; //3.session策略处理，如果配置了用户Session最大并发数，就是在此处进行判断处理 sessionStrategy.onAuthentication(authResult, request, response); &#125; catch (InternalAuthenticationServiceException failed) &#123; logger.error( \"An internal error occurred while trying to authenticate the user.\", failed); //4.认证失败抛出异常，执行认证失败的方法 unsuccessfulAuthentication(request, response, failed); return; &#125; catch (AuthenticationException failed) &#123; // Authentication failed unsuccessfulAuthentication(request, response, failed); return; &#125; // 认证成功的处理，默认为false，所以认证成功后不进入下一个过滤器 if (continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; //5.认证成功，调用认证成功的方法 successfulAuthentication(request, response, chain, authResult); &#125;&#125; 然后再来详细分析子类的attemptAuthentication认证方法。 123456789101112131415161718192021222324252627282930313233public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; //1.验证Post请求 if (postOnly &amp;&amp; !request.getMethod().equals(\"POST\")) &#123; throw new AuthenticationServiceException( \"Authentication method not supported: \" + request.getMethod()); &#125; //2.获取表单提交的数据 String username = obtainUsername(request); String password = obtainPassword(request); if (username == null) &#123; username = \"\"; &#125; if (password == null) &#123; password = \"\"; &#125; username = username.trim(); //3.使用获取的数据构造成对象，标记成未认证 UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( username, password); //4.把请求一些属性信息设置到对象里 setDetails(request, authRequest); //5.调用方法进行身份认证（调用UserDetailsService） return this.getAuthenticationManager().authenticate(authRequest);&#125; 1234567891011121314public interface Authentication extends Principal, Serializable &#123; Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); //用户密码 Object getCredentials(); //请求携带的一些属性信息（例如：remoteAddress，sessionId） Object getDetails(); //未认证时为前端请求传入的用户名，认证成功后为封装认证用户信息的UserDetails对象 Object getPrincipal(); //是否被认证 boolean isAuthenticated(); //设置是否被认证 void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException;&#125; 以下类实现了Authentication接口，并通过参数的不同进行区分认证状态。 1234567891011121314151617181920212223public class UsernamePasswordAuthenticationToken extends AbstractAuthenticationToken &#123; private final Object principal; private Object credentials; //用于封装前端请求传入的未认证的用户信息 public UsernamePasswordAuthenticationToken(Object principal, Object credentials) &#123; super(null); this.principal = principal; this.credentials = credentials; //设置认证状态 setAuthenticated(false); &#125; //用于封装认证成功后的用户信息 public UsernamePasswordAuthenticationToken(Object principal, Object credentials, Collection&lt;? extends GrantedAuthority&gt; authorities) &#123; super(authorities); this.principal = principal; this.credentials = credentials; super.setAuthenticated(true); // must use super, as we override &#125;&#125; 上述过程中，UsernamePasswordAuthenticationFilter 过滤器的attemptAuthentication() 方法最后过程将未认证的 Authentication 对象传入ProviderManager 类的 authenticate() 方法进行身份认证。 ProviderManager 是 AuthenticationManager 接口的实现类，该接口是认证相关的核心接口，也是认证的入口。 在实际开发中，我们可能有多种不同的认证方式，例如：用户名+ 密码、邮箱+密码、手机号+验证码等，而这些认证方式的入口始终只有一个，那就是AuthenticationManager。 在该接口的常用实现类 ProviderManager 内部会维护一个List列表，存放多种认证方式，实际上这是委托者模式（Delegate）的应用。 每种认证方式对应着一个 AuthenticationProvider，AuthenticationManager 根据认证方式的不同（根据传入的 Authentication 类型判断）委托对应的 AuthenticationProvider 进行用户认证。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class ProviderManager implements AuthenticationManager, MessageSourceAware,InitializingBean &#123; //传入未认证的Authentication对象 public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; //1.获取传入的Authentication类型，即 UsernamePasswordAuthenticationToken Class&lt;? extends Authentication&gt; toTest = authentication.getClass(); AuthenticationException lastException = null; AuthenticationException parentException = null; Authentication result = null; Authentication parentResult = null; boolean debug = logger.isDebugEnabled(); //2.迭代认证方式列表 for (AuthenticationProvider provider : getProviders()) &#123; //3.判断当前AuthenticationProvider是否适用UsernamePasswordAuthenticationToken类型 if (!provider.supports(toTest)) &#123; continue; &#125; try &#123; //4.如果认证成功，会返回一个标记已认证的Authentication对象 result = provider.authenticate(authentication); if (result != null) &#123; //5.认证成功后，将传入的Authentication对象中的details信息拷贝到已认证的Authentication对象中 copyDetails(authentication, result); break; &#125; &#125; catch (AuthenticationException e) &#123; &#125; &#125; if (result == null &amp;&amp; parent != null) &#123; // 6.认证失败，适用父类型 AuthenticationManager进行验证 try &#123; result = parentResult = parent.authenticate(authentication); &#125; catch (ProviderNotFoundException e) &#123; &#125; &#125; if (result != null) &#123; //7.认证成功之后去除result的敏感信息，要求实现CredentialsContainer接口 //如去除用户密码缓存，默认的UsernamePasswordAuthenticationToken有实现 if (eraseCredentialsAfterAuthentication &amp;&amp; (result instanceof CredentialsContainer)) &#123; ((CredentialsContainer) result).eraseCredentials(); &#125; //8.发布认证成功的事件 if (parentResult == null) &#123; eventPublisher.publishAuthenticationSuccess(result); &#125; return result; &#125; //9.认证失败抛出异常信息 if (lastException == null) &#123; lastException = new ProviderNotFoundException(messages.getMessage( \"ProviderManager.providerNotFound\", new Object[] &#123; toTest.getName() &#125;, \"No AuthenticationProvider found for &#123;0&#125;\")); &#125; if (parentException == null) &#123; prepareException(lastException, authentication); &#125; throw lastException; &#125;&#125; 上述过程就是认证流程的最核心部分，接下来重新回到UsernamePasswordAuthenticationFilter 过滤器的 doFilter() 方法，查看认证成功/失败的处理： 123456789101112131415161718//认证成功后的处理protected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, Authentication authResult) throws IOException, ServletException &#123; //1.将认证成功的用户信息对象封装到SecurityContext中，SecurityContextHolder是对ThreadLocal的封装 SecurityContextHolder.getContext().setAuthentication(authResult); //2.rememberMe的处理 rememberMeServices.loginSuccess(request, response, authResult); //3.发布认证成功的事件 if (this.eventPublisher != null) &#123; eventPublisher.publishEvent(new InteractiveAuthenticationSuccessEvent( authResult, this.getClass())); &#125; //4.调用认证成功处理器 successHandler.onAuthenticationSuccess(request, response, authResult);&#125; 1234567891011//认证失败后的处理protected void unsuccessfulAuthentication(HttpServletRequest request, HttpServletResponse response, AuthenticationException failed) throws IOException, ServletException &#123; //1.清除该线程在SecurityContextHolder中对应的SecurityContext对象 SecurityContextHolder.clearContext(); //2.rememberMe处理 rememberMeServices.loginFail(request, response); //3.调用认证失败处理器 failureHandler.onAuthenticationFailure(request, response, failed);&#125; 权限访问流程上一个部分通过源码的方式介绍了认证流程，下面介绍权限访问流程，主要是对ExceptionTranslationFilter 过滤器和 FilterSecurityInterceptor 过滤器进行介绍。 123456789101112131415161718192021222324252627282930public class ExceptionTranslationFilter extends GenericFilterBean &#123; public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; try &#123; //1.直接放行请求 chain.doFilter(request, response); logger.debug(\"Chain processed normally\"); &#125; catch (IOException ex) &#123; throw ex; &#125; catch (Exception ex) &#123; //2.捕获出现的异常进行处理 Throwable[] causeChain = throwableAnalyzer.determineCauseChain(ex); //3.访问要认证的资源，但当前请求未认证所抛出的异常 RuntimeException ase = (AuthenticationException) throwableAnalyzer .getFirstThrowableOfType(AuthenticationException.class, causeChain); //4.访问权限受限的资源所抛出的异常 if (ase == null) &#123; ase = (AccessDeniedException) throwableAnalyzer.getFirstThrowableOfType( AccessDeniedException.class, causeChain); &#125; &#125; &#125;&#125; FilterSecurityInterceptor 是过滤器链的最后一个过滤器，该过滤器是过滤器链的最后一个过滤器，根据资源权限配置来判断当前请求是否有权限访问对应的资源。如果访问受限会抛出相关异常，最终所抛出的异常会由前一个过滤器ExceptionTranslationFilter 进行捕获和处理。具体源码如下： 1234567891011121314151617181920212223242526272829303132333435public class FilterSecurityInterceptor extends AbstractSecurityInterceptor implements Filter &#123; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; FilterInvocation fi = new FilterInvocation(request, response, chain); invoke(fi); &#125; public void invoke(FilterInvocation fi) throws IOException, ServletException &#123; if ((fi.getRequest() != null) &amp;&amp; (fi.getRequest().getAttribute(FILTER_APPLIED) != null) &amp;&amp; observeOncePerRequest) &#123; fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; else &#123; if (fi.getRequest() != null &amp;&amp; observeOncePerRequest) &#123; fi.getRequest().setAttribute(FILTER_APPLIED, Boolean.TRUE); &#125; //1.根据资源权限配置来判断当前请求是否有权限访问对应的资源。 //如果不能访问，则抛出相应的异常 InterceptorStatusToken token = super.beforeInvocation(fi); try &#123; //2.访问相关资源，通过SpringMvc的核心组件DispatcherServlet进行访问 fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; finally &#123; super.finallyInvocation(token); &#125; super.afterInvocation(token, null); &#125; &#125;&#125; 需要注意，Spring Security 的过滤器链是配置在 SpringMVC 的核心组件DispatcherServlet 运行之前。也就是说，请求通过 Spring Security 的所有过滤器，不意味着能够正常访问资源，该请求还需要通过 SpringMVC 的拦截器链。 认证共享在前面讲解认证成功的处理方法 successfulAuthentication() 时，有以下代码： 1SecurityContextHolder.getContext().setAuthentication(authResult); 12345678910111213141516171819202122232425262728public class SecurityContextHolder &#123; //清空当前线程对应的ThreadLocal&lt;SecurityContext&gt;存储 public static void clearContext() &#123; strategy.clearContext(); &#125; //如果当前线程对应的ThreadLocal&lt;SecurityContext&gt;没有任何对象存储 //strategy.getContext会创建并返回一个空的SecurityContext对象 //并且该空的SecurityContext对象会存入ThreadLocal&lt;SecurityContext&gt; public static SecurityContext getContext() &#123; return strategy.getContext(); &#125; private static void initialize() &#123; if (!StringUtils.hasText(strategyName)) &#123; //默认使用MODE_THREADLOCAL模式 strategyName = MODE_THREADLOCAL; &#125; //省略代码... &#125; //设置当前线程对应的ThreadLocal&lt;SecurityContext&gt;存储 public static void setContext(SecurityContext context) &#123; strategy.setContext(context); &#125;&#125; 前面提到过，在 UsernamePasswordAuthenticationFilter 过滤器认证成功之后，会在认证成功的处理方法中将已认证的用户信息对象 Authentication 封装进SecurityContext，并存入 SecurityContextHolder。 之后，响应会通过 SecurityContextPersistenceFilter 过滤器，该过滤器的位置在所有过滤器的最前面，请求到来先进它，响应返回最后一个通过它，所以在该过滤器中处理已认证的用户信息对象 Authentication 与 Session 绑定。 认证成功的响应通过 SecurityContextPersistenceFilter 过滤器时，会从SecurityContextHolder 中取出封装了已认证用户信息对象 Authentication 的SecurityContext，放进 Session 中。 当请求再次到来时，请求首先经过该过滤器，该过滤器会判断当前请求的 Session 是否存有 SecurityContext 对象，如果有则将该对象取出再次放入 SecurityContextHolder 中，之后该请求所在的线程获得认证用户信息，后续的资源访问不需要进行身份认证； 当响应再次返回时，该过滤器同样从 SecurityContextHolder 取出SecurityContext 对象，放入 Session 中。具体源码如下： 12345678910111213141516171819202122232425262728293031323334public class SecurityContextPersistenceFilter extends GenericFilterBean &#123; public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) req; HttpServletResponse response = (HttpServletResponse) res; //省略部分代码... HttpRequestResponseHolder holder = new HttpRequestResponseHolder(request,response); //1.请求到来时，检查当前Session中是否存有SecurityContext对象 //如果有，从Session中取出该对象，如果没有，创建一个空的SecurityContext对象 SecurityContext contextBeforeChainExecution = repo.loadContext(holder); try &#123; //2.将上述获得SecurityContext对象放入SecurityContextHolder中 SecurityContextHolder.setContext(contextBeforeChainExecution); //3.进入下一个过滤器 chain.doFilter(holder.getRequest(), holder.getResponse()); &#125; finally &#123; //4.响应返回时，从SecurityContextHolder中取出SecurityContext SecurityContext contextAfterChainExecution = SecurityContextHolder .getContext(); //5.移除SecurityContextHolder中的SecurityContext SecurityContextHolder.clearContext(); //6.将取出的SecurityContext对象放进Session repo.saveContext(contextAfterChainExecution, holder.getRequest(), holder.getResponse()); request.removeAttribute(FILTER_APPLIED); &#125; &#125;&#125; 图形验证码12345&lt;dependency&gt; &lt;groupId&gt;com.github.penggle&lt;/groupId&gt; &lt;artifactId&gt;kaptcha&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627@AutowiredProducer captchaProducer;//添加获取验证码图片的controller@GetMapping(\"/kaptcha\")public void getKaptchaImage(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpSession session = request.getSession(); response.setDateHeader(\"Expires\", 0); response.setHeader(\"Cache-Control\", \"no-store, no-cache, must-revalidate\"); response.addHeader(\"Cache-Control\", \"post-check=0, pre-check=0\"); response.setHeader(\"Pragma\", \"no-cache\"); response.setContentType(\"image/jpeg\"); //创建图片验证码 String capText = captchaProducer.createText(); //每次请求时将最新的图片验证码存放到session会话的作用域中 session.setAttribute(Constants.KAPTCHA_SESSION_KEY, capText); BufferedImage bi = captchaProducer.createImage(capText); ServletOutputStream out = response.getOutputStream(); ImageIO.write(bi, \"jpg\", out); try &#123; out.flush(); &#125; finally &#123; out.close(); &#125;&#125; 1234567891011121314151617181920212223//生成图片验证码的配置类@Configurationpublic class Kaconfig &#123; @Bean public DefaultKaptcha getDefaultKaptcha()&#123; DefaultKaptcha captchaProducer = new DefaultKaptcha(); Properties properties = new Properties(); properties.setProperty(\"kaptcha.border\", \"yes\"); properties.setProperty(\"kaptcha.border.color\", \"105,179,90\"); properties.setProperty(\"kaptcha.textproducer.font.color\", \"blue\"); properties.setProperty(\"kaptcha.image.width\", \"310\"); properties.setProperty(\"kaptcha.image.height\", \"240\"); properties.setProperty(\"kaptcha.textproducer.font.size\", \"30\"); properties.setProperty(\"kaptcha.session.key\", \"code\"); properties.setProperty(\"kaptcha.textproducer.char.length\", \"4\"); // properties.setProperty(\"kaptcha.textproducer.char.string\", \"678\"); properties.setProperty(\"kaptcha.obscurificator.impl\", \"com.google.code.kaptcha.impl.ShadowGimpy\"); properties.setProperty(\"kaptcha.textproducer.font.names\", \"宋体,楷体,微软雅黑\"); Config config = new Config(properties); captchaProducer.setConfig(config); return captchaProducer; &#125;&#125; 123456789101112131415161718192021222324252627282930313233//编写校验图片验证码的Filter过滤器public class CodeFilter implements Filter &#123; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest req = (HttpServletRequest)request; HttpServletResponse resp = (HttpServletResponse)response; String uri = req.getServletPath(); if(uri.equals(\"/login\") &amp;&amp; req.getMethod().equalsIgnoreCase(\"post\")) &#123; //从Session会话作用域中获取图片验证码 String sessionCode = req.getSession().getAttribute(Constants.KAPTCHA_SESSION_KEY).toString(); //获取表单中提交的图片验证码 String formCode = req.getParameter(\"code\").trim(); //比对验证码是否正确 if(StringUtils.isEmpty(formCode)) &#123; throw new RuntimeException(\"验证码不能为空\"); &#125; if(sessionCode.equalsIgnoreCase(formCode)) &#123; System.out.println(\"验证通过\"); &#125; System.out.println(req.getSession().getAttribute(Constants.KAPTCHA_SESSION_KEY)); throw new AuthenticationServiceException(\"xx\"); &#125; //若通过则调用Filter链 chain.doFilter(request, response); &#125;&#125; 校验图片验证码，最好在最外层的Filter中进行，不要让请求流转到校验账号密码的Filter中 12345678910@Configuration@EnableWebSecuritypublic class SecuritySecureConfig extends WebSecurityConfigurerAdapter &#123; //基于Http的请求配置 @Override protected void configure(HttpSecurity http) throws Exception &#123; http.addFilterBefore(new CodeFilter, UsernamePasswordAuthenticationFilter.class); &#125;&#125;","categories":[{"name":"Security","slug":"Security","permalink":"https://midkuro.gitee.io/categories/Security/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.gitee.io/tags/SpringBoot/"}]},{"title":"'Spring Boot Cache 缓存'","slug":"springboot-cache","date":"2020-06-04T14:00:00.000Z","updated":"2020-11-12T04:18:26.363Z","comments":true,"path":"2020/06/04/springboot-cache/","link":"","permalink":"https://midkuro.gitee.io/2020/06/04/springboot-cache/","excerpt":"","text":"Spring Boot CacheJSR 规范Java Caching定义了5个核心接口，分别是CachingProvider, CacheManager,Cache, Entry 和 Expiry。 CachingProvider定义了创建、配置、获取、管理和控制多个CacheManager。一个应用可以在运行期访问多个CachingProvider。 CacheManager定义了创建、配置、获取、管理和控制多个唯一命名的Cache，这些Cache存在于CacheManager的上下文中。一个CacheManager仅被一个CachingProvider所拥有。 Cache是一个类似Map的数据结构并临时存储以Key为索引的值。一个Cache仅被一个CacheManager所拥有。Entry是一个存储在Cache中的key-value对。 Expiry 每一个存储在Cache中的条目有一个定义的有效期。一旦超过这个时间，条目为过期的状态。一旦过期，条目将不可访问、更新和删除。缓存有效期可以通过ExpiryPolicy设置。 如果要使用JSR规范，可以引入以下依赖 1234&lt;dependency&gt; &lt;groupId&gt;javax.cache&lt;/groupid&gt; &lt;artifactId&gt;cache-api&lt;/artifactId&gt;&lt;/dependency&gt; Spring CacheSpring从3.1开始定义了org.springframework.cache.Cache和org.springframework.cache.CacheManager接口来统一不同的缓存技术；并支持使用JCache（JSR-107）注解简化我们开发； Cache接口为缓存的组件规范定义，包含缓存的各种操作集合；Cache接口下Spring提供了各种xxxCache的实现；如RedisCache，EhCacheCache , ConcurrentMapCache等； 每次调用需要缓存功能的方法时，Spring会检查检查指定参数的指定的目标方法是否已经被调用过；如果有就直接从缓存中获取方法调用后的结果，如果没有就调用方法并缓存结果后返回给用户。下次调用直接从缓存中获取。 使用Spring缓存抽象时我们需要关注以下两点； 确定方法需要被缓存以及他们的缓存策略 从缓存中读取之前缓存存储的数据 缓存注解 Cache 缓存接口，定义缓存操作。实现有：RedisCache、EhCacheCache、ConcurrentMapCache等 CacheManager 缓存管理器，管理各种缓存（Cache）组件 @Cacheable 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存 @CacheEvict 清空缓存 @CachePut 保证方法被调用，又希望结果被缓存。 @EnableCaching 开启基于注解的缓存 keyGenerator 缓存数据时key生成策略 serialize 缓存数据时value序列化策略 案例： 123456@Cacheable(value = &#123;\"emp\"&#125;)public Employee getEmp(Integer id)&#123; System.out.println(\"查询\"+id+\"号员工\"); Employee emp = employeeMapper.getEmpById(id); return emp;&#125; cacheNames/value：指定缓存组件的名字;将方法的返回结果放在哪个缓存中，是数组的方式，可以指定多个缓存； key：缓存数据使用的key；可以用它来指定。默认是使用方法参数的值：《方法参数，方法返回值》 编写SpEL：#id #a0 #p0 #root.args[0] 都表示参数id的值. cacheManager：指定缓存管理器；或者cacheResolver指定获取解析器 keyGenerator：key的生成器；可以自己指定key的生成器的组件id，和key属性二选一使用 condition：指定符合条件的情况下才缓存；如condition = &quot;#id&gt;0“ unless:否定缓存；当unless指定的条件为true，方法的返回值就不会被缓存；可以获取到结果进行判断 如unless = &quot;#result == null&quot; sync：是否使用异步模式 原理通过自动配置类CacheAutoConfiguration加载 123456789@Configuration@ConditionalOnClass(CacheManager.class)@ConditionalOnBean(CacheAspectSupport.class)@ConditionalOnMissingBean(value = CacheManager.class, name = \"cacheResolver\")@EnableConfigurationProperties(CacheProperties.class)@AutoConfigureAfter(&#123; CouchbaseAutoConfiguration.class, HazelcastAutoConfiguration.class, HibernateJpaAutoConfiguration.class, RedisAutoConfiguration.class &#125;)@Import(CacheConfigurationImportSelector.class)public class CacheAutoConfiguration &#123;&#125; @Import(CacheConfigurationImportSelector.class)主要用于导入容器中需要使用的组件。 1234567891011static class CacheConfigurationImportSelector implements ImportSelector &#123; @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; CacheType[] types = CacheType.values(); String[] imports = new String[types.length]; for (int i = 0; i &lt; types.length; i++) &#123; imports[i] = CacheConfigurations.getConfigurationClass(types[i]); &#125; return imports; &#125;&#125; 具体导入了以下组件： 1234567891011org.springframework.boot.autoconfigure.cache.GenericCacheConfigurationorg.springframework.boot.autoconfigure.cache.JCacheCacheConfigurationorg.springframework.boot.autoconfigure.cache.EhCacheCacheConfigurationorg.springframework.boot.autoconfigure.cache.HazelcastCacheConfigurationorg.springframework.boot.autoconfigure.cache.InfinispanCacheConfigurationorg.springframework.boot.autoconfigure.cache.CouchbaseCacheConfigurationorg.springframework.boot.autoconfigure.cache.RedisCacheConfigurationorg.springframework.boot.autoconfigure.cache.CaffeineCacheConfigurationorg.springframework.boot.autoconfigure.cache.GuavaCacheConfigurationorg.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration【默认】org.springframework.boot.autoconfigure.cache.NoOpCacheConfiguration 默认生效的配置类：SimpleCacheConfiguration。 123456789101112131415161718192021222324@Configuration@ConditionalOnMissingBean(CacheManager.class)@Conditional(CacheCondition.class)class SimpleCacheConfiguration &#123; private final CacheProperties cacheProperties; private final CacheManagerCustomizers customizerInvoker; SimpleCacheConfiguration(CacheProperties cacheProperties, CacheManagerCustomizers customizerInvoker) &#123; this.cacheProperties = cacheProperties; this.customizerInvoker = customizerInvoker; &#125; @Bean public ConcurrentMapCacheManager cacheManager() &#123; ConcurrentMapCacheManager cacheManager = new ConcurrentMapCacheManager(); List&lt;String&gt; cacheNames = this.cacheProperties.getCacheNames(); if (!cacheNames.isEmpty()) &#123; cacheManager.setCacheNames(cacheNames); &#125; return this.customizerInvoker.customize(cacheManager); &#125;&#125; 它主要作用是给容器中注入一个cacheManager(缓存管理器)，cacheManager是一个接口，提供了一个通过name获取一个缓存对象cache的API。 123456public interface CacheManager &#123; @Nullable Cache getCache(String name); Collection&lt;String&gt; getCacheNames();&#125; SimpleCacheConfiguration使用ConcurrentMapCacheManager实例化cacheManager。 123456789101112131415161718192021222324252627public class ConcurrentMapCacheManager implements CacheManager, BeanClassLoaderAware &#123; //使用ConcurrentMap做缓存集合 private final ConcurrentMap&lt;String, Cache&gt; cacheMap = new ConcurrentHashMap&lt;&gt;(16); @Override @Nullable public Cache getCache(String name) &#123; Cache cache = this.cacheMap.get(name); if (cache == null &amp;&amp; this.dynamic) &#123; synchronized (this.cacheMap) &#123; cache = this.cacheMap.get(name); if (cache == null) &#123; //判断无该缓存时初始化 cache = createConcurrentMapCache(name); this.cacheMap.put(name, cache); &#125; &#125; &#125; return cache; &#125; protected Cache createConcurrentMapCache(String name) &#123; SerializationDelegate actualSerialization = (isStoreByValue() ? this.serialization : null); return new ConcurrentMapCache(name, new ConcurrentHashMap&lt;&gt;(256), isAllowNullValues(), actualSerialization); &#125;&#125; 可以看到ConcurrentMapCacheManager使用了ConcurrentMapCache类型作为缓存组件。 1234public class ConcurrentMapCache extends AbstractValueAdaptingCache &#123; private final String name; private final ConcurrentMap&lt;Object, Object&gt; store; //存储缓存数据&#125; ConcurrentMapCacheManager可以获取和创建ConcurrentMapCache类型的缓存组件；他的作用将数据保存在ConcurrentMap中； @Cacheable 方法运行之前，先去查询Cache（缓存组件），按照cacheNames指定的名字获取；（CacheManager先获取相应的缓存），第一次获取缓存如果没有Cache组件会自动创建。 去Cache中查找缓存的内容，使用一个key，默认就是方法的参数； key是按照某种策略生成的；默认是使用keyGenerator生成的，默认使用SimpleKeyGenerator生成key； SimpleKeyGenerator生成key的默认策略； 如果没有参数；key=new SimpleKey()； 如果有一个参数：key=参数的值 如果有多个参数：key=new SimpleKey(params)； 没有查到缓存就调用目标方法； 将目标方法返回的结果，放进缓存中： 核心： 使用CacheManager【ConcurrentMapCacheManager】按照名字得到Cache【ConcurrentMapCache】组件 key使用keyGenerator生成的，默认是SimpleKeyGenerator. @Cacheable标注的方法执行之前先来检查缓存中有没有这个数据，默认按照参数的值作为key去查询缓存 如果没有就运行方法并将结果放入缓存；以后再来调用就可以直接使用缓存中的数据； @CachePut既调用方法，又更新缓存数据；同步更新缓存，修改了数据库的某个数据，同时更新缓存； 运行时机： 先调用目标方法 将目标方法的结果缓存起来 通过调度updateEmp修改员工信息，并指定key才能达到更新缓存的目的，否则无法更新对应的缓存信息。下例使用传入的参数的员工id：key = &quot;#employee.id&quot;或者返回后的id：key = &quot;#result.id&quot;当做key，更新缓存中相同key的Cache对象，达到执行更新语句时更新缓存数据目的。 注意：@Cacheable的key是不能用#result 123456@CachePut(value = \"emp\",key = \"#result.id\")public Employee updateEmp(Employee employee)&#123; System.out.println(\"updateEmp:\"+employee); employeeMapper.updateEmp(employee); return employee;&#125; @CacheEvict缓存清除注解： key：指定要清除的数据 allEntries = true时，将清除这个缓存中的所有数据。 beforeInvocation = false：缓存的清除是否在方法之前执行，默认代表缓存清除操作是在方法执行之后执行;如果出现异常缓存就不会清除 beforeInvocation = true：代表清除缓存操作是在方法运行之前执行，无论方法是否出现异常，缓存都清除 123456@CacheEvict(value=\"emp\",allEntries = true /*,key = \"#id\",*/)public void deleteEmp(Integer id)&#123; System.out.println(\"deleteEmp:\"+id); employeeMapper.deleteEmpById(id); int i = 10/0;&#125; @Caching12345678910111213//定义复杂的缓存规则@Caching( cacheable = &#123; @Cacheable(value=\"emp\",key = \"#lastName\") &#125;, put = &#123; @CachePut(value=\"emp\",key = \"#result.id\"), @CachePut(value=\"emp\",key = \"#result.email\") &#125;)public Employee getEmpByLastName(String lastName)&#123; return employeeMapper.getEmpByLastName(lastName);&#125; @CacheConfig123456789101112//抽取缓存的公共配置@CacheConfig(cacheNames=\"emp\") @Servicepublic class EmployeeService &#123; //不需要再写 value=\"emp\" @CachePut(key = \"#result.id\") public Employee updateEmp(Employee employee)&#123; System.out.println(\"updateEmp:\"+employee); employeeMapper.updateEmp(employee); return employee; &#125;&#125; 自定义KeyGenerator12345678910111213@Configurationpublic class MyCacheConfig &#123; @Bean(\"myKeyGenerator\") public KeyGenerator keyGenerator()&#123; return new KeyGenerator()&#123; @Override public Object generate(Object target, Method method, Object... params) &#123; return method.getName() + Arrays.asList(params).toString(); &#125; &#125;; &#125;&#125; 123456@Cacheable(value = &#123;\"emp\"&#125;, keyGenerator = \"myKeyGenerator\")public Employee getEmp(Integer id)&#123; System.out.println(\"查询\"+ id +\"号员工\"); Employee emp = employeeMapper.getEmpById(id); return emp;&#125; 缓存API12345678910// 使用缓存管理器得到缓存，进行api调用public Employee getEmpById(Integer id)&#123; Employee employee = employeeMapper.getEmpById(id); //获取某个缓存 Cache cache = empCacheManager.getCache(\"emp\"); dept.put(\"emp:1\",employee); return employee;&#125; RedisCache缓存配置类的初始化是有顺序的，当添加了Redis组件后，有一个RedisCacheConfiguration类，当找不到其他缓存配置类时，默认使用SimpleCacheConfiguration。 12345678910111213141516171819@Configuration@ConditionalOnClass(&#123;RedisConnectionFactory.class&#125;)@AutoConfigureAfter(&#123;RedisAutoConfiguration.class&#125;)@ConditionalOnBean(&#123;RedisConnectionFactory.class&#125;)@ConditionalOnMissingBean(&#123;CacheManager.class&#125;)@Conditional(&#123;CacheCondition.class&#125;)class RedisCacheConfiguration &#123; @Bean public RedisCacheManager cacheManager(RedisConnectionFactory redisConnectionFactory, ResourceLoader resourceLoader) &#123; RedisCacheManagerBuilder builder = RedisCacheManager.builder(redisConnectionFactory).cacheDefaults(this.determineConfiguration(resourceLoader.getClassLoader())); List&lt;String&gt; cacheNames = this.cacheProperties.getCacheNames(); if (!cacheNames.isEmpty()) &#123; builder.initialCacheNames(new LinkedHashSet(cacheNames)); &#125; return (RedisCacheManager)this.customizerInvoker.customize(builder.build()); &#125;&#125; 看到使用RedisCacheConfiguration时，默认创建RedisCacheManager作为缓存管理类，以RedisCache作为组件。 默认保存数据以key-value的形式存储到Redis,都是Object对象，利用序列化保存，默认创建的RedisCacheManager操作Redis使用的是RedisTemplate&lt;Object,Object&gt;对象，使用的是JDK序列化机制，正常情况下需要配置redisTemplate的序列化机制，达到以JSON的方式序列化对象。 12345678910111213141516171819202122232425262728293031323334353637@Configurationpublic class MyRedisConfig &#123; @Bean public RedisTemplate&lt;Object, Employee&gt; empRedisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Employee&gt; template = new RedisTemplate&lt;Object, Employee&gt;(); template.setConnectionFactory(redisConnectionFactory); FastJsonRedisSerializer&lt;Employee&gt; ser = new FastJsonRedisSerializer&lt;Employee&gt;(Employee.class); template.setDefaultSerializer(ser); return template; &#125; @Bean public RedisCacheManager employeeCacheManager(RedisConnectionFactory redisConnectionFactory) &#123; RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(RedisSerializer.string())) .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new FastJsonRedisSerializer&lt;&gt;(Object.class))) .disableCachingNullValues(); return RedisCacheManager.builder( RedisCacheWriter.nonLockingRedisCacheWriter(redisConnectionFactory)).cacheDefaults(config).build(); &#125; @Override public KeyGenerator keyGenerator() &#123; return (target, method, params) -&gt; &#123; StringBuilder sb = new StringBuilder(); sb.append(target.getClass().getName()); sb.append(method.getName()); for (Object obj : params) &#123; sb.append(obj.toString()); &#125; return sb.toString(); &#125;; &#125;&#125; 当序列化的对象（Employee）里属性包含其他实体类（如Department）时，这时候缓存Employee对象时依旧能存储到redis中，但是无法反序列化回来。 原因是因为我们操作的是RedisTemplate&lt;Object, Employee&gt;对象，无法反序列化非Employee的对象，所以这个时候需要添加Department类的相关RedisCacheManager及RedisTemplate&lt;Object,Department&gt;。","categories":[{"name":"Cache","slug":"Cache","permalink":"https://midkuro.gitee.io/categories/Cache/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.gitee.io/tags/SpringBoot/"}]},{"title":"'Spring Boot Starter 启动配置原理'","slug":"springboot-starter","date":"2020-06-03T14:00:00.000Z","updated":"2020-11-12T04:21:47.486Z","comments":true,"path":"2020/06/03/springboot-starter/","link":"","permalink":"https://midkuro.gitee.io/2020/06/03/springboot-starter/","excerpt":"","text":"SpringBoot 启动配置原理启动配置原理12345public class SpringBootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootApplication.class, args); &#125;&#125; 点进启动类的run方法可以看到，在源码中先创建SpringApplication对象，然后在执行它的run方法。 1234567public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123; return run(new Class&lt;?&gt;[] &#123; primarySource &#125;, args);&#125;public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args);&#125; 创建SpringApplication对象1234567891011121314public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); //保存主配置类 this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); //判断当前是否一个web应用 this.webApplicationType = WebApplicationType.deduceFromClasspath(); //从类路径下找到META‐INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); //从类路径下找到ETA‐INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 运行run方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); //获取SpringApplicationRunListeners；从类路径下META‐INF/spring.factories SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的SpringApplicationRunListener.starting()方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); //准备环境 //创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //加载忽略Bean的配置信息 configureIgnoreBeanInfo(environment); //输出图标 Banner printedBanner = printBanner(environment); //创建IOC容器 ApplicationContext；决定创建web的ioc还是普通的ioc context = createApplicationContext(); //出异常时作报告用 exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); //准备上下文环境;将environment保存到ioc中； //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 //回调所有的SpringApplicationRunListener的contextPrepared()； //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat）； //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置） refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; //所有的SpringApplicationRunListener回调started方法 listeners.started(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调 //ApplicationRunner先回调，CommandLineRunner再回调 callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; //当IOC容器、environment初始化完成，run方法即将结束时回调listeners的running方法 listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; //整个SpringBoot应用启动完成以后返回启动的ioc容器； return context;&#125; 123456789101112131415161718192021222324252627282930313233private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; //准备上下文环境;将environment保存到ioc中； context.setEnvironment(environment); postProcessApplicationContext(context); //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 applyInitializers(context); //回调所有的SpringApplicationRunListener的contextPrepared()； listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton(\"springApplicationArguments\", applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton(\"springBootBanner\", printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.lazyInitialization) &#123; context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor()); &#125; // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, \"Sources must not be empty\"); load(context, sources.toArray(new Object[0])); //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； listeners.contextLoaded(context);&#125; 123456789protected void applyInitializers(ConfigurableApplicationContext context) &#123; for (ApplicationContextInitializer initializer : getInitializers()) &#123; Class&lt;?&gt; requiredType = GenericTypeResolver.resolveTypeArgument(initializer.getClass(), ApplicationContextInitializer.class); Assert.isInstanceOf(requiredType, context, \"Unable to call initializer.\"); //回调之前保存的所有的ApplicationContextInitializer的initialize方法 initializer.initialize(context); &#125;&#125; 1234private SpringApplicationRunListeners getRunListeners(String[] args) &#123; Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123;SpringApplication.class, String[].class&#125;; return new SpringApplicationRunListeners(logger, getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args));&#125; 配置在META-INF/spring.factories： ApplicationContextInitializer 、SpringApplicationRunListener 只需要放在ioc容器中 ：ApplicationRunner 、CommandLineRunner 事件监听机制ApplicationContextInitializer 123456public class HelloApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println(\"ApplicationContextInitializer...initialize...\"+applicationContext); &#125;&#125; SpringApplicationRunListener 123456789101112131415161718192021222324252627282930313233public class HelloSpringApplicationRunListener implements SpringApplicationRunListener &#123; //必须有的构造器 public HelloSpringApplicationRunListener(SpringApplication application, String[] args)&#123; &#125; @Override public void starting() &#123; System.out.println(\"SpringApplicationRunListener...starting...\"); &#125; @Override public void environmentPrepared(ConfigurableEnvironment environment) &#123; Object o = environment.getSystemProperties().get(\"os.name\"); System.out.println(\"SpringApplicationRunListener...environmentPrepared..\"+o); &#125; @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; System.out.println(\"SpringApplicationRunListener...contextPrepared...\"); &#125; @Override public void contextLoaded(ConfigurableApplicationContext context) &#123; System.out.println(\"SpringApplicationRunListener...contextLoaded...\"); &#125; @Override public void started(ConfigurableApplicationContext context) &#123; System.out.println(\"SpringApplicationRunListener...started...\"); &#125;&#125; 配置（META-INF/spring.factories）\\表示换行，,表示分隔 123org.springframework.context.ApplicationContextInitializer=\\ com.springboot.listener.HelloApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=\\ com.springboot.listener.HelloSpringApplicationRunListener ApplicationRunner 1234567@Componentpublic class HelloApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println(\"ApplicationRunner...run....\"); &#125;&#125; CommandLineRunner 1234567@Componentpublic class HelloCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println(\"CommandLineRunner...run...\"+ Arrays.asList(args)); &#125;&#125; 123456789输出顺序：SpringApplicationRunListener...starting...SpringApplicationRunListener...environmentPrepared...ApplicationContextInitializer...initialize...SpringApplicationRunListener...contextPrepared...SpringApplicationRunListener...contextLoaded...ApplicationRunner...run....CommandLineRunner...run...SpringApplicationRunListener...started... 自定义starterSpringBoot starter机制SpringBoot中的starter是一种非常重要的机制，能够抛弃以前繁杂的配置，将其统一集成进starter，应用者只需要在maven中引入starter依赖，SpringBoot就能自动扫描到要加载的信息并启动相应的默认配置。 starter让我们摆脱了各种依赖库的处理，需要配置各种信息的困扰。SpringBoot会自动通过classpath路径下的类发现需要的Bean，并注册进IOC容器。 SpringBoot提供了针对日常企业应用研发各种场景的spring-boot-starter依赖模块。所有这些依赖模块都遵循着约定成俗的默认配置，并允许我们调整这些配置，即遵循“约定大于配置”的理念。 为什么要自定义starter在我们的日常开发工作中，经常会有一些独立于业务之外的配置模块，我们经常将其放到一个特定的包下，然后如果另一个工程需要复用这块功能的时候，需要将代码硬拷贝到另一个工程，重新集成一遍，麻烦至极。 如果我们将这些可独立于业务代码之外的功配置模块封装成一个个starter，复用的时候只需要将其在pom中引用依赖即可，SpringBoot为我们完成自动装配。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter中集成了spring全家桶的许多依赖支持，如下： 命名规范启动器（starter），启动器模块是一个空 JAR 文件，仅提供辅助性依赖管理，这些依赖可能用于自动装配或者其他类库。 一个完整的Spring Boot Starter可能包含以下组件： autoconfigure模块：包含自动配置的代码 starter模块：提供对autoconfigure模块的依赖，以及一些其它的依赖 如果你不需要区分这两个概念的话，也可以将自动配置代码模块与依赖管理模块合并成一个模块。 官方命名空间： – 前缀：“spring-boot-starter-” – 模式：spring-boot-starter-模块名 – 举例：spring-boot-starter-web、spring-boot-starter-actuator、spring-boot-starter-jdbc 推荐自定义命名空间： – 后缀：“-spring-boot-starter” – 模式：模块-spring-boot-starter – 举例：mybatis-spring-boot-starter 如何编写1234567@Configuration //指定这个类是一个配置类@ConditionalOnXXX //在指定条件成立的情况下自动配置类生效@AutoConfigureAfter //指定自动配置类的顺序@Bean //给容器中添加组件@ConfigurationPropertie //结合相关xxxProperties类来绑定相关的配置@EnableConfigurationProperties //让xxxProperties生效加入到容器中 123456自动配置类要能加载将需要启动就加载的自动配置类，配置在META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ 新建项目新建一个工程名midkuro-spring-boot-starter的maven空项目，只做pom.xml的依赖引入。 新建一个工程名midkuro-spring-boot-starter-autoconfigurer的Spring-boot项目 并修改其``midkuro-spring-boot-starter-autoconfigurer项目的pom.xml文件，引入spring-boot-starter`依赖 123456789101112131415161718192021222324252627282930&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;midkuro-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;maven-jar-plugin.version&gt;2.6&lt;/maven-jar-plugin.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 然后修改midkuro-spring-boot-starter的pom.xml，引入相关依赖： 123456789101112131415161718192021222324&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;midkuro-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;midkuro-spring-boot-starter&lt;/name&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;midkuro-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 定义配置类在midkuro-spring-boot-starter-autoconfigurer工程中增加配置类 12345678910111213141516171819202122232425package cn.midkuro.com.autoconfigurer;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = \"mtex.hello\")public class HelloProperties &#123; private String prefix; private String suffix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public String getSuffix() &#123; return suffix; &#125; public void setSuffix(String suffix) &#123; this.suffix = suffix; &#125;&#125; 123456789101112131415161718package cn.midkuro.com.autoconfigurer;public class HelloService &#123; private HelloProperties properties; public HelloProperties getProperties() &#123; return properties; &#125; public void setProperties(HelloProperties properties) &#123; this.properties = properties; &#125; public String sayHello(String name) &#123; return properties.getPrefix() + \"-\" + name + \"-\" + properties.getSuffix(); &#125;&#125; 123456789101112131415161718192021222324package cn.midkuro.com.autoconfigurer;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration@ConditionalOnWebApplication //只有在web环境中生效@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration &#123; @Autowired private HelloProperties properties; @Bean public HelloService helloService() &#123; HelloService helloService = new HelloService(); helloService.setProperties(properties); return helloService; &#125;&#125; 配置spring.factories想要xxxAutoConfiguration配置默认生效，需要在META-INF/spring.factories增加启动类相关配置 123# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\cn.midkuro.com.autoconfigurer.HelloServiceAutoConfiguration \\斜杠符号表示换行，多个类以,逗号分开，具体可以参考spring-boot-starter的配置文件： 123456789101112131415161718192021222324252627# Initializersorg.springframework.context.ApplicationContextInitializer=\\org.springframework.boot.autoconfigure.SharedMetadataReaderFactoryContextInitializer,\\org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.autoconfigure.BackgroundPreinitializer# Auto Configuration Import Listenersorg.springframework.boot.autoconfigure.AutoConfigurationImportListener=\\org.springframework.boot.autoconfigure.condition.ConditionEvaluationReportAutoConfigurationImportListener# Auto Configuration Import Filtersorg.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\\org.springframework.boot.autoconfigure.condition.OnBeanCondition,\\org.springframework.boot.autoconfigure.condition.OnClassCondition,\\org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\... 测试新建工程名midkuro-spring-boot-starter-test的spring-boot项目，引入打包好的自定义starter依赖： 123456789101112131415161718192021222324252627282930313233343536373839&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.mastercom&lt;/groupId&gt; &lt;artifactId&gt;mtex-spring-boot-starter-test&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;maven-jar-plugin.version&gt;2.6&lt;/maven-jar-plugin.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.midkuro.com&lt;/groupId&gt; &lt;artifactId&gt;midkuro-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 新建测试Controller： 12345678910@RestControllerpublic class HelloController &#123; @Autowired private HelloService helloService; @GetMapping(\"/sayHello\") public void sayHello(String name) &#123; helloService.sayHello(name); &#125;&#125; 添加配置到application.properties中： 12mtex.hello.prefix=hellomtex.hello.suffix=world 运行启动类SpringBootStarterTestApplication： 1234567891011package cn.midkuro.com;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class SpringBootStarterTestApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootStarterTestApplication.class, args); &#125;&#125;","categories":[{"name":"Starter","slug":"Starter","permalink":"https://midkuro.gitee.io/categories/Starter/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.gitee.io/tags/SpringBoot/"}]},{"title":"'Spring Boot 数据访问&整合Druid监控'","slug":"springboot-druid","date":"2020-06-03T13:00:00.000Z","updated":"2020-11-12T04:19:27.001Z","comments":true,"path":"2020/06/03/springboot-druid/","link":"","permalink":"https://midkuro.gitee.io/2020/06/03/springboot-druid/","excerpt":"","text":"SpringBoot 数据访问简介对于数据访问层，无论是SQL还是NOSQL，Spring Boot默认采用整合Spring Data的方式进行统一处理，添加大量自动配置，屏蔽了很多设置。引入各种xxxTemplate，xxxRepository来简化我们对数据访问层的操作。对我们来说只需要进行简单的设置即可。 JDBC12345678910&lt;!--pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql‐connector‐java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 1234567#application.ymlspring: datasource: username: root password: 123456 url: jdbc:mysql://localhost:3306/jdbc driver‐class‐name: com.mysql.jdbc.Driver 12345678910111213141516@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringBoot06DataJdbcApplicationTests &#123; @Autowired DataSource dataSource; @Test public void contextLoads() throws SQLException &#123; //org.apache.tomcat.jdbc.pool.DataSource System.out.println(dataSource.getClass()); Connection connection = dataSource.getConnection(); System.out.println(connection); connection.close(); &#125;&#125; 在默认的情况下，使用org.apache.tomcat.jdbc.pool.DataSource作为数据源，数据源的所有配置都在DataSourceProperties中能找到。 自动配置原理： org.springframework.boot.autoconfifigure.jdbc： 1、参考DataSourceConfifiguration，根据配置创建数据源，默认使用Tomcat连接池；可以使用 spring.datasource.type指定自定义的数据源类型； 2、SpringBoot默认可以支持； 1org.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource 3、自定义数据源类型 12345678910/*** Generic DataSource configuration. */ @ConditionalOnMissingBean(DataSource.class) @ConditionalOnProperty(name = \"spring.datasource.type\") static class Generic &#123; @Bean public DataSource dataSource(DataSourceProperties properties) &#123; //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); &#125;&#125; 4、DataSourceInitializer：implement ApplicationListener 作用： runSchemaScripts(); 运行建表语句； runDataScripts(); 运行插入数据的sql语句； 默认只需要将文件命名为： 123456chema‐*.sql、data‐*.sql 默认规则：schema.sql，schema‐all.sql； 可以使用 schema: ‐ classpath:department.sql 指定位置 5、操作数据库：自动配置了JdbcTemplate操作数据库 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package org.springframework.boot.autoconfigure.jdbc;@Configuration@ConditionalOnClass(&#123; DataSource.class, JdbcTemplate.class &#125;)@ConditionalOnSingleCandidate(DataSource.class)@AutoConfigureAfter(DataSourceAutoConfiguration.class)@EnableConfigurationProperties(JdbcProperties.class)public class JdbcTemplateAutoConfiguration &#123; @Configuration static class JdbcTemplateConfiguration &#123; private final DataSource dataSource; private final JdbcProperties properties; JdbcTemplateConfiguration(DataSource dataSource, JdbcProperties properties) &#123; this.dataSource = dataSource; this.properties = properties; &#125; @Bean @Primary @ConditionalOnMissingBean(JdbcOperations.class) public JdbcTemplate jdbcTemplate() &#123; JdbcTemplate jdbcTemplate = new JdbcTemplate(this.dataSource); JdbcProperties.Template template = this.properties.getTemplate(); jdbcTemplate.setFetchSize(template.getFetchSize()); jdbcTemplate.setMaxRows(template.getMaxRows()); if (template.getQueryTimeout() != null) &#123; jdbcTemplate .setQueryTimeout((int) template.getQueryTimeout().getSeconds()); &#125; return jdbcTemplate; &#125; &#125; @Configuration @Import(JdbcTemplateConfiguration.class) static class NamedParameterJdbcTemplateConfiguration &#123; @Bean @Primary @ConditionalOnSingleCandidate(JdbcTemplate.class) @ConditionalOnMissingBean(NamedParameterJdbcOperations.class) public NamedParameterJdbcTemplate namedParameterJdbcTemplate( JdbcTemplate jdbcTemplate) &#123; return new NamedParameterJdbcTemplate(jdbcTemplate); &#125; &#125;&#125; 整合druid数据源123456&lt;!--pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627#application.ymlspring: datasource: username: root password: 123456 url: jdbc:mysql://localhost:3306/jdbc driver-class-name: com.mysql.jdbc.Driver #配置使用druid数据源 type: com.alibaba.druid.pool.DruidDataSource #druid数据源的相关配置 initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙 filters: stat,wall,log4j maxPoolPreparedStatementPerConnectionSize: 20 useGlobalDataSourceStat: true connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 默认情况下，druid的数据源的连接池等相关配置信息是不会被自动注入配置的，需要手动配置。 12345678910111213141516171819202122232425262728293031323334353637383940414243@Configurationpublic class DruidConfig &#123; //通过前缀相同，将属性注入到druidDataSource中 @ConfigurationProperties(prefix = \"spring.datasource\") @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), \"/druid/*\"); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"loginUsername\",\"admin\"); initParams.put(\"loginPassword\",\"123456\"); initParams.put(\"allow\",\"\");//默认就是允许所有访问 initParams.put(\"deny\",\"192.168.15.21\"); //禁止该IP访问 bean.setInitParameters(initParams); return bean; &#125; //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); //设置不拦截掉静态资源、druid请求 Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"exclusions\",\"*.js,*.css,/druid/*\"); bean.setInitParameters(initParams); //设置过滤器拦截所有请求 bean.setUrlPatterns(Arrays.asList(\"/*\")); return bean; &#125;&#125;","categories":[{"name":"Druid","slug":"Druid","permalink":"https://midkuro.gitee.io/categories/Druid/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.gitee.io/tags/SpringBoot/"}]},{"title":"'Java 密码学 非对称加密'","slug":"cryptography-asymmetric","date":"2020-05-30T13:00:00.000Z","updated":"2020-11-13T05:52:33.207Z","comments":true,"path":"2020/05/30/cryptography-asymmetric/","link":"","permalink":"https://midkuro.gitee.io/2020/05/30/cryptography-asymmetric/","excerpt":"","text":"密码学消息摘要消息摘要（Message Digest）又称为数字摘要(Digital Digest)，它是一个唯一对应一个消息或文本的固定长度的值，它由一个单向Hash加密函数对消息进行作用而产生，使用数字摘要生成的值是不可以篡改的，为了保证文件或者值的安全。 无论输入的消息有多长，计算出来的消息摘要的长度总是固定的。 例如应用MD5算法摘要的消息有128个比特位，用SHA-1算法摘要的消息最终有160比特位的输出，只要输入的消息不同，对其进行摘要以后产生的摘要消息也必不相同，但相同的输入必会产生相同的输出。 消息摘要是单向、不可逆的。常见算法：MD5、SHA1、SHA256、SHA512。 在线加密消息摘要 public abstract class MessageDigest类为应用程序提供小弟摘要算法功能，如SHA-1、SHA-256。消息摘要是采用任意大小的数据并输出固定长度散列值得安全单向散列函数。 字符串消息摘要12345678910111213public class MD5Demo &#123; public static void main(String[] args) throws Exception&#123; // 原文 String input = \"aa\"; // 算法 String algorithm = \"MD5\"; // 获取数字摘要对象 MessageDigest messageDigest = MessageDigest.getInstance(algorithm); // 获取消息数字摘要的字节数组 byte[] bytes = messageDigest.digest(input.getBytes()); System.out.println(new String(bytes)); &#125;&#125; 如果直接输出bytes字节对象会造成以下乱码： 可以像DES一样通过Base64对乱码进行加密处理达到可视化数据的效果。 123byte[] digest = messageDigest.digest(input.getBytes());//输出：QSS8CpM1wn8IbyS6IHpJEg==System.out.println(Base64.encode(digest)); 使用在线 md5 加密 ，发现我们生成的值和代码生成的值不一样，那是因为消息摘要不是使用base64进行编码的，所以我们需要把值转成16进制 12345678910111213141516171819202122232425262728293031323334public class DigestDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"aa\"; String md5 = getDigest(input, \"MD5\"); //4124bc0a9335c27f086f24ba207a4912 System.out.println(md5); &#125; private static String toHex(byte[] digest) throws Exception &#123; StringBuilder sb = new StringBuilder(); for (byte b : digest) &#123; // 转成16进制 String s = Integer.toHexString(b &amp; 0xff); if (s.length() == 1)&#123; // 如果生成的字符只有一个，高位补0 s = \"0\"+s; &#125; sb.append(s); &#125; System.out.println(\"16进制数据的长度：\" + sb.toString().getBytes().length); return sb.toString(); &#125; private static String getDigest(String input, String algorithm) throws Exception &#123; //创建消息摘要 MessageDigest messageDigest = MessageDigest.getInstance(algorithm); // 执行消息摘要算法 byte[] digest = messageDigest.digest(input.getBytes()); System.out.println(\"密文的字节长度:\" + digest.length); return toHex(digest); &#125;&#125; 其他消息摘要： 12345678910111213141516public class DigestDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"aa\"; String md5 = getDigest(input, \"MD5\"); String sha1 = getDigest(input, \"SHA-1\"); System.out.println(sha1); String sha256 = getDigest(input, \"SHA-256\"); System.out.println(sha256); String sha512 = getDigest(input, \"SHA-512\"); System.out.println(sha512); &#125;&#125; 文件消息摘要123456789101112131415private static String getDigestFile(String filePath, String algorithm) throws Exception&#123; FileInputStream fis = new FileInputStream(filePath); int len; byte[] buffer = new byte[1024]; ByteArrayOutputStream baos = new ByteArrayOutputStream(); while ( (len = fis.read(buffer))!=-1)&#123; baos.write(buffer,0,len); &#125; // 获取消息摘要对象 MessageDigest messageDigest = MessageDigest.getInstance(algorithm); // 获取消息摘要 byte[] digest = messageDigest.digest(baos.toByteArray()); System.out.println(\"密文的字节长度：\"+digest.length); return toHex(digest); &#125; 如使用sha-1算法，可以实现秒传功能，不管咱们如何修改文件的名字，最后得到的值是一样的，如果原文修改了，那么sha-1值就会不一样。 总结： MD5算法 : 摘要结果16个字节, 转16进制后32个字节 SHA1算法 : 摘要结果20个字节, 转16进制后40个字节 SHA256算法 : 摘要结果32个字节, 转16进制后64个字节 SHA512算法 : 摘要结果64个字节, 转16进制后128个字节 非对称加密①非对称加密算法又称现代加密算法，常见算法有RSA、ECC ② 非对称加密是计算机通信安全的基石，保证了加密数据不会被破解。 ③ 与对称加密算法不同，非对称加密算法需要两个密钥：公开密钥(publickey) 和私有密钥(privatekey) ④ 公开密钥和私有密钥是一对 ⑤ 如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密。 ⑥ 如果用私有密钥对数据进行加密，只有用对应的公开密钥才能解密。 ⑦ 因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。 特点： 加密和解密使用不同的密钥 如果使用私钥加密, 只能使用公钥解密 如果使用公钥加密, 只能使用私钥解密 处理数据的速度较慢, 因为安全级别高 public abstract class KeyPairGenerator类用于生成公钥和密钥对。密钥对生成器使用getInstance工厂方法构造。 生成公钥和私钥123456789101112131415161718192021222324252627282930313233343536373839404142434445import com.sun.org.apache.xml.internal.security.utils.Base64;import javax.crypto.Cipher;import javax.crypto.spec.SecretKeySpec;import java.io.File;import java.nio.charset.Charset;import java.security.*;import java.security.spec.PKCS8EncodedKeySpec;public class RSADemo &#123; public static void main(String[] args) throws Exception &#123; // 加密算法 String algorithm = \"RSA\"; // 创建密钥对生成器对象 KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(algorithm); // 生成密钥对 KeyPair keyPair = keyPairGenerator.generateKeyPair(); // 生成私钥 PrivateKey privateKey = keyPair.getPrivate(); // 生成公钥 PublicKey publicKey = keyPair.getPublic(); // 获取私钥字节数组 byte[] privateKeyEncoded = privateKey.getEncoded(); // 获取公钥字节数组 byte[] publicKeyEncoded = publicKey.getEncoded(); // 对公私钥进行base64编码 String privateKeyString = Base64.encode(privateKeyEncoded); String publicKeyString = Base64.encode(publicKeyEncoded); // 打印私钥 System.out.println(\"私钥：\" + privateKeyString); // 打印公钥 System.out.println(\"公钥：\" + publicKeyString); String input = \"测试\"; //使用RSA私钥加密 Cipher cipher = Cipher.getInstance(algorithm); cipher.init(Cipher.ENCRYPT_MODE,privateKey); byte[] bytes = cipher.doFinal(input.getBytes()); System.out.println(\"私钥加密：\" + Base64.encode(bytes)); cipher.init(Cipher.DECRYPT_MODE,publicKey); byte[] bytes1 = cipher.doFinal(bytes); System.out.println(\"公钥解密：\" + new String(bytes1)); &#125;&#125; 必须使用私钥加密公钥解密，或者公钥加密私钥解密，若使用同一把钥匙进行加密解密时，将会出现以下错误： 保存公钥和私钥123456789101112131415161718192021222324252627282930313233public static void main(String[] args) throws Exception &#123; // 加密算法 String algorithm = \"RSA\"; //生成密钥对并保存在本地文件中 generateKeyToFile(algorithm, \"a.pub\", \"a.pri\");&#125; /** * 生成密钥对并保存在本地文件中 * * @param algorithm : 算法 * @param pubPath : 公钥保存路径 * @param priPath : 私钥保存路径 * @throws Exception */public static void generateKeyToFile(String algorithm, String pubPath, String priPath) throws Exception &#123; // 获取密钥对生成器 KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(algorithm); // 获取密钥对 KeyPair keyPair = keyPairGenerator.generateKeyPair(); // 获取公钥 PublicKey publicKey = keyPair.getPublic(); // 获取私钥 PrivateKey privateKey = keyPair.getPrivate(); // 获取byte数组 byte[] publicKeyEncoded = publicKey.getEncoded(); byte[] privateKeyEncoded = privateKey.getEncoded(); // 进行Base64编码 String publicKeyString = Base64.encode(publicKeyEncoded); String privateKeyString = Base64.encode(privateKeyEncoded); // 保存文件 FileUtils.writeStringToFile(new File(pubPath), publicKeyString, Charset.forName(\"UTF-8\")); FileUtils.writeStringToFile(new File(priPath), privateKeyString, Charset.forName(\"UTF-8\"));&#125; 读取公钥和私钥1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import com.sun.org.apache.xml.internal.security.utils.Base64;import org.apache.commons.io.FileUtils;import javax.crypto.Cipher;import javax.crypto.spec.SecretKeySpec;import java.io.File;import java.nio.charset.Charset;import java.security.*;import java.security.spec.PKCS8EncodedKeySpec;import java.security.spec.X509EncodedKeySpec;public class RSAdemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试\"; String algorithm = \"RSA\"; PrivateKey privateKey = getPrivateKey(\"a.pri\", algorithm); PublicKey publicKey = getPublicKey(\"a.pub\", algorithm); String encode = encryptRSA(algorithm, privateKey, input); String decode = decryptRSA(algorithm, publicKey, encode); System.out.println(decode); &#125; public static PublicKey getPublicKey(String pulickPath,String algorithm) throws Exception&#123; // 将文件内容转为字符串 String publicKeyString = FileUtils.readFileToString(new File(pulickPath), Charset.defaultCharset()); // 获取密钥工厂 KeyFactory keyFactory = KeyFactory.getInstance(algorithm); // 构建密钥规范 进行Base64解码 X509EncodedKeySpec spec = new X509EncodedKeySpec(Base64.decode(publicKeyString)); // 生成公钥 return keyFactory.generatePublic(spec); &#125; public static PrivateKey getPrivateKey(String priPath,String algorithm) throws Exception&#123; // 将文件内容转为字符串 String privateKeyString = FileUtils.readFileToString(new File(priPath), Charset.defaultCharset()); // 获取密钥工厂 KeyFactory keyFactory = KeyFactory.getInstance(algorithm); // 构建密钥规范 进行Base64解码 PKCS8EncodedKeySpec spec = new PKCS8EncodedKeySpec(Base64.decode(privateKeyString)); // 生成私钥 return keyFactory.generatePrivate(spec); &#125; /** * 使用公钥解密数据 * * @param algorithm : 算法 * @param encrypted : 密文 * @param key : 公钥 * @return : 原文 * @throws Exception */ public static String decryptRSA(String algorithm,Key key,String encrypted) throws Exception&#123; Cipher cipher = Cipher.getInstance(algorithm); cipher.init(Cipher.DECRYPT_MODE,key); byte[] decode = Base64.decode(encrypted); byte[] bytes = cipher.doFinal(decode); return new String(bytes); &#125; /** * 使用密钥加密数据 * * @param algorithm : 算法 * @param input : 原文 * @param key : 私钥 * @return : 密文 * @throws Exception */ public static String encryptRSA(String algorithm,Key key,String input) throws Exception&#123; Cipher cipher = Cipher.getInstance(algorithm); cipher.init(Cipher.ENCRYPT_MODE,key); byte[] bytes = cipher.doFinal(input.getBytes()); return Base64.encode(bytes); &#125;&#125; 数字签名数字签名（又称公钥数字签名）是只有信息的发送者才能产生的别人无法伪造的一段数字串，这段数字串同时也是对信息的发送者发送信息真实性的一个有效证明。它是一种类似写在纸上的普通的物理签名，但是使用了公钥加密领域的技术来实现的，用于鉴别数字信息的方法。一套数字签名通常定义两种互补的运算，一个用于签名，另一个用于验证。数字签名是非对称密钥加密技术与数字摘要技术的应用。 数字签名的含义：在网络中传输数据时候，给数据添加一个数字签名，表示是谁发的数据，而且还能证明数据没有被篡改。 数字签名的主要作用就是保证了数据的有效性（验证是谁发的）和完整性（证明信息没有被篡改）。 基本原理为了理解得清楚，我们通过案例一步一步来讲解。话说张三有俩好哥们A、B。由于工作原因，张三和AB写邮件的时候为了安全都需要加密。于是张三想到了数字签名： 整个思路是这个样子的： 第一步：加密采用非对称加密，张三有三把钥匙，两把公钥，送给朋友。一把私钥留给自己。 第二步：A或者B写邮件给张三：A先用公钥对邮件加密，然后张三收到邮件之后使用私钥解密。 第三步：张三写邮件给A或者B： （1）张三写完邮件，先用hash函数生成邮件的摘要，附着在文章上面，这就完成了数字签名，然后张三再使用私钥加密。就可以把邮件发出去了。 （2）A或者是B收到邮件之后，先把数字签名取下来，然后使用自己的公钥解密即可。这时候取下来的数字签名中的摘要若和张三的一致，那就认为是张三发来的，再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。 上面的流程我们使用一张图来演示一下： 首先把公钥送给朋友A和B： 数字证书上面提到我们对签名进行验证时，需要用到公钥。如果公钥是伪造的，那我们无法验证数字签名了，也就根本不可能从数字签名确定对方的合法性了。这时候证书就闪亮登场了。我们可能都有考各种证书的经历，比如说普通话证书，四六级证书等等，但是归根结底，到任何场合我们都能拿出我们的证书来证明自己确实已经考过了普通话，考过了四六级。这里的证书也是同样的道理。 如果不理解证书的作用，我们可以举一个例子，比如说我们的毕业证书，任何公司都会承认。为什么会承认？因为那是国家发得，大家都信任国家。也就是说只要是国家的认证机构，我们都信任它是合法的。 那么这个证书是如何生成的呢？我们再来看一张图： 网页加密我们看一个应用“数字证书”的实例：https协议。这个协议主要用于网页加密 首先，客户端向服务器发出加密请求。 服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。 客户端（浏览器）的“证书管理器”，有“受信任的根证书颁发机构”列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。 如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。 如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。 如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.security.*;import com.sun.org.apache.xml.internal.security.utils.Base64;public class SignatureDemo &#123; public static void main(String[] args) throws Exception &#123; String a = \"123\"; PrivateKey privateKey = RSADemo.getPrivateKey(\"a.pri\", \"RSA\"); PublicKey publicKey = RSADemo.getPublicKey(\"a.pub\", \"RSA\"); String signaturedData = getSignature(a, \"sha256withrsa\", privateKey); boolean b = verifySignature(a, \"sha256withrsa\", publicKey, signaturedData); &#125; /** * 生成签名 * * @param input : 原文 * @param algorithm : 算法 * @param privateKey : 私钥 * @return : 签名 * @throws Exception */ private static String getSignature(String input, String algorithm, PrivateKey privateKey) throws Exception &#123; // 获取签名对象 Signature signature = Signature.getInstance(algorithm); // 初始化签名 signature.initSign(privateKey); // 传入原文 signature.update(input.getBytes()); // 开始签名 byte[] sign = signature.sign(); // 对签名数据进行Base64编码 return Base64.encode(sign); &#125; /** * 校验签名 * * @param input : 原文 * @param algorithm : 算法 * @param publicKey : 公钥 * @param signaturedData : 签名 * @return : 数据是否被篡改 * @throws Exception */ private static boolean verifySignature(String input, String algorithm, PublicKey publicKey, String signaturedData) throws Exception &#123; // 获取签名对象 Signature signature = Signature.getInstance(algorithm); // 初始化签名 signature.initVerify(publicKey); // 传入原文 signature.update(input.getBytes()); // 校验数据 return signature.verify(Base64.decode(signaturedData)); &#125;&#125; keytool工具keytool工具路径：C:\\Program Files\\Java\\jre1.8.0_91\\bin 常用命令：生成keypair： 12keytool -genkeypairkeytool -genkeypair -alias lisi（后面部分是为证书指定别名，否则采用默认的名称为mykey） 看看keystore中有哪些项目： 12keytool -list 或 keytool -list -vkeytool -exportcert -alias lisi -file lisi.cer 生成可打印的证书： 1keytool -exportcert -alias lisi -file lisi.cer –rfc 显示数字证书文件中的证书信息： 1keytool -printcert -file lisi.cer 直接双击lisi.cer，用window系统的内置程序打开lisi.cer 生成私钥公钥（1）生成密钥证书 下边命令生成密钥证书，采用RSA 算法每个证书包含公钥和私钥 创建一个文件夹，在该文件夹下执行如下命令行： 1keytool -genkeypair -alias midkuro -keyalg RSA -keypass midkuro -keystore midkuro.jks -storepass midkuro Keytool是一个java提供的证书管理工具 12345-alias：密钥的别名 -keyalg：使用的hash算法 -keypass：密钥的访问密码 -keystore：密钥库文件名，xc.keystore保存了生成的证书 -storepass：密钥库的访问密码 （2）查询证书信息 1keytool -list -keystore migkuro.jks （3）删除别名 1keytool -delete -alias midkuro -keystore midkuro.jks 导出公钥openssl是一个加解密工具包，这里使用openssl来导出公钥信息。 安装 openssl，安装资料目录下的Win64OpenSSL-1_1_0g.exe 配置openssl的path环境变量，如下图： 本教程配置在C:\\OpenSSL-Win64\\bin cmd进入midkuro.jks文件所在目录执行如下命令（如下命令在windows下执行，会把-变成中文方式，请将它改成英文的-）： 1keytool -list -rfc --keystore midkuro.jks | openssl x509 -inform pem -pubkey 下面段内容是公钥： 123456789-----BEGIN PUBLIC KEY-----MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvFsEiaLvij9C1Mz+oyAmt47whAaRkRu&#x2F;8kePM+X8760UGU0RMwGti6Z9y3LQ0RvK6I0brXmbGB&#x2F;RsN38PVnhcP8ZfxGUH26kX0RK+tlrxcrG+HkPYOH4XPAL8Q1lu1n9x3tLcIPxq8ZZtuIyKYEmoLKyMsvTviG5flTpDprT25unWgE4md1kthRWXOnfWHATVY7Y&#x2F;r4obiOL1mS5bEa&#x2F;iNKotQNnvIAKtjBM4RlIDWMa6dmz+lHtLtqDD2LF1qwoiSIHI75LQZ&#x2F;CNYaHCfZSxtOydpNKq8eb1&#x2F;PGiLNolD4La2zf0&#x2F;1dlcr5mkesV570NxRmU1tFm8Zd3MZlZmyv9QIDAQAB-----END PUBLIC KEY----- 将上边的公钥拷贝到文本public.key文件中，合并为一行,可以将它放到需要实现授权认证的工程中。","categories":[{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.gitee.io/categories/Cryptography/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.gitee.io/tags/Cryptography/"}]},{"title":"'Java 密码学 对称加密'","slug":"cryptography-symmetrical","date":"2020-05-29T13:00:00.000Z","updated":"2020-11-13T05:52:19.394Z","comments":true,"path":"2020/05/29/cryptography-symmetrical/","link":"","permalink":"https://midkuro.gitee.io/2020/05/29/cryptography-symmetrical/","excerpt":"","text":"密码学Byte和BitByte : 字节. 数据存储的基本单位，比如移动硬盘1T ， 单位是byte bit : 比特, 又叫位. 一个位要么是0要么是1. 数据传输的单位 , 比如家里的宽带100MB，下载速度并没有达到100MB，一般都是12-13MB，那么是因为需要使用 100 / 8 关系: 1Byte = 8bit 英文对应的字节1234567891011121314public class ByteBit &#123; public static void main(String[] args) &#123; String a = \"a\"; byte[] bytes = a.getBytes(); for (byte b : bytes) &#123; int c=b; // 打印发现byte实际上就是ascii码 System.out.println(c); //97 // 我们在来看看每个byte对应的bit，byte获取对应的bit String s = Integer.toBinaryString(c); System.out.println(s); //1100001 &#125; &#125;&#125; 打印英文字符串的字节，实际打印的就是ascii编码！ 中文对应的字节1234567891011public class ByteBitDemo &#123; public static void main(String[] args) throws Exception&#123; String a = \"尚\"; byte[] bytes = a.getBytes(); for (byte b : bytes) &#123; System.out.print(b + \" \"); String s = Integer.toBinaryString(b); System.out.println(s); &#125; &#125;&#125; 在编码UTF-8的中，一个中文是由三个字节组成的！ 12345678910111213public static void main(String[] args) throws Exception&#123; String a = \"尚\"; // 在中文情况下，不同的编码格式，对应不同的字节 //GBK :编码格式占2个字节 // UTF-8：编码格式占3个字节 byte[] bytes = a.getBytes(\"GBK\"); // byte[] bytes = a.getBytes(\"UTF-8\"); for (byte b : bytes) &#123; System.out.print(b + \" \"); String s = Integer.toBinaryString(b); System.out.println(s); &#125;&#125; 在编码GBK的中，一个中文是由两个字节组成的！在UTF-8编码格式中，一个中文由占3个字节组成。 常见加密 采用单钥密码系统的加密方法，同一个密钥可以同时用作信息的加密和解密，这种加密方法称为对称加密，也称为单密钥加密。 示例： 我们现在有一个原文3要发送给B 设置密钥为108, 3 * 108 = 324, 将324作为密文发送给B B拿到密文324后, 使用324/108 = 3 得到原文 常见加密算法： DES : Data Encryption Standard，即数据加密标准，是一种使用密钥加密的块算法，1977年被美国联邦政府的国家标准局确定为联邦资料处理标准（FIPS），并授权在非密级政府通信中使用，随后该算法在国际上广泛流传开来。 AES : Advanced Encryption Standard, 高级加密标准 .在密码学中又称Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。 特点： 加密速度快, 可以加密大文件 密文可逆, 一旦密钥文件泄漏, 就会导致数据暴露 加密后Ascii编码表找不到对应字符, 会出现乱码 一般结合Base64使用 Base64Base64是网络上最常见的用于传输8Bit字节码的可读性编码算法之一，可读性编码算法不是为了保护数据的安全性，而是为了可读性，可读性编码不改变信息内容，只改变信息内容的表现形式。 所谓Base64，即是说在编码过程中使用了64种字符： ① 小写 a - z = 26个字母 ② 大写 A - Z = 26个字母 ③ 数字 0 - 9 = 10 个数字 ④ + / = 2个符号 Base58是Bitcoin(比特币)中使用的一种编码方式，主要用于产生Bitcoin的钱包地址，相比Base64，Base58不使用数字”0”，字母大写”O”，字母大写”I”，和字母小写”i”，以及”+”和”/“符号。 base64 是 3个字节为一组，一个字节 8位，一共 就是24位 ，然后，把3个字节转成4组，每组6位 3 * 8 = 4 * 6 = 24 ，每组6位，缺少的2位，会在高位进行补0，这样做的好处在于 ，base取的是后面6位，去掉高2位 ，那么Base64的取值就可以控制在0-63位了，所以就叫base64，111 111 = 32 + 16 + 8 + 4 + 2 + 1 = 63 可能发现一个问题，base64加密后有个=号，但是在映射表里面没有发现 =号 ， 这个地方需要注意，等号非常特殊，因为base64是三个字节一组 ，如果当我们的位数不够的时候，会使用等号来补齐。 123456789101112import com.sun.org.apache.xerces.internal.impl.dv.util.Base64;public class TestBase64 &#123; public static void main(String[] args) &#123; // 1表示一个字节，不够三个字节，所以需要后面通过 == 号补齐 System.out.println(Base64.encode(\"1\".getBytes())); //MQ== System.out.println(Base64.encode(\"12\".getBytes())); //MTI= System.out.println(Base64.encode(\"123\".getBytes())); //MTIz // 测试:中文(UTF-8)占6个字节，6 * 8 = 48 ，刚刚好被整除，所以没有等号 System.out.println(Base64.encode(\"测试\".getBytes())); //5rWL6K+V &#125;&#125; Base64的相关包默认使用apache提供的即可，不同的依赖包，提供的API略有不同。 在Eclipse中，可以使用import org.apache.tomcat.util.codec.binary.Base64;， 在Idea中，可以使用import com.sun.org.apache.xerces.internal.impl.dv.util.Base64; DES加密Cipher文档 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import javax.crypto.Cipher;import javax.crypto.spec.SecretKeySpec;import org.apache.tomcat.util.codec.binary.Base64;public class DesDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试测试\"; // 密钥 String key = \"12345678\"; // 加密算法 String transformation = \"DES\"; // 算法类型 String algorithm = \"DES\"; System.out.println(\"原文：\" + input); String encryptDes = encryptDes(input, key, transformation, algorithm); System.out.println(\"加密：\" + encryptDes); String decryptDes = decryptDes(encryptDes, key, transformation, algorithm); System.out.println(\"解密：\" + decryptDes); &#125; /** * 加密算法 * * @param input 原文 * @param key 密钥 * @param transformation 算法 * @param algorithm 加密类型 * @return * @throws Exception */ public static String encryptDes(String input, String key, String transformation, String algorithm) throws Exception &#123; // 获取加密对象 Cipher cipher = Cipher.getInstance(transformation); // 创建加密规则 第一个参数key的字节 第二个参数表示加密算法 SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(), algorithm); // 初始化加密模式和算法 Cipher.ENCRYPT_MODE:加密模式 cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec); // 加密 byte[] bytes = cipher.doFinal(input.getBytes()); // 输出加密后的数据 return Base64.encodeBase64String(bytes); &#125; /** * 解密算法 * * @param encryptDes 密文 * @param key 密钥 * @param transformation 加密算法 * @param algorithm 加密类型 * @return * @throws Exception */ public static String decryptDes(String encryptDes, String key, String transformation, String algorithm) throws Exception &#123; Cipher cipher = Cipher.getInstance(transformation); SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(), algorithm); // Cipher.DECRYPT_MODE:解密模式 cipher.init(Cipher.DECRYPT_MODE, secretKeySpec); byte[] bytes = cipher.doFinal(Base64.decodeBase64(encryptDes)); return new String(bytes); &#125;&#125; DES规定密钥key必定是8个字节，如果加密算法的key不足8个字节时，如key=123456 将会出现以下错误： 1234567byte[] bytes = cipher.doFinal(input.getBytes());for (byte b : bytes) &#123; //会打印出负数 System.out.println(b); &#125;//会出现乱码System.out.println(new String(bytes)); 当在加密的过程中执行上述代码，以字符串的形式直接输出加密后的bytes数组，会出现，将会出现以下错误： 出现乱码是因为对应的字节出现负数，但负数，没有出现在 ascii 码表里面，所以常使用base64配合转码！ 123byte[] bytes = cipher.doFinal(input.getBytes());//使用Base64配合输出System.out.println(Base64.encodeBase64String(bytes)); AES加密AES 加密解密和 DES 加密解密代码一样，只需要修改加密算法就行，可以直接拷贝 DSC 加解密代码。 12345678910111213public class AesDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试测试\"; //AES加密算法，比较高级，所以key的大小必须是16个字节 String key = \"1234567812345678\"; String transformation = \"AES\"; String algorithm = \"AES\"; String encryptDes = encryptDes(input, key, transformation, algorithm); //d+tFlhF2ISyzd725BV0bRg== System.out.println(\"加密：\" + encryptDes); &#125;&#125; AES比DES要高级，所以Key的大小必须是16个字节，如果依旧使用8个字节，将会遇见以下错误： 加密模式加密模式：https://docs.oracle.com/javase/8/docs/api/javax/crypto/Cipher.html ECBECB : Electronic codebook, 电子密码本. 需要加密的消息按照块密码的块大小被分为数个块，并对每个块进行独立加密。 优缺点： 优点 : 可以并行处理数据 缺点 : 同样的原文生成同样的密文, 不能很好的保护数据 CBCCBC : Cipher-block chaining, 密码块链接. 每个明文块先与前一个密文块进行异或后，再进行加密。在这种方法中，每个密文块都依赖于它前面的所有明文块。 优缺点： 优点 : 同样的原文生成的密文不一样，加密很安全 缺点 : 串行处理数据，加密速度很慢 填充模式当需要按块处理的数据, 数据长度不符合块处理需求时, 按照一定的方法填充满块长的规则。 NoPadding不填充，在DES加密算法下, 要求原文长度必须是8byte的整数倍，在AES加密算法下, 要求原文长度必须是16byte的整数倍。 PKCS5Padding数据块的大小为8位, 不够就补足 Tips： 如果没有写加密模式和填充模式，则默认使用的加 密模式和填充模式为 : ECB/PKCS5Padding 如果使用CBC模式, 在初始化Cipher对象时, 需要增加参数, 初始化向量IV : IvParameterSpec iv = new IvParameterSpec(key.getBytes()); 加密模式和填充模式 123456789101112131415AES/CBC/NoPadding (128)AES/CBC/PKCS5Padding (128)AES/ECB/NoPadding (128)AES/ECB/PKCS5Padding (128)DES/CBC/NoPadding (56)DES/CBC/PKCS5Padding (56)DES/ECB/NoPadding (56)DES/ECB/PKCS5Padding (56)DESede/CBC/NoPadding (168)DESede/CBC/PKCS5Padding (168)DESede/ECB/NoPadding (168)DESede/ECB/PKCS5Padding (168)RSA/ECB/PKCS1Padding (1024, 2048)RSA/ECB/OAEPWithSHA-1AndMGF1Padding (1024, 2048)RSA/ECB/OAEPWithSHA-256AndMGF1Padding (1024, 2048) ECB案例： 12345678910111213import org.apache.tomcat.util.codec.binary.Base64;public class DesDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试测试\"; String key = \"12345678\"; //加密算法/加密模式/填充模式 String transformation = \"DES/ECB/PKCS5Padding\"; String algorithm = \"DES\"; String encryptDes = encryptDes(input, key, transformation, algorithm); System.out.println(\"加密：\" + encryptDes); &#125;&#125; CBC案例： 12345678910111213141516171819202122//在加密模式为CBC下需要增加IV向量public static String encryptDes(String input, String key, String transformation, String algorithm) throws Exception &#123; Cipher cipher = Cipher.getInstance(transformation); SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(), algorithm); //增加iv向量 IvParameterSpec iv = new IvParameterSpec(key.getBytes()); //传参Iv对象 cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec, iv); byte[] bytes = cipher.doFinal(input.getBytes()); return Base64.encodeBase64String(bytes);&#125;public static String decryptDes(String encryptDes, String key, String transformation, String algorithm) throws Exception &#123; Cipher cipher = Cipher.getInstance(transformation); SecretKeySpec secretKeySpec = new SecretKeySpec(key.getBytes(), algorithm); //增加iv向量 IvParameterSpec iv = new IvParameterSpec(key.getBytes()); //传参Iv对象 cipher.init(Cipher.DECRYPT_MODE, secretKeySpec,iv); byte[] bytes = cipher.doFinal(Base64.decodeBase64(encryptDes)); return new String(bytes);&#125; NoPadding案例： 12345678910111213import org.apache.tomcat.util.codec.binary.Base64;public class DesDemo &#123; public static void main(String[] args) throws Exception &#123; String input = \"测试12\"; String key = \"12345678\"; //加密算法/加密模式/填充模式 String transformation = \"DES/ECB/NoPadding\"; String algorithm = \"DES\"; String encryptDes = encryptDes(input, key, transformation, algorithm); System.out.println(\"加密：\" + encryptDes); &#125;&#125; 使用不填充模式Nopadding时，加密的文本必须是8个字节的倍数，若上述的input = &quot;测试&quot;,只有6个字节时（UTF-8下），将会出现以下错误： 值得一提的是，在使用iv向量进行加密时，加密的key也必须是8个字节的倍数！","categories":[{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.gitee.io/categories/Cryptography/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.gitee.io/tags/Cryptography/"}]},{"title":"'Java 密码学 基本概念'","slug":"cryptography-base","date":"2020-05-29T04:00:00.000Z","updated":"2020-11-13T05:52:38.016Z","comments":true,"path":"2020/05/29/cryptography-base/","link":"","permalink":"https://midkuro.gitee.io/2020/05/29/cryptography-base/","excerpt":"","text":"密码学密码学基本概念密码在我们的生活中有着重要的作用，那么密码究竟来自何方，为何会产生呢？ 密码学是网络安全、信息安全、区块链等产品的基础，常见的非对称加密、对称加密、散列函数等，都属于密码学范畴。 密码学有数千年的历史，从最开始的替换法到如今的非对称加密算法，经历了古典密码学，近代密码学和现代密码学三个阶段。密码学不仅仅是数学家们的智慧，更是如今网络空间安全的重要基础。 古典密码学在古代的战争中，多见使用隐藏信息的方式保护重要的通信资料。比如先把需要保护的信息用化学药水写到纸上，药水干后，纸上看不出任何的信息，需要使用另外的化学药水涂抹后才可以阅读纸上的信息。 这些方法都是在保护重要的信息不被他人获取，但藏信息的方式比较容易被他人识破，例如增加哨兵的排查力度，就会发现其中的猫腻，因而随后发展出了较难破解的古典密码学。 替换法替换法很好理解，就是用固定的信息将原文替换成无法直接阅读的密文信息。例如将 b 替换成 w ，e 替换成p ，这样bee 单词就变换成了wpp，不知道替换规则的人就无法阅读出原文的含义。 替换法有单表替换和多表替换两种形式。单表替换即只有一张原文密文对照表单，发送者和接收者用这张表单来加密解密。在上述例子中，表单即为：a b c d e - s w t r p 。 多表替换即有多张原文密文对照表单，不同字母可以用不同表单的内容替换。 例如约定好表单为：表单 1：abcde-swtrp 、表单2：abcde-chfhk 、表单 3：abcde-jftou。 规定第一个字母用第三张表单，第二个字母用第一张表单，第三个字母用第二张表单，这时 bee单词就变成了 (312)fpk ，破解难度更高，其中 312 又叫做密钥，密钥可以事先约定好，也可以在传输过程中标记出来。 移位法移位法就是将原文中的所有字母都在字母表上向后（或向前）按照一个固定数目进行偏移后得出密文，典型的移位法应用有 “ 恺撒密码 ”。 例如约定好向后移动2位（abcde - cdefg），这样 bee 单词就变换成了dgg。 同理替换法，移位法也可以采用多表移位的方式，典型的多表案例是“维尼吉亚密码”（又译维热纳尔密码），属于多表密码的一种形式。 古典密码破解方式古典密码虽然很简单，但是在密码史上是使用的最久的加密方式，直到“概率论”的数学方法被发现，古典密码就被破解了。 英文单词中字母出现的频率是不同的，e以12.702%的百分比占比最高，z 只占到0.074%，感兴趣的可以去百科查字母频率详细统计数据。如果密文数量足够大，仅仅采用频度分析法就可以破解单表的替换法或移位法。 多表的替换法或移位法虽然难度高一些，但如果数据量足够大的话，也是可以破解的。以维尼吉亚密码算法为例，破解方法就是先找出密文中完全相同的字母串，猜测密钥长度，得到密钥长度后再把同组的密文放在一起，使用频率分析法破解。 近代密码学古典密码的安全性受到了威胁，外加使用便利性较低，到了工业化时代，近现代密码被广泛应用。 恩尼格玛机是二战时期纳粹德国使用的加密机器，后被英国破译，参与破译的人员有被称为计算机科学之父、人工智能之父的图灵。 恩尼格玛机使用的加密方式本质上还是移位和替代，只不过因为密码表种类极多，破解难度高，同时加密解密机器化，使用便捷，因而在二战时期得以使用。 现代密码学散列函数散列函数，也叫杂凑函数、摘要函数或哈希函数，可将任意长度的消息经过运算，变成固定长度数值，常见的有MD5、SHA-1、SHA256，多应用在文件校验，数字签名中。 MD5 可以将任意长度的原文生成一个128位（16字节）的哈希值 SHA-1可以将任意长度的原文生成一个160位（20字节）的哈希值 对称密码对称密码应用了相同的加密密钥和解密密钥。对称密码分为：序列密码(流密码)，分组密码(块密码)两种。流密码是对信息流中的每一个元素（一个字母或一个比特）作为基本的处理单元进行加密，块密码是先对信息流分块，再对每一块分别加密。 例如原文为1234567890，流加密即先对1进行加密，再对2进行加密，再对3进行加密……最后拼接成密文；块加密先分成不同的块，如1234成块，5678成块，90XX(XX为补位数字)成块，再分别对不同块进行加密，最后拼接成密文。前文提到的古典密码学加密方法，都属于流加密。 非对称密码对称密码的密钥安全极其重要，加密者和解密者需要提前协商密钥，并各自确保密钥的安全性，一但密钥泄露，即使算法是安全的也无法保障原文信息的私密性。 在实际的使用中，远程的提前协商密钥不容易实现，即使协商好，在远程传输过程中也容易被他人获取，因此非对称密钥此时就凸显出了优势。 非对称密码有两支密钥，公钥（publickey）和私钥（privatekey），加密和解密运算使用的密钥不同。用公钥对原文进行加密后，需要由私钥进行解密；用私钥对原文进行加密后（此时一般称为签名），需要由公钥进行解密（此时一般称为验签）。公钥可以公开的，大家使用公钥对信息进行加密，再发送给私钥的持有者，私钥持有者使用私钥对信息进行解密，获得信息原文。因为私钥只有单一人持有，因此不用担心被他人解密获取信息原文。 如何设置密码才安全 密码不要太常见，不要使用类似于123456式的常用密码。 各应用软件密码建议不同，避免出现一个应用数据库被脱库，全部应用密码崩塌， 可在设置密码时增加注册时间、注册地点、应用特性等方法。例如tianjin123456，表示在天津注册的该应用。 ASCII编码ASCII（American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统，主要用于显示现代英语和其他西欧语言。它是现今最通用的单字节编码系统，并等同于国际标准ISO/IEC 646。 创建Maven项目，添加pom.xml依赖 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 12345678910111213141516public class AsciiDemo &#123; public static void main(String[] args) &#123; char a = 'A'; int b = a; // 打印ascii码 System.out.println(b); //65 String a = \"AaZ\"; // 获取ascii码，需要把字符串转成字符 char[] chars = a.toCharArray(); for (char c : chars) &#123; int asciiCode = c; System.out.println(asciiCode); //65 97 90 &#125; &#125;&#125; 恺撒加密凯撒密码在密码学中，恺撒密码是一种最简单且最广为人知的加密技术。 凯撒密码最早由古罗马军事统帅盖乌斯·尤利乌斯·凯撒在军队中用来传递加密信息，故称凯撒密码。这是一种位移加密方式，只对26个字母进行位移替换加密，规则简单，容易破解。下面是位移1次的对比： 将明文字母表向后移动1位，A变成了B，B变成了C……，Z变成了A。同理，若将明文字母表向后移动3位： 则A变成了D，B变成了E……，Z变成了C。 字母表最多可以移动25位。凯撒密码的明文字母表向后或向前移动都是可以的，通常表述为向后移动，如果要向前移动1位，则等同于向后移动25位，位移选择为25即可。 它是一种替换加密的技术，明文中的所有字母都在字母表上向后（或向前）按照一个固定数目进行偏移后被替换成密文。 例如，当偏移量是3的时候，所有的字母A将被替换成D，B变成E，以此类推。 这个加密方法是以恺撒的名字命名的，当年恺撒曾用此方法与其将军们进行联系。 恺撒密码通常被作为其他更复杂的加密方法中的一个步骤。 简单来说就是当秘钥为n，其中一个待加密字符ch，加密之后的字符为ch+n，当ch+n超过’z’时，回到’a’计数。 凯撒位移加密123456789101112131415161718192021//把 hello world 往右边移动3位public class KaiserDemo &#123; public static void main(String[] args) &#123; String input = \"Hello world\"; // 往右边移动3位 int key = 3; // 用来拼接 StringBuilder sb = new StringBuilder(); // 字符串转换成字节数组 char[] chars = input.toCharArray(); for (char c : chars) &#123; int asciiCode = c; // 移动3位 asciiCode = asciiCode + key; char newChar = (char) asciiCode; sb.append(newChar); &#125; System.out.println(sb.toString()); //khoor#zruog &#125;&#125; 凯撒加密和解密12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class KaiserDemo &#123; public static void main(String[] args) &#123; String orignal = \"Hello world\"; // 往右边偏移三位 int key = 3; // 选中我即将抽取的代码，按快捷键Ctrl + Alt + M String encryptKaiser = encryptKaiser(orignal,key); System.out.println(\"加密：\" + encryptKaiser); String decryptKaiser = decryptKaiser(encryptKaiser,key); System.out.println(\"解密：\" + decryptKaiser); &#125; /** * 使用凯撒加密方式解密数据 * * @param encryptedData :密文 * @param key :密钥 * @return : 源数据 */ public static String decryptKaiser(String encryptedData, int key) &#123; // 将字符串转为字符数组 char[] chars = encryptedData.toCharArray(); StringBuilder sb = new StringBuilder(); for (char aChar : chars) &#123; // 获取字符的ASCII编码 int asciiCode = aChar; // 偏移数据 asciiCode -= key; // 将偏移后的数据转为字符 char result = (char) asciiCode; // 拼接数据 sb.append(result); &#125; return sb.toString(); &#125; /** * 使用凯撒加密方式加密数据 * * @param orignal :原文 * @param key :密钥 * @return :加密后的数据 */ public static String encryptKaiser(String orignal, int key) &#123; // 将字符串转为字符数组 char[] chars = orignal.toCharArray(); StringBuilder sb = new StringBuilder(); for (char aChar : chars) &#123; // 获取字符的ascii编码 int asciiCode = aChar; // 偏移数据 asciiCode += key; // 将偏移后的数据转为字符 char result = (char) asciiCode; // 拼接数据 sb.append(result); &#125; return sb.toString(); &#125;&#125; 频度分析法加密者选择将组成信息的字母替代成别的字母，比如说将a写成1，这样就不能被解密者直接拿到信息了。 这难不倒解密者，以英文字母为例，为了确定每个英文字母的出现频率，分析一篇或者数篇普通的英文文章，英文字母出现频率最高的是e，接下来是t，然后是a……，然后检查要破解的密文，也将每个字母出现的频率整理出来，假设密文中出现频率最高的字母是j，那么就可能是e的替身，如果密码文中出现频率次高的但是P，那么可能是t的替身，以此类推便就能解开加密信息的内容。这就是频率分析法。 将明文字母的出现频率与密文字母的频率相比较的过程 通过分析每个符号出现的频率而轻易地破译代换式密码 在每种语言中，冗长的文章中的字母表现出一种可对之进行分辨的频率。 e是英语中最常用的字母，其出现频率为八分之一 运行计算article.txt文本中各个符号的出现次数，如下： 然后对该文本进行位移3位，得到密文报，并在此统计密文的符号出现次数： 运行结果 # 出现次数最多， 我们知道在英文当中 e 出现的频率是最高的，我们假设现在 # 号，就是 e ，变形而来的 ，我们可以对照 ascii 编码表 ，我们的凯撒加密当中位移是加了一个 key ，所以我们 猜测 两个值直接相差 -66 ，我们现在就以 -66 进行解密 生成一个文件，我们查看第一个文件发现，根本读不懂，所以解密失败，我们在猜测 h 是 e ，h 和 e 之间相差3 ，所以我们在去看第二个解密文件，发现我们可以读懂，解密成功。","categories":[{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.gitee.io/categories/Cryptography/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.gitee.io/tags/Cryptography/"}]},{"title":"'NIO New IO/Non-Blocking IO'","slug":"java-nio","date":"2020-05-28T03:00:00.000Z","updated":"2020-05-28T12:14:20.435Z","comments":true,"path":"2020/05/28/java-nio/","link":"","permalink":"https://midkuro.gitee.io/2020/05/28/java-nio/","excerpt":"","text":"NIONIO的简介Java NIO（New IO）是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面向缓冲区的、基于通道的IO操作。NIO将以更加高效的方式进行文件的读写操作。 与IO的区别 IO NIO 面向流(Stream Oriented) 面向缓冲区(Buffer Oriented) 阻塞IO(Blocking IO) 非阻塞IO(Non Blocking IO) (无) 选择器(Selectors) 传统IO是通过建立管道，把数据以流的方式发送，类似于生活中的水流，并且是单向传输。 而NIO是通过创建一条通道，文件传输的对端通过把文件内容存储在缓冲区中，发送到另一端后，另一端从缓冲区中读取内容，通道类似于生活中的火车轨道，它不具备存储功能，它只负责传输，而缓冲区则负责存储。 通道和缓冲区Java NIO系统的核心在于：通道(Channel)和缓冲区(Buffer)。通道表示打开到 IO 设备(例如：文件、套接字)的连接。若需要使用 NIO 系统，需要获取用于连接 IO 设备的通道以及用于容纳数据的缓冲区。然后操作缓冲区，对数据进行处理。 简而言之，Channel 负责传输，Buffer 负责存储。 缓冲区缓冲区（Buffer）：在 Java NIO 中负责数据的存取。缓冲区就是数组。用于存储不同数据类型的数据。 缓冲区（Buffer）：一个用于特定基本数据类型的容器。由 java.nio 包定义的，所有缓冲区都是 Buffer 抽象类的子类。Java NIO 中的 Buffer 主要用于与NIO 通道进行交互，数据是从通道读入缓冲区，从缓冲区写入通道中的。 Buffer 就像一个数组，可以保存多个相同类型的数据。根据数据类型不同(boolean 除外) ，有以下 Buffer 常用子类：ByteBuffer、CharBuffer、ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。 上述 Buffer 类 他们都采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。都是通过如下方法获取一个 Buffer对象： 123456//创建一个容量为 capacity 的 ByteBuffer 对象方法 public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity);&#125; 属性Buffer 中的重要概念： 容量 (capacity) ：表示 Buffer 最大数据容量，缓冲区容量不能为负，并且创建后不能更改。 限制 (limit)：第一个不应该读取或写入的数据的索引，即位于limit 后的数据不可读写。缓冲区的限制不能为负，并且不能大于其容量。 位置 (position)：下一个要读取或写入的数据的索引。缓冲区的位置不能为负，并且不能大于其限制 标记 (mark)与重置 (reset)：标记是一个索引，通过 Buffer 中的mark() 方法指定 Buffer 中一个特定的 position，之后可以通过调用 reset()方法恢复到这个 position。 标记、位置、限制、容量遵守以下不变式： 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity。 方法 描述 Buffer clear() 清空缓冲区并返回对缓冲区的引用 Buffer flip() 将缓冲区的界限设置为当前位置，并将当前位置重置为 0 int capacity() 返回 Buffer 的 capacity 大小 boolean hasRemaining() 判断缓冲区中是否还有元素 int limit() 返回 Buffer 的界限(limit) 的位置 Buffer limit(int n) 将设置缓冲区界限为 n, 并返回 Buffer mark() 对缓冲区设置标记 int position() 返回缓冲区的当前位置 position Buffer position(int n) 将设置缓冲区的当前位置为 n , 并返回修改后的 Buffer 对象 int remaining() 返回 position 和 limit 之间的元素个数 Buffer reset() 将位置 position 转到以前设置的 mark 所在的位置 Buffer rewind() 将位置设为 0， 取消设置的 mark Buffer 所有子类提供了两个用于数据操作的方法：get() 与 put() 方法 获取 Buffer 中的数据 get() ：读取单个字节 get(byte[] dst)：批量读取多个字节到 dst 中 get(int index)：读取指定索引位置的字节(不会移动 position) 放入数据到 Buffer 中 put(byte b)：将给定单个字节写入缓冲区的当前位置 put(byte[] src)：将 src 中的字节写入缓冲区的当前位置 put(int index, byte b)：将指定字节写入缓冲区的索引位置(不会移动 position) 案例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Testpublic void test1() &#123; String str = \"abcde\"; //1. 分配一个指定大小的缓冲区 ByteBuffer buf = ByteBuffer.allocate(1024); System.out.println(\"-----------------allocate()----------------\"); System.out.println(buf.position());//0 System.out.println(buf.limit());//1024 System.out.println(buf.capacity());//1024 //2. 利用 put() 存入数据到缓冲区中 buf.put(str.getBytes()); System.out.println(\"-----------------put()----------------\"); System.out.println(buf.position());//5 System.out.println(buf.limit());//1024 System.out.println(buf.capacity());//1024 //3. 切换读取数据模式 buf.flip(); System.out.println(\"-----------------flip()----------------\"); System.out.println(buf.position());//0 System.out.println(buf.limit());//5 System.out.println(buf.capacity());//1024 //4. 利用 get() 读取缓冲区中的数据 byte[] dst = new byte[buf.limit()]; buf.get(dst); System.out.println(new String(dst, 0, dst.length));//abcde System.out.println(\"-----------------get()----------------\"); System.out.println(buf.position()); //5 System.out.println(buf.limit());//5 System.out.println(buf.capacity());//1024 //5. rewind() : 可重复读 buf.rewind(); System.out.println(\"-----------------rewind()----------------\"); System.out.println(buf.position());//0 System.out.println(buf.limit());//5 System.out.println(buf.capacity());//1024 //6. clear() : 清空缓冲区. 但是缓冲区中的数据依然存在，但是处于“被遗忘”状态 buf.clear(); System.out.println(\"-----------------clear()----------------\"); System.out.println(buf.position());//0 System.out.println(buf.limit());//1024 System.out.println(buf.capacity());//1024 System.out.println((char)buf.get());//a&#125; 123456789101112131415161718192021222324252627282930@Testpublic void test2()&#123; String str = \"abcde\"; ByteBuffer buf = ByteBuffer.allocate(1024); buf.put(str.getBytes()); buf.flip(); byte[] dst = new byte[buf.limit()]; buf.get(dst, 0, 2); System.out.println(new String(dst, 0, 2));//ab System.out.println(buf.position());//2 //mark() : 标记 buf.mark(); buf.get(dst, 2, 2); System.out.println(new String(dst, 2, 2));//cd System.out.println(buf.position());4 //reset() : 恢复到 mark 的位置 buf.reset(); System.out.println(buf.position());//2 //判断缓冲区中是否还有剩余数据 if(buf.hasRemaining())&#123; //获取缓冲区中可以操作的数量 System.out.println(buf.remaining());//3 &#125;&#125; 字节缓冲区字节缓冲区（ByteBuffer）比较特殊，它能够创建两种类型的缓冲区，分别是直接缓冲区和非直接缓冲区。直接缓冲区通过API的allocateDirect（）方法创建，而非直接缓冲区则是平时使用的allocate()方法。 非直接缓冲区 正常情况下，应用程序都是在操作系统上的用户地址空间，俗称用户空间，我们的IO请求都是需要先经过用户空间，用户空间向内核空间发起IO请求，内核空间去物理磁盘加载数据，然后内核空间将加载后的数据拷贝到用户空间，用户空间才将数据返回给应用程序，也就是说，非直接缓冲区都需要经过一次数据从内核空间拷贝到用户空间的一个过程。 直接缓冲区 当使用直接缓冲区时， Java 虚拟机会尽最大努力直接在此缓冲区上执行本机IO 操作。也就是说，在每次调用基础操作系统的一个本机 I/O 操作之前（或之后），虚拟机都会尽量避免将缓冲区的内容复制到中间缓冲区中（或从中间缓冲区中复制内容）。 直接字节缓冲区可以通过调用此类的allocateDirect()工厂方法来创建。此方法返回的缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不明显。 直接缓冲区有一个很严重的劣势，就是当应用程序把数据存放到直接缓冲区时，它什么时候向物理磁盘触发IO操作是无法控制被应用程序控制的，它是由操作系统掌控的。 并且响应结果到应用程序的效率不固定，很有可能出现磁盘IO操作已经完成，但是应用程序尚未得到回应，导致内存数据无法被释放，当大规模的并发产生时，它带来的影响是致命的，但是不可否认的是，即时它短时间内未响应，效率也依旧比非直接缓冲区快！ 所以，建议将直接缓冲区主要分配给那些易受基础系统的本机 I/O 操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处时分配它们。 直接字节缓冲区还可以通过 FileChannel的map()方法将文件区域直接映射到内存中来创建。该方法返回MappedByteBuffer 。 如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或稍后的某个时间导致抛出不确定的异常。 123456@Testpublic void test3() &#123; //分配直接缓冲区 ByteBuffer buf = ByteBuffer.allocateDirect(1024); System.out.println(buf.isDirect()); //true&#125; 判断字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其 isDirect() 方法来确定。提供此方法是为了能够在性能关键型代码中执行显式缓冲区管理。 1234567891011121314151617181920212223//使用直接缓冲区完成文件的复制(内存映射文件)@Testpublic void test4() throws IOException&#123; long start = System.currentTimeMillis(); FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"2.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE); //内存映射文件 MappedByteBuffer inMappedBuf = inChannel.map(MapMode.READ_ONLY, 0, inChannel.size()); MappedByteBuffer outMappedBuf = outChannel.map(MapMode.READ_WRITE, 0, inChannel.size()); //直接对缓冲区进行数据的读写操作 byte[] dst = new byte[inMappedBuf.limit()]; inMappedBuf.get(dst); outMappedBuf.put(dst); inChannel.close(); outChannel.close(); long end = System.currentTimeMillis(); System.out.println(\"耗费时间为：\" + (end - start));&#125; 通道通道（Channel）：由 java.nio.channels 包定义的。Channel 表示 IO 源与目标打开的连接。 Channel 类似于传统的 流。只不过 Channel 本身不能直接访问数据，Channel 只能与Buffer 进行交互。 在以前，内核空间请求物理磁盘都需要通过请求CPU提供的IO接口才能访问，由于这样导致CPU阻塞，利用率降低，所以分发了一块机器内存专门处理IO接口，传统IO流通过访问IO接口，并由DMA（直接存储器）向CPU申请权限许可，当许可获得后，就可以将IO操作授权给DMA全权处理，而不需要占用CPU的处理时间，大大提高了CPU的利用率。 当有大量的应用程序向操作系统发起IO请求时，会造成创建多个DMA数据总线，当DMA总线过多时，会造成总线冲突的问题。因为它们都会向CPU申请权限许可，最终也会影响CPU的性能。 通道Channel附属于CPU中央处理器，是一个完全独立的处理器，有一套自身定义的命令和传输方式，专门用于IO操作，无需像CPU获得权限许可，和CPU彻底断绝关系，通道本质上和IO流没什么区别，只是在大型IO请求时，通道相较原来的IO流，CPU的利用率会更高。 实现类： Java 为 Channel 接口提供的最主要实现类如下： FileChannel：用于读取、写入、映射和操作文件的通道。 DatagramChannel：通过 UDP 读写网络中的数据通道。 SocketChannel：通过 TCP 读写网络中的数据。 ServerSocketChannel：可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个SocketChannel。 获取通道： 获取通道的一种方式是对支持通道的对象调用getChannel()方法。支持通道的类如下： FileInputStream FileOutputStream RandomAccessFile DatagramSocket Socket ServerSocket 获取通道的其他方式是使用 Files 类的静态方法 newByteChannel() 获取字节通道。或者通过通道的静态方法 open()打开并返回指定通道。 123456public static FileChannel open(Path path, OpenOption... options) throws IOException &#123; Set&lt;OpenOption&gt; set = new HashSet&lt;OpenOption&gt;(options.length); Collections.addAll(set, options); return open(path, set, NO_ATTRIBUTES);&#125; 其中可变参数OpenOption是指对文件的操作权限，具体可参考StandardOpenOption.class。 StandardOpenOption.READ 只读模式 StandardOpenOption.WRITE 写模式 StandardOpenOption.CREATE 文件不存在则创建，存在则覆盖 StandardOpenOption.CREATE_NEW 文件不存在则创建，存在则报错 FileChannel的常用方法： 方法 描述 int read(ByteBuffer dst) 从 Channel 中读取数据到 ByteBuffer long read(ByteBuffer[] dsts) 将 Channel 中的数据“分散”到 ByteBuffer[] int write(ByteBuffer src) 将 ByteBuffer 中的数据写入到 Channel long write(ByteBuffer[] srcs) 将 ByteBuffer[]中的数据“聚集”到 Channel long position() 返回此通道的文件位置 FileChannel position(long p) 设置此通道的文件位置 long size() 返回此通道的文件的当前大小 FileChannel truncate(long s) 将此通道的文件截取为给定大小 void force(boolean metaData) 强制将所有对此通道的文件更新写入到存储设备中 数据传输通道之间的传输可以通过write()、read()接口，如下： 1234//将Buffer 中数据写入Channelint bytesWritten = outChannel.write(buf);//从 Channel 读取数据到 Bufferint bytesRead = inChannel.read(buf); 也可以使用更简便的 transferFrom()、transferTo()接口，通过直接缓冲区实现，如下： 1234//将数据从源通道(inChannel)传输到outChannel中inChannel.transferTo(0, inChannel.size(), outChannel);//与上同义outChannel.transferFrom(inChannel, 0, inChannel.size()); 案例： 123456789101112131415161718192021222324252627//利用通道完成文件的复制（非直接缓冲区）@Testpublic void test1() throws Exception &#123; long start = System.currentTimeMillis(); FileInputStream fis = new FileInputStream(\"1.jpg\"); FileOutputStream fos = new FileOutputStream(\"2.jpg\"); //1、获取通道 FileChannel inChannel = fis.getChannel(); FileChannel outChannel = fos.getChannel(); //2、分配指定大小的缓冲区 ByteBuffer buf = ByteBuffer.allocate(1024); //3、将通道中的数据存入缓冲区中 while(inChannel.read(buf) != -1)&#123; buf.flip(); //切换读取数据的模式 //4、将缓冲区中的数据写入通道中 outChannel.write(buf); buf.clear(); //清空缓冲区 &#125; outChannel.close(); inChannel.close(); fos.close(); fis.close(); long end = System.currentTimeMillis(); System.out.println(\"耗费时间为：\" + (end - start));&#125; 12345678910111213//通道之间的数据传输(直接缓冲区)@Testpublic void test3() throws IOException&#123; FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(\"2.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE); //inChannel.transferTo(0, inChannel.size(), outChannel); outChannel.transferFrom(inChannel, 0, inChannel.size()); inChannel.close(); outChannel.close();&#125; 分散和聚集分散读取（Scattering Reads）是指从 Channel中读取的数据分散到多个 Buffer 中，按照缓冲区的顺序，从 Channel 中读取的数据依次将 Buffer 填满。 聚集写入（Gathering Writes）是指将多个 Buffer 中的数据聚集到 Channel，按照缓冲区的顺序，写入 position 和 limit 之间的数据到 Channel 。 123456789101112131415161718192021222324252627282930//分散和聚集 @Test public void test4() throws IOException&#123; RandomAccessFile raf1 = new RandomAccessFile(\"1.txt\", \"rw\"); //1. 获取通道 FileChannel channel1 = raf1.getChannel(); //2. 分配指定大小的缓冲区 ByteBuffer buf1 = ByteBuffer.allocate(100); ByteBuffer buf2 = ByteBuffer.allocate(1024); //3. 分散读取 ByteBuffer[] bufs = &#123;buf1, buf2&#125;; channel1.read(bufs); for (ByteBuffer byteBuffer : bufs) &#123; byteBuffer.flip(); &#125; System.out.println(new String(bufs[0].array(), 0, bufs[0].limit())); System.out.println(\"-----------------\"); System.out.println(new String(bufs[1].array(), 0, bufs[1].limit())); //4. 聚集写入 RandomAccessFile raf2 = new RandomAccessFile(\"2.txt\", \"rw\"); FileChannel channel2 = raf2.getChannel(); channel2.write(bufs); &#125; 字符集Charset用来处理字符串和字节数组相互转换的编码问题。 1234567891011@Testpublic void test5() &#123; Map&lt;String, Charset&gt; map = Charset.availableCharsets(); Set&lt;Entry&lt;String, Charset&gt;&gt; set = map.entrySet(); //输出所有支持的字符集编码格式 for (Entry&lt;String, Charset&gt; entry : set) &#123; System.out.println(entry.getKey() + \"=\" + entry.getValue()); &#125;&#125; 用什么编码格式转义的，就需要用什么编码格式反转义。 1234567891011121314@Testpublic void test6() throws IOException &#123; Charset cs1 = Charset.forName(\"GBK\"); CharBuffer cBuf = CharBuffer.allocate(1024); cBuf.put(\"测试测试！\"); cBuf.flip(); // 编码 ByteBuffer bBuf = cs1.encode(cBuf); // 解码 bBuf.flip(); CharBuffer cBuf2 = cs1.decode(bBuf); System.out.println(cBuf2.toString());&#125; 阻塞传统的 IO 流都是阻塞式的。也就是说，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务。因此，在完成网络通信进行 IO 操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量客户端时，性能急剧下降。 当客户端向服务端起请求时，服务端调度accept()创建Socket链接，客户端发送的数据首先会先到达内核空间，这时候的服务端需要等待内核空间完全接收完数据，数据准备完成后，将数据从内核空间拷贝到用户空间。 内核空间并不知道客户端数据是否发送完毕，或者是否有新数据发送，所以只能一直等待着客户端的响应，而在内核空间等待的这段时间中，服务端一直处于阻塞状态，它在等待着内核空间将数据拷贝到用户空间。 1234567891011121314151617181920212223242526272829//阻塞客户端@Testpublic void client() throws IOException&#123; SocketChannel sChannel = SocketChannel.open(new InetSocketAddress(\"127.0.0.1\", 9898)); FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ); ByteBuffer buf = ByteBuffer.allocate(1024); while(inChannel.read(buf) != -1)&#123; buf.flip(); sChannel.write(buf); buf.clear(); &#125; //告诉服务端已经传送完毕 //如果不加这段代码，服务端将一直阻塞，而客户端也一直阻塞等待服务端的反馈 sChannel.shutdownOutput(); //接收服务端的反馈 int len = 0; while((len = sChannel.read(buf)) != -1)&#123; buf.flip(); System.out.println(new String(buf.array(), 0, len)); buf.clear(); &#125; inChannel.close(); sChannel.close();&#125; 12345678910111213141516171819202122232425262728//服务端@Testpublic void server() throws IOException&#123; ServerSocketChannel ssChannel = ServerSocketChannel.open(); FileChannel outChannel = FileChannel.open(Paths.get(\"2.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.CREATE); ssChannel.bind(new InetSocketAddress(9898)); SocketChannel sChannel = ssChannel.accept(); ByteBuffer buf = ByteBuffer.allocate(1024); while(sChannel.read(buf) != -1)&#123; buf.flip(); outChannel.write(buf); buf.clear(); &#125; //发送反馈给客户端 buf.put(\"服务端接收数据成功\".getBytes()); buf.flip(); sChannel.write(buf); sChannel.close(); outChannel.close(); ssChannel.close();&#125; 非阻塞Java NIO 是非阻塞模式的。当线程从某通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞 IO 的空闲时间用于在其他通道上执行 IO 操作，所以单独的线程可以管理多个输入和输出通道。因此，NIO 可以让服务器端使用一个或有限几个线程来同时处理连接到服务器端的所有客户端。 当用户线程发起一个read操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。 客户端的所有通道都将注册到Selector选择器上，选择器将监控通道上的IO状况，当通道上的数据准备就绪后，选择器才会将这个任务分配到服务端一个或者多个线程上运行。 选择器选择器（Selector） 是 SelectableChannle 对象的多路复用器，Selector 可以同时监控多个 SelectableChannel 的 IO 状况，也就是说，利用 Selector可使一个单独的线程管理多个 Channel，Selector 是非阻塞 IO 的核心。 12//通过调用 Selector.open() 方法创建一个 Selector。Selector selector = Selector.open(); 1234567891011121314//1. 获取通道ServerSocketChannel ssChannel = ServerSocketChannel.open();//2. 切换非阻塞模式ssChannel.configureBlocking(false);//3. 绑定连接ssChannel.bind(new InetSocketAddress(9898));//4. 获取选择器Selector selector = Selector.open();//5. 将通道注册到选择器上, 并且指定“监听接收事件”ssChannel.register(selector, SelectionKey.OP_ACCEPT); 当调度上面的第五步的regitster接口将通道注册选择器时，选择器对通道的监听事件，需要通过第二个参数 ops 指定。 可以监听的事件类型（可使用 SelectionKey 的四个常量表示）： 读 : SelectionKey.OP_READ （1） 写 : SelectionKey.OP_WRITE （4） 连接 : SelectionKey.OP_CONNECT （8） 接收 : SelectionKey.OP_ACCEPT （16） 若注册时不止监听一个事件，则可以使用“位或”操作符连接。 1int ops = SelectionKey.OP_READ | SelectionKey.OP_WRITE; SelectionKey：表示 SelectableChannel 和 Selector 之间的注册关系。每次向选择器注册通道时就会选择一个事件(选择键)。选择键包含两个表示为整数值的操作集。操作集的每一位都表示该键的通道所支持的一类可选择操作。 Selector 常用方法： 方法 描述 Set keys() 所有的 SelectionKey 集合。代表注册在该Selector上的Channel selectedKeys() 被选择的 SelectionKey 集合。返回此Selector的已选择键集 int select() 监控所有注册的Channel，当它们中间有需要处理的 IO 操作时，该方法返回，并将对应得的 SelectionKey 加入被选择的SelectionKey 集合中，该方法返回这些 Channel 的数量。 int select(long timeout) 可以设置超时时长的 select() 操作 int selectNow() 执行一个立即返回的 select() 操作，该方法不会阻塞线程 Selector wakeup() 使一个还未返回的 select() 方法立即返回 void close() 关闭该选择器 SelectionKey 常用方法： 方法 描述 int interestOps() 获取感兴趣事件集合 int readyOps() 获取通道已经准备就绪的操作的集合 SelectableChannel channel() 获取注册通道 Selector selector() 返回选择器 boolean isReadable() 检测 Channal 中读事件是否就绪 boolean isWritable() 检测 Channal 中写事件是否就绪 boolean isConnectable() 检测 Channel 中连接是否就绪 boolean isAcceptable() 检测 Channel 中接收是否就绪 案例： 1234567891011121314151617181920212223242526//客户端@Testpublic void client() throws IOException&#123; //1. 获取通道 SocketChannel sChannel = SocketChannel.open(new InetSocketAddress(\"127.0.0.1\", 9898)); //2. 切换非阻塞模式 sChannel.configureBlocking(false); //3. 分配指定大小的缓冲区 ByteBuffer buf = ByteBuffer.allocate(1024); //4. 发送数据给服务端 Scanner scan = new Scanner(System.in); while(scan.hasNext())&#123; String str = scan.next(); buf.put((new Date().toString() + \"\\n\" + str).getBytes()); buf.flip(); sChannel.write(buf); buf.clear(); &#125; //5. 关闭通道 sChannel.close();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//服务端@Testpublic void server() throws IOException&#123; //1. 获取通道 ServerSocketChannel ssChannel = ServerSocketChannel.open(); //2. 切换非阻塞模式 ssChannel.configureBlocking(false); //3. 绑定连接 ssChannel.bind(new InetSocketAddress(9898)); //4. 获取选择器 Selector selector = Selector.open(); //5. 将通道注册到选择器上, 并且指定“监听接收事件” ssChannel.register(selector, SelectionKey.OP_ACCEPT); //6. 轮询式的获取选择器上已经“准备就绪”的事件 while(selector.select() &gt; 0)&#123; //7. 获取当前选择器中所有注册的“选择键(已就绪的监听事件)” Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator(); while(it.hasNext())&#123; //8. 获取准备“就绪”的是事件 SelectionKey sk = it.next(); //9. 判断具体是什么事件准备就绪 if(sk.isAcceptable())&#123; //10. 若“接收就绪”，获取客户端连接 SocketChannel sChannel = ssChannel.accept(); //11. 切换非阻塞模式 sChannel.configureBlocking(false); //12. 将该通道注册到选择器上 sChannel.register(selector, SelectionKey.OP_READ); &#125;else if(sk.isReadable())&#123; //13. 获取当前选择器上“读就绪”状态的通道 SocketChannel sChannel = (SocketChannel) sk.channel(); //14. 读取数据 ByteBuffer buf = ByteBuffer.allocate(1024); int len = 0; while((len = sChannel.read(buf)) &gt; 0 )&#123; buf.flip(); System.out.println(new String(buf.array(), 0, len)); buf.clear(); &#125; &#125; //15. 取消选择键 SelectionKey it.remove(); &#125; &#125;&#125; 管道Java NIO 管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取。 123456789101112131415161718192021222324@Testpublic void test1() throws IOException&#123; //1. 获取管道 Pipe pipe = Pipe.open(); //---------------线程A[start]---------------- //2. 将缓冲区中的数据写入管道 ByteBuffer buf = ByteBuffer.allocate(1024); Pipe.SinkChannel sinkChannel = pipe.sink(); buf.put(\"通过单向管道发送数据\".getBytes()); buf.flip(); sinkChannel.write(buf); //---------------线程A[end]------------------ //---------------线程B[start]---------------- //3. 读取缓冲区中的数据 Pipe.SourceChannel sourceChannel = pipe.source(); buf.flip(); int len = sourceChannel.read(buf); System.out.println(new String(buf.array(), 0, len)); //---------------线程B[end]------------------ sourceChannel.close(); sinkChannel.close();&#125;","categories":[{"name":"NIO","slug":"NIO","permalink":"https://midkuro.gitee.io/categories/NIO/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"NIO","slug":"NIO","permalink":"https://midkuro.gitee.io/tags/NIO/"}]},{"title":"'Redis（四） Spring Boot 整合 Redis'","slug":"springboot-redis","date":"2020-05-27T12:00:00.000Z","updated":"2020-06-05T15:38:33.195Z","comments":true,"path":"2020/05/27/springboot-redis/","link":"","permalink":"https://midkuro.gitee.io/2020/05/27/springboot-redis/","excerpt":"","text":"Spring Boot 整合 RedisRedis配置文件12345&lt;!-- pom.xml--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; Redis的配置文件集中在RedisProperties中，配置文件中以spring.redis前缀开头。 以下列出一些常用配置： 1234567891011121314151617181920212223242526272829@ConfigurationProperties(prefix = \"spring.redis\")public class RedisProperties &#123; private int database = 0; //使用的数据库下标 private String host = \"localhost\"; private String password; private int port = 6379; private boolean ssl; private Duration timeout; //超时时间 private RedisProperties.Sentinel sentinel; //哨兵模式 private RedisProperties.Cluster cluster; //集群模式 public static class Sentinel &#123; private String master; private List&lt;String&gt; nodes; &#125; public static class Cluster &#123; private List&lt;String&gt; nodes; private Integer maxRedirects; &#125; public static class Pool &#123; private int maxIdle = 8; private int minIdle = 0; private int maxActive = 8; private Duration maxWait = Duration.ofMillis(-1L); private Duration timeBetweenEvictionRuns; &#125;&#125; 1234#application.propertiesspring.redis.host= localhostspring.redis.port=6379spring.redis.password= 自动配置123456789101112131415161718192021222324@Configuration@ConditionalOnClass(RedisOperations.class)@EnableConfigurationProperties(RedisProperties.class)@Import(&#123; LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class &#125;)public class RedisAutoConfiguration &#123; @Bean @ConditionalOnMissingBean(name = \"redisTemplate\") public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; &#125; @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; &#125;&#125; 可以看到RedisAutoConfiguration默认创建两个Bean，其中创建了一个主要以String类型操作的stringRedisTemplate，也就是说可以直接通过注解使用这些Bean。 RedisAutoConfiguration初始化两个Bean时使用了@ConditionalOnMissingBean注解，如果我们想要自己实现初始化Bean，只需要自行编写个配置类注入Bean组件即可。 序列化redisTemplate如果保存的是对象时，默认使用JdkSerializationRedisSerializer类作为序列化机制，将对象序列化后的数据（非明文）存储到redis数据库中。Redis规定序列化机制的实现类需要实现RedisSerializer接口。 123456789101112131415public interface RedisSerializer&lt;T&gt; &#123; @Nullable static RedisSerializer&lt;Object&gt; java(@Nullable ClassLoader classLoader) &#123; return new JdkSerializationRedisSerializer(classLoader); &#125; static RedisSerializer&lt;Object&gt; json() &#123; return new GenericJackson2JsonRedisSerializer(); &#125; static RedisSerializer&lt;String&gt; string() &#123; return StringRedisSerializer.UTF_8; &#125;&#125; 在不配置的情况下，默认JDK序列化机制，普遍情况下，我们习惯把对象以String或者JSON的结构存储到Redis，这时候需要手动配置序列化机制，而只要我们引入了相关的依赖包，如FastJson，就能够找到对应的序列化器FastJsonRedisSerializer。 12345678910111213141516@Configurationpublic class MyRedisConfig &#123; //手动配置redisTemplate @Bean public RedisTemplate&lt;Object, Object&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;Object, Object&gt;(); template.setConnectionFactory(redisConnectionFactory); FastJsonRedisSerializer&lt;Object&gt; ser = new FastJsonRedisSerializer&lt;Object&gt;(Object.class); //设置默认序列化器，对所有的key-value类型都生效 template.setDefaultSerializer(ser); return template; &#125;&#125; 测试1234567891011121314151617181920212223242526272829303132333435363738394041@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringbootApplicationTests &#123; @Autowired EmployeeMapper employeeMapper; @Autowired StringRedisTemplate stringRedisTemplate; //操作k-v都是字符串的 @Autowired RedisTemplate redisTemplate; //k-v都是对象的 /** * Redis常见的五大数据类型 * String（字符串）、List（列表）、Set（集合）、Hash（散列）、ZSet（有序集合） * stringRedisTemplate.opsForValue()[String（字符串）] * stringRedisTemplate.opsForList()[List（列表）] * stringRedisTemplate.opsForSet()[Set（集合）] * stringRedisTemplate.opsForHash()[Hash（散列）] * stringRedisTemplate.opsForZSet()[ZSet（有序集合）] */ @Test public void test01()&#123; //给redis中保存数据 stringRedisTemplate.opsForValue().append(\"msg\",\"hello\"); String msg = stringRedisTemplate.opsForValue().get(\"msg\"); System.out.println(msg); stringRedisTemplate.opsForList().leftPush(\"mylist\",\"1\"); stringRedisTemplate.opsForList().leftPush(\"mylist\",\"2\"); &#125; //测试保存对象 @Test public void test02()&#123; Employee emp = new Employee(\"张三\",\"男\"); //默认如果保存对象，使用jdk序列化机制，序列化后的数据保存到redis中 //配置redisTemplate的序列化机制，将对象数据以JSON的方式保存 redisTemplate.opsForValue().set(\"emp-01\",emp); &#125;","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/tags/Redis/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.gitee.io/tags/SpringBoot/"}]},{"title":"'Redis（三） 集群'","slug":"redis-cluster","date":"2020-05-26T03:00:00.000Z","updated":"2020-12-08T01:31:36.840Z","comments":true,"path":"2020/05/26/redis-cluster/","link":"","permalink":"https://midkuro.gitee.io/2020/05/26/redis-cluster/","excerpt":"","text":"Redis集群Redis复制(Master/Slave)Redis的复制，也就是我们所说的主从复制，主机数据更新后根据配置和策略，自动同步到备机的master/slaver机制，Master以写为主，Slave以读为主的策略。主要用来读写分离和容灾恢复。 配从(库)不配主(库)，配置主从复制，只需要把从库指向一个主库，实现对主库的复制即可，不需要主库做任何操作。 可以通过命令配置达到效果，但是每次与master断开之后，都需要重新执行命令连接，除非配置进redis.conf文件，新版本的slaveof改名成replicaof。 1slaveof 主库IP 主库端口 建议配置时拷贝多个redis.conf文件，通过redis-server启动时指定启动的配置文件即可。配置文件需要修改相应的配置： 开启守护线程后台运行 修改PID文件名称 修改指定端口 修改Log文件名称 修改dump.rdb名称 12#redis.conf配置slaveof &lt;masterip&gt; &lt;masterport&gt; 一主二仆 可以看到从库（6380端口）配置了主库（6379端口）后，能够看到他的role标识为slave。 可以看到主库的role标识为master，其中connected_slaves连接的salve是1个。 当有多个slave时，他们配置的master都是同一个，即所有salve都直接和master进行数据同步策略。 薪火相传上一个slave可以是下一个slave的master，slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中下一个的master,可以有效减轻master的写压力。 就好比如slave1（6380端口）配置了主库master（6379），然后salve2（6381端口）配置了slave1做master，那么当6379端口的主库修改了数据时，会先同步到slave1，然后再由slave1同步到slave2。 中途变更转向:会清除之前的数据，重新建立拷贝最新的。 反客为主当主库master故障时，从库slave是不会自动上位成master，将依旧保持slave从库，这并不是我们想要的结果，可以通过手动将从库转换成主库，并修改其他从库的master配置，使当前数据库停止与其他数据库的同步，转成主数据库 1SLAVEOF no one 复制原理slave启动成功连接到master后会发送一个sync命令,master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步。 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。 增量复制：master继续将新的所有收集到的修改命令依次传给slave,完成增量同步。 但是只要是重新连接master,一次完全同步（全量复制)将被自动执行 哨兵模式哨兵模式是反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库 通过创建sentinel.conf配置文件，并新增监控机器的配置，一组sentinel能同时监控多个Master。 12345# sentinel monitor 自定义的名称 127.0.0.1 6379 1#上面最后一个数字1，表示主机挂掉后salve投票看让谁接替成为主机，得票数多的成为主机sentinel monitor host6379 127.0.0.1 6379 1sentinel monitor host6380 127.0.0.1 6380 1sentinel monitor host6381 127.0.0.1 6381 1 1234#linux系统执行命令redis-sentinel sentinel.conf#window系统执行命令redis-server.exe sentinel.conf --sentinel 通过执行启动哨兵，当master节点挂了后，哨兵模式会自动从salve中投票选举出新的master，原来的master节点重新加入时，将会变成salve节点。哨兵模式最低限度能够达到仅剩一台slave时，将之升级为master，即支持当master机器没有slave节点时，依旧能够正常工作。 由于所有的写操作都是先在master上操作，然后同步更新到slave上，所以从master同步到slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave机器数量的增加也会使这个问题更加严重。 代理twemproxy官方文档 代理多个Redis进行分片数据分发。 12345678910111213[root@localhost twemproxy]# wget https://github.com/twitter/twemproxy/archive/master.zip[root@localhost twemproxy]# unzip master.zip[root@localhost twemproxy]# cd twemproxy-master/[root@localhost twemproxy-master]# yum install automake libtool[root@localhost twemproxy-master]# autoreconf -fvi[root@localhost twemproxy-master]# ./configure --enable-debug=full[root@localhost twemproxy-master]# make 123456789101112#设置使用全局命令nutcracker[root@localhost scripts]# cd scripts/[root@localhost scripts]# cp nutcracker.init /etc/init.d/twemproxy[root@localhost scripts]# chmod +x /etc/init.d/twemproxy[root@localhost scripts]# mkdir /etc/nutcracker[root@localhost scripts]# cp ../conf/* /etc/nutcracker/[root@localhost scripts]# cp ../src/nutcracker /usr/bin 123456789101112131415161718192021222324252627282930#修改配置文件[root@localhost scripts]# cd /etc/nutcracker/[root@localhost nutcracker]# vi nutcracker.yml`alpha: listen: 127.0.0.1:22121 hash: fnv1a_64 distribution: ketama auto_eject_hosts: true redis: true server_retry_timeout: 2000 server_failure_limit: 1 servers: - 127.0.0.1:6379:1 #起两个实例 - 127.0.0.1:6380:1`[root@localhost nutcracker]# systemctl start twemproxy.service[root@localhost nutcracker]# redis-cli -p 22121#因为分治了，不支持keys、watch、MULTI127.0.0.1:22121&gt; keys *Error: Server closed the connection127.0.0.1:22121&gt; set k3 111OK127.0、.0.1:22121&gt; set k4 1111OK 12345678#如果执行 autoreconf -fvi 提示版本过低，则执行以下命令[root@localhost yum.repos.d]# cd /etc/yum.repos.d/[root@localhost yum.repos.d]# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo[root@localhost yum.repos.d]# yum clean all#回到twemproxy-master目录下[root@localhost twemproxy-master]# yum search autoconf[root@localhost twemproxy-master]# yum install autoconf268 predixy官方文档 三台哨兵做集群，监控两个主从Redis，自动将两个主从进行分组，数据分而治之到不同的Master中。 123456789101112131415161718192021222324252627282930313233343536373839404142[root@localhost predixy]# wget https://github.com/joyieldInc/predixy/releases/download/1.0.5/predixy-1.0.5-bin-amd64-linux.tar.gz[root@localhost predixy]# tar xf predixy-1.0.5-bin-amd64-linux.tar.gz[root@localhost predixy]# cd predixy-1.0.5/conf[root@localhost conf]# vi predixy.conf `Bind 127.0.0.1:7617Include sentinel.conf`[root@localhost conf]# vi sentinel.conf`SentinelServerPool &#123; Databases 16 Hash crc16 HashTag \"&#123;&#125;\" Distribution modula MasterReadPriority 60 StaticSlaveReadPriority 50 DynamicSlaveReadPriority 50 RefreshInterval 1 ServerTimeout 1 ServerFailureLimit 10 ServerRetryTimeout 1 KeepAlive 120 Sentinels &#123; #哨兵的集群 + 127.0.0.1 26379 + 127.0.0.1 26780 + 127.0.0.1 26781 &#125; #哨兵监控的主从名称 Group ooxx &#123; &#125; Group xxoo &#123; &#125;&#125;` 1234567#redis的哨兵模式配置文件sentinel-26379.conf 监控两个主从的redisport 26379#36379是主节点，从节点是36380sentinel monitor ooxx 127.0.0.1 36379 2 #46379是主节点，从节点是46380sentinel monitor xxoo 127.0.0.1 46379 2 1234567#redis的哨兵模式配置文件sentinel-26380.conf 监控两个主从的redisport 26380#36379是主节点，从节点是36380sentinel monitor ooxx 127.0.0.1 36379 2 #46379是主节点，从节点是46380sentinel monitor xxoo 127.0.0.1 46379 2 1234567#redis的哨兵模式配置文件sentinel-26381.conf 监控两个主从的redisport 26381#36379是主节点，从节点是36380sentinel monitor ooxx 127.0.0.1 36379 2 #46379是主节点，从节点是46380sentinel monitor xxoo 127.0.0.1 46379 2 1234#进入bin目录[root@localhost bin]# ./predixy ../conf/predixy.conf[root@localhost bin]# redis-cli -p 7617127.0.0.1:7617&gt; Redis-Cluster自从redis 3.0版本开始支持redis-cluster集群，redis-cluster采用无中心结构，每个节点保存数据和整个集群的状态，每个节点都和其他所有节点连接。 无需proxy代理，客户端直接与redis集群的每个节点连接，根据同样的hash算法计算出key对应的slot，然后直接在slot对应的redis节点上执行命令。 在redis看来，响应时间是最苛刻的条件，增加一层带来的开销是redis不能接受的。因此，redis实现了客户端对节点的直接访问，为了去中心化，节点之间通过gossip协议交换互相的状态，以及探测新加入的节点信息。redis集群支持动态加入节点，动态迁移slot，以及自动故障转移。 数据分片redis 集群使用数据分片（sharding）而非一致性哈希（consistency hashing）来实现，Redis Cluster 采用的是虚拟槽分区算法，这个槽是用来存放缓存信息的单位，一个redis 集群包含 16384 个哈希槽（hash slot），槽的范围是 0 -16383，数据库中的每个键都属于这 16384 个哈希槽的其中一个。 集群使用公式 CRC16(key) % 16384 来计算键key属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。集群中的每个节点负责处理一部分哈希槽。 举个例子， 一个集群可以有三个节点， 其中： 节点 A 负责处理 0 号至 5500 号哈希槽。 节点 B 负责处理 5501 号至 11000 号哈希槽。 节点 C 负责处理 11001 号至 16383 号哈希槽。 此时 Redis Client 需要根据一个Key获取对应的 Value 的数据，首先通过 CRC16(key)%16384 计算出 Slot 的值，假设计算的结果是 5000，将这个数据传送给 Redis Cluster，集群接收到以后会到一个对照表中查找这个 Slot=5000 属于那个缓存节点。发现属于“节点 A ”负责，于是顺着红线的方向调用节点 A中存放的 Key-Value 的内容并且返回给 Redis Client。 这种将哈希槽分布到不同节点的做法使得用户可以很容易地向集群中添加或者删除节点。 比如说： 如果用户将新节点 D 添加到集群中， 那么集群只需要将节点 A 、B 、 C 中的某些槽移动到节点 D 就可以了。 如果用户要从集群中移除节点 A ， 那么集群只需要将节点 A 中的所有哈希槽移动到节点 B 和节点 C ， 然后再移除空白（不包含任何哈希槽）的节点 A 就可以了。 因为将一个哈希槽从一个节点移动到另一个节点不会造成节点阻塞，且成本很低， 所以无论是添加新节点还是移除已存在节点， 又或者改变某个节点包含的哈希槽数量， 都不会造成集群下线。 数据访问客户端在初始化的时候只需要知道一个节点的地址即可，客户端会先尝试向这个节点执行命令，比如“get key”，如果key所在的slot刚好在该节点上，则能够直接执行成功。如果slot不在该节点，则节点会返回MOVED错误，同时把该slot对应的节点告诉客户端。客户端可以去该节点执行命令。 集群支持hash tags功能，即可以把一类key定位到同一个slot，tag的标识目前不支持配置，只能使用{}，redis处理hash tag的逻辑也很简单，redis只计算从第一次出现{，到第一次出现}的substring的hash值，substring为空，则仍然计算整个key的值，也能取出tag值。 12345678910111213127.0.0.1:6379&gt; set &#123;oo&#125;k2 aaaOK127.0.0.1:6379&gt; set &#123;oo&#125;k3 bbbOK127.0.0.1:6379&gt; WATCH &#123;oo&#125;k2OK127.0.0.1:6379&gt; set &#123;oo&#125;k2 cccQUEUED127.0.0.1:6379&gt; get &#123;oo&#125;k3QUEUED127.0.0.1:6379&gt; exec1) OK2) \"bbb\" 我们都知道，redis单机支持mutl-key操作（mget、mset）。redis cluster对mutl-key命令的支持，只能支持多key都在同一个slot上，即使多个slot在同一个节点上也不行。通过hash tag可以很好的做到这一点。 数据结构Redis Cluster中的每个节点都保存了集群的配置信息，并且存储在clusterState中，结构如下： 上图的各个变量语义如下: clusterState 记录了从集群中某个节点视角，来看集群配置状态； currentEpoch 表示整个集群中最大的版本号，集群信息每变更一次，改版本号都会自增。 nodes 是一个列表，包含了本节点所感知的，集群所有节点的信息（clusterNode），也包含自身的信息。 clusterNode 记录了每个节点的信息，其中包含了节点本身的版本 Epoch；自身的信息描述：节点对应的数据分片范围（slot）、为master时的slave列表、为slave时的master等。 每个节点包含一个全局唯一的NodeId。 当集群的数据分片信息发生变更（数据在节点间迁移时），Redis Cluster仍然保持对外服务。 当集群中某个master出现宕机时，Redis Cluster 会自动发现，并触发故障转移的操作。会将master的某个slave晋升为新的 master。 由此可见，每个节点都保存着Node视角的集群结构。它描述了数据的分片方式，节点主备关系，并通过Epoch作为版本号实现集群结构信息的一致性，同时也控制着数据迁移和故障转移的过程。 节点通信在Redis Cluster中，这个配置信息交互通过Redis Cluster Bus来完成（独立端口）。Redis Cluster Bus上交互的信息结构如下： clusterMsg 中的type指明了消息的类型，配置信息的一致性主要依靠PING/PONG。每个节点向其他节点频繁的周期性的发送PING/PONG消息。对于消息体中的Gossip部分，包含了sender/receiver 所感知的其他节点信息，接受者根据这些Gossip 跟新对集群的认识。 对于大规模的集群，如果每次PING/PONG 都携带着所有节点的信息，则网络开销会很大。此时Redis Cluster 在每次PING/PONG，只包含了随机的一部分节点信息。由于交互比较频繁，短时间的几次交互之后，集群的状态也会达成一致。 一致性当Cluster 结构不发生变化时，各个节点通过gossip 协议在几轮交互之后，便可以得知Cluster的结构信息，达到一致性的状态。但是当集群结构发生变化时（故障转移/分片迁移等），优先得知变更的节点通过Epoch变量，将自己的最新信息扩散到Cluster，并最终达到一致。 clusterNode 的Epoch描述的单个节点的信息版本；clusterState 的currentEpoch 描述的是集群信息的版本，它可以辅助Epoch 的自增生成。因为currentEpoch 是维护在每个节点上的，在集群结构发生变更时，Cluster 在一定的时间窗口控制更新规则，来保证每个节点的currentEpoch都是最新的。更新规则如下： 当某个节点率先知道了变更时，将自身的currentEpoch 自增，并使之成为集群中的最大值。再用自增后的currentEpoch 作为新的Epoch 版本； 当某个节点收到了比自己大的currentEpoch时，更新自己的currentEpoch； 当收到的Redis Cluster Bus 消息中的某个节点的Epoch &gt; 自身的时，将更新自身的内容； 当Redis Cluster Bus 消息中，包含了自己没有的节点时，将其加入到自身的配置中。 上述的规则保证了信息的更新都是单向的，最终朝着Epoch更大的信息收敛。同时Epoch也随着currentEpoch的增加而增加，最终将各节点信息趋于稳定。 为了使得集群在一部分节点下线或者无法与集群的大多数（majority）节点进行通讯的情况下， 仍然可以正常运作， Redis 集群对节点使用了主从复制功能： 集群中的每个节点都有 1 个至 N 个复制品（replica）， 其中一个复制品为主节点（master）， 而其余的 N-1 个复制品为从节点（slave）。 集群间节点支持主从关系，复制的逻辑基本复用了单机版的实现。不过还是有些地方需要注意。 首先集群间节点建立主从关系不再使用原有的SLAVEOF命令和SLAVEOF配置，而是通过cluster replicate命令，这保证了主从节点需要先完成握手，才能建立主从关系。 集群是不能组成链式主从关系的，也就是说从节点不能有自己的从节点。不过对于集群外的没开启集群功能的节点，redis并不干预这些节点去复制集群内的节点，但是在集群故障转移时，这些集群外的节点，集群不会处理。 集群内节点想要复制另一个节点，需要保证本节点不再负责任何slot，不然redis也是不允许的。 集群内的从节点在与其他节点通信的时候，传递的消息中数据分布表和epoch是master的值。 集群主节点出现故障，发生故障转移，其他主节点会把故障主节点的从节点自动提为主节点，原来的主节点恢复后，自动成为新主节点的从节点。 这里先说明，把一个master和它的全部slave描述为一个group，故障转移是以group为单位的，集群故障转移的方式跟sentinel的实现很类似。 均衡集群在集群运行过程中，有的master的slave宕机，导致了该master成为孤儿master（orphaned masters），而有的master有很多slave。 此处孤儿master的定义是那些本来有slave，但是全部离线的master，对于那些原来就没有slave的master不能认为是孤儿master。 redis集群支持均衡slave功能，官方称为Replica migration，而我觉得均衡集群的slave更好理解该概念。集群能把某个slave较多的group上的slave迁移到那些孤儿master上，该功能通过cluster-migration-barrier参数配置，默认为1。 slave在每次定时任务都会检查是否需要迁移slave，即把自己变成孤儿master的slave。 满足以下条件，slave就会成为孤儿master的slave： 自己所在的group是slave最多的group。 目前存在孤儿master。 自己所在的group的slave数目至少超过2个，只有自己一个的话迁移到其他group，自己原来的group的master又成了孤儿master。 自己所在的group的slave数量大于cluster-migration-barrier配置。 与group内的其他slave基于memcmp比较node id，自己的node id最小。这个可以防止多个slave并发复制孤儿master，从而原来的group失去过多的slave。 优势 去中心化，集群最大可增加1000个节点，性能随节点增加而线性扩展。 解耦 数据 和 节点 之间的关系，简化了节点 扩容 和 收缩 难度。 节点自身 维护槽的 映射关系，不需要 客户端 或者 代理服务 维护 槽分区元数据。 劣势 key 批量操作 支持有限。类似 mset、mget 操作，目前只支持对具有相同 slot 值的key 执行 批量操作。对于 映射为不同 slot 值的key 由于执行 mget、mget 等操作可能存在于多个节点上，因此不被支持。 只支持 多 key 在 同一节点上 的 事务操作，当多个 key 分布在 不同 的节点上时 无法 使用事务功能。 key 作为 数据分区 的最小粒度，不能将一个 大的键值 对象如 hash、list 等映射到 不同的节点。 不支持多数据库空间，单机下的Redis可以支持 16 个数据库（db0 ~ db15），集群模式下只能使用一个 数据库空间，即 db0。 复制结构 只支持一层，从节点 只能复制 主节点，不支持 嵌套树状复制 结构。 集群搭建1234567891011121314151617181920212223#redis.conf相关集群配置#配置为cluster模式cluster-enabled yes#集群节点配置信息，包括nodeid，集群信息。此文件非常关键，要确保故障转移或者重启的时候此文件还在，所以如果在docker环境下要外挂到外部存储cluster-config-file nodes-6379.conf#节点连接超时，如果集群规模小，都在同一个网络环境下，可以配置的短些，更快的做故障转移cluster-node-timeout 2000#慢查询日志，用于性能分析，生产环境可设置为1000（毫秒）slowlog-log-slower-than 1000#保存慢查询的队列长度 ，设置为1000slowlog-max-len 1000#设置为0，默认为10如果master slave都挂掉，slave跟master失联又超过这个数值*timeout的数值，就不会发起选举了。#如果设置为0，就是永远都会尝试发起选举，尝试从slave变为matercluster-slave-validity-factor 10#设置为no，默认为yes，故障发现到自动完成转移期间整个集群是不可用状态，对于大多数业务无法容忍这种情况#因此要设置为no，当主节点故障时只影 响它负责槽的相关命令执行，不会影响其他主节点的可用性cluster-require-full-coverage yes 123456789101112131415161718192021222324252627#分别修改不同的redis.conf，注意，不同的redis.conf分开文件夹#端口分别为6301~6306port 6301#dir ./ 修改成每个conf的路径dir /usr/local/redis1#cluster-enabled yes 开启集群模式cluster-enabled yes#打开配置集群结点信息文件(6301~6306)cluster-config-file nodes-6301.conf#打开结点超时配置cluster-node-timeout 15000# 持久化配置appendonly yes#修改`PID`文件名称pidfile /var/run/redis-6301.pid#修改`Log`文件名称logfile redis-6301.log#修改`dump.rdb`名称dbfilename dump-6301.rdb 12345#查群脚本命令帮助文档[root@localhost /]# redis-cli --cluster create help#--cluster-replicas 1表示给每个master分配一个slave，系统会自动分配master和salveredis-cli --cluster create --cluster-replicas 1 127.0.0.1:6301 127.0.0.1:6302 127.0.0.1:6303 127.0.0.1:6304 127.0.0.1:6305 127.0.0.1:6306 12345678910#查看集群状态[root@localhost /]# redis-cli -p 6301 cluster info#查看集群节点状态[root@localhost /]# redis-cli -p 6301 cluster nodes#使用redis-cli连接到集群，指定-c参数[root@localhost /]# redis-cli -p 6001 -c#重新分槽[root@localhost /]# redis-cli -cluster reshard 127.0.0.1 6301 当访问的slot在当前机器时，直接返回，当数据在其他master管理的slot中时，会自动重定位到负责该slot的master机器 可以看到当我把6303端口的master停止后，6304端口的slave上位成master。 当我重启6303端口的redis时，6303端口的redis自动成为6304端口master的salve。 部分内容出自文章： https://blog.csdn.net/wuxian90/article/details/81590252 https://www.cnblogs.com/pingyeaa/p/11294773.html https://www.jianshu.com/p/84dbb25cc8dc https://nealli.gitee.io/2020/05/21/Redis%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/tags/Redis/"}]},{"title":"'Redis（二） Hash算法'","slug":"redis-hash","date":"2020-05-26T02:00:00.000Z","updated":"2020-12-08T01:17:41.918Z","comments":true,"path":"2020/05/26/redis-hash/","link":"","permalink":"https://midkuro.gitee.io/2020/05/26/redis-hash/","excerpt":"","text":"Redis算法数据分布算法普通Hash算法（modula）比如你有 N 个 redis实例，那么如何将一个key映射到redis上呢，你很可能会采用类似下面的通用方法计算 key的 hash 值，然后均匀的映射到到 N 个 redis上： hash(key)%N 如果增加一个redis，映射公式变成了 hash(key)%(N+1) 如果一个redis宕机了，映射公式变成了 hash(key)%(N-1) 在这两种情况下，每一个redis管理的数据全部要重新计算移动，几乎所有的缓存都失效了。会导致数据库访问的压力陡增，严重情况，还可能导致数据库宕机。 随机分配算法(random)随机将数据分发到Redis集群中，Client无法准确地从某台机器获取相对的数据，该做法常用于消息队列中。 一致性Hash算法(ketama) 将内存想象成一个环，由于hash值有32位，因此将内存分出2 ^32（0~2 ^32-1）个地址 将节点的IP+算法确定唯一的哈希值，之后在内存中确定节点的位置 当保存数据时，根据key进行哈希运算，确定唯一的一个位置 根据当前key位置顺时针查找最近的node节点进行挂载（在内存中，加法计算快于减法运算，因此采用顺时针查找） 将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。 假设将中四台服务器使用ip地址哈希后在环空间的位置如下： 将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。 假设4个存储对象 Object A、B、C、D，经过对 Key 的哈希计算后，它们的位置如下： 根据一致性哈希算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。 容错性和可扩展性假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。 如果在系统中增加一台服务器Node X，如下图所示： 此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。 综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 如果这时候新增了一个结点，对原来缓存的一部分数据的访问将会落到新增的结点上，但是这时候结点并没有数据缓存，它将去数据库中查找并缓存，原先已经缓存数据的结点需要通过淘汰算法（LRU）淘汰数据，它并没有从原缓存结点复制数据到新节点中。 虚拟节点但一致性哈希算法也有一个严重的问题，就是数据倾斜。如果在分片的集群中，节点太少，并且分布不均，一致性哈希算法就会出现部分节点数据太多，部分节点数据太少。也就是说无法控制节点存储数据的分配。如下图，大部分数据都在 A 上了，B 的数据比较少。 节点数越少，越容易出现节点在哈希环上的分布不均匀，导致各节点映射的对象数量严重不均衡(数据倾斜)；相反，节点数越多越密集，数据在哈希环上的分布就越均匀。 以删除节点为例，假设删除了Node B节点，原来Node B节点的数据将转移到Node C上，这样Node C的内存使用率会骤增，如果Node B上存在热点数据，Node C会扛不住甚至会可能挂掉，挂掉之后数据又转移给Node D,如此循环会造成所有节点崩溃，也就是缓存雪崩。 为了解决雪崩现象和数据倾斜现象，提出了虚拟节点这个概念。就是将真实节点计算多个哈希形成多个虚拟节点并放置到哈希环上，定位算法不变，只是多了一步虚拟节点到真实节点映射的过程 但实际部署的物理节点有限，我们可以用有限的物理节点，虚拟出足够多的虚拟节点(Virtual Node)，最终达到数据在哈希环上均匀分布的效果。 如下图，实际只部署了2个节点 Node A/B，每个节点都复制成3倍，结果看上去是部署了6个节点。可以想象，当复制倍数为 2^32 时，就达到绝对的均匀，通常可取复制倍数为32或更高。 这就解决了雪崩的问题，当某个节点宕机后，其数据并没有全部分配给某一个节点，而是被分到了多个节点，数据倾斜的问题也随之解决。 实现一致性哈希算法，既可以在客户端实现，也可以在中间件上实现（如 proxy）。在客户端实现中，当客户端初始化的时候，需要初始化一张预备的 Redis 节点的映射表：hash(key)=&gt; . 这有一个缺点，假设有多个客户端，当映射表发生变化的时候，多个客户端需要同时拉取新的映射表。 另一个种是中间件（proxy）的实现方法，即在客户端和 Redis 节点之间加多一个代理，代理经过哈希计算后将对应某个 key 的请求分发到对应的节点，一致性哈希算法就在中间件里面实现。可以发现，twemproxy 就是这么做的。 哈希槽redis 集群（cluster）并没有选用上面一致性哈希，而是采用了哈希槽（slot）的这种概念。主要的原因就是上面所说的，一致性哈希算法对于数据分布、节点位置的控制并不是很友好。 首先哈希槽其实是两个概念，第一个是哈希算法。redis cluster 的 hash 算法不是简单的hash()，而是 crc16 算法，一种校验算法。另外一个就是槽位的概念，空间分配的规则。 其实哈希槽的本质和一致性哈希算法非常相似，不同点就是对于哈希空间的定义。一致性哈希的空间是一个圆环，节点分布是基于圆环的，无法很好的控制数据分布。而 redis cluster 的槽位空间是自定义分配的，类似于 windows 盘分区的概念。这种分区是可以自定义大小，自定义位置的。 redis cluster 包含了16384个哈希槽，每个 key 通过计算后都会落在具体一个槽位上，而这个槽位是属于哪个存储节点的，则由用户自己定义分配。例如机器硬盘小的，可以分配少一点槽位，硬盘大的可以分配多一点。如果节点硬盘都差不多则可以平均分配。所以哈希槽这种概念很好地解决了一致性哈希的弊端。 当有新节点加入时，它不再需要像一致性Hash算法那样把每个key取出来重新计算hash值，只需要从旧节点中将新节点应该缓存的槽位数据拷贝到新节点中即可。 另外在容错性和扩展性上，表象与一致性哈希一样，都是对受影响的数据进行转移。而哈希槽本质上是对槽位的转移，把故障节点负责的槽位转移到其他正常的节点上。扩展节点也是一样，把其他节点上的槽位转移到新的节点上。 弊端是聚合操作很难实现，并且不支持跨机器事务，但是提供了Hash Tag让用户控制需要计算的Key都集中在一个Redis中。 缓存缓存穿透key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。 解决办法： 一个一定不存在缓存及查询不到的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。 最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 另外也有一个更为简单的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 缓存击穿key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 业界比较常用的做法是使用互斥锁(mutex key)，简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作，比如Redis的SETNX（SET if Not eXists），去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 缓存雪崩当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。 大多数系统设计者考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。 锁排队的解决方式分布式环境的并发问题，有可能还要解决分布式锁的问题；线程还会被阻塞，用户体验很差！因此，在真正的高并发场景下很少使用！ 还有一个简单方案就是将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 部分内容出自文章： https://blog.csdn.net/qq_42695926/java/article/details/83090131 https://www.cnblogs.com/lihonglin2016/p/10039670.html https://blog.csdn.net/kefengwang/java/article/details/81628977 https://www.cnblogs.com/xichji/p/11286443.html","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/tags/Redis/"}]},{"title":"'Redis（四） Redis 常用命令'","slug":"redis-command","date":"2020-05-24T02:00:00.000Z","updated":"2020-12-03T14:57:57.461Z","comments":true,"path":"2020/05/24/redis-command/","link":"","permalink":"https://midkuro.gitee.io/2020/05/24/redis-command/","excerpt":"","text":"RedisRedis是一个单线程 + Epoll + 计算向数据移动的内存型数据库。 常用命令常见命令文档、Redis命令参考手册完整版 redis-cli -h host -p port -a password 命令 描述 SELECT 切换数据库 Dbsize 查看当前数据库的key的数量 Flushdb 清空当前库 Flushall 通杀全部库 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157127.0.0.1:6379&gt; help @genericDEL key [key ...]summary: Delete a keysince: 1.0.0DUMP keysummary: Return a serialized version of the value stored at the specified key.since: 2.6.0EXISTS key [key ...]summary: Determine if a key existssince: 1.0.0EXPIRE key secondssummary: Set a key's time to live in secondssince: 1.0.0EXPIREAT key timestampsummary: Set the expiration for a key as a UNIX timestampsince: 1.2.0KEYS patternsummary: Find all keys matching the given patternsince: 1.0.0MIGRATE host port key| destination-db timeout [COPY] [REPLACE] [KEYS key]summary: Atomically transfer a key from a Redis instance to another one.since: 2.6.0MOVE key dbsummary: Move a key to another databasesince: 1.0.0OBJECT subcommand [arguments [arguments ...]]summary: Inspect the internals of Redis objectssince: 2.2.3PERSIST keysummary: Remove the expiration from a keysince: 2.2.0PEXPIRE key millisecondssummary: Set a key's time to live in millisecondssince: 2.6.0PEXPIREAT key milliseconds-timestampsummary: Set the expiration for a key as a UNIX timestamp specified in millisecondssince: 2.6.0PTTL keysummary: Get the time to live for a key in millisecondssince: 2.6.0RANDOMKEY -summary: Return a random key from the keyspacesince: 1.0.0RENAME key newkeysummary: Rename a keysince: 1.0.0RENAMENX key newkeysummary: Rename a key, only if the new key does not existsince: 1.0.0RESTORE key ttl serialized-value [REPLACE]summary: Create a key using the provided serialized value, previously obtained using DUMP.since: 2.6.0SCAN cursor [MATCH pattern] [COUNT count]summary: Incrementally iterate the keys spacesince: 2.8.0SORT key [BY pattern] [LIMIT offset count] [GET pattern [GET pattern ...]] [ASC|DESC] [ALPHA] [STORE destination]summary: Sort the elements in a list, set or sorted setsince: 1.0.0TOUCH key [key ...]summary: Alters the last access time of a key(s). Returns the number of existing keys specified.since: 3.2.1TTL keysummary: Get the time to live for a keysince: 1.0.0TYPE keysummary: Determine the type stored at keysince: 1.0.0UNLINK key [key ...]summary: Delete a key asynchronously in another thread. Otherwise it is just as DEL, but non blocking.since: 4.0.0WAIT numreplicas timeoutsummary: Wait for the synchronous replication of all the write commands sent in the context of the current connectionsince: 3.0.0POST ...options...summary: Help not availablesince: not knownSUBSTR key arg arg summary: Help not availablesince: not knownRESTORE-ASKING key arg arg ...options...summary: Help not availablesince: not knownHOST: ...options...summary: Help not availablesince: not knownPFDEBUG arg arg ...options...summary: Help not availablesince: not knownMODULE arg ...options...summary: Help not availablesince: not knownGEORADIUSBYMEMBER_RO key arg arg arg ...options...summary: Help not availablesince: not knownXSETID key arg summary: Help not availablesince: not knownGEORADIUS_RO key arg arg arg arg ...options...summary: Help not availablesince: not knownASKING summary: Help not availablesince: not knownPSYNC arg arg summary: Help not availablesince: not knownREPLCONF ...options...summary: Help not availablesince: not knownLATENCY arg ...options...summary: Help not availablesince: not knownPFSELFTEST summary: Help not availablesince: not knownLOLWUT ...options...summary: Help not availablesince: not known String字符串有正向索引和反向索引，正向开头index=0开始，反向末尾index=-1开始。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273127.0.0.1:6379&gt; help @StringAPPEND key valuesummary: Append a value to a keysince: 2.0.0DECR keysummary: Decrement the integer value of a key by onesince: 1.0.0DECRBY key decrementsummary: Decrement the integer value of a key by the given numbersince: 1.0.0GET keysummary: Get the value of a keysince: 1.0.0GETRANGE key start endsummary: Get a substring of the string stored at a keysince: 2.4.0GETSET key valuesummary: Set the string value of a key and return its old valuesince: 1.0.0INCR keysummary: Increment the integer value of a key by onesince: 1.0.0INCRBY key incrementsummary: Increment the integer value of a key by the given amountsince: 1.0.0INCRBYFLOAT key incrementsummary: Increment the float value of a key by the given amountsince: 2.6.0MGET key [key ...]summary: Get the values of all the given keyssince: 1.0.0MSET key value [key value ...]summary: Set multiple keys to multiple valuessince: 1.0.1MSETNX key value [key value ...]summary: Set multiple keys to multiple values, only if none of the keys existsince: 1.0.1PSETEX key milliseconds valuesummary: Set the value and expiration in milliseconds of a keysince: 2.6.0SET key value [expiration EX seconds|PX milliseconds] [NX|XX]summary: Set the string value of a keysince: 1.0.0SETEX key seconds valuesummary: Set the value and expiration of a keysince: 2.0.0SETNX key valuesummary: Set the value of a key, only if the key does not existsince: 1.0.0SETRANGE key offset valuesummary: Overwrite part of a string at key starting at the specified offsetsince: 2.2.0STRLEN keysummary: Get the length of the value stored in a keysince: 2.2.0 123Incr等数值命令适用场景：抢购，秒杀，详情页，点赞，评论规避并发下，对数据库的事务操作，完全由redis内存操作代替 BitMap对二进制的Index位数进行设置值 1234567891011121314151617181920212223BITCOUNT key [start end]summary: Count set bits in a stringsince: 2.6.0BITFIELD key [GET type offset] [SET type offset value] [INCRBY type offset increment] [OVERFLOW WRAP|SAT|FAIL]summary: Perform arbitrary bitfield integer operations on stringssince: 3.2.0BITOP operation destkey key [key ...]summary: Perform bitwise operations between stringssince: 2.6.0BITPOS key bit [start] [end]summary: Find first bit set or clear in a stringsince: 2.8.7SETBIT key offset valuesummary: Sets or clears the bit at offset in the string value stored at keysince: 2.2.0GETBIT key offsetsummary: Returns the bit value at offset in the string value stored at keysince: 2.2.0 123456789101112131415161718192021222324案例：setbit k1 1 1 0100 0000&#x3D;@setbit k1 7 1 0100 0001&#x3D;Asetbit k1 9 1 0100 0001 0100 0000&#x3D;A@默认会转换成字符集 ascii 输出其他一般叫做扩展字符集扩展： 其他字符集不在对ascii重编码redis的位操作适用场景：1.有用户系统，统计用户登录天数，且窗口随机,每个用户有366位数据，一天一个，用BITCOUNT算出多少天setbit sean 1 1setbit sean 7 1setbit sean 364 1STRLEN seanBITCOUNT sean -2 -12.活跃用户统计！随即窗口,多少用户多少个bit，一天一个key，数据与运算后使用BITCOUNTsetbit 20190101 1 1setbit 20190102 1 1setbit 20190102 7 1bitop or destkey 20190101 20190102BITCOUNT destkey 0 -1 Hash12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061127.0.0.1:6379&gt; help @hashHDEL key field [field ...]summary: Delete one or more hash fieldssince: 2.0.0HEXISTS key fieldsummary: Determine if a hash field existssince: 2.0.0HGET key fieldsummary: Get the value of a hash fieldsince: 2.0.0HGETALL keysummary: Get all the fields and values in a hashsince: 2.0.0HINCRBY key field incrementsummary: Increment the integer value of a hash field by the given numbersince: 2.0.0HINCRBYFLOAT key field incrementsummary: Increment the float value of a hash field by the given amountsince: 2.6.0HKEYS keysummary: Get all the fields in a hashsince: 2.0.0HLEN keysummary: Get the number of fields in a hashsince: 2.0.0HMGET key field [field ...]summary: Get the values of all the given hash fieldssince: 2.0.0HMSET key field value [field value ...]summary: Set multiple hash fields to multiple valuessince: 2.0.0HSCAN key cursor [MATCH pattern] [COUNT count]summary: Incrementally iterate hash fields and associated valuessince: 2.8.0HSET key field valuesummary: Set the string value of a hash fieldsince: 2.0.0HSETNX key field valuesummary: Set the value of a hash field, only if the field does not existsince: 2.0.0HSTRLEN key fieldsummary: Get the length of the value of a hash fieldsince: 3.2.0HVALS keysummary: Get all the values in a hashsince: 2.0.0 List123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869127.0.0.1:6379&gt; help @listBLPOP key [key ...] timeoutsummary: Remove and get the first element in a list, or block until one is availablesince: 2.0.0BRPOP key [key ...] timeoutsummary: Remove and get the last element in a list, or block until one is availablesince: 2.0.0BRPOPLPUSH source destination timeoutsummary: Pop a value from a list, push it to another list and return it; or block until one is availablesince: 2.2.0LINDEX key indexsummary: Get an element from a list by its indexsince: 1.0.0LINSERT key BEFORE|AFTER pivot valuesummary: Insert an element before or after another element in a listsince: 2.2.0LLEN keysummary: Get the length of a listsince: 1.0.0LPOP keysummary: Remove and get the first element in a listsince: 1.0.0LPUSH key value [value ...]summary: Prepend one or multiple values to a listsince: 1.0.0LPUSHX key valuesummary: Prepend a value to a list, only if the list existssince: 2.2.0LRANGE key start stopsummary: Get a range of elements from a listsince: 1.0.0LREM key count valuesummary: Remove elements from a listsince: 1.0.0LSET key index valuesummary: Set the value of an element in a list by its indexsince: 1.0.0LTRIM key start stopsummary: Trim a list to the specified rangesince: 1.0.0RPOP keysummary: Remove and get the last element in a listsince: 1.0.0RPOPLPUSH source destinationsummary: Remove the last element in a list, prepend it to another list and return itsince: 1.2.0RPUSH key value [value ...]summary: Append one or multiple values to a listsince: 1.0.0RPUSHX key valuesummary: Append a value to a list, only if the list existssince: 2.2.0 Set12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061127.0.0.1:6379&gt; help @setSADD key member [member ...]summary: Add one or more members to a setsince: 1.0.0SCARD keysummary: Get the number of members in a setsince: 1.0.0SDIFF key [key ...]summary: Subtract multiple setssince: 1.0.0SDIFFSTORE destination key [key ...]summary: Subtract multiple sets and store the resulting set in a keysince: 1.0.0SINTER key [key ...]summary: Intersect multiple setssince: 1.0.0SINTERSTORE destination key [key ...]summary: Intersect multiple sets and store the resulting set in a keysince: 1.0.0SISMEMBER key membersummary: Determine if a given value is a member of a setsince: 1.0.0SMEMBERS keysummary: Get all the members in a setsince: 1.0.0SMOVE source destination membersummary: Move a member from one set to anothersince: 1.0.0SPOP key [count]summary: Remove and return one or multiple random members from a setsince: 1.0.0SRANDMEMBER key [count]summary: Get one or multiple random members from a setsince: 1.0.0SREM key member [member ...]summary: Remove one or more members from a setsince: 1.0.0SSCAN key cursor [MATCH pattern] [COUNT count]summary: Incrementally iterate Set elementssince: 2.8.0SUNION key [key ...]summary: Add multiple setssince: 1.0.0SUNIONSTORE destination key [key ...]summary: Add multiple sets and store the resulting set in a keysince: 1.0.0 123特性：【无序】&amp;&amp;【随机性】&amp;&amp;【去重】放入的多少不同，元素存储的顺序不同。 Sorted_set123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101127.0.0.1:6379&gt; help @sorted_setBZPOPMAX key [key ...] timeoutsummary: Remove and return the member with the highest score from one or more sorted sets, or block until one is availablesince: 5.0.0BZPOPMIN key [key ...] timeoutsummary: Remove and return the member with the lowest score from one or more sorted sets, or block until one is availablesince: 5.0.0ZADD key [NX|XX] [CH] [INCR] score member [score member ...]summary: Add one or more members to a sorted set, or update its score if it already existssince: 1.2.0ZCARD keysummary: Get the number of members in a sorted setsince: 1.2.0ZCOUNT key min maxsummary: Count the members in a sorted set with scores within the given valuessince: 2.0.0ZINCRBY key increment membersummary: Increment the score of a member in a sorted setsince: 1.2.0ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]summary: Intersect multiple sorted sets and store the resulting sorted set in a new keysince: 2.0.0ZLEXCOUNT key min maxsummary: Count the number of members in a sorted set between a given lexicographical rangesince: 2.8.9ZPOPMAX key [count]summary: Remove and return members with the highest scores in a sorted setsince: 5.0.0ZPOPMIN key [count]summary: Remove and return members with the lowest scores in a sorted setsince: 5.0.0ZRANGE key start stop [WITHSCORES]summary: Return a range of members in a sorted set, by indexsince: 1.2.0ZRANGEBYLEX key min max [LIMIT offset count]summary: Return a range of members in a sorted set, by lexicographical rangesince: 2.8.9ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]summary: Return a range of members in a sorted set, by scoresince: 1.0.5ZRANK key membersummary: Determine the index of a member in a sorted setsince: 2.0.0ZREM key member [member ...]summary: Remove one or more members from a sorted setsince: 1.2.0ZREMRANGEBYLEX key min maxsummary: Remove all members in a sorted set between the given lexicographical rangesince: 2.8.9ZREMRANGEBYRANK key start stopsummary: Remove all members in a sorted set within the given indexessince: 2.0.0ZREMRANGEBYSCORE key min maxsummary: Remove all members in a sorted set within the given scoressince: 1.2.0ZREVRANGE key start stop [WITHSCORES]summary: Return a range of members in a sorted set, by index, with scores ordered from high to lowsince: 1.2.0ZREVRANGEBYLEX key max min [LIMIT offset count]summary: Return a range of members in a sorted set, by lexicographical range, ordered from higher to lower strings.since: 2.8.9ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]summary: Return a range of members in a sorted set, by score, with scores ordered from high to lowsince: 2.2.0ZREVRANK key membersummary: Determine the index of a member in a sorted set, with scores ordered from high to lowsince: 2.0.0ZSCAN key cursor [MATCH pattern] [COUNT count]summary: Incrementally iterate sorted sets elements and associated scoressince: 2.8.0ZSCORE key membersummary: Get the score associated with the given member in a sorted setsince: 1.2.0ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]summary: Add multiple sorted sets and store the resulting sorted set in a new keysince: 2.0.0 Bloom123456789101112131415161718192021222324252627BF.ADD key ...options...summary: Help not availablesince: not knownBF.EXISTS key ...options...summary: Help not availablesince: not knownBF.INSERT key ...options...summary: Help not availablesince: not knownBF.DEBUG key ...options...summary: Help not availablesince: not knownBF.MEXISTS key ...options...summary: Help not availablesince: not knownBF.INFO key ...options...summary: Help not availablesince: not knownBF.MADD key ...options...summary: Help not availablesince: not known 1redis-server --loadmodule &#x2F;opt&#x2F;redis&#x2F;redisbloom.so 持久化RDB 1234#主动触发阻塞的RDB操作（如关机，明确调用）127.0.0.1:6379&gt; save#主动触发异步的RDB操作（Fork进程）127.0.0.1:6379&gt; bgsage AOF 12#主动触发重写AOP操作127.0.0.1:6379&gt; BGREWRITEAOF 常见问题 Redis如何保证Sorted_set的排序和插入效率？ 底层使用跳表Skip List实现的，详细链接 Redis如何淘汰过期的keys? Redis keys过期有两种方式：被动和主动方式。 当一些客户端尝试访问它时，key会被发现并主动的过期。 当然，这样是不够的，因为有些过期的keys，永远不会访问他们。 无论如何，这些keys应该过期，所以定时随机测试设置keys的过期时间。所有这些过期的keys将会从密钥空间删除。 具体就是Redis每秒10次做的事情： 测试随机的20个keys进行相关过期检测。 删除所有已经过期的keys。 如果有多于25%的keys过期，重复步奏1. 这是一个平凡的概率算法，基本上的假设是，我们的样本是这个密钥控件，并且我们不断重复过期检测，直到过期的keys的百分百低于25%,这意味着，在任何给定的时刻，最多会清除1/4的过期keys。 Redis如何解决缓存穿透？ 布隆过滤器，采用多种映射函数将一个元素映射到bitmap的多个位中，当判断元素是否存在时，需要这些位的都是1，若有一个不为1，则不存在。 概率解决问题 12341.穿透了，不存在2.client，增加redis中的key，value标记3.数据库增加了元素4.完成元素对bloom的添加","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/tags/Redis/"}]},{"title":"'Zookeeper 详解'","slug":"zookeeper-base","date":"2020-05-24T02:00:00.000Z","updated":"2020-11-29T06:38:54.636Z","comments":true,"path":"2020/05/24/zookeeper-base/","link":"","permalink":"https://midkuro.gitee.io/2020/05/24/zookeeper-base/","excerpt":"","text":"Zookeeper官方帮助文档 ZooKeeper是一个高性能，高可用性，高可靠性的分布式应用程序的分布式，开放源代码协调服务。 官网测试统计，在事件③和事件⑤将Leader宕机，ZooKeeper只需不到200毫秒即可选出新的领导者。随着关注者的恢复，ZooKeeper一旦开始处理请求就能够再次提高吞吐量。 数据模型ZooKeeper提供的名称空间与标准文件系统的名称空间非常相似。名称是由斜杠（/）分隔的一系列路径元素。ZooKeeper命名空间中的每个节点都由路径标识。 这种数据模型适用的场景： 1234561.统一配置管理&lt;- 1M数据2.分组管理 &lt;- path结构3.统一命名 &lt;- sequential4.同步 &lt;- 临时节点5.分布式锁 &lt;- 临时节点 锁依托一个父节点,且具备 -s 序列，代表父节点下可以有多把锁，后面的ID节点盯着前面的ID节点 特征 使用12345678910#Zookeeper需要java环境[root@localhost zookeeper]# wget https://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.5.8/apache-zookeeper-3.5.8-bin.tar.gz[root@localhost zookeeper]# tar xf apache-zookeeper-3.5.8.tar.gz[root@localhost zookeeper]# cd apache-zookeeper-3.5.8-bin[root@localhost zookeeper]# cp zoo_sample.cfg zoo.cfg[root@localhost zookeeper]# vi zoo.cfg 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# The number of milliseconds of each tick# Leader和Follow心跳 tickTime=2000# The number of ticks that the initial# synchronization phase can take# 重试 主可以忍耐 一个follow的 2000 * 10 的一个延迟，超过则认为有问题initLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgement# 同步 主和Follow 超过 2000 * 5 没有回馈，则认为有问题syncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.# 数据持久化目录 需要将默认目录改成其他目录dataDir=/local/zookeeper/data# the port at which the clients will connect# 客户端连接Zookeeper的端口号clientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients# 最大客户端连接数#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to \"0\" to disable auto purge feature#autopurge.purgeInterval=1#由于ZK没有像Redis那种发布订阅自动识别哨兵的集群，需要人为规划ZK集群server.1=192.168.163.128:2888:3888server.2=192.168.163.129:2888:3888server.3=192.168.163.130:2888:3888server.4=192.168.163.131:2888:3888#server.X X满足过半通过3台时，最大的就是Leader 1234567891011121314# 进入上面配置的数据持久化目录[root@localhost zookeeper]# cd data/# 设置myid文件 值为 1 表示这是server.1, 其他机器同理 1~4[root@localhost data]# echo 1 &gt; myid[root@localhost data]# vi /etc/profile···export ZOOKEEPER_HOME=/home/local/zookeeper/apache-zookeeper-3.5.8-binexport PATH=$ZOOKEEPER_HOME/bin:$PATH···#这样就可以直接在任何目录下使用zk的相关命令[root@localhost data]# source /etc/profile 1234567[root@localhost zookeeper]# zkServer.sh helpZooKeeper JMX enabled by defaultUsing config: /home/local/zookeeper/apache-zookeeper-3.5.8/bin/../conf/zoo.cfgUsage: /home/local/zookeeper/apache-zookeeper-3.5.8/bin/zkServer.sh [--config &lt;conf-dir&gt;] &#123;start|start-foreground|stop|restart|status|print-cmd&#125;#默认不阻塞启动，当前使用阻塞启动看日志[root@localhost zookeeper]# zkServer.sh start-foreground 1234567#启动顺序 128、129、130、131#当前服务器 130 leader 因为已经启动三台，满足过半[root@localhost ~]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /home/local/zookeeper/apache-zookeeper-3.5.8/bin/../conf/zoo.cfgClient port found: 2181. Client address: localhost.Mode: leader 假设这时候主动把130给停了，那么ZK会先比对哪台Follow的数据是最新的，如果有多台数据最新的Follow，则谁Server.X大就推选谁。 12#任意一台机器链接ZK[root@localhost ~]# zkCli.sh 12345678910111213141516171819202122232425262728[zk: localhost:2181(CONNECTED) 0] helpZooKeeper -server host:port cmd args addauth scheme auth close config [-c] [-w] [-s] connect host:port create [-s] [-e] [-c] [-t ttl] path [data] [acl] delete [-v version] path deleteall path delquota [-n|-b] path get [-s] [-w] path getAcl [-s] path history listquota path ls [-s] [-w] [-R] path ls2 path [watch] printwatches on|off quit reconfig [-s] [-v version] [[-file path] | [-members serverID=host:port1:port2;port3[,...]*]] | [-add serverId=host:port1:port2;port3[,...]]* [-remove serverId[,...]*] redo cmdno removewatches path [-c|-d|-a] [-l] rmr path set [-s] [-v version] path data setAcl [-s] [-v version] [-R] path acl setquota -n|-b val path stat [-w] path sync pathCommand not found: Command not found help 1234567891011121314151617181920212223242526#查看根目录[zk: localhost:2181(CONNECTED) 2] ls /[zookeeper]#创建节点 默认是持久节点[zk: localhost:2181(CONNECTED) 3] create /ooxx \"\"Created /ooxx#再次目录[zk: localhost:2181(CONNECTED) 4] ls /[ooxx, zookeeper]#创建节点里的节点[zk: localhost:2181(CONNECTED) 5] create /ooxx/xxoo \"\"Created /ooxx/xxoo#再次节点里的目录[zk: localhost:2181(CONNECTED) 6] ls /ooxx[xxoo]#设置节点里的值[zk: localhost:2181(CONNECTED) 7] set /ooxx \"hello\"#获取节点里的值[zk: localhost:2181(CONNECTED) 8] get /ooxxhello 123456789101112131415161718192021222324#查看节点的状态[zk: localhost:2181(CONNECTED) 11] stat /ooxx# cZxid 有64位，前32位表示Leader的纪元，后32位表示事务ID# ZK顺序执行，Leader维护着一个自增事务ID：00000002# 0x2 表示的是Leader的纪元# cZxid 的 c 表示 create，cZxid表示也就是创建节点的事务IDcZxid = 0x200000002# 创建时间ctime = Fri Nov 27 22:19:42 CST 2020# 修改节点的事务IDmZxid = 0x200000004mtime = Fri Nov 27 22:20:53 CST 2020# 当前这个节点下创建的最后一个节点的ID,也就是 /ooxx/xxoo的cZxidpZxid = 0x200000003cversion = 1dataVersion = 1aclVersion = 0#临时持有者 0x0表示持久节点，否则对应的是sessionIdephemeralOwner = 0x0dataLength = 5numChildren = 1#删除节点[zk: localhost:2181(CONNECTED) 12] deleteall /ooxx 12345678910111213141516171819202122232425#断开客户端重新连接，能够看到日志输出了Sssionid = 0x1000092017d00042020-11-27 22:37:43,097 [myid:localhost:2181] - INFO [main-SendThread(localhost:2181):ClientCnxn$SendThread@1394] - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000092017d0004, negotiated timeout = 30000WATCHER::WatchedEvent state:SyncConnected type:None path:null# create [-s] [-e] [-c] [-t ttl] path [data] [acl]# 创建一个临时节点[zk: localhost:2181(CONNECTED) 0] create -e /xoxo \"aaa\"Created /xoxo#查看临时节点状态[zk: localhost:2181(CONNECTED) 1] stat /xoxocZxid = 0x20000000dctime = Fri Nov 27 22:38:40 CST 2020mZxid = 0x20000000dmtime = Fri Nov 27 22:38:40 CST 2020pZxid = 0x20000000dcversion = 0dataVersion = 0aclVersion = 0#临时节点归属于 0x1000092017d0004 的SessionIdephemeralOwner = 0x1000092017d0004dataLength = 3numChildren = 0 12345678910111213141516171819#这时候用另外一台机器连接zk，得到【sessionid = 0x400002966df0000】#查看目录，能够查看到 xoxo[zk: localhost:2181(CONNECTED) 0] ls /[ooxx, xoxo, zookeeper]#查看临时节点状态[zk: localhost:2181(CONNECTED) 1] stat /xoxocZxid = 0x20000000dctime = Fri Nov 27 22:38:40 CST 2020mZxid = 0x20000000dmtime = Fri Nov 27 22:38:40 CST 2020pZxid = 0x20000000dcversion = 0dataVersion = 0aclVersion = 0#在其他节点中也能看到它的归属其他Session状态ephemeralOwner = 0x1000092017d0004dataLength = 3numChildren = 0 12345# 这时候将【sessionid = 0x1000092017d0004】的链接断开# 然后在【sessionid = 0x400002966df0000】的链接中查看# 已经查不到xoxo节点了，它随着session的断开而消失[zk: localhost:2181(CONNECTED) 1] ls /[ooxx, zookeeper] 123#在临时节点里再新增节点会提示错误，因为临时节点无法加子节点[zk: localhost:2181(CONNECTED) 8] create /aaa/xxxEphemerals cannot have children: /aaa/xxx Zookeeper提供了统一视图的功能，它在客户端连接到Zookeeper创建Session时，会执行将Session添加到统一视图的事务，这时候事务ID + 1，当Session退出时，会执行一个将Session从统一视图删除的事务，事务ID +1。 12345678910111213141516#【sessionid = 0x400002966df0000】[zk: localhost:2181(CONNECTED) 4] create /xoxo \"\"Created /xoxo[zk: localhost:2181(CONNECTED) 5] stat /xoxo#认准当前事务ID是 00000010cZxid = 0x200000010ctime = Fri Nov 27 22:59:37 CST 2020mZxid = 0x200000010mtime = Fri Nov 27 22:59:37 CST 2020pZxid = 0x200000010cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 0numChildren = 0 123456789101112131415161718#这时候创建一个客户端连接，创建了【sessionid = 0x400002966df0001】#回到【sessionid = 0x400002966df0000】[zk: localhost:2181(CONNECTED) 6] create /oxox \"bbb\"Created /oxox[zk: localhost:2181(CONNECTED) 7] stat /oxox# 可以看到当前事务ID是 00000012cZxid = 0x200000012ctime = Fri Nov 27 23:04:14 CST 2020mZxid = 0x200000012mtime = Fri Nov 27 23:04:14 CST 2020pZxid = 0x200000012cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 3numChildren = 0 如果一个客户端连接了一个Zookeeper，这时候如果这台Zookeeper挂了，客户端的连接将转移到另外一台Zookeeper，这时候会重新创建Session吗？ 也就是说，创建Session后，每个Zookeeper都能够从统一视图中获得这个Session会话，如果某个节点挂了，客户端转移另一台Zookeeper时，只要在Session超时的时间内重新连接了，就能保持原Session，默认超时时间是3秒。 通信12#分别在4台机器上查看Socket通信状态[root@localhost ~]# netstat -natp | egrep '(2888|3888)' 原理Paxos Paxos ZAB ZAB：原子广播协议 创建 选举 123456每个节点自己会有myid、Zxid新的Leader1，经验最丰富的Zxid,2，myid3.原Follower的zxid都是可信的，都是经过过半投票后产生的数据 在上图集群中，Leader节点是node04，并且触发了过半通过，而node03节点尚未同步最新数据（Zxid=07 –&gt; Zxid=08），假设这时候Leader挂了，并且node03的心跳检测最先识别出Leader挂了，触发了选举机制。 1234567步骤：1. node03推选自己做Leader，将自身信息发送给其他节点2. 其他节点对比Zxid，发现比自身旧，驳回node03节点信息3. 驳回的节点被动推选自己做Leader，将自身信息发给其他节点4. 每个节点接收到驳回的节点信息后，【比对Zxid，相等时再比对myid，然后自身节点对合适的节点投票】5. 节点向合适的节点发送自身的投票结果6. 节点向其他节点转发合适的节点信息 123456789最终投票信息如下：node01节点： node02： + 1 (node02投票自身) + 1 (node01投票node02) + 1 (node03转发node02)node02节点： node02: + 1 (node02投票自身) + 1 (node01投票node02) + 1 (node03投票node02) node03节点： node02： + 1 (node02投票自身) + 1 (node03投票node02) + 1 (node01转发node02) Watch 代码12345&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.8&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132public class App &#123; public static void main(String[] args) throws Exception &#123; //zk是有session概念的，没有连接池的概念 //watch:观察，回调 //watch的注册值发生在 读类型调用，get，exites。。。 //第一类：new zk 时候，传入的watch，这个watch，session级别的，跟path 、node没有关系。 final CountDownLatch cd = new CountDownLatch(1); final ZooKeeper zk = new ZooKeeper(\"192.168.150.11:2181,192.168.150.12:2181,192.168.150.13:2181,192.168.150.14:2181\", 3000, sessionWatcher(cd)); //线程阻塞等待zookeeper连接完成，它是个异步模型 cd.await(); //打印当前zookeeper状态 如果没有闭锁，可能是CONNECTING，加了闭锁则是Connected printState(zk); //创建节点 String pathName = zk.create(\"/ooxx\", \"olddata\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL); //查询节点时增加Watch机制，watch监控会在节点修改时触发 final Stat stat = new Stat(); byte[] node = zk.getData(\"/ooxx\", new Watcher() &#123; @Override public void process(WatchedEvent event) &#123; System.out.println(\"getData watch: \" + event.toString()); try &#123; //true 会使用default Watch 重新注册 ： new zk的那个watch //zk.getData(\"/ooxx\", true, stat); // this将当前Watch重新注册到zk中 zk.getData(\"/ooxx\", this, stat); &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, stat); System.out.println(new String(node)); //触发回调 Stat stat1 = zk.setData(\"/ooxx\", \"newdata\".getBytes(), 0); //如果没有重新注册Watch，就不会再触发回调，重新注册了，就会触发回调 Stat stat2 = zk.setData(\"/ooxx\", \"newdata01\".getBytes(), stat1.getVersion()); System.out.println(\"-------async start----------\"); //异步获取数据，响应式编程 zk.getData(\"/ooxx\", false, new AsyncCallback.DataCallback() &#123; @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) &#123; System.out.println(\"-------async call back----------\"); System.out.println(ctx.toString()); System.out.println(new String(data)); &#125; &#125;, \"abc\"); System.out.println(\"-------async over----------\"); System.in.read(); &#125; public static void printState(ZooKeeper zk) &#123; ZooKeeper.States state = zk.getState(); switch (state) &#123; case CONNECTING: System.out.println(\"ing......\"); break; case ASSOCIATING: break; case CONNECTED: System.out.println(\"ed........\"); break; case CONNECTEDREADONLY: break; case CLOSED: break; case AUTH_FAILED: break; case NOT_CONNECTED: break; &#125; &#125; public static Watcher sessionWatcher(CountDownLatch cd) &#123; return new Watcher() &#123; //Watch 的回调方法！ @Override public void process(WatchedEvent event) &#123; Event.KeeperState state = event.getState(); Event.EventType type = event.getType(); String path = event.getPath(); System.out.println(\"new zk watch: \" + event.toString()); switch (state) &#123; case Unknown: break; case Disconnected: break; case NoSyncConnected: break; case SyncConnected: System.out.println(\"connected\"); cd.countDown(); break; case AuthFailed: break; case ConnectedReadOnly: break; case SaslAuthenticated: break; case Expired: break; &#125; switch (type) &#123; case None: break; case NodeCreated: break; case NodeDeleted: break; case NodeDataChanged: break; case NodeChildrenChanged: break; &#125; &#125; &#125;; &#125;&#125; 配置中心1234567891011121314151617181920212223public class ZKUtils &#123; private static ZooKeeper zk; private static String address = \"192.168.150.11:2181,192.168.150.12:2181,192.168.150.13:2181,192.168.150.14:2181/testLock\"; //自定义了一个Session的Watch private static DefaultWatch watch = new DefaultWatch(); private static CountDownLatch init = new CountDownLatch(1); public static ZooKeeper getZK()&#123; try &#123; zk = new ZooKeeper(address,1000,watch); watch.setCc(init); init.await(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return zk; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334public class DefaultWatch implements Watcher &#123; CountDownLatch cc ; public void setCc(CountDownLatch cc) &#123; this.cc = cc; &#125; @Override public void process(WatchedEvent event) &#123; System.out.println(event.toString()); switch (event.getState()) &#123; case Unknown: break; case Disconnected: break; case NoSyncConnected: break; case SyncConnected: cc.countDown(); break; case AuthFailed: break; case ConnectedReadOnly: break; case SaslAuthenticated: break; case Expired: break; &#125; &#125;&#125; 123456789101112public class MyConf &#123; private String conf ; public String getConf() &#123; return conf; &#125; public void setConf(String conf) &#123; this.conf = conf; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class TestConfig &#123; ZooKeeper zk; @Before public void conn ()&#123; zk = ZKUtils.getZK(); &#125; @After public void close ()&#123; try &#123; zk.close(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; @Test public void getConf()&#123; WatchCallBack watchCallBack = new WatchCallBack(); watchCallBack.setZk(zk); MyConf myConf = new MyConf(); watchCallBack.setConf(myConf); //数据不存在的话，就阻塞等待数据 watchCallBack.aWait(); //1，节点不存在 //2，节点存在 while(true)&#123; if(myConf.getConf().equals(\"\"))&#123; System.out.println(\"conf diu le ......\"); watchCallBack.aWait(); &#125;else&#123; System.out.println(myConf.getConf()); &#125; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class WatchCallBack implements Watcher ,AsyncCallback.StatCallback, AsyncCallback.DataCallback &#123; ZooKeeper zk ; MyConf conf ; CountDownLatch cc = new CountDownLatch(1); public MyConf getConf() &#123; return conf; &#125; public void setConf(MyConf conf) &#123; this.conf = conf; &#125; public ZooKeeper getZk() &#123; return zk; &#125; public void setZk(ZooKeeper zk) &#123; this.zk = zk; &#125; //获取数据阻塞等待 public void aWait()&#123; zk.exists(\"/AppConf\",this,this ,\"ABC\"); try &#123; cc.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //调用get的callback @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) &#123; //如果数据存在，添加进配置对象，然后释放闭锁 if(data != null )&#123; String s = new String(data); conf.setConf(s); cc.countDown(); &#125; &#125; //调用exist的callback @Override public void processResult(int rc, String path, Object ctx, Stat stat) &#123; //如果节点存在，则调用get方法，并添加回调 if(stat != null)&#123; zk.getData(\"/AppConf\",this,this,\"sdfs\"); &#125; &#125; //Watch的注册事件 @Override public void process(WatchedEvent event) &#123; switch (event.getType()) &#123; case None: break; case NodeCreated: //如果事件检测到节点创建，则获取数据，释放闭锁阻塞 zk.getData(\"/AppConf\",this,this,\"sdfs\"); break; case NodeDeleted: //容忍性 //如果数据被删了，则清空数据，重置闭锁，重新阻塞 conf.setConf(\"\"); cc = new CountDownLatch(1); break; case NodeDataChanged: //如果数据变化了，重新获取值 zk.getData(\"/AppConf\",this,this,\"sdfs\"); break; case NodeChildrenChanged: break; &#125; &#125;&#125; 分布式锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167public class TestLock &#123; ZooKeeper zk; ZKConf zkConf; DefaultWatch defaultWatch; @Before public void conn()&#123; zkConf = new ZKConf(); zkConf.setAddress(\"192.168.163.128:2181,192.168.163.129:2181,192.168.163.130:2181,192.168.163.131:2181/testLock\"); zkConf.setSessionTime(1000); defaultWatch = new DefaultWatch(); ZKUtils.setConf(zkConf); ZKUtils.setWatch(defaultWatch); zk = ZKUtils.getZK(); &#125; @After public void close()&#123; ZKUtils.closeZK(); &#125; @Test public void testlock()&#123; for (int i = 0; i &lt; 10; i++) &#123; new Thread()&#123; @Override public void run() &#123; WatchCallBack watchCallBack = new WatchCallBack(); watchCallBack.setZk(zk); String name = Thread.currentThread().getName(); watchCallBack.setThreadName(name); try &#123; //tryLock watchCallBack.tryLock(); System.out.println(name + \" at work\"); watchCallBack.getRootData(); // Thread.sleep(1000); //unLock watchCallBack.unLock(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;.start(); &#125; while(true)&#123; &#125; &#125;&#125;public class WatchCallBack implements Watcher, AsyncCallback.StringCallback, AsyncCallback.Children2Callback,AsyncCallback.StatCallback,AsyncCallback.DataCallback &#123; ZooKeeper zk; CountDownLatch cc = new CountDownLatch(1); String lockName ; String threadName; public String getThreadName() &#123; return threadName; &#125; public void setThreadName(String threadName) &#123; this.threadName = threadName; &#125; public ZooKeeper getZk() &#123; return zk; &#125; public void setZk(ZooKeeper zk) &#123; this.zk = zk; &#125; public void tryLock() &#123; //重入 try &#123; zk.create(\"/lock\", threadName.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL, this, threadName ); cc.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public void getRootData() throws KeeperException, InterruptedException &#123; byte[] data = zk.getData(\"/\", false, new Stat()); System.out.println(new String(data)); &#125; public void unLock()&#123; try &#123; zk.delete(\"/\"+lockName,-1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; &#125; //getChileden.... @Override public void processResult(int rc, String path, Object ctx, List&lt;String&gt; children, Stat stat) &#123; //获得所目录的所有有序节点，然后排序，然后取自己在有序list中的index if(children == null)&#123; System.out.println(ctx.toString() + \"list null\"); &#125;else&#123; try &#123; Collections.sort(children); int i = children.indexOf(lockName); if(i&lt;1)&#123; System.out.println(threadName+\" i am first...\"); zk.setData(\"/\",threadName.getBytes(),-1); cc.countDown(); &#125;else&#123; System.out.println(threadName+\" watch \"+children.get(i-1)); zk.exists(\"/\"+children.get(i-1),this); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; //create.... @Override public void processResult(int rc, String path, Object ctx, String name) &#123; //每个线程启动后创建锁，然后get锁目录的所有孩子，不注册watch在锁目录 System.out.println(ctx.toString()+\" create path: \"+ name); lockName = name.substring(1); zk.getChildren(\"/\", false, this, ctx ); &#125; @Override public void process(WatchedEvent event) &#123; Event.EventType type = event.getType(); switch (type) &#123; case NodeDeleted: zk.getChildren(\"/\", false, this, \"\"); break; case NodeChildrenChanged: break; &#125; &#125; @Override public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) &#123; &#125; @Override public void processResult(int rc, String path, Object ctx, Stat stat) &#123; //监控失败了怎么办 &#125;&#125;","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/tags/Redis/"}]},{"title":"'Redis（一） NoSql 之 Redis'","slug":"redis-nosql","date":"2020-05-23T02:00:00.000Z","updated":"2020-11-25T13:04:32.714Z","comments":true,"path":"2020/05/23/redis-nosql/","link":"","permalink":"https://midkuro.gitee.io/2020/05/23/redis-nosql/","excerpt":"","text":"NoSql之RedisNoSQLNoSQL（Not Only SQL），不仅仅是SQL，泛指非关系型的数据库，随着互联网web2.0网站的兴起，传统的关系型数据库在应付web2.0网站，特别是超大规模和高并发地SNS类型的web2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，尤其是大数据应用难题，包括超大规模数据的存储。 这些类型的数据存储不需要固定的模式，无需多余操作就可以横向扩展。 ACID关系型数据库遵循ACID规则事务在英文中是transaction，和现实世界中的交易很类似，它有如下四个特性： 1、A (Atomicity) 原子性原子性很容易理解，也就是说事务里的所有操作要么全部做完，要么都不做，事务成功的条件是事务里的所有操作都成功，只要有一个操作失败，整个事务就失败，需要回滚。 2、C (Consistency) 一致性一致性也比较容易理解，也就是说数据库要一直处于一致的状态，事务的运行不会改变数据库原本的一致性约束。 3、I (Isolation) 独立性所谓的独立性是指并发的事务之间不会互相影响，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响。 4、D (Durability) 持久性持久性是指一旦事务提交后，它所做的修改将会永久的保存在数据库上，即使出现宕机也不会丢失。 CAP在分布式数据库中的CAP原理： 1、C (Consistency) 强一致性 2、A (Availability) 可用性 3、P (Partition tolerance) 分区容错性 CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。 因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三 大类： CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。 CP - 满足一致性，分区容忍必的系统，通常性能不是特别高。 AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。 分布式和集群的简介： 分布式：不同的多台服务器上面部署不同的服务模块（工程），他们之间通过Rpc/Rmi之间通信和调用，对外提供服务和组内协作。 集群：不同的多台服务器上面部署相同的服务模块，通过分布式调度软件进行统一的调度，对外提供服务和访问。 Redisredis采用单进程模型来处理客户端的请求、对读写等事件的响应。 默认16个数据库，类似数组下表从零开始，初始默认使用零号库 默认端口6379 索引都是从零开始 常见命令文档、Redis命令参考手册完整版 客户端访问redis-cli -h host -p port -a password 查询使用文档help @string、help @generic 命令 描述 SELECT 切换数据库 Dbsize 查看当前数据库的key的数量 Flushdb 清空当前库 Flushall 通杀全部库 五大数据类型Stringstring是redis最基本的类型，可以理解成与Memcached一模一样的类型，一个key对应一个value。 string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。 string类型是redis最基本的数据类型，一个redis中字符串value最多可以是512M。 HashHash（哈希） 是一个键值对集合，以string类型的field和value的映射表，hash特别适合用于存储对象。类似Java里面的Map&lt;String,Object&gt;。 ListList（列表） 是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。它的底层实际是个链表。 SetSet（集合）是string类型的无序集合。它是通过HashTable实现实现的。 zsetzset(sorted set：有序集合)和set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。 常用命令Redis 键(Key) Redis 字符串(String) 案例： getrange：获取指定区间范围内的值，类似between......and的关系，从零到负一表示全部 setrange设置指定区间范围内的值，格式是setrange key值 具体值 setex:设置带过期时间的key和value，原子操作结合,动态设置。 setnx:只有在 key 不存在时设置 key 的值。 mset:同时设置一个或多个 key-value 对。 Redis 列表(List) 案例： lpop/rpop：从列表左端/右端移除第一个元素并返回 lindex：通过索引获取列表中的元素 lindex key index lrem：从left往right删除2个值等于v1的元素，返回的值为实际删除的数量，LREM list3 0 value，表示删除全部给定的值。零个就是全部值 ltrim：截取指定索引区间的元素，格式是ltrim list的key 起始索引 结束索引 rpoplpush：移除列表的最后一个元素，并将该元素添加到另一个列表并返回 linsert：在list某个已有值的前/后再添加具体值 性能总结它是一个字符串链表，left、right都可以插入添加；如果键不存在，创建新的链表；如果键已存在，新增内容；如果值全移除，对应的键也就消失了。链表的操作无论是头和尾效率都极高，但假如是对中间元素进行操作，效率就很惨淡了。 Redis 集合(Set) 案例： scard：获取集合里面的元素个数 serm key value ：删除集合中元素 srandmember：从set集合里面随机取出2个，如果超过最大数量就全部取出，如果写的值是负数，比如-3 ，表示需要取出3个，但是可能会有重复值。 spop key：随机出栈 sdiff：在第一个set里而不在后面任何一个set里的项 sinter：取交集 sunion：取并集 Redis 哈希(Hash) Hash十分常用的命令有hset/hget/hmset/hmget/hgetall/hdel/hkeys/hvals Redis 有序集合(Zset)在set基础上，加一个score值。之前set是k1 v1 v2 v3，现在zset是k1 score1 v1 score2 v2。 zadd/zrange： zrangebyscore：zrangebyscore key 开始sorce 结束sorce ，withscores表示携带分数，(表示不包含，limit 用户限制返回数量 limit 开始下标 数量 zrem：删除元素，格式是zrem zset的key 项的值，项的值可以是多个 zcard ：获取集合中元素个数 zcount ：获取分数区间内元素个数，zcount key 开始分数区间 结束分数区间 zrank： 获取value在zset中的下标位置 zscore：按照值获得对应的分数 zrevrank key values：正序、逆序获得下标索引值 zrevrange：按照分数反序输出 zrevrangebyscore：zrevrangebyscore key 结束score 开始score 配置文件redis的配置文件在redis的安装目录下，在linux环境下，配置文件命名是redis.conf，在windows系统下是redis.window.conf Units单位12345678910111213#`redis`在配置文件的开头定义了一些基本的度量单位，并且不区分大小写。# Redis configuration file example# Note on units: when memory size is needed, it is possible to specify# it in the usual form of 1k 5GB 4M and so forth:## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive so 1GB 1Gb 1gB are all the same. GENERAL通用12345678910111213141516171819202122232425262728293031323334353637383940#Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程daemonize no#当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定pidfile /var/run/redis.pid#指定Redis监听端口，默认端口为6379port 6379#绑定redis对外提供的IP地址bind 127.0.0.1#设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列 + 已经完成三次握手队列。#在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。tcp-backlog 511#当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能timeout 300#单位为秒，如果设置为0，则不会进行Keepalive检测，建议设置成60tcp-keepalive 0#指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，生产上一般选择为noticeloglevel notice#日志记录方式，默认为标准输出#如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/nulllogfile redis.log#是否把日志输出到syslog中sys-enabled no#指定syslog里的日志标志syslog-ident redis#设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库iddatabases 16#设置当本机为slave服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步slaveof &lt;masterip&gt; &lt;masterport&gt; SHAPSHOTTING快照1234567891011121314151617181920212223242526272829# Save the DB on disk:# save &lt;seconds&gt; &lt;changes&gt;#触发RDB持久化的三种策略#指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合#当900秒内出现一次key的变化save 900 1#当300秒内出现10次key的变化save 300 10#当60秒内出现10000次key的变化save 60 10000#如果想禁用RDB持久化的策略，只要不设置任何save指令，或者给save传入一个空字符串参数也可以#save \"\"#如果配置成no，表示你不在乎数据不一致或者有其他的手段发现和控制stop-writes-on-bgsave-error yes#对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。#如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能rdbcompression yes#在存储快照后，还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗#如果希望获取到最大的性能提升，可以关闭此功能rdbchecksum yes#指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb#指定本地数据库存放目录dir ./ SECURITY安全12345#当master服务设置了密码保护时，slav服务连接master的密码masterauth &lt;master-password&gt; #设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭requirepass foobared LIMITS限制12345678910111213141516#设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数#如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxclients 128 #指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，移除规则可以通过maxmemory-policy来指定。#当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区maxmemory &lt;bytes&gt;#六种移除数据的策略：#volatile-lru：使用LRU算法移除key，只对设置了过期时间的键#allkeys-lru：使用LRU算法移除key#volatile-random：在过期集合中移除随机的key，只对设置了过期时间的键#allkeys-random：移除随机的key#volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key#noeviction：不进行移除。针对写操作，只是返回错误信息Maxmemory-policy noeviction APPEND ONLY MODE追加12345678910111213141516171819#指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。#因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为noappendonly no#指定更新日志文件名，默认为appendonly.aofappendfilename appendonly.aof#指定更新日志条件，共有3个可选值： #no：表示等操作系统进行数据缓存同步到磁盘（快） #always：表示每次更新操作后手动调用fsync()将数据写到磁盘（性能差，完整性好） #everysec：表示每秒同步一次（折衷，默认值）appendfsync everysec#重写时是否可以运用Appendfsync，用默认no即可，保证数据安全性。no-appendfsync-on-rewrite no#当文件大小是上次重写后大小的一倍且文件大于64M时触发重写auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 其他配置1234567891011121314151617181920212223242526272829303132#指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中vm-enabled no #虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享vm-swap-file /tmp/redis.swap #将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys)#当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0vm-max-memory 0 #Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的#建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值vm-page-size 32 #设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。vm-pages 134217728 #设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4vm-max-threads 4 #设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启glueoutputbuf yes #指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法hash-max-zipmap-entries 64hash-max-zipmap-value 512 #指定是否激活重置哈希，默认为开启activerehashing yes #3指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件include /path/to/local.conf Redis持久化Redis支持两种数据的持久化方式，分别是RDB和AOF，并且支持两种方式共存。 RDB（Redis DataBase）Redis的RDB持久化策略是指在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里。 Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。 RDB的缺点是最后一次持久化后的数据可能丢失。 Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。 保存RDB持久化默认保存的是dump.rdb文件，路径于Redis的安装目录一致，通过save或bgsave命令配置触发规则。 1234567#redis.conf配置文件的三种策略，关闭则配置 save \"\"#当900秒内出现一次key的变化save 900 1#当300秒内出现10次key的变化save 300 10#当60秒内出现10000次key的变化save 60 10000 使用save命令时只管保存，其他命令均阻塞，使用bgsave时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。可以通过lastsave命令获取最后一次成功执行快照的时间。 执行flushall命令，会马上产生dump.rdb文件，但里面是空的，无意义。 恢复可以通过定时备份dump.rdb文件到其他目录，当redis故障时，将备份文件 dump.rdb 移动到 Redis 安装目录并启动服务即可。 优势适合大规模的数据恢复，对数据完整性和一致性要求不高的数据。 劣势RDB是在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改，而且Fork子进程备份时，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑。 可以通过动态配置停止RDB保存规则的方法：redis-cli config set save &quot;&quot; 总结 RDB是一个非常紧凑的文件 RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程，接下来的工作全部由子进程来做，父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能 与AOF相比，在恢复大的数据集的时候，RDB方式会更快一些 数据丢失风险大 RDB需要经常fork子进程来保存数据到硬盘上，当数据集比较大的时候，fork的过程是非常耗时的，可能会导致redis在一些毫秒级别不能响应客户端请求 AOF(Append Only File)AOF持久化策略是以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据。 换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 保存AOF持久化默认保存的是appendonly.aof文件，路径于Redis的安装目录一致，需要通过配置才能开启AOF持久化 12#redis.conf中的AOF持久化开关appendonly yes 恢复当appendonly.aof文件无损时，直接将该文件拷贝到redis的安装目录下，重启redis即可完成恢复。 当appendonly.aof文件受损时，可以在redis的安装目录下执行redis-check-aof --fix appendonly.aof进行文件修复，然后重启redis进行恢复。 AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制,当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。 AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，遍历新进程的内存中数据，每条记录有一条的Set语句。重写AOF文件的操作，并没有读取旧的AOF文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的AOF文件，这点和快照有点类似。 Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次重写后大小的一倍且文件大于64M时触发。 1234#redis.conf配置文件#可以配置重写的百分比及文件大小auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 优势数据丢失率降低，最多丢失1秒内的数据。 12345#指定更新日志条件，共有3个可选值： #no：表示等操作系统进行数据缓存同步到磁盘（快） #always：同步持久化，每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好 #everysec：异步操作，每秒记录一次，如果一秒内宕机，有数据丢失appendfsync everysec 劣势相同数据集的数据而言AOF文件要远大于RDB文件，恢复速度慢于RDB，AOF运行效率要慢于RDB,每秒同步策略效率较好，不同步效率和RDB相同。 总结 AOF文件是一个只进行追加的日志文件 Redis可以在AOF文件体积变得过大时，自动地在后台对AOF进行重写 AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析也很轻松 对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积 根据所使用的fsync策略，AOF的速度可能会慢于RDB 总结 RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储 AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以Redis协议追加保存每次写的操作到文件末尾。Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大 只做缓存：如果你只希望你的数据在服务器运行的时候存在,也可以不使用任何持久化方式 同时开启两种持久化方式： 在这种情况下,当Redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。 RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？ 建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)，快速重启，留着作为一个万一的手段。 性能建议：因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。 如果Enable AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只加载自己的AOF文件就可以了。 代价一是带来了持续的IO，二是AOF重写的最后将重写过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。 只要硬盘许可，应该尽量减少AOF重写的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。 如果不Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了重写时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。 Redis事务Redis事务是指可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞。 可以用来一个队列中，一次性、顺序性、排他性的执行一系列命令。 常用命令 正常执行 放弃事务 全体连坐 不符合Redis协议的语法错误，类似于Java的编译错误一样，会导致整个事务执行失败。 冤头债主 符合Redis协议的语法，但是在运行中异常，类似于Java的运行时错误一样，只会导致该条命令执行失败，不会影响及回滚其他命令。 Watch监控悲观锁悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁 乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。 乐观锁策略:提交版本必须大于记录当前版本才能执行更新 无加塞 先监控再开启multi，保证两笔金额变动在同一个事务内。 有加塞 监控了key，如果key被修改了，后面一个事务的执行失效。 unwatch 小结 一旦执行了exec之前加的监控锁都会被取消掉了 Watch指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变，比如某个list已被别的客户端push/pop过了，整个事务队列都不会被执行 通过watch命令在事务执行之前监控了多个Keys，倘若在watch之后有任何Key的值发生了变化，exec命令执行的事务都将被放弃，同时返回Nullmulti-bulk应答以通知调用者事务执行失败 如果watch监控后Key值发生了变化，只能通过重新查询新值再重新开启事务进行操作 总结开启事务后的三个阶段： 开启：以MULTI开始一个事务 入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面 执行：由EXEC命令触发事务 开启事务后的三个特性： 单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题 不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 Redis发布订阅 必须要先订阅后发布才能收到消息。 执行PUBLISH c2 hello-redis即可对c2频道发布消息，支持订阅多个的通配符PSUBSCRIBE new*，发送消息PUBLISH new1 redis2015。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/tags/Redis/"}]},{"title":"'ActiveMQ（八） 高级特性'","slug":"activemq-feature","date":"2020-05-22T17:00:08.000Z","updated":"2020-11-12T04:20:38.947Z","comments":true,"path":"2020/05/23/activemq-feature/","link":"","permalink":"https://midkuro.gitee.io/2020/05/23/activemq-feature/","excerpt":"","text":"ActiveMQ高级特性异步投递ActiveMQ支持同步、异步两种发送的模式将消息发送到Broker，模式的选择对发送延时有巨大的影响。producer能够达到怎样的产出率（产出率=发送数据总量/时间）主要受发送延时的影响，使用异步发送可以显著的提高发送的性能。 ActiveMQ默认使用异步发送的模式，除非明确指定使用同步发送的方式或者在未使用事务的前提下发送持久化的消息，这两种情况都是同步发送的。 如果没有使用事务且发送的是持久化消息，每一次发送都是同步发送的且会阻塞producer直到broker返回一个确认，表示消息已经被安全的持久化到磁盘。确认机制提供了消息安全的保障，但同时会阻塞客户端，带来了很大的延时。 很多高性能的应用，允许在失败的情况下有少量的数据丢失，如果你的应用满足这个这点，你可以使用异步发送来提高生产率，即使发送的是持久化的消息。 异步发送可以最大化producer端的发送效率。我们通常在发送消息量比较密集的情况下使用异步发送，它可以很大的提升producer性能。 不过这也带来了额外的问题，就是需要消耗较多的Client端内存，同时也会导致broker端的性能增加。 此外它不能有效的确保消息的发送成功，在useAsyncSend=true的情况下客户端需要容忍消息丢失的可能。 可以参考官网的三种异步投递配置方式： 异步发送确认机制异步发送丢失消息的场景是：生产者设置了UseAsyncSend=true，使用producer.send(msg)持久发送消息。由于消息不阻塞，生产者会认为所有send的消息均被成功发送至MQ。 如果MQ突然宕机，此时生产者端内存中尚未被发送至MQ的消息都会丢失。所以正确的异步发送方式是需要接收回调的。 同步发送和异步发送的区别： 同步发送等send不阻塞了就表示一定发送成功了。 异步发送需要接收回执并由客户端再判断一次是否发送成功。 12345678910111213141516171819202122232425262728293031323334353637public class JmsProducer &#123; //ActiveMQ服务器的链接地址 private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; //队列名称 private static final String QUEUE_NAME = \"queue01\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //设置异步投递 factory.setUseAsyncSend(true); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); //注意：强转成ActiveMQMessageProducer类 ActiveMQMessageProducer producer = (ActiveMQMessageProducer)session.createProducer(queue); for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"message---\" + i); message.setJMSMessageID(UUID.randomUUID.toString()); String messageID = message.getJMSMessageID(); //使用具备回调函数的API发送消息 producer.send(message, new AsyncCallback() &#123; @Override public void onSuccess() &#123; System.out.println(messageID + \"has been send\"); &#125; @Override public void onException(JMSException exception) &#123; System.out.println(messageID + \"fail to send\"); &#125; &#125;); &#125; producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列queue01完毕\"); &#125;&#125; 延迟投递和定时投递12&lt;!--activemq.xml在boker属性上配置schedulerSupport=\"true\"--&gt;&lt;broker xmlns=\"http://activemq.apache.org/schema/core\" brokerName=\"localhost\" dataDirectory=\"$&#123;activemq.data&#125;\" schedulerSupport=\"true\"&gt; Property name type description AMQ_SCHEDULED_DELAY long 延迟投递的时间 AMQ_SCHEDULED_PERIOD long 重复投递的时间间隔 AMQ_SCHEDULED_REPEAT int 重复投递次数 AMQ_SCHEDULED_CRON String Cron表达式 通过在ActiveMQ的配置文件中开启定时调度SchedulerSupport=&quot;true&quot;，默认为false。然后使用ScheduleMessage类进行消息属性配置。 1234567891011121314151617181920212223242526272829//生产者public class JmsProducer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue-delay\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); MessageProducer producer = session.createProducer(queue); //设置延迟投递时间 long delay = 3 * 1000; //设置重复投递的时间间隔 long period = 4 * 1000; //重复投递次数 int repeat = 5; for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"delay-message---\" + i); message.setLongProperty(ScheduleMessage.AMQ_SCHEDULED_DELAY, delay); message.setLongProperty(ScheduleMessage.AMQ_SCHEDULED_PERIOD, period); message.setIntProperty(ScheduleMessage.AMQ_SCHEDULED_REPEAT, repeat); producer.send(message); &#125; producer.close(); session.close(); connection.close(); &#125;&#125; 重试机制那些情况会引发消息重发？ Client用了transactions且在session中调用了rollback() Client用了transactions且在调用commit()之前关闭或者没有commit Client在CLINET_ACKNOWLEDGE的传递模式下，在session中调用了recover() 默认消息重发的时间间隔是每秒钟，重发次数是6次。 有毒消息Poison ACK： 一个消息被redelivedred超过默认的最大重发次数（默认6次）时。消费端会给MQ发送一个Poison ack表示这个消息有毒，告诉broker不要再发了。这个时候broker会把这个消息放到DLQ（死信队列），详情请参照官网。 属性 默认值 描述 collisionAvoidanceFactor 0.15 设置防止冲突范围的政府百分比，只有启动UseCollisionAvoidance参数时才生效，也就是在延迟时间再加一个 maximumRedelivers 6 最大重传次数，达到最大重连次数后抛出异常。为-1时不限制次数，为0时表示不进行重传。 maximumRedeliveryDelay -1 最大传送延迟，只在UseExponentialBackOff为true时有效（V5.5），假设首次重连间隔为10ms，倍数为2，那么第二次重连时间间隔为20ms，第三次重连时间间隔为40ms，当重连时间间隔的大于最大重连时间间隔时，以后每次重连时间间隔都为最大重连时间间隔。 initialRedeliveryDelay 1000L 初始重发延迟时间 redeliveryDelay 1000L 重发延迟时间，当initialRedeliveryDelay=0时生效 useCollisionAvoidance false 启用防止冲装功能 useExponentialBackOff false 启用指数倍数递增的方式增加延迟时间 backOffMultiplier 5 重连时间间隔递增倍数，只有值大于1和启动useExponentialBackOff参数时才生效 配置重试次数12345678910111213//修改最大重试次数public class JmsConsumer_Redelivery &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue-redelivery\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //使用自身的配置类，设置重试次数3次 RedeliveryPolicy redeliveryPolicy = new RedeliveryPolicy(); redeliveryPolicy.setMaximumRedeliveries(3); activeMQConnectionFactory.setRedeliveryPolicy(redeliveryPolicy); //省略后续代码... &#125;&#125; 整合Spring123456789&lt;!--定义reDelivery重发机制--&gt;&lt;bean id=\"activeMQRedeliveryPolicy\" class=\"org.apache.activemq.RedeliveryPolicy\"&gt; &lt;property name=\"maximumRedeliveries\" value=\"3\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--创建连接工厂并指定配置--&gt;&lt;bean id=\"connectionFactory\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.1.132:61616\"&gt;&lt;/property&gt; &lt;property name=\"redeliveryPolicy\" ref=\"activeMQRedelivery\" /&gt;&lt;/bean&gt; 死信队列ActiveMQ中引入了死信队列（Dead Letter queue）的概念，即一条消息再被重发了多次后（默认为重发6次redeliveryConter==6），将会被ActiveMQ移入私信队列，开发人员可以在这个Queue中查看处理出错的消息，进行人工干预，主要用来处理失败的消息，详情请查看官网。 一般生产环境中在使用MQ的时候设计两个队列：一个是核心业务队列，一个是死信队列。 核心业务队列，就是比如上图专门用来让订单系统发送订单消息的，然后另外一个私信队列就是用来处理异常情况的。 假设第三方物流系统故障了，此时无法请求，那么仓储系统每次消费到一条订单消息，尝试通知发货和配送都会遇到对方的接口报错。此时仓储系统就可以把这条消息拒绝访问或者标志位处理失败。一旦表这条消息处理失败后，MQ就会把这条消息转入提前设置好的一个死信队列中。 然后看到的就是，在第三方物流系统故障期间，所有订单消息全部处理失败，全部都会转入私信队列，然后你的仓储系统得专门有一个后台线程，监控第三方系统是否正常。一旦发现对方回复正常，这个后台线程就从私信队列消费处理失败的订单，重新执行发货和配送的通知逻辑。 共享死信队列SharedDeadLetterStrategy（共享死信队列），将所有的DeadLetter保存在一个共享的队列中，这是ActiveMQ broker端默认的策略。 共享队列默认为ActiveMQ.DLQ，可以通过deadLetterQueue属性来设定。 123&lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy deadLetterQueue=\"DLQ-QUEUE\" /&gt;&lt;/deadLetterStrategy&gt; 个人死信队列IndividualDeadLetterStrategy（个人死信队列），把DeadLetter放入各自的死信通道中。 对于Queue而言，死信通道的前缀默认为ActiveMQ.DLQ.Queue. 对于Topic而言，死信通道的前缀默认为ActiveMQ.DLQ.Topic. 比如队列Order，那么它对应的死信队列通道为ActiveMQ.DLQ.Queue.Order，我们使用queuePrefix、topicPrefix来指定上述前缀。 默认情况下，无论是Topic还是Queue，Broker将使用Queue来保存DeadLetter，即死信通道通常为Queue，不过开发也可以指定为Topic。 12345&lt;policyEntry queue=\"order\"&gt; &lt;deadLetterStrategy&gt; &lt;individualDeadLetterStrategy queuePrefix=\"DLQ.\" useQueueForQueueMessages=\"false\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 将队列Order中出现的DeadLetter保存在DLQ.Order中，不过此时DLQ.Order为Topic。 属性useQueueForQueueMessages设置使用队列保存死信队列，还可以设置useQueueForTopicMessages，使用Topic来保存死信队列，默认为true。 自动删除过期消息有时需要直接删除过期的消息而不需要发送到死信队列中，processExpired表示是否将过期消息放入私信队列，默认为true。 123456&lt;!--\"&gt; \"类似SQL的 * --&gt;&lt;policyEntry queue=\"&gt; \" &gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStragegy processExpired=\"false\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 存放非持久消息默认情况下，ActiveMQ不会把非持久的死消息发送到死信队列中。processNonPersistent表示是否将非持久化消息放入死信队列，默认为false。 如果想把非持久化的消息发送到死信队列中，需要设置属性processNonPersistent=&quot;true&quot; 12345&lt;policyEntry queue=\"&gt; \"&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processNonPersistent=\"true\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 重复消费如何保证消息不被重复消费？幂等性问题？ ​ 网络延迟传输中，会造成进行MQ重试中，在重试过程中，可能会造成重复消费。 如果消息是做数据库的插入操作，给这个消息做一个唯一主键，那么就算出现重复消息的情况，就会导致主键冲突，避免数据库出现脏数据。 或者准备个第三方来做消息记录，以redis为例，给消息分配一个全局id，只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis，消费者开始消费前，先去redis中查询有没有消费记录即可。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/categories/ActiveMQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（七） 多节点集群'","slug":"activemq-cluster","date":"2020-05-22T17:00:07.000Z","updated":"2020-11-12T04:20:35.228Z","comments":true,"path":"2020/05/23/activemq-cluster/","link":"","permalink":"https://midkuro.gitee.io/2020/05/23/activemq-cluster/","excerpt":"","text":"ActiveMQActiveMQ多节点集群引入消息队列之后该如何保证其高可用性？ 基于Zookeeper和LevelDB搭建ActiveMQ集群，提供主备方式的高可用集群功能，避免单点故障。 三种集群方式：官网介绍 在ActiveMQ V5.6版本之后推出LevelDB的持久化引擎，它使用了自定义的索引代替常用的BTree索引，其持久化性能高于KahaDB，虽然默认的持久化方式还是KahaDB，但是LevelDB可能会是趋势。 在ActiveMQ V5.9版本还提供了基于LevelDB和Zookeeper的数据复制方式，作为Master-Slave方式的首选数据复制方案。 ZK+R LevelDB Store从ActiveMQ V5.9开始，ActiveMQ的集群实现方式取消了传统的Master-Slave方式，增加了基于Zookeeper+LevelDB的Master-Slave实现方式，从V5.9版本后也是官网推荐的。 原理说明： ​ 使用Zookeeper集群注册所有的ActiveMQ Broker但只有其中一个Broker可以提供服务，它将被视为Master，其他Broker处于待机状态被视为Slave。 如果Master因故障而不能提供服务ZooKeeper会从Slave中选举出一个Broker充当Master。 Slave连接Master并同步他们的存储状态，Slave不接受客户端连接。所有存储操作都将被复制到连接至Master的Slaves。 如果Master宕机，得到了最新更新的Slave会成为Master。故障节点在恢复会重新加入到集群中并连接Master进入Slave模式。 所有需要同步的消息操作都将等待存储状态被复制到其他法定节点的操作完成才能算完成。 所以，如果你配置了replicas=3，那么法定大小是（3/2+1）=2。Master将会存储并更新然后等待（2-1）=1个Slave存储和更新完成，才汇报success。至于为什么是2-1个，可以结合Zookeeper的watch机制、选举算法、原子广播ZAB协议。 有一个节点要作为观察者存在，当一个新的Master被选中，需要至少保障一个法定节点在线，以能够找到拥有最新状态的节点，这个节点才可以成为新的Master。 部署规划和步骤要求关闭防火墙并保证可以ping通ActiveMQ服务器，要求具备Zookeeper集群并可以成功启动。 集群部署规划列表 主机 Zookeeper集群端口 AMQ集群Bind端口 AMQ消息TCP端口 管理控制台端口 AMQ安装目录 192.168.1.132 2191 bind=”tcp://0.0.0.0:63631” 61616 8161 /mq_node01 192.168.1.132 2192 bind=”tcp://0.0.0.0:63632” 61617 8162 /mq_node02 192.168.1.132 2193 bind=”tcp://0.0.0.0:63633” 61618 8163 /mq_node03 修改控制台端口12345&lt;!--AMQ目录/conf/jetty.xml--&gt;&lt;bean id=\"jettyPort\" class=\"org.apache.activemq.web.WebConsolePort\" init-method=\"start\"&gt; &lt;property name=\"host\" value=\"0.0.0.0\" /&gt; &lt;property name=\"port\" value=\"8161\"&gt;&lt;/bean&gt; HostName映射1234#hostname名字映射vim /etc/hosts#增加自己机器配置192.168.1.132 mq-server brokerName一致123&lt;!--三个节点的brokerName要求全部一致--&gt;&lt;!--修改每个AMQ的activemq.xml文件--&gt;&lt;broker xmlns=\"http://activemq.apache.org/schema/core\" brokerName=\"kuromq\" dataDirectory=\"$&#123;activemq.data&#125;\"&gt; 持久化配置三个节点的持久化配置要求一致，Bind根据不同MQ实例调整 12345678910&lt;persistenceAdapter&gt; &lt;replicatedLevelDB directory=\"$&#123;activemq.data&#125;/leveldb\" replicas=\"3\" bind=\"tcp://0.0.0.0:63633\" zkAdress=\"localhost2191,localhost2192,localhost2193\" hostname=\"#mq-server\" sync=\"local_disk\" zkPath=\"/activemq/leveldb-stores\" /&gt;&lt;/persistenceAdapter&gt; 修改消息端口修改activemq.xml的消息协议的端口，调整为上述规划的端口。 然后按照顺序启动3个ActiveMQ节点，前提是Zookeeper集群已经成功启动运行。 zk集群的节点状态12#进入任意一台zookeeper目录下的bin./zkCli.sh -server 127.0.0.1:2191 集群启动后对Zookeeper数据抓图，可以看到ActiveMQ的三个节点，分别是00000000000，00000000001，00000000002。 第二张图00000000000的值可以看到elected的值不为空，说明这个节点是Master，其他两个是Slave。 集群可用性测试ActiveMQ的客户端只能访问Master的Broker，其他处于Slave的Broker不能访问，所以客户端连接的Broker应该使用failover协议(失败转移)。 当一个ActiveMQ节点挂掉或者一个Zookeeper节点挂掉，ActiveMQ服务依然正常运行，如果仅剩一个ActiveMQ节点，由于不能选举Master，所以ActiveMQ不能正常运行。 同样的，如果Zookeeper仅剩一个节点活动，不管ActiveMQ各个节点存活与否，ActiveMQ也不能正常提供服务，ActiveMQ集群的高可用依赖于Zookeeper集群的高可用。 12//BrokerURL调整public static final String ACTIVE_URL=\"failover:(tcp://192.168.1.132:61616,tcp://192.168.1.132:61617,tcp://192.168.1.132:61618)?randomize=false\"; 测试：3台机器中的ActiveMQ只会有一个MQ可以被客户端连接使用，在测试时可以把Master关掉，然后再重试客户端消息发送和消息还可以正常使用，则说明集群搭建正常。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/categories/ActiveMQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（六） 消息持久化'","slug":"activemq-persistent","date":"2020-05-22T17:00:06.000Z","updated":"2020-11-12T04:20:52.054Z","comments":true,"path":"2020/05/23/activemq-persistent/","link":"","permalink":"https://midkuro.gitee.io/2020/05/23/activemq-persistent/","excerpt":"","text":"ActiveMQ消息持久化消息持久化是一种MQ服务器宕机了，消息不会丢失的机制。为避免意外宕机以后丢失信息，需要做到重启后可以恢复消息队列，消息系统一般都会采用持久化机制。 ActiveMQ消息持久化机制有JDBC,AMQ，KahaDB和LevelDB，无论使用哪种持久化方式，消息的存储逻辑都是一致的。 就是在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等再试图将消息发送给接收者，成功则将消息从存储中删除，失败则继续尝试发送。 消息中心启动以后首先要检查指定的存储位置，如果有未发送成功的消息，则需要把消息发送出去。 AMQ Message StoreAMQ是一种文件存储形式，它具有写入速度快和容易恢复的特点。消息存储在一个个文件中，文件的默认大小为32M，当一个存储文件中的消息已经全部被消费，那么这个文件将被标识为可删除，在下一个清除阶段，这个文件被删除。AMQ适用于ActiveMQ5.3之前的版本，现在已经不使用了。 KahaDB消息存储KahaDB是从ActiveMQ5.4开始到至今的默认持久化插件，可用于任何场景，提高性能和恢复能力。 消息存储使用一个事务日志和仅仅用一个索引文件来存储它所有的地址。 KahaDB是一个专门针对消息持久化的解决方案，它对典型的消息使用模型进行了优化。 数据被追加到data logs中，当不在需要log文件中的数据的时候，log会被丢弃。 1234&lt;!--activemq.xml的配置--&gt;&lt;persistenceAdapter&gt; &lt;kahaDB directory=\"$&#123;activemq.data&#125;/kahadb\" /&gt;&lt;/persistenceAdapter&gt; 在ActiveMQ安装目录下的data/kahadb文件夹中，只有四类文件和一个lock，跟ActiveMQ的其他几种文件存储引擎相比十分简洁。 db-&lt;Number&gt;.log： KahaDB存储消息到预定义大小的数据记录文件中，文件命名为db-&lt;Number&gt;.log。当数据文件已满时，一个新的文件会随之创建，Number数值也会随之递增，它随着消息数量的增加，如每32M一个文件，文件名按照数字进行编号，如db-1.log、db-2.log、db-3.log……当不再有引用到数据文件中的任何消息时，文件会被删除或者归档。 db.data： 该文件包含了持久化的BTree索引，索引了消息数据记录中的消息，他是消息的索引文件，本质上是B-Tree（B树），使用B-Tree作为索引指向db-&lt;Number&gt;.log里面存储的消息。 db.free： 当db.data文件里哪些页面是空闲的，文件具体内容是所有的空闲页的ID，方便后续db.data建立索引时使用，保证索引的连续性，没有碎片。 db.redo： 用来进行消息恢复，如果KahaDB消息存储在强制退出后启动，用于恢复Btree索引。 Lock： 文件锁，标识当前获得KahaDB读取权限的Broker。 LevelDB消息存储这种文件系统时从ActiveMQ5.8之后引进的，它和KahaDB非常相似，也是基于文件的本地数据库储存形式，但是它提供比KahaDB更快的持久性。 但它不能使用自定义B-Tree实现来索引与写日志，而是使用基于LevelDB的索引。 1234&lt;!--默认的配置如下:--&gt;&lt;persistenceAdapter&gt; &lt;levelDB directory=\"activemq-data\" /&gt;&lt;/persistenceAdapter&gt; JDBC消息存储以Mysql数据库为例，需要将Mysql数据库的驱动包mysql-connector-java-5.1.38.jar添加到ActiveMQ目录下的lib文件夹中。 然后修改activemq.xml配置文件，按照如下修改： 12345678&lt;!--原KahaDB的配置--&gt;&lt;persistenceAdapter&gt; &lt;kahaDB directory=\"$&#123;activemq.data&#125;/kahadb\" /&gt;&lt;/persistenceAdapter&gt;&lt;!--修改成JDBC配置--&gt;&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource=\"#mysql-ds\" createTablesOnStartup=\"true\" /&gt;&lt;/persistenceAdapter&gt; dataSource指定将要引用的持久化数据库的bean名称，createTablesOnStartup参数表示是否在启动的时候创建数据库表，默认值是true，这样每次启动都会去创建数据库表了，一般是第一次启动的时候设置为true，之后改成false。 上文指定了一个数据库实例mysql-ds，所以需要创建一个mysql-ds的实例，通过activemq.xml中的&lt;broker&gt;标签外设置bean 1234567&lt;bean id=\"mysql-ds\" class=\"org.apache.commons.dbcp2.BasicDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost/activemq?relaxAutoCommit=true\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;property name=\"poolPreparedStatements\" value=\"true\"/&gt; &lt;/bean&gt; 其中的org.apache.commons.dbcp2.BasicDataSource是JDBC驱动包自带的，当然也可以替换成C3P0或者Druid，但是lib文件夹就需要再添加C3p0或者Druid相关的依赖包。 然后创建一个与上方配置相同的数据库（activemq），执行语句CREATE DATABASE activemq 。 如果配置正常且启动成功，将会在数据库创建三张表ACTIVEMQ_MSGS、ACTIVEMQ_ACKS、ACTIVEMQ_LOCK。 ACTIVE_MSGS 列名 意义 ID 自增的数据库主键 CONTAINER 消息的Destination MSGID_PROD 消息发送者的主键 MSG_SEQ 消息发送的顺序，MSGID_PROD+MSG_SEQ可以组成JMS的MessageID EXPIRATION 消息过期时间，存储的是从1970-01-01到现在的毫秒数 MSG 消息本体的Java序列化对象的二进制数据 PRIORITY 优先级，0-9，数值越大优先级越高 ACTIVEMQ_ACKSactivemq_acks用于存储订阅关系。如果是持久化Topic，订阅者和服务器的订阅关系在这个表保存。 列名 意义 CONTAINER 消息的Destination SUB_DEST 如果是使用Static集群，这个字段会有集群其他系统的信息 CLIENT_ID 每个订阅者都必须有一个唯一的客户端ID用以区分 SUB_NAME 订阅者名称 SELECTOR 选择器，可以只消费满足条件的消息。条件可以用自定义属性实现，可支持多属性AND和OR操作 LAST_ACKED_ID 记录消费过的消息的ID ACTIVEMQ_LOCK表activemq_lock在集群环境中才有用，只有一个Broker可以获得消息，称为Master Broker，其他的只能作为备份等待Master Broker不可用，才可能称为下一个Master Broker。这个表用于记录哪个Broker是当前的Master Broker。 队列在点对点类型中： 当DeliveryMode设置为NON_PERSISTENCE时，消息被保存在内存中； 当DeliveryMode设置为PERSISTENCE时，消息保存在broker的相应的文件或者数据库中。 而且点对点类型中消息一旦被Consumer消费就从broker中删除。 12//开启消息持久化producer.setDeliveryMode(DeliveryMode.PERSISTENT); 能够看到开启消息持久化后，生产者发送消息到队列中，通过查询activemq_msgs表能够看到数据变化情况。 主题开启消息持久化，先启动消费者订阅再运行生产者，可以看到activemq_acks的变化情况。 总结一定要开启消息持久化： 如果是队列： 在没有消费者消费的情况下会将消息保存到activemq_msgs表中，只要有任意一个消费者已经消费国了，消费之后这些消息将会被立刻删除。 如果是主题： 一般是先启动消费者订阅然后再生产的情况下会将消息保存到activemq_acks。 数据库Jar包： 记得需要使用到的相关Jar文件放置到ActiveMQ安装路径下的lib目录。mysql-jdbc驱动包和对应的数据库连接池Jar包 createTablesOnStartup属性： 在jdbcPersistenceAdapter标签中设置了这个属性为true时，在第一次启动ActiveMQ时，ActiveMQ服务节点会自动创建所需要的数据表，启动完成后可以更改为false。 下划线： java.lang.illeglStateException:BeanFactory not initalized or already closed，这是因为操作系统机器名中有“_”符号，请更改机器名并重启后即可解决问题。 JDBC增强版 JDBC Message store With ActiveMQ Journal，简称JDBC增强版，这种方式客服了JDBC Store的不足，JDBC每次消息过来，都需要去写库和读库。 ActiveMQ Journal，使用高速缓存写入技术，大大提高了性能。 当消费者的消费速度能够及时跟上生产者消息的生产速度时，Journal文件能够大大减少需要写入到DB中的消息。 举个例子： ​ 生产者生产了1000条消息，这1000条消息会保存到journal文件，如果消费者的消费速度很快的情况下，在journal文件还没有同步到DB之前，消费者已经消费了90%以上的消息，那么这个时候只需要同步剩余的10%的消息到DB。 如果消费者消费的速度很慢，这时候journal文件可以使消息以批量方式写到DB。 1234567891011121314&lt;!--原JDBC的配置--&gt;&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource=\"#mysql-ds\" createTablesOnStartup=\"true\" /&gt;&lt;/persistenceAdapter&gt;&lt;!--修改成JDBC Journal配置--&gt;&lt;persistenceAdapter&gt; &lt;journalPersistenceAdapterFactory journalLogFiles=\"4\" journalLogFilSize=\"32768\" useJournal=\"true\" useQuickJournal=\"true\" dataSource=\"#mysql-ds\" dataDirectory=\"activemq-data\" /&gt;&lt;/persistenceAdapter&gt; 总结持久化消息主要是指MQ所在的服务器宕机后消息不会丢失的机制。 持久化机制演化过程： 从最初的AMQ Message Store方案到ActiveMQ V4版本中推出的High performance journal（高性能事务支持）附件，并且同步推出了关于关系型数据库的存储方案。 ActiveMQ V5.3版本中又推出了对KahaBD的支持（V5.4版本后成为ActiveMQ默认的持久化方案），后来AciveMQ V5.8版本开始支持LevelDB，到现在，v5.9+版本提供了标准的Zookeeper+LevelDB集群化方案。 ActiveMQ的消息持久化机制： AMQ： 基于日志文件 KahaDB：基于日志文件，从ActiveMQ 5.4开始默认的持久化插件 JDBC：基于第三方数据库 LevelDB：基于文件的本地数据库储存，从ActiveMQ 5.8版本之后又推出了LevelDB的持久化引擎性能高于KahaDB Replicated LevelDB Store：从ActiveMQ 5.9提供了基于LevelDB和Zookeeper的数据复制方式，用于Master-slave方式的首选数据复制方案。 无论使用哪种持久化方式，消息的存储逻辑都是一致的： 就是在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等，然后试图将消息发送给接收者，发送成功则将消息从存储中删除，失败则继续尝试。消息中心启动以后首先要检查指定的存储位置，如果有未发送的消息，则需要把消息发送出去。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/categories/ActiveMQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（五） SpringBoot整合ActiveMQ'","slug":"activemq-springboot","date":"2020-05-22T17:00:05.000Z","updated":"2020-11-12T04:21:04.661Z","comments":true,"path":"2020/05/23/activemq-springboot/","link":"","permalink":"https://midkuro.gitee.io/2020/05/23/activemq-springboot/","excerpt":"","text":"ActiveMQSpringBoot整合ActiveMQpom.xml1234567&lt;!-- pom.xml增加依赖--&gt;&lt;!-- activemq所对JMS的支持，整合Spring和Activemq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; application.yml123456789#application.ymlspring: activemq: broker-url: tcp://192.168.1.132:61616 user: admin password: admin jms: #fasle = Queue true = Topic 默认Queue pub-sub-domain: false Bean12345678910111213@Component@EnableJms //开启SpringBoot对Jms的支持public class ConfigBean &#123; @Bean public Queue queue() &#123; return new ActiveMQQueue(\"myQueueName\"); &#125; @Bean public Topic topic() &#123; return new ActiveMQTopic(\"myTopicName\"); &#125;&#125; 生产者-定时调度123456789101112131415161718192021@Componentpublic class Queue_Produce &#123; @Autowired private JmsMessagingTemplate jmsMessagingTmplate; @Autowired private Queue queue; //@Autowired //private Topic topic; public void produceMsg() &#123; //convertAndSend自动转换消息的类型 jmsMessagingTemplate.convertAndSend(queue,\"SpringBoot队列发送消息\"); //jmsMessagingTemplate.convertAndSend(topic,\"SpringBoot主题发送消息\"); &#125; //间隔3秒定投 @Scheduled(fixedDelay = 3000) public void produceMsgScheduled() &#123; jmsMessagingTemplate.convertAndSend(queue,\"SpringBoot定时投递消息\"); &#125;&#125; 1234567@SpringBootApplication@EnableScheduling //激活定时调度public class MainApp_Produce &#123; public static void main(String[] args) &#123; SpringApplication.run(MainApp_Produce.class, args); &#125;&#125; Junits12345678910111213//单元测试执行@SpringBootTest(classes = MainApp_Produce.class)@RunWith(SpringJUnit4ClassRunner.class)@WebAppConfigurationpublic class TestActiveMQ &#123; @Autowired private Queue_Produce queue_produce; @Test public void testSend() throws Exception &#123; queue_produce.produceMsg(); &#125;&#125; 消费者-监听器12345678@Componentpublic class Queue_Consumer &#123; //设置监听器 @JmsListener(destination = \"myQueueName\") public void receive(TextMessage textMessage) throws JMSException &#123; System.out.println(\"消费者收到消息：\" + textMessage.getText()); &#125;&#125;","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/categories/ActiveMQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（四） Spring整合ActiveMQ'","slug":"activemq-spring","date":"2020-05-22T17:00:04.000Z","updated":"2020-11-12T04:20:59.940Z","comments":true,"path":"2020/05/23/activemq-spring/","link":"","permalink":"https://midkuro.gitee.io/2020/05/23/activemq-spring/","excerpt":"","text":"ActiveMQSpring整合ActiveMQpom.xml依赖123456789101112131415161718192021222324&lt;!-- pom.xml增加依赖--&gt;&lt;!-- activemq所对JMS的支持，整合Spring和Activemq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.3.23.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--activemq所需要的pool包配置--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt;&lt;!--activemq相关依赖配置--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.xbean&lt;/groupId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt;&lt;/dependency&gt; applicationContext.xml123456789101112131415161718192021222324252627282930313233&lt;!-- applicationContext.xml--&gt;&lt;!-- 开启包的自动扫描--&gt;&lt;context:component-scan bean-package=\"*\" /&gt;&lt;!--配置生产者--&gt;&lt;bean id =\"jmsFactory\" class=\"org.apache.activemq.pool.PooledConnectionFactory\" destroy-method=\"stop\"&gt; &lt;property name=\"connectionFactory\"&gt; &lt;!--真正可以产生Connection的ConnectionFactory，由对应的JMS服务厂商提供--&gt; &lt;bean class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.1.132:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=\"maxConnections\" value=\"100\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--这是个队列目的地，点对点的--&gt;&lt;bean id =\"destinationQueue\" class=\"org.apache.activemq.command.ActiveMQQueue\"&gt; &lt;!--构造注入--&gt; &lt;constructor-arg index=\"0\" value=\"spring-active-queue\" /&gt;&lt;/bean&gt; &lt;!-- &lt;bean id =\"desctinationTopic\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;constructor-arg index=\"0\" value=\"spring-active-topic\"&gt;&lt;/bean&gt; --&gt;&lt;!--Spring提供的JMS工具类，它可以进行消息、接收等--&gt;&lt;bean id=\"jmsTemplate\" class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"jmsFactory\" /&gt; &lt;!--消息默认目的地，ref根据提供的bean配置Queue/Topic的bean id--&gt; &lt;property name=\"defaultDestination\" ref=\"destinationQueue\" /&gt; &lt;property name=\"messageConverter\"&gt; &lt;bean class=\"org.springframework.jms.support.converter.SimpleMessageConverter\" /&gt; &lt;/property&gt;&lt;/bean&gt; 生产者12345678910111213141516@Servicepublic class SpringMQ_Produce &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlAppalicationContext(\"applicationContext.xml\"); SpringMQ_Produce produce = (SpringMQ_Produce)ctx.getBean(\"springMQ_Produce\"); produce.jmsTemplate.send(new MessageCreator() &#123; @Override public Message createMessage(Session session) throws JMSException &#123; TextMessage message = session.createTextMessage(\"Spring和ActiveMQ的整合\"); return message; &#125; &#125;); &#125;&#125; 消费者1234567891011@Servicepublic class SpringMQ_Consumer &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); SpringMQ_Consumer consumer = (SpringMQ_Consumer)ctx.getBean(\"springMQ_Consumer\"); String value = (String)consumer.jmsTemplate.receiveAndConvert(); System.out.println(\"消费者收到消息：\" + value); &#125;&#125; 监听器配置12345678&lt;!-- applicationContext.xml 增加bean id--&gt;&lt;!--配置监听程序--&gt;&lt;bean id=\"jmsContainer\" class=\"org.springframework.jms.listener.DefaultMessageListenerContainer\"&gt; &lt;property name=\"connectionFactory\" ref=\"jmsFactory\" /&gt; &lt;property name=\"destination\" ref=\"destinationQueue\" /&gt; &lt;!--public class MyMessageListener implements MessageListener--&gt; &lt;property name=\"messageListener\" ref=\"myMessageListener\"/&gt;&lt;/bean&gt; 1234567891011121314@Componentpublic class MyMessageListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 配置监听器后，只需要启动生产者，消费者不用启动，自动会监听记录。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/categories/ActiveMQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（三） 传输协议'","slug":"activemq-protocol","date":"2020-05-22T17:00:02.000Z","updated":"2020-11-12T04:20:56.081Z","comments":true,"path":"2020/05/23/activemq-protocol/","link":"","permalink":"https://midkuro.gitee.io/2020/05/23/activemq-protocol/","excerpt":"","text":"ActiveMQ传输协议ActiveMQ支持client和Broker的通讯协议有：TCP、NIO、UDP、SSL、Http(s)、VM。 其中配置Transport Connector的文件在ActiveMQ的安装目录的conf/activemq.xml中的&lt;transportConnectors&gt;标签中。 123456789&lt;!--配置传输官网 http://activemq.apache.org/configuring-transports.html--&gt;&lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name=\"openwire\" uri=\"tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&amp;trace=true\"/&gt; &lt;transportConnector name=\"amqp\" uri=\"amqp://0.0.0.0:5672?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"stomp\" uri=\"stomp://0.0.0.0:61613?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"mqtt\" uri=\"mqtt://0.0.0.0:1883?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"ws\" uri=\"ws://0.0.0.0:61614?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt;&lt;/transportConnectors&gt; TCP协议ActiveMQ中默认的消息协议就是openwire，也就是Transmission Control Protocal(TCP)协议。 这是默认的Broker配置，TCP的Client监听端口61616 在网络传输数据前，必须要序列化数据，消息是通过一个叫wire protocol的来序列化成字节流。 默认情况下ActiveMQ把wire protocol叫做OpenWire，它的目的是促使网络上的效率和数据快速交互。 TCP连接的URI形式如：tcp:hostname:port?key=value&amp;key=value，后面的参数是可选的 TCP传输的优点： TCP协议传输可靠性高，稳定性强 高效性：字节流方式传递，效率很高 有效性、可用性：应用广泛，支持任何平台 关于Transport协议的可配置参数可以参考官网 NIO协议 即New I/O API Protocol(NIO)，和TCP协议类似但NIO侧重底层的访问操作。它允许开发人员对统一资源可有更多的client调用和服务端有更多的负载。 适合NIO协议的场景： 可能有大量的Client去连接到Broker上，一般情况下，大量的Client去连接Broker是被操作系统的现成所限制的。因此，NIO的实现比TCP需要更少的线程去运行，工作中常用NIO协议，建议使用NIO协议 可能对于Broker有一个很迟钝的网络传输，NIO比TCP提供更好的性能。 NIO连接的URI形式：nio://hostname:port?key=value Transport Conector配置示例，参考官网 1234567&lt;broker&gt; ... &lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61616\"/&gt; &lt;/transportConnectors&gt; ...&lt;/broker&gt; 123&lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61618?trace=true\"/&gt; &lt;/transportConnectors&gt; AMQP协议即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。 STOMP协议即Streaming Text Orientated Message Protocol，是流文本定向消息协议，是一种为MOM（Message Oriented Middleware，面向消息的中间件） 设计的简单文本协议。 SSL协议Secure Sockets Layer Protocol（SSL）安全加固协议 MQTT协议MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分，该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和制动器（比如通过Twitter让房屋联网）的通信协议。 WS协议Web Socket协议 ActiveMQ支持的网络协议 协议 描述 TCP 默认的协议，性能相对可以 NIO 基于TCP协议智商的，进行了扩展和优化，具有更好的扩展性 UDP 性能比TCP更好，但是不具备可靠性 SSL 安全链接 HTTP(S) 基于HTTP或者HTTPS VM VM本身不是协议，当客户端和代理在同一个Java虚拟机(VM)中运行时，他们之间需要通信，但不想占用网络通道，而是直接通信，可以使用该方式 NIO增强123&lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61618?trace=true\"/&gt; &lt;/transportConnectors&gt; 当配置了activemq.xml配置了NIO协议之后，项目中的配置broker-url= nio://192.168.1.132:61618后，表示61618端口使用以TCP协议为基础的NIO网络IO模型。 但是这样的设置智能使这个端口支持Openwire协议，那么我们怎么既让这个端口支持NIO网络IO模型，又让它支持多个协议呢？ 可以通过使用auto关键字，组合+符号来为端口设置多种特性，达到基于NIO网络IO模型支持多种协议。 1&lt;transportConnector name=\"auto+nio\" uri=\"auto+://0.0.0.0:61608?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&amp;amp;org.apache.activemq.transport.nio.SelectorManager.corePoolSize=20&amp;amp;org.apache.activemq.transport.nio.SelectorManager.maxmumPoolSize=50\"/&gt;","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/categories/ActiveMQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（二） Java消息服务'","slug":"activemq-jms","date":"2020-05-22T17:00:01.000Z","updated":"2020-11-12T04:20:43.142Z","comments":true,"path":"2020/05/23/activemq-jms/","link":"","permalink":"https://midkuro.gitee.io/2020/05/23/activemq-jms/","excerpt":"","text":"ActiveMQJMSJavaEE是一套使用JAVA进行企业级Web应用开发的大家一致遵循的工业标准。JavaEE平台提供了一个基于组件的方法来加快设计、开发、装配及部署企业应用程序。 JavaEE的13种核心技术规范： JDBC（Java Database）数据库连接 JNDI（Java Naming and Directory Interfaces）Java 的命名和目录接口 EJB（Enterprise JavaBean） RMI（Remote Method Invoke）远程方法调用 Java IDL（Interface Description Language）/CORBA（Common Object Broker Architecture）Java 接口定义语言/公用对象请求代理程序体系结构 JSP（Java Server Pages） Servlet XML（Extensible Markup Language）可扩展标记语言 JMS（Java Message Service）Java 消息服务 JTA（Java Transaction API）Java 事务 API JTS（Java Transaction Service）Java 事务服务 JavaMail JAF（JavaBean Activation Framework） JMS全称是Java Message Service（Java消息服务是JAVA EE的一门技术）。JMS的客户端之间可以通过JMS服务进行异步的消息传输。JMS用于和面向消息的中间件相互通信的应用程序接口(API)。它既支持点对点的域，有支持发布/订阅(publish/subscribe)类型的域，并且提供对下列类型的支持： 经认可的消息传递 事务型消息的传递 一致性消息和具有持久性的订阅者支持。 JMS消息系统带来的好处： 提供消息灵活性； 松散耦合 异步性。 JMS消息系统带来的好处：1、提供消息灵活性；2、松散耦合；3、异步性。 消息队列的比较 特性 ActiveMQ RabbitMQ Kafka RocketMQ PRODUCER-COMSUMER 支持 支持 支持 支持 PUBLISH-SUBSCRIBE 支持 支持 支持 支持 REQUEST-REPLY 支持 支持 - 支持 API完备性 高 高 高 低（静态配置） 多语言支持 支持，JAVA优先 语言无关 支持，JAVA优先 支持 单机呑吐量 万级 万级 十万级 单机万级 消息延迟 - 微秒级 毫秒级 - 可用性 高（主从） 高（主从） 非常高（分布式） 高 消息丢失 - 低 理论上不会丢失 - 消息重复 - 可控制 理论上会有重复 - 文档的完备性 高 高 高 中 提供快速入门 有 有 有 无 首次部署难度 - 低 中 高 JMS的组成结构和特点 JMS provider：实现JMS接口和规范的消息中间件 JMS producer：消息生产者，创建和发送JMS消息的客户端应用 JMS consumer：消息消费者，接受和处理JMS消息的客户端应用 JMS message ：消息，包括消息头、消息体、消息属性 消息头 JMSDestination：消息发送的目的地，主要指Queue和Topic JMSDeliveryMode：持久和持久模式 一条持久性消息：应该被传送一次仅仅一次，意味着如果JMS提供者出现故障，该消息并不会丢失，它会在服务器恢复之后再次传递。 一条非持久的消息：最多传送一次，这意味着服务器出现故障，该消息将永远丢失。 JMSExpiration：消息过期时间，默认永不过期 消息过期时间等于Destnation的send方法中的timeToLive值加上发送时刻的GMT时间值。 如果消息TimeToLive值等于零，则JMSExpiration被设置为零，表示该消息永不过期。 如果发送后，在消息过期时间之后消息还没有被发送到目的地，则该消息被清除。 JMSPriority：消息优先级 从0-9 十个级别，0到4是普通消息，5到9是加急消息。 JMS不要求MQ严格按照这是个优先级发送消息，但必须保证加急消息要先于普通消息到达，默认是4级。 JMSMessageID：唯一识别每个消息的标识，由MQ产生。 消息体 TextMessage：普通字符串消息，包含一个String MapMessage：一个Map类型的消息，Key为String类型，而值为Java的基本类型 BytesMessage：二进制数组消息，包含一个byte[] StreamMessage：Java数据流，用标准流操作来顺序的填充和读取 ObjectMessage：对象消息，包含一个可序列化的Java对象 123//例子MapMessage mapMessage = session.createMapMessage();mapMessage.setBoolean(\"key\", false); 发送和接受的消息体类型必须一致对应。 消息属性如果需要除消息头字段以外的值，那么可以使用消息属性，主要用于识别/去重/重点标注消息。 他们是以属性名和属性值对的形式制定的。可以将属性，可以看做是消息头的扩展，属性指定一些消息头没有包括的附加消息。比如可以在属性里指定消息选择器。 1234TextMessage message = session.createTextMessage();message.setText(text);//自定义属性message.setStringProperty(\"userName\",\"张三\"); JMS的可靠性持久性Persistent持久性参数说明： 非持久：当服务器宕机，消息不存在 12MessageProducer producer = session.createProducer(queue);producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); 持久：当服务器宕机，消息依然存在 12MessageProducer producer = session.createProducer(queue);producer.setDeliveryMode(DeliveryMode.PERSISTENT); 当不配置持久化时，队列默认的消息默认是持久化消息，此模式保证这些消息只被传送一次和成功使用一次。对这些消息，可靠性是优先考虑因素。 可靠性的另一个重要方面是确保持久化消息传递至目标后，消息服务在向消费者传送他们之前不会丢失这些消息。 持久化Topic-订阅主题123456789101112131415161718192021222324//生产者public class JmsTopicProducer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String TOPIC_NAME = \"topic-Persist\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Topic topic = session.createTopic(TOPIC_NAME); MessageProducer producer = session.createProducer(topic); //设置生产者的持久化消息 producer.setDeliveryMode(DeliveryMode.PERSISTENT); //设置完了持久化配置，然后再启动连接 connection.start(); for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"持久化消息：message---\" + i); producer.send(message); &#125; producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列topic完毕\"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334//订阅者public class JmsTopicConsumer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String TOPIC_NAME = \"topic-Persist\"; public static void main(String[] args) throws JMSException, IOException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); //设置订阅者的ID connection.setClientID(\"zhangsan\"); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Topic topic = session.createTopic(TOPIC_NAME); //创建持久化的订阅者 TopicSubscriber subscriber = session.createDurableSubscriber(topic, \"remark...\"); //设置完毕后再启动start connection.start(); //监听主题 subscriber.setMessageListener((message) -&gt; &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(\"收到持久化订阅消息：\" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); // 控制台不灭 System.in.read(); subscriber.close(); session.close(); connection.close(); System.out.println(\"订阅消费完毕\"); &#125;&#125; 需要先启动订阅者，再启动生产者，订阅主题需要为每个订阅者设置ClientID并创建订阅者，这时候生产消息时可以看到，订阅者处于激活状态并接收并消费了三条消息。 这时候把订阅者后台关闭，订阅者从激活状态变为离线状态，可以看到如下图： 当订阅者重新订阅时，会从离线状态重新变为激活状态。 切记：一定要先运行一次消费者，等于向MQ注册，类似于我订阅了这个主题，然后再运行生产者发送信息，此时无论消费者是否在线，都会接收到，不在线的话，下次链接时，会把没有收过的消息都接收下来。 事务Transaction事务偏生产者，签收偏消费者 123456//第一个参数是事务开关，第二个是签收参数Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);//提交事务session.commit();//回滚事务session.rollback(); false：只要执行send，就会进入到队列中。关闭事务，那第二个签收参数的设置需要有效 true：先执行send再执行commit，消息才被真正的提交到队列中，消息需要批量发送，需要缓冲区处理 生产者/消费者设置了事务开关等于true时，只有执行了session.commit();消息才会被生产/消费，所以事务的级别是比签收的级别高的。 签收123456789//Acknowledge签收方式//1.自动签收--常用Session.AUTO_ACKNOWLEDGE;//2.手动签收--常用Session.CLIENT_ACKNOWLEDGE;//3.可允许重复的签收Session.UPS_OK_ACKNOWLEDGE;//4.和事务组合的签收Session.SESSION_TRANSACTED; 非事务的情况下，默认行为是自动签收，当使用手动签收时，客户端需要调用message.acknowledge()方法手动签收。 在事务的情况下，只有commit后才能将全部消息变为已消费。在事务性会话中，当一个事务被成功提交则消息被自动签收，如果事务回滚，则消息会再次被传送。 非事务性会话中，消息何时被确认取决于创建会话时的应答模式（acknowledgement mode） JMS的点对点总结点对点模型是基于队列的，生产者发消息到队列，消费者从队列接收消息，队列的存在使消息的异步传输称为可能。 如果在Session关闭是有部分消息已被收到但还没有被签收（acknowledged），那么当消费者下次连接到相同的队列时，这些消息还会被再次接收。 队列可以长久地保存消息直到消费者收到消息。消费者不需要因为担心消息会丢西而时刻和队列保持激活的连接状态，充分体现了异步传输模式的优势。 JMS的发布订阅总结JMS Pub/Sub模型定义了如何向一个内容节点发布和订阅消息，这些节点被称作topic。 主题可以被认为是消息的传输中介，发布者（publisher）发布消息到主题，订阅者（subscribe）从主题订阅消息。 非持久订阅主题使得消息订阅和消息发布者保持互相独立，不需要接触 即可保证消息的传送。 非持久订阅只有当客户处于激活状态，也就是和MQ保持连接状态才能收到发送到某个主题的消息。 如果消费者处于离线状态，生产者发送的主题消息将会丢失作废，消费者永远不会收到。 持久订阅客户端首先向MQ注册一个自己的身份ID识别号，当这个客户端处于离线时，生产者会为这个ID保存所有发送到主题的消息，当客户端再次连接到MQ时会根据消费者的ID得到所有当自己处于离线时发送到主题的消息。 非持久订阅状态下，不能恢复或重新派送一个未签收的消息。持久订阅才能恢复或重新派送一个未签收的消息。 BrokerMQ消息服务器实例被称作Broker，作为server提供消息核心服务。 在linux环境下通过指定不同的配置文件启动多个MQ服务器实例的命令如下 1./activemq start xbean:file/apache-active-5.15.9/conf/my-activemq.xml 嵌入式Broker12345678910111213141516&lt;!-- pom.xml增加依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.xbean&lt;/groupId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.5&lt;/version&gt;&lt;/dependency&gt; 123456789public class EmbedBroker &#123; public static void main(String[] args) throws Exception&#123; //ActiveMQ也支持在vm中通信基于嵌入式的broker BrokerService brokerService = newBrokerService(); brokerService.setUseJmx(true); brokerService.addConnector(\"tcp://localhost:61616\"); brokerService.start(); &#125;&#125;","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/categories/ActiveMQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/tags/ActiveMQ/"}]},{"title":"'ActiveMQ（一） 基础概念'","slug":"activemq-mq","date":"2020-05-22T17:00:00.000Z","updated":"2020-11-12T04:20:47.563Z","comments":true,"path":"2020/05/23/activemq-mq/","link":"","permalink":"https://midkuro.gitee.io/2020/05/23/activemq-mq/","excerpt":"","text":"ActiveMQ消息队列的产品种类 常见的四大消息队列，其中RabbitMQ是使用erlang语言编写的，其他三个是Java语言编写的，kafka在大数据场景下比较常用，ActiveMQ是Apache公司研发的消息队列，而RocketMQ是阿里基于ActiveMQ和kafka的研发的。 消息队列种类繁多，但是从技术的维度来讲，每个消息队列应该都具备以上各种机制，本篇文章主要针对ActiveMQ进行讲解，举一反三。 为什么要引入MQ在没引入MQ之前，举个生活场景的例子，学生排队向老师请教问题，每个学生需要耗费5分钟的时间，这样导致学生将会被占用很长的时间，如下图： 在引入MQ后，可以将学生的问题以某种约定约束的格式进行收集，收集到指定的问题库中，当老师空闲出时间时将会去回答学生的问题，如下图： 在这种场景下，每个学生都只需要提交问题到问题库，然后可以做自己想做的事情，而不需要在原地等待老师解决完问题再离开，实现了微服务的异步通信。 微服务架构后，链式调用是我们写程序的一般流程，为了完成一个整体功能会将其拆分成多个函数（子模块），比如模块A调用模块B，模块B调用模块C，模块C调用模块D。 但是在大型分布式应用中，一个功能别后要调用许多接口，从单机架构过渡到分布式微服务架构的时候，会产生哪些问题？ 系统之间接口耦合比较严重 面对大流量并发时，容易被冲垮 等待同步存在性能问题 根据上述的问题，在设计系统时可以明确要达到的目标： 要做到系统解耦，当新模块接进来时，可以做到代码改动最小：能够解耦 设置流量缓冲池，可以让后端系统按照自身吞吐能力进行消费，不被冲垮：能够削峰 强弱依赖梳理能将非关键调用链路的操作异步化并提升整体系统的吞吐能力：能够异步 MQ的作用定义面向消息的中间件(message-orented middleware)MOM能够很好的解决以上的问题。 是指利用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。 通过提供消息传递和消息排队模型在分布式环境下提供应用解耦、弹性伸缩、冗余存储、流量削峰、异步通信、数据同步等功能。 大致的过程是这样的： 发送者把消息发送给消息服务器，消息服务器将消息存放在若干队列/主题中，在合适的时候，消息服务器会将消息转发给接受者。 在这个过程中，发布和接受是异步的，也就是发送无需等待，而且发送者和接受者的生命周期也没有必然关系； 尤其在发布pub/订阅sub模式下，也可以完成一对多的通信，即让一个消息有多个接受者。 ActiveMQ基础ActiveMQ官网 ActiveMQ下载 通过解压下载包，进入bin目录执行activemq即可启动 默认进程端口是61616； WEB网页地址：http://IP:8161 默认用户名/密码：admin/admin 备注：ActiveMQ采用61616端口提供JMS服务，采用8161端口提供管理控制台服务 MQ标准API讲解1234567891011&lt;!-- activeMQ所需要的jar包配置--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.xbean&lt;/groupId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;3.16&lt;/version&gt;&lt;/dependency&gt; 通过连接工厂ConnectionFactory创建连接，获取Session会话，Session会话按照约定格式创建消息Message、生产者Producer、消费者Consumer， 通过将消息发送给目的地Destination（队列Queue/主题Topic），生产者消费者通过目的地 生产 / 消费 消息。 在点对点的消息传递域中，目的地被称为队列(Queue) 在发布订阅消息作用域中，目的地被称为主题(Topic) 创建连接工厂123456789101112131415161718192021222324//1.ActiveMQConnectionFactory的构造器public ActiveMQConnectionFactory() &#123; this(DEFAULT_BROKER_URL);&#125;public ActiveMQConnectionFactory(String brokerURL) &#123; this(createURI(brokerURL));&#125;public ActiveMQConnectionFactory(URI brokerURL) &#123; setBrokerURL(brokerURL.toString());&#125;public ActiveMQConnectionFactory(String userName, String password, URI brokerURL) &#123; setUserName(userName); setPassword(password); setBrokerURL(brokerURL.toString());&#125;public ActiveMQConnectionFactory(String userName, String password, String brokerURL) &#123; setUserName(userName); setPassword(password); setBrokerURL(brokerURL);&#125; 可以看到，创建连接工厂的构造器支持传参ActiveMQ的URL，当不传参用户名和密码时，将采用默认admin/admin，其中当使用无参的构造器时，会默认使用DEFAULT_BROKER_URL常量中的URL当做链接串。 123456789101112131415public static final String DEFAULT_BROKER_URL = \"failover://\"+DEFAULT_BROKER_BIND_URL;public static final String DEFAULT_BROKER_BIND_URL; static&#123; //可以看到，默认的URL是以TCP协议开头 final String defaultURL = \"tcp://\" + DEFAULT_BROKER_HOST + \":\" + DEFAULT_BROKER_PORT; //用户配置的MQ服务器地址 String bindURL = null; /* 省略部分代码 */ //当不存在用户配置的地址时，使用默认地址defaultURL bindURL = (bindURL == null || bindURL.isEmpty()) ? defaultURL : bindURL; DEFAULT_BROKER_BIND_URL = bindURL; &#125; 1234567891011121314private static final String DEFAULT_BROKER_HOST;private static final int DEFAULT_BROKER_PORT;static&#123; String host = null; String port = null; /* 省略部分代码 */ //当找不到用户配置的IP、端口时，使用默认的localhost和61616 host = (host == null || host.isEmpty()) ? \"localhost\" : host; port = (port == null || port.isEmpty()) ? \"61616\" : port; DEFAULT_BROKER_HOST = host; DEFAULT_BROKER_PORT = Integer.parseInt(port);&#125; 生产者编码1234567891011121314151617181920212223242526272829303132public class JmsProducer &#123; //ActiveMQ服务器的链接地址 private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; //队列名称 private static final String QUEUE_NAME = \"queue01\"; public static void main(String[] args) throws JMSException &#123; //1.创建连接工厂，按照给定的URL地址，采用默认的用户名和密码 ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //2.通过连接工厂，获得连接Connection并访问 Connection connection = factory.createConnection(); connection.start(); //3.创建会话session //两个参数，第一个叫事务，第二个叫签收 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //4.创建目的地（具体是队列还是主题） Queue queue = session.createQueue(QUEUE_NAME); //5.创建消息的生产者 MessageProducer producer = session.createProducer(queue); //6.使用MessageProducer生产3条消息发送到MQ队列里面 for (int i = 1; i &lt;= 3; i++) &#123; //7.创建消息 TextMessage message = session.createTextMessage(\"message---\" + i); //8.通过MessageProducer发送给MQ producer.send(message); &#125; //9.关闭资源 producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列queue01完毕\"); &#125;&#125; 通过访问http://192.168.1.132:8161，登录后能够看到产生了3条消息 消费者编码12345678910111213141516171819202122232425262728public class JmsConsumer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue01\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); //创建消费者 MessageConsumer consumer = session.createConsumer(queue); //循环监听 while (true) &#123; //发送的什么消息类型，就需要使用什么消息类型接收 //接收消息等待四秒，当四秒后依旧没消息返回则不等待 TextMessage message = (TextMessage) consumer.receive(4000L); if (message != null) &#123; System.out.println(message.getText()); &#125; else &#123; break; &#125; &#125; consumer.close(); session.close(); connection.close(); System.out.println(\"消费者消费消息队列query01完毕\"); &#125;&#125; 当执行消费者之后，被消费的消息Messages Dequeued为3。消息被消费，然后等待四秒后消费者退出循环，所以待消费者数量Number Of Consumers为0，没有消费者继续等待消费消息。 12345//消费者接收消息的方式//1.阻塞式接收消息，当无消息则一直等待直到有消息返回Message receive() throws JMSException;//2.设置等待时长，当超过该时长则不等待，直接返回Message receive(long timeout) throws JMSException; 1234567891011121314151617181920212223242526272829//通过使用监听的方式消费消息，用于替换上述while循环//异步非阻塞方式（监听器onMessage()）//订阅者或接受者通过MessageConsumer的setMessage(MessageListener)注册一个消息监听器//当消息到达之后，系统自动调用监听器的onMessage(Message message)方法consumer.setMessageListener(new MessageListener() &#123; @Override public void onMessage(Message message) &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(\"消费消息：\" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;);//或者使用lambda表达式consumer.setMessageListener((message) -&gt; &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(\"消费消息：\" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125;); JMS开发步骤 创建一个ConnectionFactory工厂 通过ConnectionFactory来创建JMS Connection 启动JMS Connection 通过Connection创建JMS Session 创建JMS Destination 创建JMS Producer或者创建JMS Message并设置Destination 创建JMS Consumer或者注册JMS Message Listener 发送或者接受JMS message(s) 关闭所有JMS资源（Connection、Session、Producer、Consumer） 队列在点对点的消息传递域中，目的地被称为队列（queue） 每个消息只能有一个消费者，类似1对1的关系。好比个人快递自己领取自己的。 消息的生产者和消费者之间没有时间上的相关性、无论消费者在生产者发送消息的时候是否处于运行状态，消费者都可以提取消息。好比我们的发送短信，发送者发送后不见得接受者会即收即看。 当有多个消费者时，将采取类似负载均衡的策略，将消息均分到各个消费者中。 消息被消费后队列中不会再存储，所以消费者不会消费到已经被消费掉的消息。 主题在发布订阅消息传递域中，目的地被称为主题（topic） 生产者将消息发布到topic中，每个消息可以有多个消费者，属于 1：N的关系 生产者和消费者之间有时间上的相关性。订阅某一个主题的消费者只能消费自它订阅之后发布的消息 生产者生产时，topic不保存消息，它是无状态的不落地，假设无人订阅就去生产，那就是一条废消息，所以，一般先启动消费者再启动生产者。 JMS规范允许客户创建持久订阅，在这一程度上放松了时间上的相关性要求。持久订阅允许消费者消费它在未处于激活状态时发送的消息，好比如微信公众号订阅。 123//与队列不同的编码在于创建目的地//Queue queue = session.createQueue(QUEUE_NAME);Topic topic = session.createTopic(TOPIC_NAME); JMSJavaEE是一套使用JAVA进行企业级Web应用开发的大家一致遵循的工业标准。JavaEE平台提供了一个基于组件的方法来加快设计、开发、装配及部署企业应用程序。 JavaEE的13种核心技术规范： JDBC（Java Database）数据库连接 JNDI（Java Naming and Directory Interfaces）Java 的命名和目录接口 EJB（Enterprise JavaBean） RMI（Remote Method Invoke）远程方法调用 Java IDL（Interface Description Language）/CORBA（Common Object Broker Architecture）Java 接口定义语言/公用对象请求代理程序体系结构 JSP（Java Server Pages） Servlet XML（Extensible Markup Language）可扩展标记语言 JMS（Java Message Service）Java 消息服务 JTA（Java Transaction API）Java 事务 API JTS（Java Transaction Service）Java 事务服务 JavaMail JAF（JavaBean Activation Framework） JMS全称是Java Message Service（Java消息服务是JAVA EE的一门技术）。JMS的客户端之间可以通过JMS服务进行异步的消息传输。JMS用于和面向消息的中间件相互通信的应用程序接口(API)。它既支持点对点的域，有支持发布/订阅(publish/subscribe)类型的域，并且提供对下列类型的支持： 经认可的消息传递 事务型消息的传递 一致性消息和具有持久性的订阅者支持。 JMS消息系统带来的好处： 提供消息灵活性； 松散耦合 异步性。 JMS消息系统带来的好处：1、提供消息灵活性；2、松散耦合；3、异步性。 消息队列的比较 特性 ActiveMQ RabbitMQ Kafka RocketMQ PRODUCER-COMSUMER 支持 支持 支持 支持 PUBLISH-SUBSCRIBE 支持 支持 支持 支持 REQUEST-REPLY 支持 支持 - 支持 API完备性 高 高 高 低（静态配置） 多语言支持 支持，JAVA优先 语言无关 支持，JAVA优先 支持 单机呑吐量 万级 万级 十万级 单机万级 消息延迟 - 微秒级 毫秒级 - 可用性 高（主从） 高（主从） 非常高（分布式） 高 消息丢失 - 低 理论上不会丢失 - 消息重复 - 可控制 理论上会有重复 - 文档的完备性 高 高 高 中 提供快速入门 有 有 有 无 首次部署难度 - 低 中 高 JMS的组成结构和特点 JMS provider：实现JMS接口和规范的消息中间件 JMS producer：消息生产者，创建和发送JMS消息的客户端应用 JMS consumer：消息消费者，接受和处理JMS消息的客户端应用 JMS message ：消息，包括消息头、消息体、消息属性 消息头 JMSDestination：消息发送的目的地，主要指Queue和Topic JMSDeliveryMode：持久和持久模式 一条持久性消息：应该被传送一次仅仅一次，意味着如果JMS提供者出现故障，该消息并不会丢失，它会在服务器恢复之后再次传递。 一条非持久的消息：最多传送一次，这意味着服务器出现故障，该消息将永远丢失。 JMSExpiration：消息过期时间，默认永不过期 消息过期时间等于Destnation的send方法中的timeToLive值加上发送时刻的GMT时间值。 如果消息TimeToLive值等于零，则JMSExpiration被设置为零，表示该消息永不过期。 如果发送后，在消息过期时间之后消息还没有被发送到目的地，则该消息被清除。 JMSPriority：消息优先级 从0-9 十个级别，0到4是普通消息，5到9是加急消息。 JMS不要求MQ严格按照这是个优先级发送消息，但必须保证加急消息要先于普通消息到达，默认是4级。 JMSMessageID：唯一识别每个消息的标识，由MQ产生。 消息体 TextMessage：普通字符串消息，包含一个String MapMessage：一个Map类型的消息，Key为String类型，而值为Java的基本类型 BytesMessage：二进制数组消息，包含一个byte[] StreamMessage：Java数据流，用标准流操作来顺序的填充和读取 ObjectMessage：对象消息，包含一个可序列化的Java对象 123//例子MapMessage mapMessage = session.createMapMessage();mapMessage.setBoolean(\"key\", false); 发送和接受的消息体类型必须一致对应。 消息属性如果需要除消息头字段以外的值，那么可以使用消息属性，主要用于识别/去重/重点标注消息。 他们是以属性名和属性值对的形式制定的。可以将属性，可以看做是消息头的扩展，属性指定一些消息头没有包括的附加消息。比如可以在属性里指定消息选择器。 1234TextMessage message = session.createTextMessage();message.setText(text);//自定义属性message.setStringProperty(\"userName\",\"张三\"); JMS的可靠性持久性Persistent持久性参数说明： 非持久：当服务器宕机，消息不存在 1producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); 持久：当服务器宕机，消息依然存在 1producer.setDeliveryMode(DeliveryMode.PERSISTENT); 当不配置持久化时，队列默认的消息默认是持久化消息，此模式保证这些消息只被传送一次和成功使用一次。对这些消息，可靠性是优先考虑因素。 可靠性的另一个重要方面是确保持久化消息传递至目标后，消息服务在向消费者传送他们之前不会丢失这些消息。 持久化Topic-订阅主题123456789101112131415161718192021222324//生产者public class JmsTopicProducer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String TOPIC_NAME = \"topic-Persist\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Topic topic = session.createTopic(TOPIC_NAME); MessageProducer producer = session.createProducer(topic); //设置生产者的持久化消息 producer.setDeliveryMode(DeliveryMode.PERSISTENT); //设置完了持久化配置，然后再启动连接 connection.start(); for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"持久化消息：message---\" + i); producer.send(message); &#125; producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列topic完毕\"); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334//订阅者public class JmsTopicConsumer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String TOPIC_NAME = \"topic-Persist\"; public static void main(String[] args) throws JMSException, IOException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); //设置订阅者的ID connection.setClientID(\"zhangsan\"); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Topic topic = session.createTopic(TOPIC_NAME); //创建持久化的订阅者 TopicSubscriber subscriber = session.createDurableSubscriber(topic, \"remark...\"); //设置完毕后再启动start connection.start(); //监听主题 subscriber.setMessageListener((message) -&gt; &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(\"收到持久化订阅消息：\" + textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); // 控制台不灭 System.in.read(); subscriber.close(); session.close(); connection.close(); System.out.println(\"订阅消费完毕\"); &#125;&#125; 需要先启动订阅者，再启动生产者，订阅主题需要为每个订阅者设置ClientID并创建订阅者，这时候生产消息时可以看到，订阅者处于激活状态并接收并消费了三条消息。 这时候把订阅者后台关闭，订阅者从激活状态变为离线状态，可以看到如下图： 当订阅者重新订阅时，会从离线状态重新变为激活状态。 切记：一定要先运行一次消费者，等于向MQ注册，类似于我订阅了这个主题，然后再运行生产者发送信息，此时无论消费者是否在线，都会接收到，不在线的话，下次链接时，会把没有收过的消息都接收下来。 事务Transaction事务偏生产者，签收偏消费者 123456//第一个参数是事务开关，第二个是签收参数Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);//提交事务session.commit();//回滚事务session.rollback(); false：只要执行send，就会进入到队列中。关闭事务，那第二个签收参数的设置需要有效 true：先执行send再执行commit，消息才被真正的提交到队列中，消息需要批量发送，需要缓冲区处理 生产者/消费者设置了事务开关等于true时，只有执行了session.commit();消息才会被生产/消费，所以事务的级别是比签收的级别高的。 签收123456789//Acknowledge签收方式//1.自动签收--常用Session.AUTO_ACKNOWLEDGE;//2.手动签收--常用Session.CLIENT_ACKNOWLEDGE;//3.可允许重复的签收Session.UPS_OK_ACKNOWLEDGE;//4.和事务组合的签收Session.SESSION_TRANSACTED; 非事务的情况下，默认行为是自动签收，当使用手动签收时，客户端需要调用message.acknowledge()方法手动签收。 在事务的情况下，只有commit后才能将全部消息变为已消费。在事务性会话中，当一个事务被成功提交则消息被自动签收，如果事务回滚，则消息会再次被传送。 非事务性会话中，消息何时被确认取决于创建会话时的应答模式（acknowledgement mode） JMS的点对点总结点对点模型是基于队列的，生产者发消息到队列，消费者从队列接收消息，队列的存在使消息的异步传输称为可能。 如果在Session关闭是有部分消息已被收到但还没有被签收（acknowledged），那么当消费者下次连接到相同的队列时，这些消息还会被再次接收。 队列可以长久地保存消息直到消费者收到消息。消费者不需要因为担心消息会丢西而时刻和队列保持激活的连接状态，充分体现了异步传输模式的优势。 JMS的发布订阅总结JMS Pub/Sub模型定义了如何向一个内容节点发布和订阅消息，这些节点被称作topic。 主题可以被认为是消息的传输中介，发布者（publisher）发布消息到主题，订阅者（subscribe）从主题订阅消息。 非持久订阅主题使得消息订阅和消息发布者保持互相独立，不需要接触 即可保证消息的传送。 非持久订阅只有当客户处于激活状态，也就是和MQ保持连接状态才能收到发送到某个主题的消息。 如果消费者处于离线状态，生产者发送的主题消息将会丢失作废，消费者永远不会收到。 持久订阅客户端首先向MQ注册一个自己的身份ID识别号，当这个客户端处于离线时，生产者会为这个ID保存所有发送到主题的消息，当客户端再次连接到MQ时会根据消费者的ID得到所有当自己处于离线时发送到主题的消息。 非持久订阅状态下，不能恢复或重新派送一个未签收的消息。持久订阅才能恢复或重新派送一个未签收的消息。 BrokerMQ消息服务器实例被称作Broker，作为server提供消息核心服务。 在linux环境下通过指定不同的配置文件启动多个MQ服务器实例的命令如下 1./activemq start xbean:file/apache-active-5.15.9/conf/my-activemq.xml 嵌入式Broker123456&lt;!-- pom.xml增加依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.5&lt;/version&gt;&lt;/dependency&gt; 123456789public class EmbedBroker &#123; public static void main(String[] args) throws Exception&#123; //ActiveMQ也支持在vm中通信基于嵌入式的broker BrokerService brokerService = newBrokerService(); brokerService.setUseJmx(true); brokerService.addConnector(\"tcp://localhost:61616\"); brokerService.start(); &#125;&#125; Spring整合ActiveMQ12345678910111213&lt;!-- pom.xml增加依赖--&gt;&lt;!-- activemq所对JMS的支持，整合Spring和Activemq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.3.23.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--activemq所需要的pool包配置--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-pool&lt;/artifactId&gt; &lt;version&gt;5.15.9&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233&lt;!-- applicationContext.xml--&gt;&lt;!-- 开启包的自动扫描--&gt;&lt;context:component-scan bean-package=\"*\" /&gt;&lt;!--配置生产者--&gt;&lt;bean id =\"jmsFactory\" class=\"org.apache.activemq.pool.PooledConnectionFactory\" destroy-method=\"stop\"&gt; &lt;property name=\"connectionFactory\"&gt; &lt;!--真正可以产生Connection的ConnectionFactory，由对应的JMS服务厂商提供--&gt; &lt;bean class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.1.132:61616\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=\"maxConnections\" value=\"100\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--这是个队列目的地，点对点的--&gt;&lt;bean id =\"destinationQueue\" class=\"org.apache.activemq.command.ActiveMQQueue\"&gt; &lt;!--构造注入--&gt; &lt;constructor-arg index=\"0\" value=\"spring-active-queue\" /&gt;&lt;/bean&gt; &lt;!-- &lt;bean id =\"desctinationTopic\" class=\"org.apache.activemq.command.ActiveMQTopic\"&gt; &lt;constructor-arg index=\"0\" value=\"spring-active-topic\"&gt;&lt;/bean&gt; --&gt;&lt;!--Spring提供的JMS工具类，它可以进行消息、接收等--&gt;&lt;bean id=\"jmsTemplate\" class=\"org.springframework.jms.core.JmsTemplate\"&gt; &lt;property name=\"connectionFactory\" ref=\"jmsFactory\" /&gt; &lt;!--消息默认目的地，ref根据提供的bean配置Queue/Topic的bean id--&gt; &lt;property name=\"defaultDestination\" ref=\"destinationQueue\" /&gt; &lt;property name=\"messageConverter\"&gt; &lt;bean class=\"org.springframework.jms.support.converter.SimpleMessageConverter\" /&gt; &lt;/property&gt;&lt;/bean&gt; 生产者12345678910111213141516@Servicepublic class SpringMQ_Produce &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlAppalicationContext(\"applicationContext.xml\"); SpringMQ_Produce produce = (SpringMQ_Produce)ctx.getBean(\"springMQ_Produce\"); produce.jmsTemplate.send(new MessageCreator() &#123; @Override public Message createMessage(Session session) throws JMSException &#123; TextMessage message = session.createTextMessage(\"Spring和ActiveMQ的整合\"); return message; &#125; &#125;); &#125;&#125; 消费者1234567891011@Servicepublic class SpringMQ_Consumer &#123; @Autowired private JmsTemplate jmsTemplate; public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); SpringMQ_Consumer consumer = (SpringMQ_Consumer)ctx.getBean(\"springMQ_Consumer\"); String value = (String)consumer.jmsTemplate.receiveAndConvert(); System.out.println(\"消费者收到消息：\" + value); &#125;&#125; 监听器配置12345678&lt;!-- applicationContext.xml 增加bean id--&gt;&lt;!--配置监听程序--&gt;&lt;bean id=\"jmsContainer\" class=\"org.springframework.jms.listener.DefaultMessageListenerContainer\"&gt; &lt;property name=\"connectionFactory\" ref=\"jmsFactory\" /&gt; &lt;property name=\"destination\" ref=\"destinationQueue\" /&gt; &lt;!--public class MyMessageListener implements MessageListener--&gt; &lt;property name=\"messageListener\" ref=\"myMessageListener\"/&gt;&lt;/bean&gt; 1234567891011121314@Componentpublic class MyMessageListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; if (message != null &amp;&amp; message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; try &#123; System.out.println(textMessage.getText()); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 配置监听器后，只需要启动生产者，消费者不用启动，自动会监听记录。 SpringBoot整合ActiveMQ1234567&lt;!-- pom.xml增加依赖--&gt;&lt;!-- activemq所对JMS的支持，整合Spring和Activemq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/dependency&gt; 123456789#application.ymlspring: activemq: broker-url: tcp://192.168.1.132:61616 user: admin password: admin jms: #fasle = Queue true = Topic 默认Queue pub-sub-domain: false 12345678910111213@Component@EnableJms //开启SpringBoot对Jms的支持public class ConfigBean &#123; @Bean public Queue queue() &#123; return new ActiveMQQueue(\"myQueueName\"); &#125; @Bean public Topic topic() &#123; return new ActiveMQTopic(\"myTopicName\"); &#125;&#125; 生产者-定时调度123456789101112131415161718192021@Componentpublic class Queue_Produce &#123; @Autowired private JmsMessagingTemplate jmsMessagingTmplate; @Autowired private Queue queue; //@Autowired //private Topic topic; public void produceMsg() &#123; //convertAndSend自动转换消息的类型 jmsMessagingTemplate.convertAndSend(queue,\"SpringBoot队列发送消息\"); //jmsMessagingTemplate.convertAndSend(topic,\"SpringBoot主题发送消息\"); &#125; //间隔3秒定投 @Scheduled(fixedDelay = 3000) public void produceMsgScheduled() &#123; jmsMessagingTemplate.convertAndSend(queue,\"SpringBoot定时投递消息\"); &#125;&#125; 1234567@SpringBootApplication@EnableScheduling //激活定时调度public class MainApp_Produce &#123; public static void main(String[] args) &#123; SpringApplication.run(MainApp_Produce.class, args); &#125;&#125; 12345678910111213//单元测试执行@SpringBootTest(classes = MainApp_Produce.class)@RunWith(SpringJUnit4ClassRunner.class)@WebAppConfigurationpublic class TestActiveMQ &#123; @Autowired private Queue_Produce queue_produce; @Test public void testSend() throws Exception &#123; queue_produce.produceMsg(); &#125;&#125; 消费者-监听器12345678@Componentpublic class Queue_Consumer &#123; //设置监听器 @JmsListener(destination = \"myQueueName\") public void receive(TextMessage textMessage) throws JMSException &#123; System.out.println(\"消费者收到消息：\" + textMessage.getText()); &#125;&#125; 传输协议ActiveMQ支持client和Broker的通讯协议有：TCP、NIO、UDP、SSL、Http(s)、VM。 其中配置Transport Connector的文件在ActiveMQ的安装目录的conf/activemq.xml中的&lt;transportConnectors&gt;标签中。 123456789&lt;!--配置传输官网 http://activemq.apache.org/configuring-transports.html--&gt;&lt;transportConnectors&gt; &lt;!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB --&gt; &lt;transportConnector name=\"openwire\" uri=\"tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&amp;trace=true\"/&gt; &lt;transportConnector name=\"amqp\" uri=\"amqp://0.0.0.0:5672?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"stomp\" uri=\"stomp://0.0.0.0:61613?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"mqtt\" uri=\"mqtt://0.0.0.0:1883?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt; &lt;transportConnector name=\"ws\" uri=\"ws://0.0.0.0:61614?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600\"/&gt;&lt;/transportConnectors&gt; TCP协议ActiveMQ中默认的消息协议就是openwire，也就是Transmission Control Protocal(TCP)协议。 这是默认的Broker配置，TCP的Client监听端口61616 在网络传输数据前，必须要序列化数据，消息是通过一个叫wire protocol的来序列化成字节流。 默认情况下ActiveMQ把wire protocol叫做OpenWire，它的目的是促使网络上的效率和数据快速交互。 TCP连接的URI形式如：tcp:hostname:port?key=value&amp;key=value，后面的参数是可选的 TCP传输的优点： TCP协议传输可靠性高，稳定性强 高效性：字节流方式传递，效率很高 有效性、可用性：应用广泛，支持任何平台 关于Transport协议的可配置参数可以参考官网 NIO协议 即New I/O API Protocol(NIO)，和TCP协议类似但NIO侧重底层的访问操作。它允许开发人员对统一资源可有更多的client调用和服务端有更多的负载。 适合NIO协议的场景： 可能有大量的Client去连接到Broker上，一般情况下，大量的Client去连接Broker是被操作系统的现成所限制的。因此，NIO的实现比TCP需要更少的线程去运行，工作中常用NIO协议，建议使用NIO协议 可能对于Broker有一个很迟钝的网络传输，NIO比TCP提供更好的性能。 NIO连接的URI形式：nio://hostname:port?key=value Transport Conector配置示例，参考官网 1234567&lt;broker&gt; ... &lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61616\"/&gt; &lt;/transportConnectors&gt; ...&lt;/broker&gt; 123&lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61618?trace=true\"/&gt; &lt;/transportConnectors&gt; AMQP协议即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。 STOMP协议即Streaming Text Orientated Message Protocol，是流文本定向消息协议，是一种为MOM（Message Oriented Middleware，面向消息的中间件） 设计的简单文本协议。 SSL协议Secure Sockets Layer Protocol（SSL）安全加固协议 MQTT协议MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分，该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和制动器（比如通过Twitter让房屋联网）的通信协议。 WS协议Web Socket协议 ActiveMQ支持的网络协议 协议 描述 TCP 默认的协议，性能相对可以 NIO 基于TCP协议智商的，进行了扩展和优化，具有更好的扩展性 UDP 性能比TCP更好，但是不具备可靠性 SSL 安全链接 HTTP(S) 基于HTTP或者HTTPS VM VM本身不是协议，当客户端和代理在同一个Java虚拟机(VM)中运行时，他们之间需要通信，但不想占用网络通道，而是直接通信，可以使用该方式 NIO增强123&lt;transportConnectors&gt; &lt;transportConnector name=\"nio\" uri=\"nio://0.0.0.0:61618?trace=true\"/&gt; &lt;/transportConnectors&gt; 当配置了activemq.xml配置了NIO协议之后，项目中的配置broker-url= nio://192.168.1.132:61618后，表示61618端口使用以TCP协议为基础的NIO网络IO模型。 但是这样的设置智能使这个端口支持Openwire协议，那么我们怎么既让这个端口支持NIO网络IO模型，又让它支持多个协议呢？ 可以通过使用auto关键字，组合+符号来为端口设置多种特性，达到基于NIO网络IO模型支持多种协议。 1&lt;transportConnector name=\"auto+nio\" uri=\"auto+://0.0.0.0:61608?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&amp;amp;org.apache.activemq.transport.nio.SelectorManager.corePoolSize=20&amp;amp;org.apache.activemq.transport.nio.SelectorManager.maxmumPoolSize=50\"/&gt; 消息持久化消息持久化是一种MQ服务器宕机了，消息不会丢失的机制。为避免意外宕机以后丢失信息，需要做到重启后可以恢复消息队列，消息系统一般都会采用持久化机制。 ActiveMQ消息持久化机制有JDBC,AMQ，KahaDB和LevelDB，无论使用哪种持久化方式，消息的存储逻辑都是一致的。 就是在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等再试图将消息发送给接收者，成功则将消息从存储中删除，失败则继续尝试发送。 消息中心启动以后首先要检查指定的存储位置，如果有未发送成功的消息，则需要把消息发送出去。 AMQ Message StoreAMQ是一种文件存储形式，它具有写入速度快和容易恢复的特点。消息存储在一个个文件中，文件的默认大小为32M，当一个存储文件中的消息已经全部被消费，那么这个文件将被标识为可删除，在下一个清除阶段，这个文件被删除。AMQ适用于ActiveMQ5.3之前的版本，现在已经不使用了。 KahaDB消息存储KahaDB是从ActiveMQ5.4开始到至今的默认持久化插件，可用于任何场景，提高性能和恢复能力。 消息存储使用一个事务日志和仅仅用一个索引文件来存储它所有的地址。 KahaDB是一个专门针对消息持久化的解决方案，它对典型的消息使用模型进行了优化。 数据被追加到data logs中，当不在需要log文件中的数据的时候，log会被丢弃。 1234&lt;!--activemq.xml的配置--&gt;&lt;persistenceAdapter&gt; &lt;kahaDB directory=\"$&#123;activemq.data&#125;/kahadb\" /&gt;&lt;/persistenceAdapter&gt; 在ActiveMQ安装目录下的data/kahadb文件夹中，只有四类文件和一个lock，跟ActiveMQ的其他几种文件存储引擎相比十分简洁。 db-&lt;Number&gt;.log： KahaDB存储消息到预定义大小的数据记录文件中，文件命名为db-&lt;Number&gt;.log。当数据文件已满时，一个新的文件会随之创建，Number数值也会随之递增，它随着消息数量的增加，如每32M一个文件，文件名按照数字进行编号，如db-1.log、db-2.log、db-3.log……当不再有引用到数据文件中的任何消息时，文件会被删除或者归档。 db.data： 该文件包含了持久化的BTree索引，索引了消息数据记录中的消息，他是消息的索引文件，本质上是B-Tree（B树），使用B-Tree作为索引指向db-&lt;Number&gt;.log里面存储的消息。 db.free： 当db.data文件里哪些页面是空闲的，文件具体内容是所有的空闲页的ID，方便后续db.data建立索引时使用，保证索引的连续性，没有碎片。 db.redo： 用来进行消息恢复，如果KahaDB消息存储在强制退出后启动，用于恢复Btree索引。 Lock： 文件锁，标识当前获得KahaDB读取权限的Broker。 LevelDB消息存储这种文件系统时从ActiveMQ5.8之后引进的，它和KahaDB非常相似，也是基于文件的本地数据库储存形式，但是它提供比KahaDB更快的持久性。 但它不能使用自定义B-Tree实现来索引与写日志，而是使用基于LevelDB的索引。 1234&lt;!--默认的配置如下:--&gt;&lt;persistenceAdapter&gt; &lt;levelDB directory=\"activemq-data\" /&gt;&lt;/persistenceAdapter&gt; JDBC消息存储以Mysql数据库为例，需要将Mysql数据库的驱动包mysql-connector-java-5.1.38.jar添加到ActiveMQ目录下的lib文件夹中。 然后修改activemq.xml配置文件，按照如下修改： 12345678&lt;!--原KahaDB的配置--&gt;&lt;persistenceAdapter&gt; &lt;kahaDB directory=\"$&#123;activemq.data&#125;/kahadb\" /&gt;&lt;/persistenceAdapter&gt;&lt;!--修改成JDBC配置--&gt;&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource=\"#mysql-ds\" createTablesOnStartup=\"true\" /&gt;&lt;/persistenceAdapter&gt; dataSource指定将要引用的持久化数据库的bean名称，createTablesOnStartup参数表示是否在启动的时候创建数据库表，默认值是true，这样每次启动都会去创建数据库表了，一般是第一次启动的时候设置为true，之后改成false。 上文指定了一个数据库实例mysql-ds，所以需要创建一个mysql-ds的实例，通过activemq.xml中的&lt;broker&gt;标签外设置bean 1234567&lt;bean id=\"mysql-ds\" class=\"org.apache.commons.dbcp2.BasicDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost/activemq?relaxAutoCommit=true\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;property name=\"poolPreparedStatements\" value=\"true\"/&gt; &lt;/bean&gt; 其中的org.apache.commons.dbcp2.BasicDataSource是JDBC驱动包自带的，当然也可以替换成C3P0或者Druid，但是lib文件夹就需要再添加C3p0或者Druid相关的依赖包。 然后创建一个与上方配置相同的数据库（activemq），执行语句CREATE DATABASE activemq 。 如果配置正常且启动成功，将会在数据库创建三张表ACTIVEMQ_MSGS、ACTIVEMQ_ACKS、ACTIVEMQ_LOCK。 ACTIVE_MSGS 列名 意义 ID 自增的数据库主键 CONTAINER 消息的Destination MSGID_PROD 消息发送者的主键 MSG_SEQ 消息发送的顺序，MSGID_PROD+MSG_SEQ可以组成JMS的MessageID EXPIRATION 消息过期时间，存储的是从1970-01-01到现在的毫秒数 MSG 消息本体的Java序列化对象的二进制数据 PRIORITY 优先级，0-9，数值越大优先级越高 ACTIVEMQ_ACKSactivemq_acks用于存储订阅关系。如果是持久化Topic，订阅者和服务器的订阅关系在这个表保存。 列名 意义 CONTAINER 消息的Destination SUB_DEST 如果是使用Static集群，这个字段会有集群其他系统的信息 CLIENT_ID 每个订阅者都必须有一个唯一的客户端ID用以区分 SUB_NAME 订阅者名称 SELECTOR 选择器，可以只消费满足条件的消息。条件可以用自定义属性实现，可支持多属性AND和OR操作 LAST_ACKED_ID 记录消费过的消息的ID ACTIVEMQ_LOCK表activemq_lock在集群环境中才有用，只有一个Broker可以获得消息，称为Master Broker，其他的只能作为备份等待Master Broker不可用，才可能称为下一个Master Broker。这个表用于记录哪个Broker是当前的Master Broker。 队列在点对点类型中： 当DeliveryMode设置为NON_PERSISTENCE时，消息被保存在内存中； 当DeliveryMode设置为PERSISTENCE时，消息保存在broker的相应的文件或者数据库中。 而且点对点类型中消息一旦被Consumer消费就从broker中删除。 12//开启消息持久化producer.setDeliveryMode(DeliveryMode.PERSISTENT); 能够看到开启消息持久化后，生产者发送消息到队列中，通过查询activemq_msgs表能够看到数据变化情况。 主题开启消息持久化，先启动消费者订阅再运行生产者，可以看到activemq_acks的变化情况。 总结一定要开启消息持久化： 如果是队列： 在没有消费者消费的情况下会将消息保存到activemq_msgs表中，只要有任意一个消费者已经消费国了，消费之后这些消息将会被立刻删除。 如果是主题： 一般是先启动消费者订阅然后再生产的情况下会将消息保存到activemq_acks。 数据库Jar包： 记得需要使用到的相关Jar文件放置到ActiveMQ安装路径下的lib目录。mysql-jdbc驱动包和对应的数据库连接池Jar包 createTablesOnStartup属性： 在jdbcPersistenceAdapter标签中设置了这个属性为true时，在第一次启动ActiveMQ时，ActiveMQ服务节点会自动创建所需要的数据表，启动完成后可以更改为false。 下划线： java.lang.illeglStateException:BeanFactory not initalized or already closed，这是因为操作系统机器名中有“_”符号，请更改机器名并重启后即可解决问题。 JDBC增强版 JDBC Message store With ActiveMQ Journal，简称JDBC增强版，这种方式客服了JDBC Store的不足，JDBC每次消息过来，都需要去写库和读库。 ActiveMQ Journal，使用高速缓存写入技术，大大提高了性能。 当消费者的消费速度能够及时跟上生产者消息的生产速度时，Journal文件能够大大减少需要写入到DB中的消息。 举个例子： ​ 生产者生产了1000条消息，这1000条消息会保存到journal文件，如果消费者的消费速度很快的情况下，在journal文件还没有同步到DB之前，消费者已经消费了90%以上的消息，那么这个时候只需要同步剩余的10%的消息到DB。 如果消费者消费的速度很慢，这时候journal文件可以使消息以批量方式写到DB。 1234567891011121314&lt;!--原JDBC的配置--&gt;&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource=\"#mysql-ds\" createTablesOnStartup=\"true\" /&gt;&lt;/persistenceAdapter&gt;&lt;!--修改成JDBC Journal配置--&gt;&lt;persistenceAdapter&gt; &lt;journalPersistenceAdapterFactory journalLogFiles=\"4\" journalLogFilSize=\"32768\" useJournal=\"true\" useQuickJournal=\"true\" dataSource=\"#mysql-ds\" dataDirectory=\"activemq-data\" /&gt;&lt;/persistenceAdapter&gt; 总结持久化消息主要是指MQ所在的服务器宕机后消息不会丢失的机制。 持久化机制演化过程： ​ 从最初的AMQ Message Store方案到ActiveMQ V4版本中推出的High performance journal（高性能事务支持）附件，并且同步推出了关于关系型数据库的存储方案。 ActiveMQ V5.3版本中又推出了对KahaBD的支持（V5.4版本后成为ActiveMQ默认的持久化方案），后来AciveMQ V5.8版本开始支持LevelDB，到现在，v5.9+版本提供了标准的Zookeeper+LevelDB集群化方案。 ActiveMQ的消息持久化机制： AMQ： 基于日志文件 KahaDB：基于日志文件，从ActiveMQ 5.4开始默认的持久化插件 JDBC：基于第三方数据库 LevelDB：基于文件的本地数据库储存，从ActiveMQ 5.8版本之后又推出了LevelDB的持久化引擎性能高于KahaDB Replicated LevelDB Store：从ActiveMQ 5.9提供了基于LevelDB和Zookeeper的数据复制方式，用于Master-slave方式的首选数据复制方案。 无论使用哪种持久化方式，消息的存储逻辑都是一致的： 就是在发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等，然后试图将消息发送给接收者，发送成功则将消息从存储中删除，失败则继续尝试。消息中心启动以后首先要检查指定的存储位置，如果有未发送的消息，则需要把消息发送出去。ActiveMQ多节点集群引入消息队列之后该如何保证其高可用性？ 基于Zookeeper和LevelDB搭建ActiveMQ集群，提供主备方式的高可用集群功能，避免单点故障。 三种集群方式：官网介绍 在ActiveMQ V5.6版本之后推出LevelDB的持久化引擎，它使用了自定义的索引代替常用的BTree索引，其持久化性能高于KahaDB，虽然默认的持久化方式还是KahaDB，但是LevelDB可能会是趋势。 在ActiveMQ V5.9版本还提供了基于LevelDB和Zookeeper的数据复制方式，作为Master-Slave方式的首选数据复制方案。 ZK+R LevelDB Store从ActiveMQ V5.9开始，ActiveMQ的集群实现方式取消了传统的Master-Slave方式，增加了基于Zookeeper+LevelDB的Master-Slave实现方式，从V5.9版本后也是官网推荐的。 原理说明： ​ 使用Zookeeper集群注册所有的ActiveMQ Broker但只有其中一个Broker可以提供服务，它将被视为Master，其他Broker处于待机状态被视为Slave。 如果Master因故障而不能提供服务ZooKeeper会从Slave中选举出一个Broker充当Master。 Slave连接Master并同步他们的存储状态，Slave不接受客户端连接。所有存储操作都将被复制到连接至Master的Slaves。 如果Master宕机，得到了最新更新的Slave会成为Master。故障节点在恢复会重新加入到集群中并连接Master进入Slave模式。 所有需要同步的消息操作都将等待存储状态被复制到其他法定节点的操作完成才能算完成。 所以，如果你配置了replicas=3，那么法定大小是（3/2+1）=2。Master将会存储并更新然后等待（2-1）=1个Slave存储和更新完成，才汇报success。至于为什么是2-1个，可以结合Zookeeper的watch机制、选举算法、原子广播ZAB协议。 有一个节点要作为观察者存在，当一个新的Master被选中，需要至少保障一个法定节点在线，以能够找到拥有最新状态的节点，这个节点才可以成为新的Master。 部署规划和步骤要求关闭防火墙并保证可以ping通ActiveMQ服务器，要求具备Zookeeper集群并可以成功启动。 集群部署规划列表 主机 Zookeeper集群端口 AMQ集群Bind端口 AMQ消息TCP端口 管理控制台端口 AMQ安装目录 192.168.1.132 2191 bind=”tcp://0.0.0.0:63631” 61616 8161 /mq_node01 192.168.1.132 2192 bind=”tcp://0.0.0.0:63632” 61617 8162 /mq_node02 192.168.1.132 2193 bind=”tcp://0.0.0.0:63633” 61618 8163 /mq_node03 修改控制台端口12345&lt;!--AMQ目录/conf/jetty.xml--&gt;&lt;bean id=\"jettyPort\" class=\"org.apache.activemq.web.WebConsolePort\" init-method=\"start\"&gt; &lt;property name=\"host\" value=\"0.0.0.0\" /&gt; &lt;property name=\"port\" value=\"8161\"&gt;&lt;/bean&gt; HostName映射1234#hostname名字映射vim /etc/hosts#增加自己机器配置192.168.1.132 mq-server brokerName一致123&lt;!--三个节点的brokerName要求全部一致--&gt;&lt;!--修改每个AMQ的activemq.xml文件--&gt;&lt;broker xmlns=\"http://activemq.apache.org/schema/core\" brokerName=\"kuromq\" dataDirectory=\"$&#123;activemq.data&#125;\"&gt; 持久化配置三个节点的持久化配置要求一致，Bind根据不同MQ实例调整 12345678910&lt;persistenceAdapter&gt; &lt;replicatedLevelDB directory=\"$&#123;activemq.data&#125;/leveldb\" replicas=\"3\" bind=\"tcp://0.0.0.0:63633\" zkAdress=\"localhost2191,localhost2192,localhost2193\" hostname=\"#mq-server\" sync=\"local_disk\" zkPath=\"/activemq/leveldb-stores\" /&gt;&lt;/persistenceAdapter&gt; 修改消息端口修改activemq.xml的消息协议的端口，调整为上述规划的端口。 然后按照顺序启动3个ActiveMQ节点，前提是Zookeeper集群已经成功启动运行。 zk集群的节点状态12#进入任意一台zookeeper目录下的bin./zkCli.sh -server 127.0.0.1:2191 集群启动后对Zookeeper数据抓图，可以看到ActiveMQ的三个节点，分别是00000000000，00000000001，00000000002。 第二张图00000000000的值可以看到elected的值不为空，说明这个节点是Master，其他两个是Slave。 集群可用性测试ActiveMQ的客户端只能访问Master的Broker，其他处于Slave的Broker不能访问，所以客户端连接的Broker应该使用failover协议(失败转移)。 当一个ActiveMQ节点挂掉或者一个Zookeeper节点挂掉，ActiveMQ服务依然正常运行，如果仅剩一个ActiveMQ节点，由于不能选举Master，所以ActiveMQ不能正常运行。 同样的，如果Zookeeper仅剩一个节点活动，不管ActiveMQ各个节点存活与否，ActiveMQ也不能正常提供服务，ActiveMQ集群的高可用依赖于Zookeeper集群的高可用。 12//BrokerURL调整public static final String ACTIVE_URL=\"failover:(tcp://192.168.1.132:61616,tcp://192.168.1.132:61617,tcp://192.168.1.132:61618)?randomize=false\"; 测试：3台机器中的ActiveMQ只会有一个MQ可以被客户端连接使用，在测试时可以把Master关掉，然后再重试客户端消息发送和消息还可以正常使用，则说明集群搭建正常。 高级特性异步投递ActiveMQ支持同步、异步两种发送的模式将消息发送到Broker，模式的选择对发送延时有巨大的影响。producer能够达到怎样的产出率（产出率=发送数据总量/时间）主要受发送延时的影响，使用异步发送可以显著的提高发送的性能。 ActiveMQ默认使用异步发送的模式，除非明确指定使用同步发送的方式或者在未使用事务的前提下发送持久化的消息，这两种情况都是同步发送的。 如果没有使用事务且发送的是持久化消息，每一次发送都是同步发送的且会阻塞producer直到broker返回一个确认，表示消息已经被安全的持久化到磁盘。确认机制提供了消息安全的保障，但同时会阻塞客户端，带来了很大的延时。 很多高性能的应用，允许在失败的情况下有少量的数据丢失，如果你的应用满足这个这点，你可以使用异步发送来提高生产率，即使发送的是持久化的消息。 异步发送可以最大化producer端的发送效率。我们通常在发送消息量比较密集的情况下使用异步发送，它可以很大的提升producer性能。 不过这也带来了额外的问题，就是需要消耗较多的Client端内存，同时也会导致broker端的性能增加。 此外它不能有效的确保消息的发送成功，在useAsyncSend=true的情况下客户端需要容忍消息丢失的可能。 可以参考官网的三种异步投递配置方式： 异步发送确认机制异步发送丢失消息的场景是：生产者设置了UseAsyncSend=true，使用producer.send(msg)持久发送消息。由于消息不阻塞，生产者会认为所有send的消息均被成功发送至MQ。 如果MQ突然宕机，此时生产者端内存中尚未被发送至MQ的消息都会丢失。所以正确的异步发送方式是需要接收回调的。 同步发送和异步发送的区别： 同步发送等send不阻塞了就表示一定发送成功了。 异步发送需要接收回执并由客户端再判断一次是否发送成功。 12345678910111213141516171819202122232425262728293031323334353637public class JmsProducer &#123; //ActiveMQ服务器的链接地址 private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; //队列名称 private static final String QUEUE_NAME = \"queue01\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //设置异步投递 factory.setUseAsyncSend(true); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); //注意：强转成ActiveMQMessageProducer类 ActiveMQMessageProducer producer = (ActiveMQMessageProducer)session.createProducer(queue); for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"message---\" + i); message.setJMSMessageID(UUID.randomUUID.toString()); String messageID = message.getJMSMessageID(); //使用具备回调函数的API发送消息 producer.send(message, new AsyncCallback() &#123; @Override public void onSuccess() &#123; System.out.println(messageID + \"has been send\"); &#125; @Override public void onException(JMSException exception) &#123; System.out.println(messageID + \"fail to send\"); &#125; &#125;); &#125; producer.close(); session.close(); connection.close(); System.out.println(\"生产者发送消息队列queue01完毕\"); &#125;&#125; 延迟投递和定时投递12&lt;!--activemq.xml在boker属性上配置schedulerSupport=\"true\"--&gt;&lt;broker xmlns=\"http://activemq.apache.org/schema/core\" brokerName=\"localhost\" dataDirectory=\"$&#123;activemq.data&#125;\" schedulerSupport=\"true\"&gt; Property name type description AMQ_SCHEDULED_DELAY long 延迟投递的时间 AMQ_SCHEDULED_PERIOD long 重复投递的时间间隔 AMQ_SCHEDULED_REPEAT int 重复投递次数 AMQ_SCHEDULED_CRON String Cron表达式 通过在ActiveMQ的配置文件中开启定时调度SchedulerSupport=&quot;true&quot;，默认为false。然后使用ScheduleMessage类进行消息属性配置。 1234567891011121314151617181920212223242526272829//生产者public class JmsProducer &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue-delay\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); Connection connection = factory.createConnection(); connection.start(); Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); Queue queue = session.createQueue(QUEUE_NAME); MessageProducer producer = session.createProducer(queue); //设置延迟投递时间 long delay = 3 * 1000; //设置重复投递的时间间隔 long period = 4 * 1000; //重复投递次数 int repeat = 5; for (int i = 1; i &lt;= 3; i++) &#123; TextMessage message = session.createTextMessage(\"delay-message---\" + i); message.setLongProperty(ScheduleMessage.AMQ_SCHEDULED_DELAY, delay); message.setLongProperty(ScheduleMessage.AMQ_SCHEDULED_PERIOD, period); message.setIntProperty(ScheduleMessage.AMQ_SCHEDULED_REPEAT, repeat); producer.send(message); &#125; producer.close(); session.close(); connection.close(); &#125;&#125; 重试机制那些情况会引发消息重发？ Client用了transactions且在session中调用了rollback() Client用了transactions且在调用commit()之前关闭或者没有commit Client在CLINET_ACKNOWLEDGE的传递模式下，在session中调用了recover() 默认消息重发的时间间隔是每秒钟，重发次数是6次。 有毒消息Poison ACK： 一个消息被redelivedred超过默认的最大重发次数（默认6次）时。消费端会给MQ发送一个Poison ack表示这个消息有毒，告诉broker不要再发了。这个时候broker会把这个消息放到DLQ（死信队列），详情请参照官网。 属性 默认值 描述 collisionAvoidanceFactor 0.15 设置防止冲突范围的政府百分比，只有启动UseCollisionAvoidance参数时才生效，也就是在延迟时间再加一个 maximumRedelivers 6 最大重传次数，达到最大重连次数后抛出异常。为-1时不限制次数，为0时表示不进行重传。 maximumRedeliveryDelay -1 最大传送延迟，只在UseExponentialBackOff为true时有效（V5.5），假设首次重连间隔为10ms，倍数为2，那么第二次重连时间间隔为20ms，第三次重连时间间隔为40ms，当重连时间间隔的大于最大重连时间间隔时，以后每次重连时间间隔都为最大重连时间间隔。 initialRedeliveryDelay 1000L 初始重发延迟时间 redeliveryDelay 1000L 重发延迟时间，当initialRedeliveryDelay=0时生效 useCollisionAvoidance false 启用防止冲装功能 useExponentialBackOff false 启用指数倍数递增的方式增加延迟时间 backOffMultiplier 5 重连时间间隔递增倍数，只有值大于1和启动useExponentialBackOff参数时才生效 配置重试次数12345678910111213//修改最大重试次数public class JmsConsumer_Redelivery &#123; private static final String ACTIVE_URL = \"tcp://192.168.1.132:61616\"; private static final String QUEUE_NAME = \"queue-redelivery\"; public static void main(String[] args) throws JMSException &#123; ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(ACTIVE_URL); //使用自身的配置类，设置重试次数3次 RedeliveryPolicy redeliveryPolicy = new RedeliveryPolicy(); redeliveryPolicy.setMaximumRedeliveries(3); activeMQConnectionFactory.setRedeliveryPolicy(redeliveryPolicy); //省略后续代码... &#125;&#125; 整合Spring123456789&lt;!--定义reDelivery重发机制--&gt;&lt;bean id=\"activeMQRedeliveryPolicy\" class=\"org.apache.activemq.RedeliveryPolicy\"&gt; &lt;property name=\"maximumRedeliveries\" value=\"3\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--创建连接工厂并指定配置--&gt;&lt;bean id=\"connectionFactory\" class=\"org.apache.activemq.ActiveMQConnectionFactory\"&gt; &lt;property name=\"brokerURL\" value=\"tcp://192.168.1.132:61616\"&gt;&lt;/property&gt; &lt;property name=\"redeliveryPolicy\" ref=\"activeMQRedelivery\" /&gt;&lt;/bean&gt; 死信队列ActiveMQ中引入了死信队列（Dead Letter queue）的概念，即一条消息再被重发了多次后（默认为重发6次redeliveryConter==6），将会被ActiveMQ移入私信队列，开发人员可以在这个Queue中查看处理出错的消息，进行人工干预，主要用来处理失败的消息，详情请查看官网。 一般生产环境中在使用MQ的时候设计两个队列：一个是核心业务队列，一个是死信队列。 核心业务队列，就是比如上图专门用来让订单系统发送订单消息的，然后另外一个私信队列就是用来处理异常情况的。 假设第三方物流系统故障了，此时无法请求，那么仓储系统每次消费到一条订单消息，尝试通知发货和配送都会遇到对方的接口报错。此时仓储系统就可以把这条消息拒绝访问或者标志位处理失败。一旦表这条消息处理失败后，MQ就会把这条消息转入提前设置好的一个死信队列中。 然后看到的就是，在第三方物流系统故障期间，所有订单消息全部处理失败，全部都会转入私信队列，然后你的仓储系统得专门有一个后台线程，监控第三方系统是否正常。一旦发现对方回复正常，这个后台线程就从私信队列消费处理失败的订单，重新执行发货和配送的通知逻辑。 共享死信队列SharedDeadLetterStrategy（共享死信队列），将所有的DeadLetter保存在一个共享的队列中，这是ActiveMQ broker端默认的策略。 共享队列默认为ActiveMQ.DLQ，可以通过deadLetterQueue属性来设定。 123&lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy deadLetterQueue=\"DLQ-QUEUE\" /&gt;&lt;/deadLetterStrategy&gt; 个人死信队列IndividualDeadLetterStrategy（个人死信队列），把DeadLetter放入各自的死信通道中。 对于Queue而言，死信通道的前缀默认为ActiveMQ.DLQ.Queue. 对于Topic而言，死信通道的前缀默认为ActiveMQ.DLQ.Topic. 比如队列Order，那么它对应的死信队列通道为ActiveMQ.DLQ.Queue.Order，我们使用queuePrefix、topicPrefix来指定上述前缀。 默认情况下，无论是Topic还是Queue，Broker将使用Queue来保存DeadLetter，即死信通道通常为Queue，不过开发也可以指定为Topic。 12345&lt;policyEntry queue=\"order\"&gt; &lt;deadLetterStrategy&gt; &lt;individualDeadLetterStrategy queuePrefix=\"DLQ.\" useQueueForQueueMessages=\"false\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 将队列Order中出现的DeadLetter保存在DLQ.Order中，不过此时DLQ.Order为Topic。 属性useQueueForQueueMessages设置使用队列保存死信队列，还可以设置useQueueForTopicMessages，使用Topic来保存死信队列，默认为true。 自动删除过期消息有时需要直接删除过期的消息而不需要发送到死信队列中，processExpired表示是否将过期消息放入私信队列，默认为true。 123456&lt;!--\"&gt; \"类似SQL的 * --&gt;&lt;policyEntry queue=\"&gt; \" &gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStragegy processExpired=\"false\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 存放非持久消息默认情况下，ActiveMQ不会把非持久的死消息发送到死信队列中。processNonPersistent表示是否将非持久化消息放入死信队列，默认为false。 如果想把非持久化的消息发送到死信队列中，需要设置属性processNonPersistent=&quot;true&quot; 12345&lt;policyEntry queue=\"&gt; \"&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processNonPersistent=\"true\" /&gt; &lt;/deadLetterStrategy&gt;&lt;/policyEntry&gt; 重复消费如何保证消息不被重复消费？幂等性问题？ ​ 网络延迟传输中，会造成进行MQ重试中，在重试过程中，可能会造成重复消费。 如果消息是做数据库的插入操作，给这个消息做一个唯一主键，那么就算出现重复消息的情况，就会导致主键冲突，避免数据库出现脏数据。 或者准备个第三方来做消息记录，以redis为例，给消息分配一个全局id，只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis，消费者开始消费前，先去redis中查询有没有消费记录即可。","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/categories/ActiveMQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/tags/ActiveMQ/"}]},{"title":"'Thread（二） 线程同步容器'","slug":"thread-containers","date":"2020-05-21T15:30:00.000Z","updated":"2020-05-26T04:01:36.575Z","comments":true,"path":"2020/05/21/thread-containers/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/thread-containers/","excerpt":"","text":"线程同步容器同步容器类同步容器类包括Vector和Hashtable，二者是早期JDK的一部分，这些同步的封装器类是由Conllections.synchronizedXxx等工厂方法创建的。 这些类实现线程安全的模式是：将他们的状态封装起来，并对每个公有方法进行同步，使得每次只有一个线程能访问容器的状态。 同步容器类的问题同步容器类都是线程安全的，但是在某些情况下可能需要额外的客户端加锁来保护复合操作。容器上常见的复合操作包括：迭代、跳转（根据指定顺序找到当前元素的下一个元素）以及条件运算。 例如 “若没有则添加”，当其他线程并发地修改容器时，他们可能会表现出意料之外的行为。 123456789public static Object getLast(Vector list) &#123; int lastIndex = list.size() - 1; return list.get(lastIndex);&#125;public static void deleteLast(Vector list) &#123; int lastIndex = list.size() -1; list.remove(liastIndex);&#125; 这些方法看似没有任何问题，从某种程度来说也确实如此——无论多少个线程同时调度他们，也不破坏Vector。但是从这些调用者角度来看，情况就不同了。 如果 线程A 在包含10个元素的Vector上调用getLast，同时 线程B 在同一个Vector上调用deleteLast，这些操作的交替执行如下图。 交替调用getLast和deleteList时将抛出ArrayIndexOutOfBoundsException，同步容器类通过其自身的锁来保护它的每个方法，通过获得容器类的锁，我们可以使getLast和deleteLast成原子操作，并确保Vector的大小在调用size和get之间不会发生变化。 12345678910111213public static Object getLast(Vector list) &#123; synchronized (list) &#123; int lastIndex = list.size() - 1; return list.get(lastIndex); &#125;&#125;public static void deleteLast(Vector list) &#123; synchronized (list) &#123; int lastIndex = list.size() -1; list.remove(liastIndex); &#125;&#125; 在调用size和相应的get之间，Vector的长度可能会发生变化，这种风险在对Vector中的元素进行迭代时仍然会出现。 123for(int i = 0; i &lt; vector.size(); i++) &#123; doSomething(vector.get(i));&#125; 在迭代的过程中，有其他线程并发地修改Vector时，可能抛出异常，但并不意味着Vector就不是线程安全的。Vector的状态仍然是有效的，但是迭代中抛异常显然不是人们所期望的。 我们可以通过加锁来解决不可靠迭代的问题，但是要牺牲一些伸缩性，通过在迭代期间持有Vector的锁，然而，这样同样会导致其他线程在迭代期间无法访问它，因此降低了并发性。 12345synchronized (vector) &#123; for(int i = 0; i &lt; vector.size(); i++) &#123; doSomething(vector.get(i)); &#125;&#125; ConcurrentModificationException无论直接迭代还是for-each循环，对容器类进行迭代的标准方式都是使用Iterator，如果有其他线程并发地修改容器，即使是使用迭代器也无法避免在迭代期间对容器加锁。 在设计同步容器类的迭代器时并没有考虑并发修改的问题，并且它们表现出的行为是 “及时失败” 的。这意味着，当他们发现容器在迭代过程中被修改时，就会抛出一个ConcurrentModificationException异常。 这种 “及时失败” 的迭代器并不是一种完善的处理机制，而只是善意的捕获并发错误，因此只能作为并发问题的预警指示器。它们采用的实现方式是，将计数器的变化于容器关联起来：如果迭代期间计数器被修改，那么hasNext或next将抛出ConcurrentModificationException。 然而有些时候开发人员并不希望在迭代期间对容器加锁，如果容器的规模很大，或者执行时间很长，长时间对容器加锁会降低程序的可伸缩性，持有锁的时间越长，那么在锁上的竞争就可能越激烈，如果许多线程都在等待锁被释放，那么将极大地降低吞吐量和CPU的利用率。 如果不希望在迭代期间对容器加锁，那么一种替代方法就是 “克隆容器“，并在副本上进行迭代，由于副本被封闭在线程内，因此其他线程不会在迭代期间对其进行修改，这样就避免了抛出异常，但是在克隆过程中仍然需要对容器加锁。 隐藏迭代器虽然加锁可以防止迭代器抛出ConcurrentModificationException，但在某些情况下，迭代器会隐藏起来，如以下程序 123456789101112131415public class HiddenIterator &#123; private final Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); public synchronized void add(Integer i) &#123; set.add(i); &#125; public synchronized void remove(Integer i) &#123; set.remove(i); &#125; public void addTenThings() &#123; Random r = new Random(); for(int i = 0; i &lt; 10; i++) add(r.nextInt()); System.out.println(\"printSet:\" + set); &#125;&#125; 该方法可能会抛出ConcurrentModificationException，因为在打印的过程中，toString对容器进行迭代，当然真正的问题在于HiddenIterator不是线程安全的。在使用println中的set之前必须先获得锁，但是在代码中通常会忽略。 ConcurrentHashMap与HashMap一样，ConcurrentHashMap也是基于散列的Map，但它使用了一种完全不同的加锁策略来提供更高的并发性和伸缩性，ConcurrentHashMap并不是将每个方法都在同一个锁上同步并使得每次只有一个线程访问容器，而是使用一种粒度更细的加锁机制来实现更大程度的共享，这种机制称为分段锁。 在这种机制中，任意数量的读取线程可以并发地访问Map，执行读取操作的线程和执行写入的操作的线程可以并发地访问Map，并且一定数量的写入线程可以并发修改Map，ConcurrentHashMap带来的结果是，在并发访问环境下将实现更高的吞吐量，而在单线程环境中只损失非常小的性能。 ConcurrentHashMap与其他并发容器一起增强了同步容器类：它提供的迭代器不会抛出ConcurrentModificationException因此不需要再迭代过程中对容器加锁，ConcurrentHashMap返回的迭代器具有弱一致性，弱一致性的迭代器可以容忍并发的修改，当创建迭代器时会遍历已有的元素，并可以（但是不保证）在迭代器被构造后将修改操作反应给容器。 与Hashtable和synchronizedMap相比，ConcurrentHashMap有着更多的优势以及更少的劣势，因此在大多数情况下，用ConcurrentHashMap来替代同步Map能进一步提高代码的可申缩性。 额外的原子Map操作一些常见的复合操作，例如：若没有则添加、若相等则移除和若相等则替换等，都已经实现为原子操作并且在ConcurrentMap的接口中声明。 1234567891011public interface ConcurrentMap&lt;K, V&gt; extends Map&lt;K, V&gt; &#123; //仅当K没有相应的映射值才插入 V putIfAbsent(K key, V value); //仅当K被映射到V时才移除 boolean remove(Object key, Object value); //仅当K被映射到oldValue时才替换为newValue V replace(K key, V value); //仅当K呗银蛇到某个值时才替换为newValue boolean replace(K key, V oldValue, V newValue); &#125; CopyOnWriteArrayList “本篇文章主要摘自《JAVA 并发编程实战》”","categories":[{"name":"Thread","slug":"Thread","permalink":"https://midkuro.gitee.io/categories/Thread/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.gitee.io/tags/Thread/"}]},{"title":"'Thread（一） 线程安全性'","slug":"thread-safety","date":"2020-05-21T15:20:00.000Z","updated":"2020-09-24T10:37:10.540Z","comments":true,"path":"2020/05/21/thread-safety/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/thread-safety/","excerpt":"","text":"线程安全性什么是线程安全性线程是CPU执行的基本单位，进程是CPU分配的基本单位。 多线程访问某个类时，不管运行环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或者异步，这个类都能表现出正确的行为，那么就称这个类是线程安全的。 示例：一个无状态的Servlet 123456//Servlet容器是一个单例多线程的容器对象public class StatelessServlet implements Servlet &#123; public void service(String param) &#123; //多线程调度该方法 &#125;&#125; StatelessServlet是无状态的，它既不包含任何域，也不包含任何对其他类中域的引用。计算过程中的临时状态存储在线程栈帧的局部变量表中，并且只能由正在执行的线程访问。 访问StatelessServlet的线程不会影响另一个访问StatelessServlet的线程计算结果。由于线程访问无状态对象的行为并不会影响其他线程中操作的正确性，因此，无状态对象一定是线程安全的。 原子性当我们在无状态对象中增加一个状态时，会出现什么情况？假设我们希望增加一个 “命中计数器” 来统计所处理的请求数量。一种直观的方法是增加一个long类型的域，并且每次处理一个请求就将这个值加1。 12345678@NotThreadSafepublic class UnsafeCountingServlet implements Servlet &#123; private long count = 0; public void service(String param) &#123; //执行方法逻辑 ++count; &#125;&#125; 不幸的是，UnsafeContingServlet并非线程安全的，尽管它在单线程环境中能够正确运行，这个类可能会丢失一些更新操作，++count并非原子的，它包含了三个独立的操作 ：读取count值，将值加1，然后将计算结果写入count。这是一个 “读取-修改-写入” 的操作，并且其结果状态依赖于之前的状态。 上述例子给出了两个线程在没有同步的情况下，同时对一个计数器执行递增操作时发生的情况。如果计数器的初始值为9，那么在某些情况下，每个线程读到的值都为9，接着执行递增操作，并且都将计数器的值设置为10。命中计数器的值就讲偏差1。 竟态条件在并发编程中，这种由于不恰当的执行时序而出现不正确的结果是一种非常重要的情况，它有一个正式的名字：竟态条件（Race Condition）。 最常见的竟态条件类型就是 “先检查后执行(Check-then-Act)” 操作，即通过一个可能失效的观测结果来决定下一步的动作。 123456789@NotThreadSafepublic class LazyInitRace &#123; private Object instance = null; public Object getInstance() &#123; if(instance == null) instance = new Object(); return instance; &#125;&#125; 在LazyInitRace中包含一个竟态条件，它可能会破坏这个类的正确性。假定 线程A 和 线程B 同时执行getInstance，A看到instance为空，因而创建一个新的Object实例，B同样需要判断instance是否为空，此时的instance是否为空，取决于不可预测的时序，包括线程的调度方式，以及A需要花多长时间来初始化Object并设置instance，如果当B检查时，instance为空，那么两次调用getInstance时可能会得到不同的结果。 在UnsafeCountingServlet的统计命中计数器中存在另一种竟态条件。在 “读取-修改-写入” 操作中，基于对象之前的状态来定义对象状态的转换，要递增一个计数器，你必须知道它之前的值，并确保在执行更新的过程中没有其他线程会修改或使用这个值。 12345678@ThreadSafepublic class CountingServlet implements Servlet &#123; private final AtomicLong count = new AtomicLong(0); public void service(String param) &#123; //执行方法逻辑 count.incrementAndGet(); &#125;&#125; 在java.util.concurrent.atomic包中包含一些原子变量类，通过用AtomicLong来代替long类型的计数器，能够确保所有对计数器状态的访问都是原子的。 内置锁Java提供了一种内置的锁机制来支持原子性：同步代码块(Synchronized Block)，同步代码块包括两个部分：一个作为锁的对象引用，一个作为由这个锁保护的代码块。 以关键字synchronized来修饰方法就是一种横跨整个方法体的同步代码快，其中该同步代码块的锁就是方法调用所在的对象。静态的synchronized方法以Class对象作为锁。 123synchronized (lock) &#123; //访问或者修改由锁保护的共享状态&#125; 每个Java对象都可以用作一个实现同步的锁，这些锁被称为内置锁或监视器锁。线程在进入同步代码块之前会自动获得锁，并且在退出同步代码块时自动释放锁。 Java的内置锁相当于一种互斥锁，最多只有一个线程能够持有这种锁，当 线程A 尝试获取一个由 线程B 持有的锁时，线程A 必须等待或者阻塞，直到 线程B 释放这个锁，如果B永远不释放锁，那么A也将永远地等下去。 重入当某个线程请求一个由其他线程持有的锁时，发出的请求的线程就会阻塞。然而，由于内置锁是可重入的，因此如果某个线程试图获得一个已经由它持有的锁，那么这个请求就会成功。 “重入”获取锁的操作粒度是“线程”，重入的实现方法是，为每一个锁关联一个获取计数值和一个所有者线程。当计数值为0时，这个锁就被认为是没有被任何线程持有，当线程请求一个未被持有的锁时，JVM将几下锁的持有者，并且将获取计数值置为1，如果同一个线程再次获取这个锁，计数值将递增，而当线程退出同步代码快时，计数器会相应递减，当计数值为0时，这个锁将被释放。 1234567891011public class Father &#123; public synchronized void method() &#123; //逻辑 &#125;&#125;public class Son extends Father &#123; public synchronized void method() &#123; System.out.println(\"calling\"); super.method(); &#125;&#125; 子类改写了父类的synchronized方法，然后调用父类中的方法，由于Father和Son都是synchronized方法，因此每个method方法在执行前都会获取Father上的锁，然而如果内置锁不是可重入的，那么在调用super.method()时将无法获得Father上的锁。 对象的共享可见性123456@NotThreadSafepublic class MutableInteger &#123; private int value; public int get() &#123; return value;&#125; public void set(int value) &#123;this.value = value;&#125;&#125; 1234567891011121314151617181920public static void main(String[] args) &#123; MutableInteger object = new MutableInteger(); for (int i = 0; i &lt; 10; i++) &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; while (true) &#123; int i = object.get(); System.out.println(i + \"-\" + new Date().toString()); if (i == 100) &#123; break; &#125; &#125; &#125; &#125;); thread.start(); &#125; object.set(100); System.out.println(new Date().toString());&#125; 输出结果： 123456789101112131415100-Thu Apr 16 16:17:04 CST 20200-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 20200-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020设置Value时间:Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 20200-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 20200-Thu Apr 16 16:17:04 CST 2020100-Thu Apr 16 16:17:04 CST 2020 MutableInteger不是线程安全的，因为 get 和 set 都是在没同步的情况下访问 value 的，如果某个线程调用了set，那么另一个正在调用 get 的线程可能会看到更新后的 value 值，也可能看不到。 123456@ThreadSafepublic class SynchronizedInteger &#123; private int value; public synchronized int get() &#123; return value;&#125; public synchronized void set(int value) &#123;this.value = value;&#125;&#125; Volatile变量volatile变量用来确保将变量的更新操作通知到其他线程，当把变量申明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序，因此在读取volatile类型的变量时总会返回最新写入的值。 123456@ThreadSafepublic class VolatileInteger &#123; private volatile int value; public int get() &#123; return value;&#125; public void set(int value) &#123;this.value = value;&#125;&#125; 然而在访问volatile时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比synchronized关键字更轻量级的同步机制。 从内存的可见性角度来看，写入volatile变量相当于退出同步代码块，而读取volatile变量就相当于进入同步代码块，但并不建议过度依赖volatile变量提供的可见性，如果在代码中依赖volatile变量来控制状态的可见性，通常比使用锁的代码更脆弱，更难以理解。 尽管volatile只能确保可见性，在复合操作情况下，无法确保其正确性，如count++，具备了”读取-修改-写入”的复合操作。 加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。 当且仅当满足以下所有条件时，才应该使用volatile变量： 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。 该变量不会与其他状态变量一起纳入不变性条件中。 在访问变量时不需要加锁。 逸出提供一个对象的引用给作用域之外的代码，我们称做发布该对象。如果在对象构造完成之前就发布该对象，就会破坏线程安全性，当某个不应该发布的对象被发布时，这种情况被称为逸出。 1234567891011public class ThisEscape &#123; public ThisEscape() &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; //多线程代码 &#125; &#125;); thread.start(); &#125;&#125; 在ThisEscape中给出了一个this引用在构造函数中逸出的示例。this引用逸出的一个常见错误是，在构造函数中启动一个线程，当对象在其构造函数中创建一个线程时，this引用都会被新创建的线程共享，在对象未完全构造之前，新的线程就可以看见它。在构造函数创建线程并没有错误，但最好不要立即启动它。 当且仅当对象的构造函数返回时，对象才处于可预测和一致的状态。当从构造函数中发布对象时，只是发布了一个尚未构造完成的对象，即使发布语句位于构造函数的最后一行，那么这种对象被认为是不正确构造。 不要再构造过程中使this引用逸出。 线程封闭当访问共享的可变数据时，通常需要使用同步，一种避免使用同步的方式就是不共享数据。如果仅在单线程内访问数据，就不需要同步。这种技术被称为线程封闭（Thread Confinement），它是实现线程安全性的最简单方式之一。 栈封闭是线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问对象，局部变量固有属性就是封闭在执行线程中，他们位于执行线程的栈中，其他线程无法访问这个栈。 1234public int execute() &#123; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); return 0;&#125; 此时只有一个引用指向集合list，这个引用被封闭在局部变量中，因此也被封闭在执行线程中，然而如果发布了对集合list（或者该对象中的任何内部数据）的引用，那么封闭性呗破坏，并导致对象list逸出。 不变性如果某个对象在被创建后其状态就不能被修改，那么这个对象就称为不可变对象。线程安全性是不可变对象的固有属性之一，他们的不变性条件是由构造函数创建的，不可变对象一定是线程安全的。 不可变性不等于将对象所有域都声明为final类型，即使对象中所有域都是final类型的，这个对象也仍然是可变的，因为final类型的域中可以保存对可变对象的引用。 123456public final class MutableClass &#123; private final List&lt;String&gt; lists = new ArrayList&lt;&gt;(); public void setValue(String value) &#123; lists.add(value); &#125;&#125; 当满足以下条件时，对象才是不可变的： 对象创建以后其状态就不能修改。 对象的所有域都是final类型。 对象是正确创建的（在对象的创建期间，this引用没有逸出） 12345678910public final class ImmutableClass &#123; private final List&lt;String&gt; lists = new ArrayList&lt;&gt;(); public ImmutableClass() &#123; lists.add(\"apple\"); lists.add(\"banana\"); &#125; public boolean isContains(String value) &#123; return lists.contains(value); &#125;&#125; 即使对象是可变的，通过将对象的某些域声明为final类型，仍然可以简化对状态的判断，相当于限制了该对象可能的状态变化。 除非需要更高的可见性，否则应将所有域都声明为私有域是一个良好的变成习惯，除非需要某个域是可变的，否则应将其声明为final域，也是一个良好的变成习惯。 要安全地发布一个对象，对象的引用以及对象的状态必须同时对其他线程可见，一个正确构造的对象可以通过以下方式来安全地发布： 在静态初始化函数中初始化一个对象引用。 将对象的引用保存到valatile类型的域或者AtomicReferance对象中 将对象的引用保存到某个正确的构造对象的final类型域中。 将对象的引用保存到一个由锁保护的域中。 在线程安全容器内部同步意味着，将对象放到某个容器，例如Vector或者synchronizedList时将满足上述最后一条需求。 线程安全库中的容器提供了以下的安全发布保证： 通过将一个键或者值放入Hashtable、synchronizedMap或者ConcurrentMap中，可以安全将它发布给任何从这些容器中访问它的线程。 通过将某个元素放入Vector、CopyOnWriteArrayList、CopyOnWriteArraySet、SynchronizedList或者synchronizedSet中，可以将该元素安全地发布到任何从这些队列中访问该元素的线程。 事实不可变对象如果对象从技术上来说事可变的，但其状态在发布后不会再改变，那么把这种对象称之为事实不可变对象。这些对象不需要满足不可变性的严格定义，在这些对象发布后，程序只需将它们视为不可变对象即可。 在没有额外的同步的情况下，任何线程都可以安全地使用被安全发布的事实不可变对象。 可变对象如果对象在构造后可以修改，那么安全发布只能确保 “发布当时” 状态的可见性，对于可变对象，不仅在发布对象时需要使用同步，而且每次对象访问时同样需要使用同步来确保后续修改操作的可见性。要安全地共享可变对象，这些对象就必须被安全地发布，并且必须是线程安全的或者由某个锁保护起来。 对象发布需求取决于它的可变性： 不可变对象可以通过任意机制来发布。 事实不可变对象必须通过安全方式来发布。 可变对象必须通过安全方式来发布，并且必须是线程安全的或者由某个锁保护起来的。 “本篇文章主要摘自《JAVA 并发编程实战》”","categories":[{"name":"Thread","slug":"Thread","permalink":"https://midkuro.gitee.io/categories/Thread/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.gitee.io/tags/Thread/"}]},{"title":"'JVM（三） 垃圾收集器'","slug":"garbage-collector","date":"2020-05-21T14:40:00.000Z","updated":"2020-12-07T02:41:47.754Z","comments":true,"path":"2020/05/21/garbage-collector/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/garbage-collector/","excerpt":"","text":"垃圾收集器与内存分配策略GC回收的区间 清理Eden区和Survivor区叫Minor GC； 清理Old区叫Major GC； 清理整个堆空间————包括年轻代和老年代叫Full GC； GC回收的定位保守式 GC在进行 GC 的时候，会从一些已知的位置（也就是GC Roots）开始扫描内存，扫描到一个数字就判断他是不是可能是指向GC堆中的一个指针,然后一直递归的扫描下去，最后完成可达性分析。 这里扫描会涉及上下边界检查，GC堆的上下界是已知的、对齐检查，通常分配空间的时候会有对齐要求，假如说是4字节对齐，那么不能被4整除的数字就肯定不是指针。 这种模糊的判断方法因为无法准确判断一个位置上是否是真的指向 GC ，GC 采取一种保守的态度，把所有可疑的引用均当作指针，所以被命名为保守式 GC。 优点：不需要准确的判断出一个指针，所以效率快。 缺点：不能识别指针和非指针，对于一些已经死掉的对象，很可能会被误认为仍有地方引用他们，引起无用的内存占用，造成资源浪费。 准确式 GC与保守式 GC 相对的就是准确式 GC，何为 准确式 GC？就是我们准确的知道，某个位置上面是否是指针。 也就是说给定某个位置上的某块数据，要能知道它的准确类型是什么，这样才可以合理地解读数据的含义； GC 所关心的含义就是 这块数据是不是指针。要实现这样的 GC，JVM就要能够判断出所有位置上的数据是不是指向 GC 堆里的引用，包括活动记录（栈、寄存器）里的数据。 在java中实现的方式是：从外部记录下类型信息，存成映射表，在HotSpot虚拟机中把这种映射表称之为OopMap，不同的虚拟机名称可能不一样。 GC开始的时候，就通过OopMap这样的一个映射表知道，在对象内的什么偏移量上是什么类型的数据，而且特定的位置记录下栈和寄存器中哪些位置是引用。 生成映射表的两种方式： 每次都遍历原始的映射表，循环的一个个偏移量扫描过去；这种用法也叫 “ 解释式 ”。 为每个映射表生成一块定制的扫描代码（想像扫描映射表的循环被展开的样子），以后每次要用映射表就直接执行生成的扫描代码；这种用法也叫 “ 编译式 ”。 半保守式 GCJVM可以选择在栈上不记录类型信息，而是通过让数据自身带上标记，也就是对象上记录类型信息。这样的话，扫描栈的时候仍然会跟保守式 GC的过程一样，但扫描到 GC 堆内的对象时因为对象带有足够类型信息了，JVM就能够判断出在该对象内什么位置的数据是引用类型了，这种是半保守式 GC。 垃圾收集器如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。这里讨论的收集器基于JDK 1.7 Update 14之后的 HotSpot 虚拟机，这个虚拟机包含的所有收集器如下图所示 上图展示了作用于不同分代的多种收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。接下来将逐一介绍这些收集器的特性、基本原理和使用场景，并重点分析 CMS 和 G1 这两款相对复杂的收集器，了解它们的部分运作细节。 先明确一点：下文是各个收集器的比较，但不是为了挑出最好的收集器，而是挑选最合适的收集器。 除Epsilon ZGC Shenandoah之外的GC都是使用逻辑分代模型，G1是逻辑分代，物理不分代，除此之外不仅逻辑分代，而且物理分代。 Serial收集器Serial收集器是最基本、发展历史最悠久的收集器，曾经是虚拟机新生代收集的唯一选择。这是一个单线程的收集器，但它的 “ 单线程 ” 的意义并不仅仅说明它只会使用一个 CPU 或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。 “Stop The World“ 这个名字也许听起来很酷，但这项工作实际上是由虚拟机在后台自动发起和自动完成的，在用户不可见的情况下把用户正常工作的线程全部停掉，这对很多应用来说都是难以接受的。下图示意了 Serial/Serial Old 收集器的运行过程。 实际上到现在为止，它依然是虚拟机运行在 Client 模式下的默认新生代收集器。它也有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比），对于限定单个 CPU 的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 在用户的桌面应用场景中，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存，桌面应用基本上不会再大了），停顿时间完全可以控制在几十毫秒最多一百多毫秒以内，只要不是频繁发生，这点停顿是可以接受的。所以，Serial 收集器对于运行在 Client 模式下的虚拟机来说是一个很好的选择。 ParNew收集器ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括 Serial 收集器可用的所有控制参数（例如：-XX:SurvivorRatio、-XX:PretenureSizeThreshold、-XX:HandlePromotionFailure等）、收集算法、Stop The World、对象分配规则、回收策略等都与 Serial 收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。ParNew 收集器的工作过程如下图所示。 ParNew 收集器除了多线程收集之外，其他与 Serial 收集器相比并没有太多创新之处，但它却是许多运行在 Server 模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了 Serial 收集器外，目前只有它能与 CMS 收集器（并发收集器，后面有介绍）配合工作。 ParNew 收集器在单 CPU 的环境中不会有比 Serial 收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个 CPU 的环境中都不能百分之百地保证可以超越 Serial 收集器。 当然，随着可以使用的 CPU 的数量的增加，它对于 GC 时系统资源的有效利用还是很有好处的。它默认开启的收集线程数与 CPU 的数量相同，在 CPU 非常多（如 32 个)的环境下，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。 注意，从 ParNew 收集器开始，后面还会接触到几款并发和并行的收集器。这里有必要先解释两个名词：并发和并行。这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，它们可以解释如下。 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个 CPU 上。 Parallel Scavenge收集器Parallel Scavenge 收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器……看上去和 ParNew 都一样，那它有什么特别之处呢？ Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同，CMS 等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标则是达到一个可控制的吞吐量（Throughput）。 所谓吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了 100 分钟，其中垃圾收集花掉1分钟，那吞吐量就是99% 。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis参数以及直接设置吞吐量大小的-XX:GCTimeRatio参数。 MaxGCPauseMillis参数允许的值是一个大于 0 的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值。 不过大家不要认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些，收集 300MB 新生代肯定比收集 500MB 快吧，这也直接导致垃圾收集发生得更频繁一些，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每次停顿70毫秒。停顿时间的确在下降，但吞吐量也降下来了。 GCTimeRatio 参数的值应当是一个 0 到 100 的整数，也就是垃圾收集时间占总时间的比率，相当于是吞吐量的倒数。如果把此参数设置为 19，那允许的最大 GC 时间就占总时间的 5%（即 1/（1+19）），默认值为 99 ，就是允许最大 1%（即 1/（1+99））的垃圾收集时间。 由于与吞吐量关系密切，Parallel Scavenge 收集器也经常称为“吞吐量优先”收集器。除上述两个参数之外，Parallel Scavenge 收集器还有一个参数-XX:+UseAdaptiveSizePolicy值得关注。这是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden 与 Survivor 区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为 GC 自适应的调节策略（GC Ergonomics）。 Serial Old 收集器Serial Old 是 Serial 收集器的老年代版本，它同样是一个单线程收集器，使用“标记-整理”算法。这个收集器的主要意义也是在于给 Client 模式下的虚拟机使用。如果在 Server 模式下，那么它主要还有两大用途：一种用途是在 JDK 1.5 以及之前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途就是作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。这两点都将在后面的内容中详细讲解。Serial Old 收集器的工作过程如下图所示。 Parallel Old收集器Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和“标记-整理”算法。这个收集器是在 JDK 1.6 中才开始提供的，在此之前，新生代的 Parallel Scavenge 收集器一直处于比较尴尬的状态。 原因是，如果新生代选择了 Parallel Scavenge 收集器，老年代除了 Serial Old（PS MarkSweep）收集器外别无选择（Parallel Scavenge 收集器无法与 CMS 收集器配合工作）。 由于老年代 Serial Old 收集器在服务端应用性能上的 “ 拖累 ”，使用了 Parallel Scavenge 收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集中无法充分利用服务器多 CPU 的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有 ParNew 加 CMS 的组合 “ 给力 ”。 直到 Parallel Old 收集器出现后，“ 吞吐量优先 ” 收集器终于有了比较名副其实的应用组合，在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。Parallel Old 收集器的工作过程如下图所示。 CMS收集器CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。 目前很大一部分的 Java 应用集中在互联网站或者 B/S 系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS 收集器就非常符合这类应用的需求，默认对象年龄是6。 从名字（包含”Mark Sweep”）上就可以看出，CMS 收集器是基于“标记—清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤，包括： 初始标记（CMS initial mark） 并发标记（CMS concurrent mark） 重新标记（CMS remark） 并发清除（CMS concurrent sweep） 其中，初始标记、重新标记这两个步骤仍然需要 “Stop The World“。初始标记仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，并发标记阶段就是进行 GC RootsTracing 的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。 由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 CMS 是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、低停顿，但是 CMS 还远达不到完美的程度，它有以下 3 个明显的缺点： 第一、导致吞吐量降低。CMS 收集器对 CPU 资源非常敏感。其实，面向并发设计的程序都对 CPU 资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。 CMS 默认启动的回收线程数是（CPU数量+3）/4，也就是当 CPU 在4个以上时，并发回收时垃圾收集线程不少于 25% 的 CPU 资源，并且随着 CPU 数量的增加而下降。但是当 CPU 不足 4 个（譬如2个）时，CMS 对用户程序的影响就可能变得很大，如果本来 CPU 负载就比较大，还分出一半的运算能力去执行收集器线程，就可能导致用户程序的执行速度忽然降低了 50%，其实也让人无法接受。 第二、CMS 收集器无法处理浮动垃圾（Floating Garbage），可能出现”Concurrent Mode Failure”失败而导致另一次 Full GC（新生代和老年代同时回收） 的产生。由于 CMS 并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留待下一次 GC 时再清理掉。这一部分垃圾就称为 “ 浮动垃圾 ” 。 也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS 收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。 在 JDK 1.5 的默认设置下，CMS收集器当老年代使用了 68% 的空间后就会被激活，这是一个偏保守的设置，如果在应用中老年代增长不是太快，可以适当调高参数-XX:CMSInitiatingOccupancyFraction的值来提高触发百分比，以便降低内存回收次数从而获取更好的性能，在 JDK 1.6 中，CMS 收集器的启动阈值已经提升至 92% 。 要是 CMS 运行期间预留的内存无法满足程序需要，就会出现一次 “Concurrent Mode Failure” 失败，这时虚拟机将启动后备预案：临时启用 Serial Old 收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。所以说参数-XX:CM SInitiatingOccupancyFraction设置得太高很容易导致大量 “Concurrent Mode Failure” 失败，性能反而降低。 第三、产生空间碎片。 CMS 是一款基于“标记—清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次 Full GC 。 为了解决这个问题，CMS 收集器提供了一个-XX:+UseCMSCompactAtFullCollection开关参数（默认就是开启的），用于在CMS收集器顶不住要进行 Full GC 时开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片问题没有了，但停顿时间不得不变长。虚拟机设计者还提供了另外一个参数-XX:CMSFullGCsBeforeCompaction，这个参数是用于设置执行多少次不压缩的 Full GC 后，跟着来一次带压缩的（默认值为0，表示每次进入Full GC时都进行碎片整理）。 G1收集器 G1（Garbage-First）收集器是当今收集器技术发展的最前沿成果之一，G1 是一款面向服务端应用的垃圾收集器。HotSpot 开发团队赋予它的使命是（在比较长期的）未来可以替换掉 JDK 1.5 中发布的 CMS 收集器。与其他 GC 收集器相比，G1 具备如下特点。 并行与并发： G1 能充分利用多 CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短 Stop-The-World 停顿的时间，部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 Java 程序继续执行。 分代收集： 与其他收集器一样，分代概念在 G1 中依然得以保留。虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次 GC 的旧对象以获取更好的收集效果。 空间整合： 与 CMS 的 “ 标记—清理 ” 算法不同，G1 从整体来看是基于 “ 标记—整理 ” 算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，会将存活较少的Region中的对象移动到另外一个Region中，然后清除整个Region。意味着 G1 运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次 GC 。 可预测的停顿： 这是 G1 相对于 CMS 的另一大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时 Java（RTSJ）的垃圾收集器的特征了。 在 G1 之前的其他收集器进行收集的范围都是整个新生代或者老年代，而 G1 不再是这样。使用 G1 收集器时，Java 堆的内存布局就与其他收集器有很大差别，它将整个 Java 堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分 Region （不需要连续）的集合。 G1 收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1 在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region（这也就是Garbage-First名称的来由），保证了 G1 收集器在有限的时间内可以获取尽可能高的收集效率。 在 G1 收集器中，Region 之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，虚拟机都是使用 Remembered Set 来避免全堆扫描的。 G1 中每个Region 都有一个与之对应的 Remembered Set，虚拟机发现程序在对 Reference 类型的数据进行写操作时，会产生一个 Write Barrier暂时中断写操作，检查 Reference 引用的对象是否处于不同的 Region 之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过 CardTable 把相关引用信息记录到被引用对象所属的 Region 的 Remembered Set 之中。当进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描也不会有遗漏。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤： 初始标记（Initial Marking） 并发标记（Concurrent Marking） 最终标记（Final Marking） 筛选回收（Live Data Counting and Evacuation） G1 的前几个步骤的运作过程和 CMS 有很多相似之处。 初始标记阶段仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改 TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的 Region 中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记阶段是从 GC Root 开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 而最终标记阶段则是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中，这阶段需要停顿线程，但是可并行执行。 最后在筛选回收阶段首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划，从Sun公司透露出来的信息来看，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。通过下图可以比较清楚地看到G1收集器的运作步骤中并发和需要停顿的阶段。 G1的新老年代比例是动态浮动的，5%~60%，当然也可以通过参数设定，但是一般不要手工指定，因为这是G1预测STW停顿时间的基准。 G1的垃圾回收有三个阶段，第一个是YGC，第二个是MixedGC，第三个才是FGC，什么时候触发YGC呢？ Eden空间内存不足、多线程并发执行 如果G1产生FGC，你应该做什么？ 1.扩内存 2.提高CPU性能（回收的快，业务逻辑产生对象的速度固定，垃圾回收越快，内存空间越大） 3.降低MixedGC触发的阈值，让MixedGC提早发生（默认是45%） XX:InitiatingHeapOccupacyPercent *默认值45%，整个堆内存空间超过这个值时，启动MixedGC 三色标记算法 产生漏标： 标记进行时增加了一个黑到白的引用，并且删除了灰对白的引用，这个白的则会漏标，漏标是指本来应该存活的对象被当做垃圾回收了。 解决方法：使其中一个条件不成立即可 incremental update是CMS使用的一种策略，而SATB是G1使用的一种策略。 为什么G1使用SATB？ 当灰色指向白色的引用消失时，如果没有黑色指向白色引用会被push到堆栈中，下次扫描时拿到这个引用，由于有RSet的存在，不需要扫描整个堆去查找指向白色的引用，效率比较高。SATB配合RSet GC日志阅读 GC 日志是处理 Java 虚拟机内存问题的基础技能，它只是一些人为确定的规则，没有太多技术含量。 每一种收集器的日志形式都是由它们自身的实现所决定的，换而言之，每个收集器的日志格式都可以不一样。但虚拟机设计者为了方便用户阅读，将各个收集器的日志都维持一定的共性，例如以下两段典型的 GC 日志： 1233.125 : [GC [DefNew : 3324K-＞152K（3712K），0.0025925 secs] 3324K-＞152K（11904K），0.0031680 secs]100.667 : [Full GC [Tenured : 0 K-＞210K（10240K），0.0149142secs] 4603K-＞210K（19456K），[Perm:2999K-＞2999K（21248K）]，0.0150007 secs] [Times:user&#x3D;0.01 sys&#x3D;0.00，real&#x3D;0.02 secs] 最前面的数字33.125： 和 100.667： 代表了 GC 发生的时间，这个数字的含义是从 Java 虚拟机启动以来经过的秒数。 GC 日志开头的 [GC 和 [Full GC 说明了这次垃圾收集的停顿类型，而不是用来区分新生代 GC 还是老年代 GC 的。 如果有 Full ，说明这次 GC 是发生了 Stop-The-World的，例如下面这段新生代收集器 ParNew 的日志也会出现 [Full GC（这一般是因为出现了分配担保失败之类的问题，所以才导致 STW）。如果是调用 System.gc() 方法所触发的收集，那么在这里将显示 [Full GC（System）。 1[Full GC 283.736 : [ParNew : 261599K-＞261599K（261952K），0.0000288 secs] 接下来的 [DefNew、[Tenured、[Perm 表示 GC 发生的区域，这里显示的区域名称与使用的 GC 收集器是密切相关的，例如上面样例所使用的 Serial 收集器中的新生代名为 “Default New Generation“，所以显示的是 [DefNew。 如果是 ParNew 收集器，新生代名称就会变为 [ParNew，意为 “Parallel New Generation“。如果采用 Parallel Scavenge 收集器，那它配套的新生代称为 PSYoungGen，老年代和永久代同理，名称也是由收集器决定的。 后面方括号内部的 3324K-＞152K（3712K含义是 GC 前该内存区域已使用容量 -＞ GC 后该内存区域已使用容量 （该内存区域总容量）。而在方括号之外的 3324K-＞152K（11904K） 表示 GC 前 Java 堆已使用容量 -＞ GC 后 Java 堆已使用容量 （Java 堆总容量）。 再往后，0.0025925 secs 表示该内存区域 GC 所占用的时间，单位是秒。有的收集器会给出更具体的时间数据，如 [Times:user=0.01 sys=0.00，real=0.02 secs] ，这里面的 user、sys 和 real 与 Linux 的 time 命令所输出的时间含义一致，分别代表用户态消耗的 CPU 时间、内核态消耗的 CPU 事件和操作从开始到结束所经过的墙钟时间（Wall Clock Time）。 CPU 时间与墙钟时间的区别是，墙钟时间包括各种非运算的等待耗时，例如等待磁盘 I/O、等待线程阻塞，而 CPU 时间不包括这些耗时，但当系统有多 CPU 或者多核的话，多线程操作会叠加这些 CPU 时间，所以读者看到 user 或 sys 时间超过 real 时间是完全正常的。 PS日志 1234eden space 5632K, 94% used [0x00000000ff980000,0x00000000ffeb3e28,0x00000000fff00000)后面的内存地址指的是，起始地址，使用空间结束地址，整体空间结束地址total &#x3D; eden + 1个survivor CMS日志123456789101112131415161718192021222324252627282930313233[GC (Allocation Failure) [ParNew: 6144K-&gt;640K(6144K), 0.0265885 secs] 6585K-&gt;2770K(19840K), 0.0268035 secs] [Times: user=0.02 sys=0.00, real=0.02 secs]//ParNew：年轻代收集器//6144-&gt;640：收集前后的对比//（6144）：整个年轻代容量//6585 -&gt; 2770：整个堆的情况//（19840）：整个堆大小[GC (CMS Initial Mark) [1 CMS-initial-mark: 8511K(13696K)] 9866K(19840K), 0.0040321 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] //8511 (13696) : 老年代使用（最大）//9866 (19840) : 整个堆使用（最大）[CMS-concurrent-mark-start][CMS-concurrent-mark: 0.018/0.018 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] //这里的时间意义不大，因为是并发执行[CMS-concurrent-preclean-start][CMS-concurrent-preclean: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] //标记Card为Dirty，也称为Card Marking[GC (CMS Final Remark) [YG occupancy: 1597 K (6144 K)][Rescan (parallel) , 0.0008396 secs][weak refs processing, 0.0000138 secs][class unloading, 0.0005404 secs][scrub symbol table, 0.0006169 secs][scrub string table, 0.0004903 secs][1 CMS-remark: 8511K(13696K)] 10108K(19840K), 0.0039567 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] //STW阶段，YG occupancy:年轻代占用及容量//[Rescan (parallel)：STW下的存活对象标记//weak refs processing: 弱引用处理//class unloading: 卸载用不到的class//scrub symbol(string) table: //cleaning up symbol and string tables which hold class-level metadata and //internalized string respectively//CMS-remark: 8511K(13696K): 阶段过后的老年代占用及容量//10108K(19840K): 阶段过后的堆占用及容量[CMS-concurrent-sweep-start][CMS-concurrent-sweep: 0.005/0.005 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] //标记已经完成，进行并发清理[CMS-concurrent-reset-start][CMS-concurrent-reset: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]//重置内部结构，为下次GC做准备 G1日志123456789101112131415161718192021222324252627282930313233343536[GC pause (G1 Evacuation Pause) (young) (initial-mark), 0.0015790 secs]//young -&gt; 年轻代 Evacuation-&gt; 复制存活对象 //initial-mark 混合回收的阶段，这里是YGC混合老年代回收[Parallel Time: 1.5 ms, GC Workers: 1] //一个GC线程[GC Worker Start (ms): 92635.7][Ext Root Scanning (ms): 1.1][Update RS (ms): 0.0][Processed Buffers: 1][Scan RS (ms): 0.0][Code Root Scanning (ms): 0.0][Object Copy (ms): 0.1][Termination (ms): 0.0][Termination Attempts: 1][GC Worker Other (ms): 0.0][GC Worker Total (ms): 1.2][GC Worker End (ms): 92636.9][Code Root Fixup: 0.0 ms][Code Root Purge: 0.0 ms][Clear CT: 0.0 ms][Other: 0.1 ms][Choose CSet: 0.0 ms][Ref Proc: 0.0 ms][Ref Enq: 0.0 ms][Redirty Cards: 0.0 ms][Humongous Register: 0.0 ms][Humongous Reclaim: 0.0 ms][Free CSet: 0.0 ms][Eden: 0.0B(1024.0K)-&gt;0.0B(1024.0K) Survivors: 0.0B-&gt;0.0B Heap: 18.8M(20.0M)-&gt;18.8M(20.0M)][Times: user=0.00 sys=0.00, real=0.00 secs] //以下是混合回收其他阶段[GC concurrent-root-region-scan-start][GC concurrent-root-region-scan-end, 0.0000078 secs][GC concurrent-mark-start]//无法evacuation，进行FGC[Full GC (Allocation Failure) 18M-&gt;18M(20M), 0.0719656 secs][Eden: 0.0B(1024.0K)-&gt;0.0B(1024.0K) Survivors: 0.0B-&gt;0.0B Heap: 18.8M(20.0M)-&gt;18.8M(20.0M)], [Metaspace: 3876K-&gt;3876K(1056768K)] [Times: user=0.07 sys=0.00, real=0.07 secs] 垃圾收集器参数总结JDK 1.7 中的各种垃圾收集器到此已全部介绍完毕，在描述过程中提到了很多虚拟机非稳定的运行参数，在下图中整理了这些参数供读者实践时参考。 内存分配与回收策略对象的内存分配，往大方向讲，就是在堆上分配，对象主要分配在新生代的Eden区上。少数情况下也可能会直接分配在老年代中，分配的规则并不是百分之百固定的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。 对象优先在Eden分配大多数情况下，对象在新生代 Eden 区中分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。 虚拟机提供了-XX:+PrintGCDetails这个收集器日志参数，告诉虚拟机在发生垃圾收集行为时打印内存回收日志，并且在进程退出的时候输出当前的内存各区域分配情况。 123456789101112private static final int_1MB=1024 * 1024; /** *VM参数：-verbose:gc-Xms20M-Xmx20M-Xmn10M-XX:+PrintGCDetails -XX:SurvivorRatio=8 */ public static void testAllocation () &#123; byte[] allocation1,allocation2,allocation3,allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; allocation4 = new byte[4 * _1MB];//出现一次Minor GC &#125; 运行结果： 12345678910111213[GC [DefNew : 6651K-＞148K（9216K），0.0070106 secs]6651K-＞6292K（19456K），0.0070426 secs][Times:user=0.00 sys=0.00，real=0.00 secs]Heapdef new generation total 9216K,used 4326K[0x029d0000，0x033d0000，0x033d0000）eden space 8192K，51%used[0x029d0000，0x02de4828，0x031d0000）from space 1024K，14%used[0x032d0000，0x032f5370，0x033d0000）to space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）tenured generation total 10240K,used 6144K[0x033d0000，0x03dd0000，0x03dd0000）the space 10240K，60%used[0x033d0000，0x039d0030，0x039d0200，0x03dd0000）compacting perm gen total 12288K,used 2114K[0x03dd0000，0x049d0000，0x07dd0000）the space 12288K，17%used[0x03dd0000，0x03fe0998，0x03fe0a00，0x049d0000）No shared spaces configured. 上方代码的 testAllocation() 方法中，尝试分配 3 个 2MB 大小和 1 个 4MB 大小的对象，在运行时通过-Xms20M、-Xmx20M、-Xmn10M这 3 个参数限制了 Java 堆大小为 20MB ，不可扩展，其中 10MB 分配给新生代，剩下的 10MB 分配给老年代。 -XX:SurvivorRatio=8决定了新生代中 Eden 区与一个 Survivor 区的空间比例是 8:1，从输出的结果也可以清晰地看到 eden space 8192K、from space 1024K、to space 1024K 的信息，新生代总可用空间为 9216KB（Eden区+1个Survivor区的总容量）。 执行 testAllocation() 中分配 allocation4 对象的语句时会发生一次 Minor GC，这次 GC 的结果是新生代 6651KB 变为 148KB ，而总内存占用量则几乎没有减少（因为 allocation1、allocation2、allocation3 三个对象都是存活的，虚拟机几乎没有找到可回收的对象）。 这次 GC 发生的原因是给 allocation4 分配内存的时候，发现 Eden 已经被占用了 6MB，剩余空间已不足以分配 allocation4 所需的 4MB 内存，因此发生 Minor GC。 GC 期间虚拟机又发现已有的 3 个 2MB 大小的对象全部无法放入 Survivor 空间（Survivor 空间只有 1MB 大小），所以只好通过分配担保机制提前转移到老年代去。 这次 GC 结束后，4MB 的 allocation4 对象顺利分配在 Eden 中，因此程序执行完的结果是 Eden 占用 4MB（被allocation4占用），Survivor 空闲，老年代被占用 6MB（被allocation1、allocation2、allocation3占用）。通过 GC 日志可以证实这一点。 Minor GC 和 Full GC 有什么不一样吗？ 新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。 老年代 GC（Major GC/Full GC）：指发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 Parallel Scavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程）。Major GC 的速度一般会比 Minor GC 慢 10 倍以上。 大对象直接进入老年代所谓的大对象是指，需要大量连续内存空间的 Java 对象，最典型的大对象就是那种很长的字符串以及数组（ byte[] 数组就是典型的大对象）。大对象对虚拟机的内存分配来说就是一个坏消息（特别是短命大对象，写程序的时候应当避免），经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。 虚拟机提供了一个 -XX:PretenureSizeThreshold 参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在 Eden 区及两个 Survivor 区之间发生大量的内存复制。 123456789private static final int_1MB=1024 * 1024; /** *VM参数：-verbose:gc-Xms20M-Xmx20M-Xmn10M-XX:+PrintGCDetails-XX:SurvivorRatio=8 *-XX:PretenureSizeThreshold=3145728 */ public static void testPretenureSizeThreshold () &#123; byte[] allocation; allocation = new byte[4 * _1MB];//直接分配在老年代中 &#125; 运行结果： 12345678910Heapdef new generation total 9216K,used 671K[0x029d0000，0x033d0000，0x033d0000）eden space 8192K，8%used[0x029d0000，0x02a77e98，0x031d0000）from space 1024K，0%used[0x031d0000，0x031d0000，0x032d0000）to space 1024K，0%used[0x032d0000，0x032d0000，0x033d0000）tenured generation total 10240K,used 4096K[0x033d0000，0x03dd0000，0x03dd0000）the space 10240K，40%used[0x033d0000，0x037d0010，0x037d0200，0x03dd0000）compacting perm gen total 12288K,used 2107K[0x03dd0000，0x049d0000，0x07dd0000）the space 12288K，17%used[0x03dd0000，0x03fdefd0，0x03fdf000，0x049d0000）No shared spaces configured. 执行以上代码中的 testPretenureSizeThreshold() 方法后，我们看到 Eden 空间几乎没有被使用，而老年代的 10MB 空间被使用了 40%，也就是 4MB 的 allocation 对象直接就分配在老年代中，这是因为 PretenureSizeThreshold 参数被设置为 3MB（就是 3145728，这个参数不能像 -Xmx 之类的参数一样直接写 3MB），因此超过 3MB 的对象都会直接在老年代进行分配。 注意 PretenureSizeThreshold 参数只对 Serial 和 ParNew 两款收集器有效，Parallel Scavenge 收集器不认识这个参数，Parallel Scavenge 收集器一般并不需要设置。如果遇到必须使用此参数的场合，可以考虑 ParNew 加 CMS 的收集器组合。 长期存活的对象将进入老年代虚拟机给每个对象定义了一个对象年龄（Age）计数器。 如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并且对象年龄设为 1 。对象在 Survivor 区中每“熬过”一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就将会被晋升到老年代中。 对象晋升老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold设置，最大15岁，因为对象头只有4bit存储对象年龄。 动态对象年龄判定为了能更好地适应不同程序的内存状况，无须等到 MaxTenuringThreshold 中要求的年龄，年龄从小到大进行累加，当加入某个年龄段后，累加和超过 Survivor 空间的一半后，这个年龄段以及年龄大于他们的对象都将直接进入老年代。 空间分配担保在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代 ，所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。 如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败，如果允许，将继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试进行一次Minor GC，如果小于或者HandlePromotionFailure设置不允许，那么将进行Full GC。 “本篇文章主要摘自《深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》”","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/tags/JVM/"}]},{"title":"'JVM（二） 垃圾回收机制'","slug":"garbage-collection","date":"2020-05-21T14:30:00.000Z","updated":"2020-12-06T15:49:27.443Z","comments":true,"path":"2020/05/21/garbage-collection/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/garbage-collection/","excerpt":"","text":"垃圾回收机制想要了解垃圾收集策略，需要先了解 Java内存区域 说起垃圾收集（Garbage Collection，GC），经过半个多世纪的发展，目前的内存的动态分配与内存回收技术已经相当成熟，一切看起来都进入了 “ 自动化 ” 时代，那为什么还要去了解GC和内存分配呢？ 答案很简单：需要排查各种内存溢出、内存泄漏问题时，当垃圾收集称为系统达到更高并发量的瓶颈时，就需要对这些 “ 自动化 ” 的技术实施必要的监控和调节。 上篇文章介绍了在内存运行时区域的各个部分，其中程序计数器、虚拟机栈、本地方法栈随线程而生，随线程而灭，不需要过多考虑回收问题，因为方法结束或者线程结束时，内存自然就回收了，这里主要讨论的是 Java 堆和方法区，本章后续讨论中的 “ 内存 ”分配和回收也仅指着一部分内存。 GC完成需要思考的三件事： 哪些内存需要回收？ 什么时候回收？ 如何回收？ 对象判断机制引用计数法引用计数法（Reference Counting）：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；计数器为 0 时，对象就是不可能再被使用的。简单高效，缺点是无法解决对象之间相互循环引用的问题。 举个简单的例子： 12345678910111213141516public class ReferenceTest &#123; public Object instance = null; public static void test() &#123; ReferenceTest objA = new ReferenceTest(); ReferenceTest objB = new ReferenceTest(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; System.gc(); &#125;&#125; 很显然，在这种情况下，引用计数法是无法解决的，而虚拟机并没有因为这两个对象互相引用就不回收它们，这也从说明虚拟机并不是通过引用计数法来判断对象是否存活的。 可达性分析算法可达性分析（Reachability Analysis），通过一系列的称为 “GC Roots”，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是不可用的。 在 Java 语言中，可作为 GC Roots 的对象包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中 JNI（Native方法）引用的对象 作为 GC Roots 的节点主要在全局性的引用与执行上下文中。要明确的是，Tracing GC必须以当前存活的对象集为 Roots，因此必须选取确定存活的引用类型对象。 GC 管理的区域是 Java 堆，虚拟机栈、方法区和本地方法栈不被 GC 所管理，因此选用这些区域内引用的对象作为 GC Roots，是不会被 GC 所回收的。 其中虚拟机栈和本地方法栈都是线程私有的内存区域，只要线程没有终止，就能确保它们中引用的对象的存活。而方法区中类静态属性引用的对象是显然存活的。常量引用的对象在当前可能存活，因此，也可能是 GC roots 的一部分。 再谈引用JDK1.2 以前，一个对象只有被引用和没有被引用两种状态。 后来，Java 对引用的概念进行了扩充，将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4 种，这 4 种引用强度依次逐渐减弱。 强引用：指在程序代码之中普遍存在的，类似 “ Object obj=new Object() ” 这类的引用，垃圾收集器永远不会回收存活的强引用对象。 软引用：还有用但并非必需的对象。在系统将要发生内存溢出异常之前 ，将会把这些对象列进回收范围之中进行第二次回收，主要用于缓存内存。 弱引用：也是用来描述非必需对象的，被弱引用关联的对象 只能生存到下一次垃圾收集发生之前 。当垃圾收集器工作时，无论内存是否足够，都会回收掉只被弱引用关联的对象，有个著名的ThreadLocal线程泄露问题。 虚引用：是最弱的一种引用关系。 无法通过虚引用来取得一个对象实例 。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。 java中的ThreadLocal中的set方法就是使用了弱引用： 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; 可以看到其set方法将获取当前线程中的ThreadLocalMap属性，然后把自身this,也就是这个ThreadLocal对象当做key，设置到ThreadLocalMap属性中,而ThreadLocalMap类的set方法中，会把Key和Value封装成一个Entry对象存放在数组里。 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; 该Entry继承了WeakReference，并在构造方法时调用了其super方法，也就是说，调用了ThreadLocal后，会有一个虚引用指向ThreadLocal。 问题：为什么这里要用虚引用呢？ 答案：为了让ThreadLocal对象的强引用失效后，GC可以回收，如果这里用了强引用，则ThreadLocal无法被回收。 问题：那ThreadLocal的内存泄漏原因是什么呢？ 答案：由于ThreadLocal被作为一个Entry的key，而当ThreadLocal被回收了之后，其key变为NULL值，但是其Value的关联关系依旧存在，无法从ThreadLocalMap中移出，会导致内存泄漏。 问题：那ThreadLocal如何避免内存泄漏？ 答案：当要释放ThreadLocal时，需要手动调用ThreadLocal.remove()方法，手动释放设置的属性内容。 如java的直接缓冲区DirectByteBuffer，它关联了对外内存，JVM通过初始化DirectByteBuffer对象时设置一个虚引用，当DirectByteBuffer对象被回收时，将会把DirectByteBuffer关联的堆外内存信息存放到一个Queue队列中，GC通过监控这个队列能够将DirectByteBuffer对象关联的堆外内存给回收。 生存与死亡不可达的对象将暂时处于“ 缓刑 ”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程： 如果对象在进行可达性分析后发现没有与 GC Roots 相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize() 方法。 当对象没有覆盖 finalize() 方法，或者 finalize() 方法已经被虚拟机调用过，虚拟机将这两种情况都视为 “没有必要执行”，直接进行第二次标记。 如果这个对象被判定为有必要执行 finalize() 方法，那么这个对象将会放置在一个叫做 F-Queue 的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的 Finalizer 线程去执行它。 这里所谓的 “ 执行 ” 是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，因为如果一个对象在 finalize() 方法中执行缓慢，将很可能会一直阻塞 F-Queue队列，甚至导致整个内存回收系统崩溃。 来看一段代码： 12345678910111213141516171819202122232425262728293031323334353637public class FinalizerTest &#123; public static FinalizerTest object = null; public void isAlive() &#123; System.out.println(\"I'm alive\"); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println(\"method finalize is executed\"); object = this; &#125; public static void main(String[] args) throws Exception &#123; object = new FinalizerTest(); // 第一次执行，finalize方法会自救 object = null; System.gc(); // 因为Finalizer方法优先级低，所以暂停0.5秒等待它 Thread.sleep(500); if (object != null) &#123; object.isAlive(); &#125; else &#123; System.out.println(\"I'm dead\"); &#125; // 下面代码和上面的完全一样，但是这次自救失败了 object = null; System.gc(); Thread.sleep(500); if (object != null) &#123; object.isAlive(); &#125; else &#123; System.out.println(\"I'm dead\"); &#125; &#125;&#125; 输出结果： 123method finalize is executedI&#39;m aliveI&#39;m dead 如果不重写finalize()方法，输出将会是： 12I&#39;m deadI&#39;m dead 值得注意的地方是，代码中有两段完全一样的代码片段，执行结果却是一次逃脱成功，一次失败，这是因为任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。 应该尽量避免使用finalize()方法拯救对象，它的运行代价高昂，不确定性大，无法保证各个对象的调用顺序，finalize()能做的所有工作，使用try-finally或者其他方法能都可以做的更好、更及时。 回收方法区永久代的垃圾收集主要回收两部分内容：废弃常量和无用的类 回收废弃常量与回收 Java 堆中的对象非常类似。以常量池中字面量的回收为例，假如一个字符串 “abc” 已经进入了常量池中，但是当前系统没有任何一个 String 对象引用它，也没有其他地方引用了这个字面量，如果这时发生内存回收，而且必要的话，这个 “abc” 常量就会被系统清理出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。 类需要满足下面3个条件才能算是无用的类： 该类所有实例都已经被回收，也就是说 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader已经被回收。 该类对应的 java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是 “ 可以 ” ，而并不是和对象一样，不使用了就必然会回收。 在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 垃圾收集算法标记-清除算法最基础的收集算法是 标记-清除（Mark-Sweep）算法，算法分为 “ 标记 ” 和 “ 清除 ”两个阶段：首先标记处所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 它主要不足有两个： 效率问题 ： 标记和清除两个过程都不高 空间问题 ： 标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 标记清除算法的执行过程如图所示： 复制算法为了解决效率问题，一种称为 “ 复制 ”(Copying)的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只是用其中的一块。当这块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次性清理掉。 这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要一动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。 复制算法的执行过程如图所示： 现在的商业虚拟机都采用这种算法来回收新生代，IBM 研究指出新生代中的对象 98% 是 “朝生夕死” 的，所以并不需要按照 1:1 的比例来划分内存空间，而是将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor 。 当回收时，将 Eden 和 Survivor 中还存活着的对象一次性地复制到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才用过的 Survivor 空间。HotSpot 虚拟机默认Eden:Survivor = 8:1，也就是每次新生代中可用内存空间为整个新生代容量的 90%（其中一块Survivor不可用），只有 10% 的内存会被“浪费”。 当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于 10% 的对象存活，当 Survivor 空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。 内存的分配担保就好比我们去银行借款，如果我们信誉很好，在 98% 的情况下都能按时偿还，于是银行可能会默认我们下一次也能按时按量地偿还贷款，只需要有一个担保人能保证如果我不能还款时，可以从他的账户扣钱，那银行就认为没有风险了。 内存的分配担保也一样，如果另外一块 Survivor 空间没有足够空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入老年代。关于对新生代进行分配担保的内容，在本章稍后在讲解垃圾收集器执行规则时还会再详细讲解。 标记-整理算法复制算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费 50% 的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都 100% 存活的极端情况，所以在老年代一般不能直接选用这种算法。 根据老年代的特点，有人提出了另外一种 “ 标记-整理 ”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 标记-整理算法的执行过程如图所示： 第一个过程和标记清除算法的第一个过程一样。然后是整理，最后在清除。 标记整理算法的优缺点： 优点：解决内存碎片问题。 缺点：不仅要标记所有存活对象，还要移动所有存活对象的地址并更新被移动的对象相关的引用。从效率上来说，要低于复制算法。 分代收集策略当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，根据对象存活周期的不同将内存划分为几块并采用不用的垃圾收集算法。 一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。 而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。 HotSpot的算法实现枚举根节点以可达性分析中从 GC Roots 节点找引用链这个操作为例，可作为 GC Roots 的节点主要在全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表）中，现在很多应用仅仅方法区就有数百兆，如果要逐个检查这里面的引用，那么必然会消耗很多时间。 另外，可达性分析对执行时间的敏感还体现在 GC 停顿上，因为这项分析工作必须在一个能确保 一致性 的快照中进行。这里的 一致性 指的是整个分析期间整个执行系统看起来就像被冻结在某个时间点上，不可以出现分析过程中对象引用关系还在不断变化的情况，否则分析结果准确性就无法得到保证。 这点是导致 GC 进行时必须停顿所有 Java 执行线程（Sun将这件事情称为”Stop The World,STW“）的其中一个重要原因，即使是在号称（几乎）不会发生停顿的 CMS 收集器中，枚举根节点时也是必须要停顿的。 因此，目前的主流 Java 虚拟机使用的都是准确式 GC（即虚拟机可以知道内存中某个位置的数据具体是什么类型。），所以当执行系统停顿下来后，并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得知哪些地方存放着对象引用。 在 HotSpot 的实现中，是使用一组称为 OopMap 的数据结构来达到枚举 GC Roots的目的，在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在 JIT 编译过程中，也会在特定的位置记录栈和寄存器中哪些位置是引用。这样， GC 在扫描时就可以直接得知这些信息了。 OopMap垃圾收集时，收集线程会对栈上的内存进行扫描，看看哪些位置存储了 Reference 类型。如果发现某个位置确实存的是 Reference 类型，就意味着它所引用的对象这一次不能被回收。 但问题是，栈上的本地变量表里面只有一部分数据是 Reference 类型的（它们是 GC 所需要的），那些非 Reference 类型的数据对 GC 而言毫无用处，但 GC 还是不得不对整个栈全部扫描一遍，这是对时间和资源的一种浪费。 一个很自然的想法是，能不能用空间换时间，在某个时候把栈上代表引用的位置全部记录下来，这样到真正 GC 的时候就可以直接读取，而不用再一点一点的扫描了。事实上，大部分主流的虚拟机也正是这么做的，比如 HotSpot ，它使用一种叫做 OopMap 的数据结构来记录这类信息。 OopMap 记录了栈上本地变量到堆上对象的引用关系。枚举根节点时，递归遍历每个栈帧的 OopMap ，通过栈中记录的被引用对象的内存地址，即可找到这些对象（ GC Roots ）。 Card TableCard Table 由于做YGC时，无法确定年轻代的对象是否被老年代的对象引用，所以需要扫描整个OLD区，效率非常低，所以JVM设计了CardTable， 如果一个OLD区CardTable中有对象指向Y区，就将这个OLD区的对象设为Dirty，下次扫描时，只需要扫描Dirty Card上的对象，而不需要扫描整个OLD区。 在结构上，Card Table用BitMap来实现。 Collection SetG1垃圾收集器的概念：一组可被回收的分区Region的集合。 在CSet中存活的数据会在GC过程中被移动到另一个可用分区，CSet中的分区可以来自Eden空间、survivor空间、或者老年代。CSet会占用不到整个对空间的1%大小。 RememberedSet RememberedSet 主要用来处理频繁的新生代 GC，执行新生代 GC而不执行老年代 GC。 背景：一般来说，GC 的过程是先枚举根节点。根节点有可能在新生代中，也有可能在老年代中。这里由于我们只想回收新生代（换句话说，不想回收老年代），所以没有必要对位于老年代的 GC Roots 做全面的可达性分析。 问题：可能存在位于老年代的某个 GC Root，它引用了新生代的某个对象，这个对象你是不能清除的。那怎么办呢？ 通过空间换时间的办法。事实上，对于位于不同年代对象之间的引用关系，虚拟机会在程序运行过程中给记录下来。对应上面所举的例子，“ 老年代对象引用新生代对象 ” 这种关系，会在引用关系发生时，在新生代所属的Region上专门开辟一块空间记录下来，这就是 RememberedSet 。 它和Card Table的区别在于Card Table是一张结构表，需要通过扫描对象才能知道对象是否可以清除，而G1可以通过RememberedSet上的信息直接判断当前对象是否可以清除，Rset中的数据来源于Card Table。 达到了规避了扫描Card Table，直接通过Rset就能判断对象清除状态的作用。 由于RSet的存在，那么每次给对象赋引用的时候，就得做一些额外的操作，这些额外的操作在GC中被称作写屏障，这个写屏障不等于内存屏障。 所以新生代的 GC Roots + RememberedSet 存储的内容，才是新生代收集时真正的 GC Roots 。然后就可以以此为据，在新生代上做可达性分析，进行垃圾回收。 Collection Set和 RemenberedSet 是G1垃圾收集器引入的两个新概念。 ZGC是基于G1的思想上做了改进，没有了RemenberedSet，而是通过颜色指针，在对象头中存储了三位的信息，作为标识。 安全点在 OopMap 的协助下，HotSpot 可以快速且准确地完成 GC Roots 枚举，但一个很现实的问题随之而来：可能导致引用关系变化，或者说 OopMap 内容变化的指令非常多，如果为每一条指令都生成对应的 OopMap，那将会需要大量的额外空间，这样 GC 的空间成本将会变得很高。 实际上，HotSpot 也的确没有为每条指令都生成 OopMap，前面已经提到，只是在 “ 特定的位置 ” 记录了这些信息，这些位置称为安全点(SafePoint)，即程序执行时并非在所有地方都能停顿下来开始 GC ，只有在到达安全点时才能暂停。 Safepoint 的选定既不能太少以致于 GC 过少，也不能过于频繁以致于过分增大运行时的负荷。 对于 Safepoint，另一个需要考虑的问题是如何在 GC 发生时让所有线程都 “跑” 到最近的安全点上再停顿下来。这里有两种方案可供选择： 抢先式中断（Preemptive Suspension） 主动式中断（Voluntary Suspension）。 其中抢先式中断不需要线程的执行代码主动去配合，在 GC 发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它 “跑” 到安全点上。现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而响应 GC 事件。 而主动式中断的思想是当 GC 需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。轮询标志的地方和安全点是重合的，另外再加上创建对象需要分配内存的地方。 一个线程意味着一个栈，一个栈由多个栈帧组成，一个栈帧对应着一个方法，一个方法里面可能有多个安全点。 GC 发生时，程序首先运行到最近的一个安全点停下来，然后更新自己的 OopMap ，记下栈上哪些位置代表着引用。 安全区域使用 Safepoint 似乎已经完美地解决了如何进入 GC 的问题，但实际情况却并不一定。Safepoint 机制保证了程序执行时，在不太长的时间内就会遇到可进入 GC 的Safepoint。但是，程序“不执行”的时候呢？ 所谓的程序不执行就是没有分配 CPU 时间，典型的例子就是线程处于 Sleep 状态或者 Blocked 状态，这时候线程无法响应 JVM 的中断请求，“走”到安全的地方去中断挂起，JVM 也显然不太可能等待线程重新被分配 CPU 时间。对于这种情况，就需要安全区域（Safe Region）来解决。 安全区域是指在一段代码片段之中，引用关系不会发生变化。 在这个区域中的任意地方开始 GC 都是安全的。我们也可以把 Safe Region 看做是被扩展了的 Safepoint。在线程执行到 Safe Region 中的代码时，首先标识自己已经进入了 Safe Region，那样，当在这段时间里 JVM 要发起 GC 时，就不用管标识自己为 Safe Region状态的线程了。 在线程要离开 Safe Region 时，它要检查系统是否已经完成了根节点枚举（或者是整个 GC 过程），如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开 Safe Region 的信号为止。 “本篇文章主要摘自《深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》”","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/tags/JVM/"}]},{"title":"'JVM（一） 运行时数据区域'","slug":"jvm-memory","date":"2020-05-21T14:20:00.000Z","updated":"2020-12-06T14:02:38.646Z","comments":true,"path":"2020/05/21/jvm-memory/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/jvm-memory/","excerpt":"","text":"运行时数据区域Java 虚拟机在执行 Java 程序过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随虚拟机进程的启动而存在，有的区域则依赖用户线程的启动和结束而建立和销毁。 程序计数器程序计数器（Program Counter Register）是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。 由于 Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器内核都只会执行一条线程中的指令。 因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是 Native 方法，这个计数器值则为空（Undefined）。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何OutOfMemoryError 情况的区域。 Java虚拟机栈与程序计数器一样，Java 虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。 虚拟机栈描述的是Java方法执行的内存模型：每个方法执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。 经常有人把Java内存区分为堆内存（Heap）和栈内存（Stack），这种划分方式的流行只能说明大多数程序员最关注的、域对象内存分配关系最密切的内存区是这两块。Java 内存区域的划分实际上远比这复杂。 其中所指的“栈”就是虚拟机栈，或者说是虚拟机栈中的局部变量表。 局部变量表局部变量表存放了编译期可知的各种基本数据类型、对象引用和returnAddress类型。 基本数据类型：boolean、byte、char、short、int、float、long、double 对象引用：reference类型，它不等同于对象本身，可能是个对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他于此对象相关的位置 returnAddress类型：指向了一条字节码指令的地址 其中64位长度的 long 和 double 类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。Slot是栈帧中的局部变量表的最小单位。 局部变量表所需的内存空间在编译期完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 虚拟机栈规定了两种异常情况： 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。 如果虚拟机栈可以动态扩展，在扩展时无法申请到足够的内存，将抛出OutOfMemoryError(OOM)异常。 操作数栈Java 虚拟机的解释执行引擎被称为“ 基于栈的执行引擎 ”，其中所指的栈就是指－操作数栈。 操作数栈也常被称为操作栈，它是一个后入先出栈。 和局部变量表一样，操作数栈也是被组织成一个以字长为单位的数组。但是和前者不同的是，它不是通过索引来访问，而是通过标准的栈操作 压栈和出栈 来访问的。 比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用。 虚拟机在操作数栈中存储数据的方式和在局部变量表中是一样的。 虚拟机把操作数栈作为它的工作区，大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。 举例来说，在JVM中执行 a = b + c的字节码执行过程中操作数栈以及局部变量表的变化如下图所示。 局部变量表中存储着 a、b、c 三个局部变量，首先将 b 和 c 分别压入栈中将栈顶的两个数出栈执行求和操作，并将结果再次压入栈顶中，之后将栈顶的数出栈赋值给 a 看一个比较经典的例子 1234567891011public class IncrementTest &#123; public static void main(String[] args) &#123; int i = 1; i = i++; int j = i++; int k = i + ++i * i++; System.out.println(\"i = \" + i); System.out.println(\"j = \" + j); System.out.println(\"k = \" + k); &#125;&#125; 答案： 123i = 4j = 1k = 11 代码分析： 代码 i = i++，自增操作是在局部变量中的，而不是在操作数栈中。 把局部变量表中的 i 的值 1 压入操作数栈中 把局部变量表中的 i 变量自增 1，此时 i 的值为 2 把操作数栈中的值 1 赋值给局部变量表中的 i 变量，此时 i 的值又变为了 1 代码 int j = i++，赋值操作发生在自增前。 把局部变量表中的 i 的值 1 压入操作数栈中 把操作数栈中的值 1 赋值给局部变量表中的 j 变量，此时 j 的值为 1 把局部变量表中的 i 变量自增 1，此时 i 的值为 2 代码 int k = i + ++i * i++ 把局部变量表中的 i 的值 2 压入操作数栈中 把局部变量表中的 i 变量自增 1，此时 i 的值为 3 把局部变量表中的 i 的值 3 压入操作数栈中（++i），此时 i 的值为 3 再把局部变量表中的 i 的值 3 压入操作数栈中（i++），此时 i 的值为 3 把局部变量表中的 i 变量自增 1，此时 i的值为 4 把操作数栈中前两个弹出求乘积（3 * 3 = 9），将结果再次压入操作数栈中 把操作数栈中前两个弹出求和（9 + 2 = 11），将结果再次压入操作数栈中 将操作数栈中的值 11 赋值给局部变量表中的 k 变量，此时 k 的值为 11 总结： 赋值 =，最后计算 = 右边的从左到右加载值依次压入操作数栈 根据运算符的优先级判断先算哪个 自增和自减操作都是直接修改变量的值，不经过操作数栈 最后赋值之前，临时结果都是保存在操作数栈中的 值得提醒的是，i++和++i都不是原子操作，因为它并不会作为一个不可分割的操作来执行，实际上它包含三个独立的操作： 读取i的值 将值加1 然后将计算结果写入i这是一个读取-修改-写入的操作序列，并且其结果状态依赖于之前的状态。 即使使用 volatile 修饰，保证了多个线程多i的可见性，每次从局部变量表读取的都是最新的值，也不是线程安全的。 如果假设 i=9，在某些情况下，多个线程读到的值都为 9，接着执行递增操作，并且都将i设置成 10 ，显然不是线程安全的。 动态链接每个栈帧中包含一个在常量池中对当前方法的引用， 目的是支持方法调用过程的动态连接。 Class 文件中存放了大量的符号引用，这些符号引用一部分会在类加载阶段或第一次使用时转化为直接引用，这种转化称为静态解析，如静态方法、私有方法等等，另一部分将在每一次运行期间转化为直接引用，这部分称为动态连接。栈帧中保存了一个引用，指向该方法在运行时常量池中的位置，通过运行时常量池的符号引用（指向堆），完成将符号引用转化为直接引用。 方法返回地址方法执行时有两种退出情况： 正常退出，即正常执行到任何方法的返回字节码指令，如 return等 异常退出，即某些指令导致了 Java 虚拟机抛出异常并且没有处理 无论何种退出情况，都将返回至方法当前被调用的位置。方法退出的过程相当于弹出当前栈帧，退出可能有三种方式： 返回值压入上层调用栈帧。 异常信息抛给能够处理的栈帧。 PC计数器指向方法调用后的下一条指令。 当方法执行正常退出时，当前栈帧承担着恢复调用者状态的责任，包括恢复调用者的局部变量表和操作数栈，以及正确递增程序计数器、跳过刚才执行的方法调用指令等。调用者的代码在被调用方法的返回值压入调用者栈帧的操作数栈后，会继续正常执行。 本地方法栈本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。Sun HotSpot虚拟机直接就把本地方法栈和虚拟机栈合二为一。 与虚拟机栈一样，本地方法栈区域也会抛出 StackOverflowError 和 OutOfMemoryError 异常。 Java堆对于大多数应用来说，Java 堆（Java Heap）是 Java 虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做 “ GC堆 ”（Garbage Collected Heap）。从内存回收的角度来看，由于现在收集器基本都采用分代收集算法，所以 Java 堆中还可以细分为：新生代和老年代；再细致一点的有 Eden 空间、From Survivor 空间、To Survivor 空间等。 从内存分配的角度来看，线程共享的 Java 堆中可能划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer,TLAB）。不过无论如何划分，都与存放的内容无关，无论哪个区域，存储的都是对象实例，进一步划分的目的是为了更好的回收内存，或者更快的分配内存。 Java 堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，当前主流的虚拟机都是按照可扩展来实现的（通过 -Xmx 和 -Xms 控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出 OutOfMemoryError异常。 TLABTLAB（Thread Local Allocation Buffer）是在Hotspot1.6引入的新技术，目的是提升在堆上创建对象的性能。 如果一个对象被创建到堆上时，需要在堆上申请指定大小的内存供新创建的对象使用，在这个过程中，堆会通过加锁或指针碰撞的方式防止同一块被重复申请，在JVM中，内存分配是一个非常频繁的动作，而给堆加锁或者校验碰撞指针的方式必定会影响内存创建效率，TLAB的出现就是为了优化这个问题。 123456789TLAB是线程的一块私有内存:1.在线程启动的时候会在堆中为其申请一块指定大小的内存，这块内存只给当前线程使用，属于线程私有的.如果线程需要为线程内的对象分配内存，就再自己的空间上分配，这样就不存在内存竞争的情况了，大大的提升了分配效率。2.当TLAB空间容量不足时，就新申请一个TLAB，原来的那个TLAB区里的对象还维持现状，因为对象只能感知到自己在Eden区。3.TLAB空间的内存非常小，默认大小仅有Eden区的1%，一般用默认的就可以。也可以通过JVM参数-XX:TLABWasteTargetPercent设置TLAB空间占Eden空间的百分比大小。 12345678# 开启TLAB-XX:+UseTLAB # 关闭TLAB-XX:-UseTLAB # 设置每个TLAB区域占Eden区的大小比例-XX:TLABWasteTargetPercent 每一个TLAB空间大小都是固定的，默认的是Eden区大小的的1%，既然大小是固定的，那么肯定会出现空间浪费的情况，比如TLAB大小是100kb，已经被使用了90kb，此时有一个12kb的对象来申请空间，但是TLAB的剩余空间已经不足以分配给这个对象了，此时怎么办？ 是新申请一个TLAB，还是直接分配到Eden区？在设计TLAB的时候就已经考虑到这种情况了，使用变量refill_waste_limit来控制一个TLAB允许被浪费的空间大小。 方法区方法区（Method Area）与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 Java 虚拟机规范对方法区的限制非常宽松，除了和 Java 堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。垃圾收集行为在这个区域是比较少出现的，其内存回收目标主要是针对常量池的回收和对类型的卸载。当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError 异常。 HotSpot 虚拟机它是Sun JDK和OpenJDK中所带的虚拟机，也是目前使用范围最广的 Java 虚拟机。在2008年和2009年，Oracle公司分别收购了BEA公司和Sun公司，Oracle同时拥有了两款优秀的Java虚拟机：JRockit VM和HotSpot VM。 永久代对于习惯在HotSpot 虚拟机上开发、部署程序的开发者来说,很多人更愿意把方法区称为“永久代”(Permanent Generation)，本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队把 GC 分代收集扩展至方法区，或者说，使用永久代来实现方法区而已。 目的是为了方法区也可以用堆内存的 GC 垃圾回收器，而不用重新针对方法区做 GC 操作，所以称永久代是方法区的一个存储实现。 方法区只是 JVM 的一种规范，不同的虚拟机实现的原理不一样，只有HotSpot虚拟机才有永久代的概念。 常量池class常量池我们写的每一个 Java 类被编译后，就会形成一份class 文件。class 文件中除了包含类的版本、字段、方法、接口等描述信息外，还有一项信息就是常量池(constant pool table)，用于存放编译器生成的各种字面量(Literal)和符号引用(Symbolic References)。 每个class文件都有一个class常量池。 字面量包括： 文本字符串 八大基本类型的值 被申明为final的常量 符号引用包括： 类和方法的全限定名 字段的名称和描述符 方法的名称和描述符 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。class文件常量池将在类加载后进入方法区的运行时常量池中存放。 一般来说，除了保存 Class 文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池中。 运行时常量池相对于 Class 文件常量池的另外一个重要特征是具备动态性，Java 语言并不要求常量一定只有编译期才能产生，也就是并非预置入 Class 文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是 String 类的 intern() 方法。 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。 字符串常量池 在HotSpot虚拟机里实现的字符串常量池(string pool)功能的是一个StringTable类，它是一个Hash表，这个StringTable在每个HotSpot虚拟机的实例只有一份，被所有的类共享。字符串常量由一个一个字符组成，放在了StringTable上。 JDK版本变化JDK1.6及以前的版本，字符串常量池是存放在永久代中。 在JDK1.7的版本中，字符串常量池从永久代移出到正常的Java 堆(Java Heap)中，原因是因为永久代空间太小，容易造成OOM。 在JDK1.8的版本中，Hotspot虚拟机废除了永久代，开始使用元空间（Metaspace）实现方法区，字符串常量池依旧保留在堆内存中，其他内容移至元空间，元空间直接在本地内存分配，而不需要占用堆内存，所以不会造成OOM现象。 值得注意的是，方法区只是Jvm的一种规范，Hotspot通过废除永久代，使用元空间实现方法区，并不存在废除方法区、方法区被元空间代替这种说法。 为什么要使用元空间取代永久代的实现？ 字符串存在永久代中，容易出现性能问题和内存溢出 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出 永久代会为 GC 带来不必要的复杂度，并且回收效率偏低 将 HotSpot 与 JRockit 合二为一 1234567public static void main(String[] args) &#123; String str = \"String\"; for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; str.intern(); str = str + str; &#125;&#125; 使用JDK1.7 或者 1.8 能够看到，往字符串常量池中无限增加，最终 OOM 的位置是在Java 堆（Java heap）中。 String.intern()用来返回常量池中的某字符串，如果常量池中已经存在该字符串，则直接返回常量池中该对象的引用。否则，在常量池中加入该对象，然后返回引用。 看一道比较常见的面试题，在不考虑 GC 的情况下，下面的代码创建了多少个 String 对象，输出结果是什么？ 123String str1 = new String(\"he\") + new String(\"llo\");String str2 = str1.intern();System.out.println(str1 == str2); 答案： 在 JDK 1.6 下输出是 false，创建了 6 个对象 在 JDK 1.7 之后的版本输出是 true，创建了 5 个对象 代码分析： 为什么输出会有这些变化呢？主要还是字符串池从永久代中脱离、移入堆区的原因， intern() 方法也相应发生了变化： 在 JDK 1.6 中，调用 intern() 首先会在字符串池中寻找equal() 相等的字符串，假如字符串存在就返回该字符串在字符串池中的引用；假如字符串不存在，虚拟机会重新在永久代上创建一个实例，将 StringTable 的一个表项指向这个新创建的实例。 在 JDK 1.7 中，由于字符串池不在永久代了，intern() 做了一些修改，更方便地利用堆中的对象。字符串存在时和 JDK 1.6一样，但是字符串不存在时不再需要重新创建实例，可以直接指向堆上的实例。 我们基于JDK1.7版本，来看个例子： 123String str1 = new String(\"abc\");String str2 = str1.intern();System.out.println(str1 == str2); //false 由于字符串常量池中已存在abc，所以返回了字符串常量池中的引用，如下图所示 再来看个例子： 1234String str1 = new String(\"he\") + new String(\"llo\");str1.intern();String str2 = \"hello\";System.out.println(str1 == str2); //true 该结果等于true应该是能够理解的，不理解的可以查看上文针对该代码的实例分析图 这里扩展一点，若是把str1.intern();代码注释掉，则产生的结果为false。 其原因在于str1对象是通过new对象拼接产生的，字符串常量池中并不存在字符串hello，当调用String str2=&quot;hello&quot;;代码时字符串常量池中产生才该字符串，所以他们并不是同一个地址引用。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域。 在 JDK 1.4 中新加入了 NIO，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。 显然，本机直接内存的分配不会受到 Java 堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括 RAM 以及 SWAP 区或者分页文件）大小以及处理器寻址空间的限制。服务器管理员在配置虚拟机参数时，会根据实际内存设置 -Xmx 等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现 OutOfMemoryError 异常。 “本篇文章主要摘自《深入理解Java虚拟机_JVM高级特性与最佳实践 第2版》”","categories":[{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/categories/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/tags/JVM/"}]},{"title":"'kubernetes（二） 环境搭建'","slug":"kubernetes-install","date":"2020-05-21T14:00:00.000Z","updated":"2020-09-23T08:24:17.097Z","comments":true,"path":"2020/05/21/kubernetes-install/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/kubernetes-install/","excerpt":"","text":"K8S的安装方式最简单的方法是使用yum install kubernetes命令安装Kubernetes集群，但仍需修改各组件的启动参数，才能完成对Kubernetes集群的配置，整个过程比较复杂，也容易出错。但是对于新手来说是一个熟悉k8s的一个过程，可以适当借鉴学习。 Kubernetes从1.4版本开始引入了命令行工具kubeadm，致力于简化集群的安装过程，并解决Kubernetes集群的高可用问题。在Kubernetes 1.13版本中，kubeadm工具进入GA阶段，宣称已经为生产环境应用准备就绪。比较推荐使用这种方式，安装便捷并且容错率高 本节先讲解基于 yum install kubernetes命令安装 Master节点：192.168.1.132 Node节点：192.168.1.134 K8S基于yum的安装安装前先关闭防火墙 1systemctl stop firewalld 修改系统文件/etc/sysconfig/selinux，将SELINUX=enforcing修改成SELINUX=disabled，然后重启Linux。或者执行以下命令 1setenforce 0 编辑/etc/sysctl.conf添加以下内容 123456net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward=1vm.swappiness = 0fs.inotify.maxuserwatches = 24576vm.max_map_count=655360 然后执行命令 sysctl -p,如果报错，执行命令modprobe br_netfilter 安装Master节点1、安装Docker 安装docker教程 2、Master节点安装etcd 1yum install etcd -y etcd用于K8S的数据存储，原生支持做集群，修改/etc/etcd/etcd.conf配置,指向Master节点 123[root@localhost /]# vim /etc/etcd/etcd.conf6 行：ETCD_LISTEN_CLIENT_URLS=\"http://0.0.0.0:2379\"22行：ETCD_ADVERTISE_CLIENT_URLS=\"http://192.168.1.132:2379\" 启动etcd服务并且设置开机自启 12[root@localhost /]# systemctl start etcd.service[root@localhost /]# systemctl enable etcd.service 检查 12345678[root@localhost /]# netstat -lntup|grep 2379tcp6 0 0 :::2379 :::* LISTEN 117472/etcd#检查健康状态[root@localhost /]# etcdctl -C http://192.168.1.132:2379 cluster-healthmember 8e9e05c52164694d is healthy: got healthy result from http://192.168.1.132:2379cluster is healthy 测试 1234567891011# 插入数据 键（目录）值（123456）[root@localhost /]# etcdctl set /test/word 123456 123456[root@localhost /]# etcdctl ls //test[root@localhost /]# etcdctl ls /test/test/word[root@localhost /]# etcdctl get /test/word # 查看值123456[root@localhost /]#etcdctl rm /test/word # 删除键值对[root@localhost /]#etcdctl rmdir /test # 删除目录 3、Master节点192.168.1.132安装K8S 以下命令根据需求二选一即可 12345#安装Master节点和Node节点的服务，适用于服务器数量不够时共用同一台服务器yum install kubernetes -y#安装Master节点需要的服务，适用于服务器数量充足分离Master和Node节点yum install kubernetes-master.x86_64 -y 本人Master节点[192.168.1.132]也安装了Node节点服务,可以用于测试两个不同宿主机上Node节点通信。 kubelet默认把数据存放在/var/lib/kubelet下面，如果根目录下空间太小，可能会把磁盘撑爆。可以将数据挂载在充足空间的盘上 1234mkdir -p /home/kubeletcp -r /var/lib/kubelet /home/rm -rf /var/lib/kubeletln -sf /home/kubelet /var/lib/kubelet 4、修改apiserver配置文件 安装好了后进入/etc/kubernetes/配置目录修改相关配置 12345678910111213[root@localhost /]# vim /etc/kubernetes/apiserver#服务的监听地址8 行: KUBE_API_ADDRESS=\"--insecure-bind-address=0.0.0.0\"#服务监听的端口11行：KUBE_API_PORT=\"--port=8080\"#通过10250端口控制kubelet14行：KUBELET_PORT=\"--kubelet-port=10250\" #APIserver是通过那个地址和端口连接etcd数据17行：KUBE_ETCD_SERVERS=\"--etcd-servers=http://192.168.1.132:2379\"#K8S创建service服务的网段配置 20行：KUBE_SERVICE_ADDRESSES=\"--service-cluster-ip-range=10.254.0.0/16\"#默认的管理控制插件---将后面的ServiceAccount去掉23行：KUBE_ADMISSION_CONTROL=\"--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota\" 5、修改通用的配置文件config 123[root@localhost kubernetes]# vim /etc/kubernetes/config#通过那个地址端口找到API服务22行：KUBE_MASTER=\"--master=[http://192.168.1.132:8080] 6、启动服务并设置开启自启 123456systemctl enable kube-apiserver.servicesystemctl start kube-apiserver.servicesystemctl enable kube-controller-manager.servicesystemctl start kube-controller-manager.servicesystemctl enable kube-scheduler.servicesystemctl start kube-scheduler.service 7、测试集群是否正常 12345[root@localhost /]# kubectl get componentstatusNAME STATUS MESSAGE ERRORetcd-0 Healthy &#123;\"health\":\"true\"&#125; controller-manager Healthy ok scheduler Healthy ok 安装Node节点1、Node节点192.168.1.134安装K8S 如果没有第二台服务器，Master节点和Node节点同一台服务器时跳过安装步骤 1yum install kubernetes-node.x86_64 -y (自动会安装docker) 值得一提的是，如果Master节点也安装了Node节点的服务，Master节点机器也需要修改以下的所有相关配置 2、修改kube-proxy服务配置文件 12[root@localhost ~]# vim /etc/kubernetes/config22行：KUBE_MASTER=\"--master=[http://192.168.1.132:8080] 3、修改kubelet服务配置文件 1234567891011[root@localhost ~]# vim /etc/kubernetes/kubelet# 监听的地址5行：KUBELET_ADDRESS=\"--address=0.0.0.0\"#kubelet端口 8行：KUBELET_PORT=\"--port=10250\"# 给自己定义唯一的名字 不能冲突 IP地址或者主机名（各自节点改各自节点的IP）11行：KUBELET_HOSTNAME=\"--hostname-override=192.168.1.134\"# Master节点的连接api的地址14行：KUBELET_API_SERVER=\"--api-servers=[http://192.168.1.132:8080]# 节点的DNS配置KUBELET_ARGS=\"--cluster-dns=192.168.1.1 --cluster-domain=cluster.local\" 如果不知道DNS配置，可以执行下列命令 12345[root@localhost kubernetes]# cat /etc/resolv.conf# Generated by NetworkManagernameserver 192.168.1.1nameserver 114.114.114.114search localdomain 如果没有任何信息显示，vim /etc/resolv.conf并增加以下内容nameserver 114.114.114.114然后把该DNS增加到kubelet文件配置中 4、修改服务通用的配置文件config 123[root@localhost kubernetes]# vim /etc/kubernetes/config#通过那个地址端口找到API服务22行：KUBE_MASTER=\"--master=[http://192.168.1.132:8080] 5、启动服务并设置开机自启 12345systemctl start kubelet.service systemctl enable kubelet.service systemctl start kube-proxy.servicesystemctl enable kube-proxy.service 6、在Master节点测试是否有节点加入集群 1234[root@localhost /]# kubectl get nodeNAME STATUS AGE192.168.1.132 Ready 8d192.168.1.134 Ready 9d 安装flanneld网络通讯由于K8S创建的Service、Pod服务均是生成的虚拟IP，两台Node节点之间的Pod通信需要通过第三方插件实现.Master节点和Node节点都需要安装和配置 1、安装flanneld 1yum install flannel -y 2、修改flanneld配置文件 1sed -i 's#http://127.0.0.1:2379#http://192.168.1.132:2379#g' /etc/sysconfig/flanneld 多网卡的话需要在LANNEL_ETCD_ENDPOINTS项中增加--iface=网卡名 这里/etc/sysconfig/flanneld可以设置密钥验证，详情请自行百度! 3、Master节点配置etcd中关于flanneld的Key 12etcdctl mk /atomic.io/network/config '&#123; \"Network\": \"172.16.0.0/16\" &#125;'etcdctl get /atomic.io/network/config 这里的/atomic.io/network需要和/etc/sysconfig/flanneld里的FLANNEL_ETCD_PREFIX配置对应。 4、设置flanneld启动配置 1234567891011121314151617181920[root@localhost /]# vim /usr/lib/systemd/system/flanneld.service[Unit]Description=Flanneld overlay address etcd agentAfter=network.targetAfter=network-online.targetWants=network-online.targetAfter=etcd.serviceBefore=docker.service[Service]Type=notifyEnvironmentFile=/etc/sysconfig/flanneldEnvironmentFile=-/etc/sysconfig/docker-networkExecStart=/usr/bin/flanneld-start $FLANNEL_OPTIONSExecStartPost=/usr/libexec/flannel/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/dockerRestart=on-failure[Install]WantedBy=multi-user.targetWantedBy=docker.service 5、设置Docker启动配置 1234567891011121314151617181920212223242526272829303132[root@localhost /]# vim /usr/lib/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=http://docs.docker.comAfter=network.targetWants=docker-storage-setup.serviceRequires=docker-cleanup.timer[Service]Type=notifyNotifyAccess=mainEnvironmentFile=/run/flannel/subnet.env #增加该行配置EnvironmentFile=-/etc/sysconfig/dockerEnvironmentFile=-/etc/sysconfig/docker-storageEnvironmentFile=-/etc/sysconfig/docker-networkEnvironment=GOTRACEBACK=crashEnvironment=DOCKER_HTTP_HOST_COMPAT=1Environment=PATH=/usr/libexec/docker:/usr/bin:/usr/sbin#更改启动方式 如果没有更改过docker存储路径，不需要配置 --graph /home/dockerExecStart=/usr/bin/dockerd --graph /home/docker $DOCKER_NETWORK_OPTIONS#增加docker启动的防火墙拦截允许配置ExecStartPost=/sbin/iptables -I FORWARD -s 0.0.0.0/0 -j ACCEPTExecReload=/bin/kill -s HUP $MAINPIDLimitNOFILE=1048576LimitNPROC=1048576LimitCORE=infinityTimeoutStartSec=0Restart=on-abnormalKillMode=process[Install]WantedBy=multi-user.target 6、启动flanneld 12345678910111213141516systemctl daemon-reloadsystemctl start flanneld.servicesystemctl enable flanneld.service#重启Master节点服务systemctl restart dockersystemctl restart kube-apiserversystemctl restart kube-controller-managersystemctl restart kube-schedulersystemctl restart kubeletsystemctl restart kube-proxy#重启Node节点服务systemctl restart dockersystemctl restart kubeletsystemctl restart kube-proxy 7、测试网段 以上的一系列操作，主要是为了让flanneld和docker创建的网络处于同一个网段，先通过设置etcd设置flanneld的网段范围，再配置docker启动前加载flanneld的配置从图中能够看到docker0和flannel0都处于同一个网段172.16.0.0中,可以用一个轻巧的容器测试一下 1234#docker拉取网络镜像[root@localhost /]# docker pull docker.io/busybox#分别在Master节点及Node节点执行命令[root@localhost /]# docker run -it docker.io/busybox:latest 从图中可以看到，创建了两个容器，IP分别是172.16.43.6和172.16.43.4互相能够Ping通。 如果不能Ping通，则在每个Node节点上都配置相应的静态路由项 1234#Master节点 #172.16.9.0 为Node节点的flannel0的IP[root@localhost ~]# route add -net 172.16.9.0 netmask 255.255.255.0 gw 192.168.1.134 #Node节点 #172.16.43.0 为Master节点的flannel0的IP[root@localhost ~]# route add -net 172.16.43.0 netmask 255.255.255.0 gw 192.168.1.132 这意味着，每一个新部署的容器都将使用这个Node（docker0的网桥IP）作为它的默认网关。而这些Node（类似路由器）都有其他docker0的路由信息，这样它们就能够相互连通了。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.gitee.io/categories/Kubernetes/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.gitee.io/tags/Kubernetes/"}]},{"title":"'kubernetes（一） 基础概念'","slug":"kubernetes-introduction","date":"2020-05-21T13:50:00.000Z","updated":"2020-05-26T04:00:00.066Z","comments":true,"path":"2020/05/21/kubernetes-introduction/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/kubernetes-introduction/","excerpt":"","text":"Docker基本概念什么是DockerDocker是使用 Google公司推出的Go 语言进行开发实现，基于Linux 内核的cgroup、namespace、以及AUFS类的Union FS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术，由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 Docker在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得Docker技术比虚拟机技术更为轻便、快捷。下面的图片比较了Docker和传统虚拟化方式的不同之处。 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程。 而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比 传统虚拟机更为轻便。 为什么要使用Docker作为一种新兴的虚拟化方式，Docker跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源：由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker对系统资源的利用率更高。 更快速的启动时间： Docker容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间 一致的运行环境： Docker的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现这段代码在我机器上没问题啊这类问题。 持续交付和部署： Docker可以通过定制应用镜像来实现持续集成、持续交付、部署。可以通过Dockerfile来进行镜像构建，结合持续集成系统进行集成测试、自动部署。 更轻松的迁移： 由于Docker确保了执行环境的一致性，使得应用的迁移更加容易，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展： Docker使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker团队提供了一大批高质量的官方镜像，既可以直接使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 基本概念镜像Image 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像 不包含任何动态数据，其内容在构建之后也不会被改变。 Docker设计时，将其设计为分层存储的架构。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除 前一层的文件，而是仅在当前层标记为该文件已删除。分层存储的特征使得镜像的复用、定制变的更为容易。 容器Container 镜像和容器的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。因此容器可以拥有自己的root文件系统、自己的网络配置、自己的进程空间，甚至自己的用户ID空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。容器也具备分层存储的特征。 Kubernetes什么是KubernetesKubernetes是一个完备的分布式系统支撑平台。Kubernetes具有完备的集群管理能力，包括多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和服务发现机制、内建的智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制，以及多粒度的资源配额管理能力。同时，Kubernetes提供了完善的管理工具，这些工具涵盖了包括开发、部署测试、运维监控在内的各个环节。因此，Kubernetes是一个全新的基于容器技术的分布式架构解决方案，并且是一个一站式的完备的分布式系统开发和支撑平台。 Kubernetes英文中字母K和S中间有8个英文，所以也简称为K8S。 为什么要使用Kubernetes 轻装上阵地开发复杂系统 可以全面拥抱微服务架构 可以随时随地迁移系统 拥有横向弹性扩容机制 Kubernetes基本概念Kubernetes中的大部分概念如Node、Pod、Replication Controller、Service等都可以被看作一种资源对象，几乎所有资源对象都可以通过Kubernetes提供的kubectl工具（或者API编程调用）执行增、删、改、查等操作并将其保存在etcd中持久化存储。从这个角度来看，Kubernetes其实是一个高度自动化的资源控制系统，它通过跟踪对比etcd库里保存的“资源期望状态”与当前环境中的“实际资源状态”的差异来实现自动控制和自动纠错的高级功能。 MasterKubernetes里的Master指的是集群控制节点，在每个Kubernetes集群里都需要有一个Master来负责整个集群的管理和控制，基本上Kubernetes的所有控制命令都发给它，它负责具体的执行过程，我们后面执行的所有命令基本都是在Master上运行的。Master通常会占据一个独立的服务器（高可用部署建议用3台服务器），主要原因是它太重要了，是整个集群的“首脑”，如果它宕机或者不可用，那么对集群内容器应用的管理都将失效。 在Master上运行着以下关键进程: Kubernetes API Server（kube-apiserver） 提供了HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程。 Kubernetes Controller Manager（kube-controller-manager） Kubernetes里所有资源对象的自动化控制中心，可以将其理解为资源对象的大总管。 Kubernetes Scheduler（kube-scheduler） 负责资源调度（Pod调度）的进程，相当于公交公司的调度室，在Master上通常还需要部署etcd服务，因为Kubernetes里的所有资源对象的数据都被保存在etcd中。 Node除了Master，Kubernetes集群中的其他机器被称为Node，在较早的版本中也被称为Minion。与Master一样，Node可以是一台物理主机，也可以是一台虚拟机。Node是Kubernetes集群中的工作负载节点，每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，其上的工作负载会被Master自动转移到其他节点上。 在每个Node上都运行着以下关键进程: kubelet 负责Pod对应的容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能。 kube-proxy 实现Kubernetes Service的通信与负载均衡机制的重要组件。 Docker Engine（docker） Docker引擎，负责本机的容器创建和管理工作。 Node可以在运行期间动态增加到Kubernetes集群中，前提是在这个节点上已经正确安装、配置和启动了上述关键进程，在默认情况下kubelet会向Master注册自己，这也是Kubernetes推荐的Node管理方式。 一旦Node被纳入集群管理范围，kubelet进程就会定时向Master汇报自身的情报，例如操作系统、Docker版本、机器的CPU和内存情况，以及当前有哪些Pod在运行等，这样Master就可以获知每个Node的资源使用情况，并实现高效均衡的资源调度策略。 而某个Node在超过指定时间不上报信息时，会被Master判定为“失联”，Node的状态被标记为不可用（Not Ready），随后Master会触发“工作负载大转移”的自动流程。 我们可以执行下述命令查看在集群中有多少个Node： 然后可以通过kubectl describe node &lt;node_name&gt;查看某个Node的详细信息: PodPod是Kubernetes最重要的基本概念，下图所示是Pod的组成示意图，我们看到每个Pod都有一个特殊的被称为根容器的Pause容器。Pause容器对应的镜像属于Kubernetes平台的一部分，除了Pause容器，每个Pod还包含一个或多个紧密相关的用户业务容器。 为什么Kubernetes会设计出一个全新的Pod的概念并且Pod有这样特殊的组成结构？ 原因之一：在一组容器作为一个单元的情况下，我们难以简单地对“整体”进行判断及有效地行动。比如，一个容器死亡了，此时算是整体死亡么？是N/M的死亡率么？引入业务无关并且不易死亡的Pause容器作为Pod的根容器，以它的状态代表整个容器组的状态，就简单、巧妙地解决了这个难题。 原因之二：Pod里的多个业务容器共享Pause容器的IP，共享Pause容器挂接的Volume，这样既简化了密切关联的业务容器之间的通信问题，也很好地解决了它们之间的文件共享问题。 Kubernetes为每个Pod都分配了唯一的IP地址，称之为Pod IP，一个Pod里的多个容器共享Pod IP地址。Kubernetes要求底层网络支持集群内任意两个Pod之间的TCP/IP直接通信，这通常采用虚拟二层网络技术来实现，例如Flannel、Open vSwitch等 因此我们需要牢记一点：在Kubernetes里，一个Pod里的容器与另外主机上的Pod容器能够直接通信，同一个Pod里的容器之间仅需通过localhost就能互相通信。 Pod、容器与Node的关系: 一个Pod中的应用容器共享同一组资源： PID命名空间：Pod中的不同应用程序可以看到其他应用程序的进程ID 网络命名空间：Pod中的多个容器能够访问同一个IP和端口范围 IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信 UTS命名空间：Pod中的多个容器共享一个主机名 Volumes（共享存储卷）：Pod中的各个容器可以访问在Pod级别定义的Volumes Pod的生命周期通过Replication Controller来管理；通过模板进行定义，然后分配到一个Node上运行，在Pod所包含容器运行结束后，Pod结束。 Kubernetes为Pod设计了一套独特的网络配置，包括：为每个Pod分配一个IP地址，使用Pod名作为容器间通信的主机名等。 LabelLabel（标签）是Kubernetes系统中另外一个核心概念。一个Label是一个key=value的键值对，其中key与value由用户自己指定。Label可以被附加到各种资源对象上，例如Node、Pod、Service、RC等，一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上。Label通常在资源对象定义时确定，也可以在对象创建后动态添加或者删除。 我们可以通过给指定的资源对象捆绑一个或多个不同的Label来实现多维度的资源分组管理功能，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。 Label相当于我们熟悉的“标签”。给某个资源对象定义一个Label，就相当于给它打了一个标签，随后可以通过Label Selector（标签选择器）查询和筛选拥有某些Label的资源对象，Kubernetes通过这种方式实现了类似SQL的简单又通用的对象查询机制。 Service在Kubernetes的世界里，虽然每个Pod都会被分配一个单独的IP地址，但这个IP地址会随着Pod的销毁而消失，这就引出一个问题：如果有一组Pod组成一个集群来提供服务，那么如何来访问它呢？Service！ 一个Service可以看作一组提供相同服务的Pod的对外访问接口，Service作用于哪些Pod是通过Label Selector来定义的。 拥有一个指定的名字（比如my-mysql-server） 拥有一个虚拟IP（Cluster IP、Service IP或VIP）和端口号，销毁之前不会改变，只能内网访问 能够提供某种远程服务能力 被映射到了提供这种服务能力的一组容器应用上 如果Service要提供外网服务，需指定公共IP和NodePort，或外部负载均衡器 Service可以通过配置NodePort，在Node上打开一个主机的真实端口，这样，能够访问Node的客户端就能通过这个端口访问到内部的Service了 Replication ControllerReplication Controller（简称RC）是Kubernetes系统中的核心概念之一，简单来说，它其实定义了一个期望的场景，即声明某种Pod的副本数量在任意时刻都符合某个预期值 目标Pod的定义 目标Pod需要运行的副本数量 要监控的目标Pod标签（Label） Kubernetes通过RC中定义的Label筛选出对应的Pod实例，并实时监控其状态和数量，如果实例数量少于定义的副本数量（Replicas），则会根据RC中定义的Pod模板来创建一个新的Pod，然后将此Pod调度到合适的Node上启动运行，直到Pod实例数量达到预定目标。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.gitee.io/categories/Kubernetes/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.gitee.io/tags/Kubernetes/"}]},{"title":"'docker（四） 安装私服仓库'","slug":"docker-registry","date":"2020-05-21T13:00:00.000Z","updated":"2020-05-26T03:57:38.966Z","comments":true,"path":"2020/05/21/docker-registry/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/docker-registry/","excerpt":"","text":"docker私服仓库docker的私服仓库存储不像maven私服有完整独立的应用，它是通过docker获取私服仓库镜像，并根据镜像创建私服仓库容器 说白了，docker的私服仓库的搭建就是拉取镜像、创建容器、上传镜像的过程 宿主机环境IP：192.168.1.131 私服仓库的搭建1、拉取私服镜像 1docker pull registry:2 2、启动私服 1docker run --name registry -tid --privileged=true --restart=always --net=host -v /home/docker/repository:/var/lib/registry registry 这里使用的是V2版本的私服仓库,/var/lib/registry是私服仓库存储上传镜像的路径，把它挂载到宿主机上避免因为容器坏损丢失私服仓库的镜像存储 3、标记镜像 12命令：docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]例子：docker tag mtex-admin 192.168.1.131:5000/mtex-admin 这里以镜像名：mtex-admin为例，标记镜像将其归入某一仓库,再次查看镜像列表 1docker images 能够看见出现了192.168.1.131:5000/mtex-admin镜像名称，细心点会发现它的镜像ID和mtex-admin是一样的也就是说，两个镜像名称都映射到同一个镜像ID上，如何避免这种情况呢？ 可以执行tag命令之后，删除原来的旧镜像名称，只保留一个名称映射 也可以在创建镜像时，镜像名称以[私服IP:端口/名称]命名,不必在执行tag命令 4、上传私服 1docker push 192.168.1.131:5000/mtex-admin 可以看到上传成功了，使用192.168.1.134试一下拉取镜像 1docker pull 192.168.1.131:5000/mtex-admin 5、配置解析 考虑到记住IP比较麻烦，可以在/etc/hosts中增加本地仓库的域名解析 1echo \"192.168.1.131 docker-registry\" &gt;&gt; /etc/hosts 这时候再执行cat /etc/hosts能够看到，已经增加进去了 6、查看私服镜像 可以通过浏览器打开http://192.168.1.131:5000/v2/_catalog查看 7、删除私服镜像 上面已经将私服的镜像内容挂载到宿主机/home/docker/repository路径中，只需要进入对应路径删除镜像即可路径目录是/home/docker/repository/docker/registry/v2/repositories 常见问题Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交互时可能会出现以下错误 1Get https://192.168.1.131:5000/v2/: http: server gave HTTP response to HTTPS client docker版本1.2以上的，在/etc/docker/daemon.json文件中增加以下内容 12#必须要增加在第一行&#123; \"insecure-registries\":[\"192.168.1.131:5000\"] 然后重启docker，重启registry 1systemctl restart docker.service 查看docker版本的命令docker -v，低于1.2的版本可以升级版本，也可以上网寻找解决方法.","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/tags/Docker/"}]},{"title":"'docker（三） 执行DockerFile创建镜像'","slug":"docker-dockfile","date":"2020-05-21T12:30:00.000Z","updated":"2020-05-26T09:39:11.800Z","comments":true,"path":"2020/05/21/docker-dockfile/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/docker-dockfile/","excerpt":"","text":"DockerFile 文件常用详解 FROM：指定基础镜像，必须为第一个命令 12345678格式： FROM &lt;image&gt; FROM &lt;image&gt;:&lt;tag&gt; FROM &lt;image&gt;@&lt;digest&gt;示例： FROM centos:7.2.1511注： tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像 MAINTAINER：维护者信息 123456格式： MAINTAINER &lt;name&gt;示例： MAINTAINER caijinkun MAINTAINER caijinkun &lt;caijinkun@mastercom.cn&gt; MAINTAINER caijinkun \"caijinkun@mastercom.cn\" RUN：构建镜像时执行的命令 123456789101112131415RUN用于在镜像容器中执行命令，其有以下两种命令执行方式：shell执行格式： RUN &lt;command&gt;exec执行格式： RUN [\"executable\", \"param1\", \"param2\"]示例： RUN [\"executable\", \"param1\", \"param2\"] RUN apk update RUN [\"/etc/execfile\", \"arg1\", \"arg1\"]注： RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像， 可以在构建时指定--no-cache参数,如：docker build --no-cache 每执行Run命令，都会创建一个中间镜像层，使得最终创建的镜像文件变大，建议把命令都在一个Run中执行，用&amp;&amp;分隔. ADD：将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget 12345678910格式： ADD &lt;src&gt;... &lt;dest&gt; ADD [\"&lt;src&gt;\",... \"&lt;dest&gt;\"] 用于支持包含空格的路径示例： ADD hom* /mydir/ # 添加所有以\"hom\"开头的文件 ADD hom?.txt /mydir/ # ? 替代一个单字符,例如：\"home.txt\" ADD test relativeDir/ # 添加 \"test\" 到 `WORKDIR`/relativeDir/ ADD test /absoluteDir/ # 添加 \"test\" 到 /absoluteDir/注： 该命令只能添加Dockerfile路径的下层文件，所以需要事先拷贝文件到该路径下 COPY：功能类似ADD，但是是不会自动解压文件，也不能访问网络资源，建议直接用ADD CMD：构建容器后调用，也就是在容器启动时才进行调用 12345678910格式： CMD [\"executable\",\"param1\",\"param2\"] (执行可执行文件，优先) CMD [\"param1\",\"param2\"] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数) CMD command param1 param2 (执行shell内部命令)示例： CMD echo \"This is a test.\" | wc - CMD [\"/usr/bin/wc\",\"--help\"] CMD [\"java\",\"-jar\",\"mtex-config-0.0.1-SNAPSHOT.jar\"]注： CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令 ENTRYPOINT：配置容器，使其可执行化。配合CMD可省去”application”，只使用参数。 1234567891011格式： ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (可执行文件, 优先) ENTRYPOINT command param1 param2 (shell内部命令)示例： FROM ubuntu ENTRYPOINT [\"top\", \"-b\"] CMD [\"-c\"]注： ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT 而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令。 ENV：设置环境变量 1234567格式： ENV &lt;key&gt; &lt;value&gt; #&lt;key&gt;之后的所有内容均会被视为其&lt;value&gt;的组成部分，因此，一次只能设置一个变量 ENV &lt;key&gt;=&lt;value&gt; ... #可以设置多个变量，每个变量为一个\"&lt;key&gt;=&lt;value&gt;\"的键值对，如果&lt;key&gt;中包含空格，可以使用\\来进行转义，也可以通过\"\"来进行标示；另外，反斜线也可以用于续行示例： ENV myName John Doe ENV myDog Rex The Dog ENV myCat=fluffy EXPOSE：指定于外界交互的端口 12345678910格式： EXPOSE &lt;port&gt; [&lt;port&gt;...]示例： EXPOSE 80 443 EXPOSE 8080 EXPOSE 11211/tcp 11211/udp注： EXPOSE并不会让容器的端口访问到主机。要使其可访问 需要在docker run 运行容器时通过 -p 来发布这些端口 或通过 -P 参数来发布EXPOSE导出的所有端口 VOLUME：用于指定持久化目录 123456789101112格式： VOLUME [\"path\"]示例： VOLUME [\"/data\",\"/home\"]注： 和docker run -v 的区别是无法挂载指定的目录. 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能： 1.卷可以容器间共享和重用 2.容器并不一定要和其它容器共享卷 3.修改卷后会立即生效 4.对卷的修改不会对镜像产生影响 5.卷会一直存在，直到没有任何容器在使用它 WORKDIR：工作目录，类似于cd命令 12345678格式： WORKDIR path示例： WORKDIR /home (这时工作目录为/home) WORKDIR jenkins-running-jar (这时工作目录为/home/jenkins-running-jar)注： 通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY等命令都会在该目录下执行。 在使用docker run运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 docker 执行DockerFile创建镜像基础镜像 docker pull centos:7.2.1511先从仓库中拉取一个centos7.2的系统，来作为最底层的镜像 先下载 jre-8u201-linux-x64.tar.gz 下载地址 以此为基础创建一个具备java环境的基础镜像 这里使用jre而非jdk，主要是为了降低镜像大小。 这里注意需要引入镜像的文件必须与Dockerfile路径同级或下级 在jre-8u201-linux-x64.tar.gz文件路径下 vi Dockerfile 创建镜像，拷贝以下内容 123456789101112131415#使用的基础镜像FROM centos:7.2.1511#作者信息MAINTAINER caijinkun \"caijinkun@mastercom.cn\"#安装中文和zip支持RUN yum -y install kde-l10n-Chinese &amp;&amp; yum -y reinstall glibc-common &amp;&amp; yum -y install unzip zip &amp;&amp; yum clean all &amp;&amp; localedef -c -f UTF-8 -i zh_CN zh_CN.utf8#加入jreADD jre-8u201-linux-x64.tar.gz /usr/local/#设置环境变量ENV JAVA_HOME /usr/local/jre1.8.0_201ENV PATH $JAVA_HOME/bin:$PATHENV LC_ALL zh_CN.utf8ENV TZ Asia/Shanghai 执行Dockfile文件 docker build -t java:jre1.8.0.201 . 并检查镜像创建是否成功docker images java mtex-config镜像基础镜像已经完毕，准备创建程序的DockerFile和程序，这里以mtex-config为例 12345678910111213#使用的基础镜像FROM java:jre1.8.0.201#作者信息MAINTAINER caijinkun \"caijinkun@mastercom.cn\"#加入服务ADD mtex-config-0.0.1-SNAPSHOT.zip tmp.zipRUN mkdir -p /home/jenkins-running-jar/mtex-config/ &amp;&amp; unzip -o tmp.zip -d /home/jenkins-running-jar/mtex-config/ &amp;&amp; rm -f tmp.zip &amp;&amp; rm -rf /home/jenkins-running-jar/mtex-config/properties &amp;&amp;rm -rf /home/jenkins-running-jar/mtex-config/properties_*#工作目录WORKDIR /home/jenkins-running-jar/mtex-config/#启动服务CMD [\"nohup\",\"java\",\"-jar\",\"mtex-config-0.0.1-SNAPSHOT.jar\"] 这里需要引入自身的配置文件夹，所以把压缩包引入镜像后先删除原配置文件夹.待使用docker启动时将自身配置文件挂载进去，也可以使用其他方式. 使用docker启动mtex-config,这里pro-properties是我自身的配置文件夹名称，这里挂载到主机的是linux自带的日志，可自行进行log日志挂载 1docker run --name mtex-config -tid --privileged=true --restart=always --net=host -v /home/jenkins-running-jar/mtex-config/pro-properties:/home/jenkins-running-jar/mtex-config/properties/ -v /home/file/nohupLog/mtex-config.log:/home/jenkins-running-jar/mtex-config/nohup.out mtex-config 启动容器时把自身的配置文件夹挂载到容器中即可.--net=host代表和主机使用同一个网段,即同一个IP和端口. 如果打算通过-p进行端口映射，需要先在启宿主机的防火墙上开启该端口，并对外暴露. mtex-sys镜像程序镜像基本都类似，都是根据业务要求挂载不同的文件即可. 12345678910111213#使用的基础镜像FROM java:jre1.8.0.201#作者信息MAINTAINER caijinkun \"caijinkun@mastercom.cn\"#加入服务ADD mtex-sys-0.0.1-SNAPSHOT.zip tmp.zipRUN mkdir -p /home/jenkins-running-jar/mtex-sys/ &amp;&amp; unzip -o tmp.zip -d /home/jenkins-running-jar/mtex-sys/ &amp;&amp; rm -f tmp.zip#工作目录WORKDIR /home/jenkins-running-jar/mtex-sys/#启动服务CMD [\"nohup\",\"java\",\"-jar\",\"mtex-sys-0.0.1-SNAPSHOT.jar\"] docker启动mtex-sys实例: 1docker run --name mtex-sys -tid --privileged=true --restart=always --net=host -v /home/file/nohupLog/mtex-sys.log:/home/jenkins-running-jar/mtex-sys/nohup.out mtex-sys 这时要注意，sys作为框架需要访问很多个项目的文件夹配置及路径，根据需求进行挂载，或者弄一个项目的共享文件夹即可.","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/tags/Docker/"}]},{"title":"'docker（二） 安装nginx redis'","slug":"docker-use","date":"2020-05-21T11:30:00.000Z","updated":"2020-09-23T08:23:12.368Z","comments":true,"path":"2020/05/21/docker-use/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/docker-use/","excerpt":"","text":"docker 安装 nginxdocker安装镜像，使用的是两个命令docker search xxx 和 docker pull xxx，xxx则为要安装的镜像名称,这里要注意的是创建容器会和主机时间相差8个小时 搜索nginx镜像 docker search nginx 安装nginx镜像 docker pull nginx 查看镜像信息 docker images nginx 建议在nginx.conf中配置使用root启动nginx避免权限不足引起问题 编辑配置文件并设置为root. 重命名镜像名称 docker tag IMAGEID REPOSITORY:TAG IMAGEID是镜像ID，REPOSITORY是镜像新名称，TAG是镜像新标签 创建并启动容器命令 docker run [OPTIONS] IMAGE [COMMAND] [ARG...] docker启动nginx实例： docker run 参数配置 作用 --name xxx 为容器指定一个名称为 xxx -t 为容器重新分配一个伪输入终端，通常与 -i 同时使用； -i 以交互模式运行容器，通常与 -t 同时使用； -d 后台运行容器，并返回容器ID； --privileged=true centos默认关闭SElinux，需要开启特权模式，以root的形式进入容器，否则是普通用户 --restart=always 容器开启自动启动 -p 端口映射，格式为：主机(宿主)端口:容器端口 -v 主机路径:容器路径 把主机的文件挂载到容器中 或 把容器文件同步到主机中 -v /etc/localtime:/etc/localtime:ro 把主机时间同步到容器中，不同步会相差8小时 123456789docker run --name nginx -tid --privileged=true --restart=always -p 8181:8181 -v /home/local/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/file/log/nginx/log:/var/log/nginx -v /home/jenkins-running-jar/static/:/home/jenkins-running-jar/static/ -v /etc/localtime:/etc/localtime:ro docker.io/nginx#分解命令#把容器的日志配置同步到主机中-v /home/file/log/nginx/log:/var/log/nginx #是把主机中的配置文件挂载到容器中-v /home/local/nginx/conf/nginx.conf:/etc/nginx/nginx.conf#挂载nginx配置中需要访问的静态文件-v /home/jenkins-running-jar/static/:/home/jenkins-running-jar/static/ docker.io/nginx为镜像名称 查看容器命令 docker ps -a 停止容器命令 docker stop 容器ID或容器名称 删除容器命令 docker rm 容器ID或者容器名称 进入容器命令 docker exec -it 容器ID /bin/bash 退出容器命令 exit 删除镜像命令 docker rmi 镜像ID docker 安装 Redis安装Redis镜像 docker pull redis:3.2 准备 redis.conf,若无此文件可自行新建同名文件并复制进去如果使用上文配置文件则可不需要执行以下操作，原版的redis.conf需修改以下几点:原文件： 1234bind 127.0.0.1protected-mode yesappendonly no//持久化# requirepass foobared 修改后： 1234#bind 127.0.0.1protected-mode noappendonly yes//持久化requirepass yourpassword //redis密码 docker启动redis实例： 1234567docker run --name redis -tid --privileged=true --restart=always -p 6379:6379 -v /home/local/redis/redis.conf:/etc/redis/redis.conf -v /home/local/redis/data:/data redis redis-server /etc/redis/redis.conf#分解命令#把主机的配置文件挂载到容器中-v /home/local/redis/redis.conf:/etc/redis/redis.conf#映射挂载的数据目录-v /home/local/redis/data:/data","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/tags/Docker/"}]},{"title":"'docker（一） 安装及存储路径配置'","slug":"docker-install","date":"2020-05-21T11:00:00.000Z","updated":"2020-05-26T03:57:18.936Z","comments":true,"path":"2020/05/21/docker-install/","link":"","permalink":"https://midkuro.gitee.io/2020/05/21/docker-install/","excerpt":"","text":"docker 安装及存储路径配置docker的安装安装docker yum install docker 启动服务 systemctl start docker.service 设置开机自启 systemctl enable docker.service 查看docker版本 docker version 使用centos7系统的，建议把selinux服务关闭，它会影响docker的启动及一些容器的使用. SELinux一共有3种状态，分别是Enforcing，Permissive和Disabled状态。第一种是默认状态，表示强制启用，第二种是宽容的意思，即大部分规则都放行。第三种是禁用，即不设置任何规则。可以通过命令 getenforce 查看selinux服务的状态，默认一般都是 Enforcing。 修改selinux状态，编辑配置文件 vi /etc/selinux/config 将 SELINUX=enforcing改为SELINUX=disabled，该操作后需要重启机器。 docker存储路径配置docker每次创建一个镜像、容器都会占据大量的内存空间，所以建议在安装的时候就把docker放在大空间的路径下，默认的docker是安装在/var/lib/docker下. 如果docker已经启动，请先关闭它 systemctl stop docker.service . 我打算把它迁移到 /home/docker 路径下，所以先创建文件夹 mkdir /home/docker 然后编辑docker存储路径配置 vi /lib/systemd/system/docker.service,找到ExecStart项 ,把它改成ExecStart=/usr/bin/dockerd --graph /home/docker 保存文件后需要执行命令重新加载配置 systemctl daemon-reload. 然后将原路径文件拷贝到新的路径下 cp -r /var/lib/docker/* /home/docker/ docker中不存在容器的话，可以把原路径下的文件删除 如果docker已经存在容器，需要迁移容器的挂载点 首先输入命令 df -hl 查看挂载点，docker容器会创建名称为overlay和shm的挂载点.这时候可以执行命令cat /proc/mounts|grep docker查看挂载点哪些是属于docker的. 然后执行 umount 挂载点全路径 去掉该容器的挂载，并修改挂载点的路径，改成迁移后的docker路径,重新执行挂载命令 mount 新挂载点路径 再次查看挂载 df -hl 这时候应该看到的都是新的路径，也可以删除原路径下的文件了，如果依旧删除失败，重启机器后可删除，然后尝试运行镜像。 如果运行镜像失败提示:Error response from daemon: shim error: docker-runc not installed on system,执行命令创建软连接cd /usr/libexec/docker/和ln -s docker-runc-current docker-runc 如果运行镜像失败提示:exec: “docker-proxy”: executable file not found in $PATH，执行命令创建软连接 ln -s /usr/libexec/docker/docker-proxy-current /usr/bin/docker-proxy 再次运行镜像，应该就能启动了，个人觉得迁移存储路径，有很大可能会出现上面的运行镜像失败的错误，如果是新装的docker迁移了存储路径，也可以先执行上面创建软连接的命令避免以后发生错误. 常用的docker命令 docker run 参数配置 作用 -v /etc/localtime:/etc/localtime:ro 把主机时间同步到容器中，不同步会相差8小时 --privileged=true centos默认关闭SElinux，需要开启特权模式，以root的形式进入容器，否则是普通用户 --restart=always 容器开启自动启动 --net=host 容器和宿主机的IP同网段 -v 主机路径:容器路径 用户把主机的文件挂载到容器中 /usr/sbin/init 在容器中开启系统命令，能够使用systemctl的命令 -d: 后台运行容器，并返回容器ID； -i: 以交互模式运行容器，通常与 -t 同时使用； -p: 端口映射，格式为：主机(宿主)端口:容器端口 -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； --name=nginx-lb 为容器指定一个名称； 命令大全","categories":[{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/categories/Docker/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/tags/Docker/"}]},{"title":"'linux（四） 安装Nodejs'","slug":"linux-nodejs","date":"2020-05-20T13:00:00.000Z","updated":"2020-11-12T04:15:42.743Z","comments":true,"path":"2020/05/20/linux-nodejs/","link":"","permalink":"https://midkuro.gitee.io/2020/05/20/linux-nodejs/","excerpt":"","text":"node.js安装第一种安装方式1.安装gcc，make，openssl 1yum install -y gcc make gcc-c++ openssl-devel 2.下载安装包下载 node-v9.3.0-linux-x64.tar.gz 下载地址 需要其他版本的请到官网中下载即可 官网地址 3.上传安装包 创建nodejs路径文件夹 1mkdir /var/local/nodejs 进入该路径,并上传安装包到该路径中 1cd /var/local/nodedjs 4.解压安装包 1tar -xf node-v9.3.0-linux-x64.tar.gz 5.编译 进入源代码所在路径 1cd node-v9.3.0-linux-x64 执行配置脚本 1./configure 编译与部署 1make &amp;&amp; make install 6.测试 12node -vnpm -v 这种方式安装，需要安装安装gcc等一些编译环境插件，而且编译比较久，部署完成后nodejs为分别放在好几个文件夹内： 123456#放置nodejs 执行程序/usr/local/bin#放置了node_modules，即nodejs的各种模块/usr/lib#放置了nodejs扩展开发用头文件/usr/include 优点是全局安装nodejs模块，直接使用，而且不受用户访问权限影响，推荐使用这种. 第二种安装方式可以不用执行上面的第一步操作，然后用以下方式替代第五步操作 确认node.js的路径，我这里是/usr/local/nodejs/node-v9.3.0-linux-x64/bin，依次执行 12ln -s /usr/local/nodejs/node-v9.3.0-linux-x64/bin/node /usr/bin/nodeln -s /usr/local/nodejs/node-v9.3.0-linux-x64/bin/npm /usr/bin/npm 注意ln指令用于创建关联（类似与Windows的快捷方式）必须给全路径，否则可能关联错误 该方式需要使用root权限去关联，并且非root用户需要做环境变量配置才能使用node.js node.js卸载1.自带工具删除 1yum remove nodejs npm -y 2.2.手动删除残留 进入 /usr/local/bin 删除 node 的可执行文件node和npm 进入 /usr/local/lib 删除所有 node 和 node_modules文件夹 进入 /usr/local/include 删除所有 node 和 node_modules 文件夹 检查 ~ 文件夹里面的”local”、”lib”、”include”、文件夹，然后删除里面的所有”node” 和”node_modules”文件夹 jenkins中使用node.js 在jenkins界面上 系统管理-全局工具配置 中配置安装的nodejs路径 先搭建一个jenkins前端构建任务，构建一次，作用是为了让jenkins检出SVN上的前端代码 到jenkins项目路径中 cd进入workspace文件夹，再进入前端任务名称的文件夹 确认检出的SVN代码文件夹中是否有package.json文件,进入文件路径中 执行以下命令安装node_modules 123npm install webpack -gnpm install webpack-cli -gnpm install --unsafe-perm=true --allow-root 然后组件安装完成后，即可在jenkins构建任务中编辑shell命令执行npm run dist-p-xxx等操作","categories":[{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.gitee.io/categories/Nodejs/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.gitee.io/tags/Linux/"},{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"}]},{"title":"'linux（三） 安装nginx redis'","slug":"linux-software","date":"2020-05-20T12:35:00.000Z","updated":"2020-12-21T14:12:02.308Z","comments":true,"path":"2020/05/20/linux-software/","link":"","permalink":"https://midkuro.gitee.io/2020/05/20/linux-software/","excerpt":"","text":"安装nginx1.下载安装包nginx-1.14.1.tar.gz 其他版本请自行下载 官网地址 2.上传并解压安装包 1tar -zxvf nginx-1.14.1.tar.gz 3.设置配置信息 1./configure --prefix=/usr/local/nginx (安装后的文件存放路径） 如果出现以下异常信息 1234./configure: error: the HTTP rewrite module requires the PCRE library.You can either disable the module by using --without-http_rewrite_moduleoption, or install the PCRE library into the system, or build the PCRE librarystatically from the source with nginx by using --with-pcre=&lt;path&gt; option. 则执行命令安装pcre-devel 1yum -y install pcre-devel 安装pcre-devel完成后再次执行命令 1./configure --prefix=/usr/local/nginx 执行完后还有可能会出现这样的问题： 1234567checking for PCRE JIT support ... not foundchecking for system md library ... not foundchecking for system md5 library ... not foundchecking for OpenSSL md5 crypto library ... not foundchecking for sha1 in system md library ... not foundchecking for OpenSSL sha1 crypto library ... not foundchecking for zlib library ... found 若出现上述问题则安装openssl 1yum -y install openssl openssl-devel 安装openssl完成后再次执行命令 1./configure --prefix=/usr/local/nginx 出现下图信息则说明配置成功 4.安装 12makemake install 出现类似这样的就表示安装成功了 123456cp conf/nginx.conf '/usr/local/nginx/conf/nginx.conf.default'test -d '/usr/local/nginx/logs' || mkdir -p '/usr/local/nginx/logs'test -d '/usr/local/nginx/logs' || mkdir -p '/usr/local/nginx/logs'test -d '/usr/local/nginx/html' || cp -R html '/usr/local/nginx'test -d '/usr/local/nginx/logs' || mkdir -p '/usr/local/nginx/logs'make[1]: Leaving directory '/root/setup/nginx/nginx-1.14.1' 安装完后/usr/local/nginx 后出现几个文件夹conf、html、logs、sbin，配置nginx.conf在文件夹conf中 启动nginx 1./usr/nginx/sbin/nginx 部分nginx启动失败解决方法 关闭SELINUX 12vi /etc/selinux/config将SELINUX=enforcing改为SELINUX=disabled 这时候需要注意，开启nginx配置的防火墙端口 开启防火墙端口教程 安装redis1.安装redis 1yum install redis 2.下载fedora的epel仓库 1yum install epel-release 3.安装redis数据库 1yum install redis 4.修改redis.conf配置文件 123456789101112原文件：bind 127.0.0.1protected-mode yesappendonly no//持久化# requirepass foobared修改后：#bind 127.0.0.1protected-mode noappendonly yes//持久化requirepass yourpassword //redis密码 5.使用配置文件启动 redis 1redis-server /etc/redis.conf &amp; 6.启动redis相关命令 12345678# 启动redisservice redis start 或 systemctl start redis.service# 停止redisservice redis stop 或 systemctl stop redis.service# 查看redis运行状态service redis status 或 systemctl status redis.service# 查看redis进程ps -ef | grep redis 7.本机测试访问 12redis-cli -h 127.0.0.1 -p 6379quit 这时候需要注意，非本机访问redis需要开启防火墙端口 开启防火墙端口教程","categories":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.gitee.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.gitee.io/tags/Linux/"},{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.gitee.io/tags/Nginx/"},{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/tags/Redis/"}]},{"title":"'linux（二） centos7设置应用程序为系统服务'","slug":"linux-systemctl","date":"2020-05-20T12:30:00.000Z","updated":"2020-11-12T04:14:31.297Z","comments":true,"path":"2020/05/20/linux-systemctl/","link":"","permalink":"https://midkuro.gitee.io/2020/05/20/linux-systemctl/","excerpt":"","text":"centos7使用systemctl以下的 xxx为服务名称，需根据自身需求修改 1.进入目录 1cd /usr/lib/systemd/system/ 2.创建xxx.service文件 1vi xxx.service 3.赋予xxx.service文件权限 1chmod 754 xxx.service xxx.service文件详解[Unit] 部份 设置参数 参数意义说明 Description 服务名称 After 说明此服务 是在哪个服务启动之后才启动的意思！基本上仅是说明服务启动的顺序而已，并没有强制要求里头的服务一定要启动后此 unit 才能启动。 Before 与 After 的意义相反，是在什么服务启动前最好启动这个服务的意思。不过这仅是规范服务启动的顺序，并非强制要求的意思。 Requires 明确的定义此服务需要在哪个服务启动后才能够启动！就是设置相依服务！如果在此项设置的前导服务没有启动，那么此服务就不会被启动！ Conflicts 代表互斥的服务！亦即这个项目后面接的服务如果有启动，那么我们这个服务本身就不能启动！我们服务有启动，则此项目后的服务就不能启动！ [Service] 部份 设置参数 参数意义说明 Type 说明这个程序启动的方式，会影响到 ExecStart,一般来说，有下面几种类型 simple：默认值，这个程序主要由 ExecStart 接的指令串来启动，启动后常驻于内存中。forking：由 ExecStart 启动的程序通过 spawns 延伸出其他子程序来作为此程序 的主要服务。原生的父程序在启动结束后就会终止运行。 传统的 unit 服务大多属于这种项目.还有oneshot、dbus、idle等类型，请自行了解. EnvironmentFile 可以指定启动脚本的环境配置文件.例如 sshd.service 的配置文件写入到 /etc/sysconfig/sshd 当中！你也可以使用 Environment= 后面接多个不同的 Shell 变量来给予设置 ExecStart 启动应用程序的命令 ExecStop 停止应用程序的命令 ExecReload 重载应用程序的命令 Restart 当设置 Restart=1 时，则当此服务终止后，会再次的启动此服务 [Install] 部份 设置参数 参数意义说明 WantedBy 这个设置后面接的大部分是 *.target unit,意思是这个服务本身是附挂在哪一个target unit下面的,都是附挂在 multi-user.target下面 redis及nginx为例以redis为例，在该路径下 vi redis.service，并复制进去以下内容，进行相应修改. 123456789101112[unit]Description&#x3D;redis - high performance web serverAfter&#x3D;network.target remote-fs.target nss-lookup.target[Service]Type&#x3D;forkingExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis-5.0.2&#x2F;start.shExecReload&#x3D;ExecStop&#x3D;&#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis-5.0.2&#x2F;stop.sh[Install]WantedBy&#x3D;multi-user.target 以nginx为例，在该路径下 vi nginx.service，并复制进去以下内容，进行相应修改. 123456789101112[unit]Description&#x3D;nginx - high performance web serverAfter&#x3D;network.target remote-fs.target nss-lookup.target[Service]Type&#x3D;forkingExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.confExecReload&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reloadExecStop&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s stop[Install]WantedBy&#x3D;multi-user.target 比如我mtex-auth服务的启动需要依赖mtex-config服务，可以这样配置vi mtex-auth.service 123456789101112[Unit]Description&#x3D;mtex-auth - high performance web serverAfter&#x3D;network.target remote-fs.target nss-lookup.target mtex-configRequires&#x3D;mtex-config[Service]Type&#x3D;forkingExecStart&#x3D;&#x2F;home&#x2F;jenkins-running-shell&#x2F;mtex-auth&#x2F;start.shExecReload&#x3D;ExecStop&#x3D;&#x2F;home&#x2F;jenkins-running-shell&#x2F;mtex-auth&#x2F;stop.sh[Install]WantedBy&#x3D;multi-user.target 服务命令操作以nginx为例，保存nginx.service文件后赋予执行权限 1chmod 754 nginx.service nginx开机自启 1systemctl enable nginx.service 启动nginx 1systemctl start nginx.service 停止nginx 1systemctl stop nginx.service 重启nginx 1systemctl restart nginx.service centos7也可以使用旧版命令 system stop xxx 、system start xxx达到效果.","categories":[{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.gitee.io/categories/Systemctl/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.gitee.io/tags/Linux/"}]},{"title":"'linux（一） 开放防火墙端口'","slug":"linux-firewalld","date":"2020-05-20T12:00:00.000Z","updated":"2020-11-12T04:16:24.347Z","comments":true,"path":"2020/05/20/linux-firewalld/","link":"","permalink":"https://midkuro.gitee.io/2020/05/20/linux-firewalld/","excerpt":"","text":"centos7开放防火墙端口启动防火墙 1systemctl start firewalld 停止防火墙 1systemctl stop firewalld 查看防火墙状态 1firewall-cmd --state 查看防火墙启动状态详情 1systemctl status firewalld 开机禁用 1systemctl disable firewalld 开机启用 1systemctl enable firewalld 查看所有打开的端口 1firewall-cmd --zone=public --list-ports 开启端口 1firewall-cmd --zone=public --add-port=80/tcp --permanent –permanent永久生效，没有此参数重启后失效 重新载入 1firewall-cmd --reload 查看端口状态 1firewall-cmd --zone=public --query-port=80/tcp 删除端口 1firewall-cmd --zone= public --remove-port=80/tcp --permanent","categories":[{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.gitee.io/categories/Firewall/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://midkuro.gitee.io/tags/Linux/"}]},{"title":"'jenkins（四） 参数化构建'","slug":"jenkins-param","date":"2020-05-20T07:50:40.000Z","updated":"2020-11-12T04:16:52.961Z","comments":true,"path":"2020/05/20/jenkins-param/","link":"","permalink":"https://midkuro.gitee.io/2020/05/20/jenkins-param/","excerpt":"","text":"jenkins参数化构建通过输入参数进行构建项目，需要插件build with parameters plugin，正常安装成功的jenkins应该都会自带了的，那么参数可以做什么事呢？如果我想要jenkins构建svn上指定版本号的代码并进行测试，就可以使用参数构建. 首先先了解一下怎么获取svn上指定的版本代码:通过项目路径@版本号进行获取的，版本号为head时，则取最新版本. 打开jenkins的任务配置，在General模块中找到参数化构建工程,勾选并添加自己的参数类型，本文选的是字符参数. 填写完相应的参数配置，需要修改项目svn的路径，将其改成项目路径@$参数名称 的格式.这时候的svn校验将失效，因为是配置了参数. 点击保存，就已经完成了参数化构建的配置了.这时候立即构建的按钮将变成Build with Parameters ,是不是觉得很简单？ 这时候又会发现，上下游均配置了参数化构建，但是触发了上游项目构建，并不能将参数传递到我的下游项目中，这时候会发现下游项目使用的是配置中的默认参数head,怎么做到传递一次参数即可触发构建呢？ 这时候要先安装一款插件Parameterized Trigger Plugin，安装完成后解除项目的上下游关系 然后编辑上游项目的任务配置，找到Post Steps模块,点击Add post-build step,能够看到多了一项选择，选中Trigger/call builds other projects 这里做的是正向配置上下游关系，上文解除了之前上下游关系，目的就是为了在这里通过参数传递进行配置。填入下游项目的工程名称，并点击Add Parameters添加参数，在这里我选择的是Predefined parameters,其他的暂时没有去了解.并填写传参的参数，格式为参数名=${参数名大写},这里我并有去测试小写能不能传递，亲们可以试试看… 这时候构建上游，也能够接收到同样的参数并指定的SVN版本号进行构建了,如果想要在shell命令中使用参数，也可以通过${参数名大写}进行取值. jenkins远程触发项目构建jenkins远程触发项目构建能够实现的功能有很多，本文主要讲解如何通过一个url进行触发构建. 打开任务配置并找到构建触发器模块，勾选触发远程构建并配置一个秘钥，这个秘钥相当于密码，密码错误的话不会触发构建. 如何调度已经说得很清楚了：http://IP:端口号/job/任务名称/build?token=秘钥 也可以使用参数进行远程触发：http://IP:端口号/job/任务名称/buildWithParameters?token=秘钥&amp;&amp;参数名=参数值 也就是说，这时候项目配置了参数构建及远程触发构建，就可以通过http请求的调度促使jenkins进行参数化远程构建… 这个时候会发现，如果我没有登录，它是不让我远程触发构建的，那我如何不需要登录就进行触发构建呢？ 首先先安装一个插件Build Authorization Token Root Plugin,然后登录用户-&gt;点击右上角的登录名-&gt;再点击设置 输入生成token的字符串，并生成一串token秘钥，切记拷贝生成的token秘钥，然后回到项目的构建触发器模块，将生成的token秘钥填入身份验证令牌中即可 这时候请求的url将发生变化: 无参请求:http://IP:端口号/buildByToken/build?job=任务名称&amp;token=秘钥 参数请求:http://IP:端口号/buildByToken/buildWithParameters?job=任务名称&amp;token=秘钥&amp;参数名=参数值","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.gitee.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"}]},{"title":"'jenkins（三） 上下游与持续集成构建'","slug":"jenkins-upstream","date":"2020-05-20T05:52:40.000Z","updated":"2020-11-12T04:16:57.030Z","comments":true,"path":"2020/05/20/jenkins-upstream/","link":"","permalink":"https://midkuro.gitee.io/2020/05/20/jenkins-upstream/","excerpt":"","text":"spring boot项目之间的引用触发上下游构建首先上下游关系是可以通过配置实现的，可以通过正向配置或反向配置实现，建议统一使用一种。 先理解一下上游下游的概念，目前我的dao项目作为一个基础类库，然后mtex-auth引入依赖dao，那么dao就是mtex-auth的上游，mtex-auth就是dao的下游。 在这情况下，上游dao主动去建立和下游的mtex-auth的关系，则为正向配置，而下游mtex-auth主动去建立和上游dao的关系，则为反向配置。 正向配置：在dao任务中找到 构建后操作模块增加构建后操作步骤，选择构建其他工程，在该路径填写mtex-auth任务名称,则dao构建成功后会主动触发mtex-auth任务进行构建 反向配置:在mtex任务中找到 构建触发器模块，勾选其他工程构建后触发并填写dao任务名称 在我的理解中，不管正向配置还是反向配置，作用都是一样的，都是建立上下游关系，上游构建成功后触发下游构建,所以建议只使用一种配置，没必要双向关系. 配置好上下游权限后，建议每一个下游任务的配置中增加限制，打开任务进入General模块，点击高级，勾选该项目上游正在构建时阻止该项目构建选项. 设想一下，如果存在项目关系如下： A项目作为B项目的上游 A项目作为C项目的上游 B项目作为C项目的上游 那么在A项目构建成功后，逻辑来讲它是会触发两个下游之间的构建，也就是B项目和C项目同时构建，等B项目构建完会再次触发一次C项目的构建。而通过勾选上游构建时阻止构建下游，就能避免这个问题。 最理想的构建顺序是 A-B-C ,那么在A任务的正向配置中，则不需要配置下游项目C，只需要配置下游项目B，反向配置也一样。 其次，在任务模块构建触发器中，建议关闭 Build whenever a SNAPSHOT dependency is built，因为该配置会根据pom文件的快照项目依赖自动创建上下游关系，导致和正反向配置重复并可能出现多次打包的情况。 jenkins持续集成构建任务关系依赖可能出现这种情况，A、B、C项目都作为D项目的上游，而A、B、C又是单独互不影响的项目，这时候它们是可以进行并发构建的，可是这样就会触发D项目的3次构建，这明显是不合理的，那么怎么做到 A、B、C项目同时构建，然后再触发下游D项目的构建呢？ 首先安装一个串行的插件 Multijob,它支持将任务捆绑构建。我们需要先解除A、B、C项目和D项目的上下游关系，也就是取消正反向配置,并且取消A、B、C任务中General模块的 该项目上游正在构建时阻止该项目构建配置，切记必须取消，否则无法进行构建. 新建任务，选择 Multijob Project,创建一个任务E。 找到构建模块，点击增加构建步骤并选择Multijob Phase,并依次添加A、B、C任务名称 这个时候可以点击每个任务右下角的高级进行详细配置 构建方式可以选择 串行或者并行，串行的话则按照添加任务的顺序进行构建，并行则同时构建。 构建条件可以选择 构建成功触发、构建失败触发、无论结果如何都触发等操作，按需求配置。 配置完成后关联E项目和D项目之间的上下游关系,并配置该项目上游正在构建时阻止该项目构建即可，就能满足触发E项目时， 触发A、B、C项目同时构建，然后再触发下游D项目的构建的操作。 这个时候如果项目是并行的，必须设置jenkins的最大并行执行器的数量,系统管理-&gt;系统设置-&gt;填写执行器数量。","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.gitee.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"}]},{"title":"'jenkins（二） 搭建简单的构建'","slug":"jenkins-use","date":"2020-05-20T05:51:40.000Z","updated":"2020-11-12T04:17:00.622Z","comments":true,"path":"2020/05/20/jenkins-use/","link":"","permalink":"https://midkuro.gitee.io/2020/05/20/jenkins-use/","excerpt":"","text":"jenkins插件安装及环境配置在使用jenkins之前，我们先学会配置jenkins的环境以及插件的安装，jenkins的环境配置均支持自动下载安装，但是不建议，也许是个人对环境路径存放位置具有强迫症吧。 首先进入jenkins页面，点击左侧 系统管理 ,然后找到 全局工具配置 然后选中 JDK及Maven的环境进行配置，点击新增将出现配置路径，将已安装的JDK及Maven路径配置上即可,对git有需要的可以自行配置. 配置完成后点击下方的save进行保存，接下来进入插件安装，点击插件管理，并进入可选插件界面 在该界面中，请不要使用右上角的 过滤 功能，由于插件过多，使用jenkins自带的过滤功能会导致浏览器卡死，所以请使用浏览器内容搜索的功能 ctrl + F在浏览器的搜索框中输入 Maven Integration 搜索maven插件，不同的插件版本命名可能略有差异，找到maven插件后在左边文本框中打钩，点击下方直接安装即可 在安装过程中，有一个安装后重启jenkins的设置，建议取消打钩，等待安装完成即可. jenkins基于maven编译简单的java项目在主界面中点击新建任务 进行创建，此时能够看到构建一个maven项目,该选项是需要安装 Maven Integration 才会出现的，选中它并输入项目名称，点击下方的确认按钮 上图的步骤2也可以通过输入一个已存在的任务名称，将任务的所有配置拷贝复制到新建任务当中. General：建议一定要勾选丢弃旧的构建，并配置构建保留天数及数量，可以配置10天、10个，感觉足以，不丢弃旧的构建容易把磁盘空间占满. 源码管理：选中SVN（Git操作也差不多）,并输入项目的svn路径，然后添加svn访问用户，输入账号密码即可，jenkins会自动帮你检测该账号能否访问svn路径并提示。 构建触发器配置： 第一个参数代表的是分钟 minute，取值 0~59； 第二个参数代表的是小时 hour，取值 0~23； 第三个参数代表的是天 day，取值 1~31； 第四个参数代表的是月 month，取值 1~12； 最后一个参数代表的是星期 week，取值 0~7，0 和 7 都是表示星期天。 常用例子: 每小时构建一次： * H/1 * * * 每隔5分钟构建一次： H/5 * * * * 每天8点30分构建一次： 30 8 * * * 每个小时的第10分钟构建一次： 10 * * * * 每周六日的1点10分构建一次： 10 1 * * 6,0 Pre Steps：构建前需要执行的一些操作，可以选择shell脚本、window命令等，这个根据需求去研究如何配置，暂时不细讲 Build： 建议使用clean install 替换 clean package 命令,clean package是把项目打包到target下，它并不会打包到maven的仓库，而clean install会打包进maven的仓库，可以避免一些不必要的问题。 比如我曾经遇见过的一个问题，A项目依赖了B项目，而B项目使用的是clean package命令，导致A项目打包的时候去maven仓库找不到B项目的jar包，所以A项目一直打包失败。 Post Steps：构建后需要执行的一些操作，同Pre Steps，其中构建不稳定指的是最近的5次构建中，曾经出现过构建失败。 构建的邮件发送通知以后再细讲，配置到这后一个简单的构建任务就已经完成了，点击保存，界面会出现新建的构建任务，点击右边的构建即可。 进入项目详情，左下角能够看到一些构建历史，点击构建历史能够查看每一次的构建详情，也能看到触发的构建原因，SVN更新的版本、信息等。","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.gitee.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"}]},{"title":"'jenkins（一） 安装及卸载'","slug":"jenkins-install","date":"2020-05-20T05:50:40.000Z","updated":"2020-11-12T04:16:38.624Z","comments":true,"path":"2020/05/20/jenkins-install/","link":"","permalink":"https://midkuro.gitee.io/2020/05/20/jenkins-install/","excerpt":"","text":"安装JDK使用jenkins，需要安装jdk及maven，可以自己安装于本机，也可以通过安装完jenkins后进行自动安装。 jdk-8u201-linux-x64.tar.gz 下载地址 官网地址 apache-maven-3.6.0-bin.tar.gz 下载地址 官网地址 如需更换版本请另行到官网中下载,在linux系统中安装包请选择 linux-x64.tar.gz后缀的安装包进行下载. 下文涉及到JDK及Maven版本相关的命令请自行修改成对应的版本. 在linux终端输入命令 cd /usr/local/ ，并创建java文件夹 mkdir java 执行 cd java 进入java路径中，并将下载的安装包上传至该路径 /usr/local/java下 然后执行命令解压下载的压缩包: tar -zxvf jdk-8u201-linux-x64.tar.gz 若提示错误则请先执行 yum install -y tar 安装压缩包命令再执行解压命令(仅限centos，其他系统请自行百度). 使用vi进入文件编辑模式，配置环境变量:vi /etc/profile 敲击键盘i进入编辑模式，在文件末尾添加以下内容: 12345export JAVA_HOME=/usr/local/java/jdk1.8.0_201export JAVA_BIN=/usr/local/java/jdk1.8.0_201/binexport PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$PATH 敲击键盘:wq 表示退出vi编辑模式并保存修改 执行命令使系统环境变量配置重新加载：source /etc/profile 测试JDK安装是否成功,输入 javac 和java -version 是否安装成功.出现下图类似的信息即安装成功 安装Maven操作与JDK基本相同，Maven环境变量需要配置的内容： 12export MAVEN_HOME=/usr/local/maven/apache-maven-3.6.0export PATH=$PATH:$MAVEN_HOME/bin` 测试Maven安装是否成功，输入 mvn -v 或者 mvn -version 即可. 安装Jenkinsjenkins安装包 jenkins-2.138.3-1.1.noarch.rpm 下载地址 官网地址 不同版本的jenkins安装插件的成功率不一样，推荐使用该jenkins版本，支持中文，并且插件安装的成功率较高。 上传安装包至linux服务器任意路径下，并在该路径下执行 rpm -ivh jenkins-2.138.3-1.1.noarch.rpm 进行安装 安装成功后可查看jenkins默认安装目录： rpm -ql jenkins 可自定义修改jenkins配置文件： vi /etc/sysconfig/jenkins 123456#jenkins端口配置JENKINS_PORT=\"8080\"#启动jenkins的用户，最好使用root，否则会出现权限不够等问题JENKINS_USER=\"jenkins\"#jenkins的项目路径，建议将其改成 `/data/jenkins` 放在大空间的路径下，避免出现空间不足等问题JENKINS_HOME=\"/var/lib/jenkins\" 若修改了JENKINS_HOME 配置，则需执行 cp -r 原路径 目标路径 命令，其中 -r 参数表示若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件. 根据上文将/var/lib/jenkins/路径修改为 /data/jenkins,则执行的命令为 cp -r /var/lib/jenkins/* /data/jenkins/ 退出vi编辑模式并保存 然后设置jenkins服务开机自启动: systemctl enable jenkins.service 启动jenkins: systemtl start jenkins.service ，将start改为restart、stop分别为重启、停止jenkins 如果启动时报错 Starting Jenkins -bash: /usr/bin/java: No such file or directory，则需要编辑文件 vim /etc/init.d/jenkins，将/usr/bin/java改为自己java的地址，自己java地址的查看命令 which java 启动jenkins后，浏览器访问 http://ip:端口 第一次登录Jenkins会要求解锁，复制红色标记中的路径，执行命令 cat 红色标记的路径，将返回的密码填入浏览器页面中，点击continue继续 输入完成后会提示安装自定义插件还是推荐插件，此处我选择左边的推荐插件，安装过程可能由于网络原因导致失败，后续失败的可以在系统设置-插件管理里面卸载或者重新安装即可，也可以在插件安装完成后选择retry重新安装失败的插件，尝试多几次即可。 创建用户并登陆 看到以下界面则代表jenkins已安装成功，到这里linux下安装配置jenkins教程就结束了 卸载Jenkins依次执行以下命令彻底卸载Jenkins 123456service jenkins stopyum clean allyum -y remove jenkinsrm -rf /var/cache/jenkins#请修改为自身机器的jenkins的路径rm -rf /var/lib/jenkins/","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.gitee.io/categories/Jenkins/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"}]}],"categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/categories/Elasticsearch/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://midkuro.gitee.io/categories/HTTPS/"},{"name":"LVS","slug":"LVS","permalink":"https://midkuro.gitee.io/categories/LVS/"},{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/categories/Spring/"},{"name":"Mybatis","slug":"Spring/Mybatis","permalink":"https://midkuro.gitee.io/categories/Spring/Mybatis/"},{"name":"SpringMVC","slug":"Spring/Mybatis/SpringMVC","permalink":"https://midkuro.gitee.io/categories/Spring/Mybatis/SpringMVC/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://midkuro.gitee.io/categories/Mybatis/"},{"name":"algorithm","slug":"algorithm","permalink":"https://midkuro.gitee.io/categories/algorithm/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.gitee.io/categories/Thread/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/categories/JVM/"},{"name":"NIO","slug":"NIO","permalink":"https://midkuro.gitee.io/categories/NIO/"},{"name":"HashMap","slug":"HashMap","permalink":"https://midkuro.gitee.io/categories/HashMap/"},{"name":"binary","slug":"binary","permalink":"https://midkuro.gitee.io/categories/binary/"},{"name":"Synchronized","slug":"Synchronized","permalink":"https://midkuro.gitee.io/categories/Synchronized/"},{"name":"springMVC","slug":"springMVC","permalink":"https://midkuro.gitee.io/categories/springMVC/"},{"name":"MYSQL","slug":"MYSQL","permalink":"https://midkuro.gitee.io/categories/MYSQL/"},{"name":"Netty","slug":"Netty","permalink":"https://midkuro.gitee.io/categories/Netty/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.gitee.io/categories/RocketMQ/"},{"name":"Seata","slug":"Seata","permalink":"https://midkuro.gitee.io/categories/Seata/"},{"name":"Stream","slug":"Stream","permalink":"https://midkuro.gitee.io/categories/Stream/"},{"name":"Sentinel","slug":"Sentinel","permalink":"https://midkuro.gitee.io/categories/Sentinel/"},{"name":"Nacos","slug":"Nacos","permalink":"https://midkuro.gitee.io/categories/Nacos/"},{"name":"Zuul","slug":"Zuul","permalink":"https://midkuro.gitee.io/categories/Zuul/"},{"name":"Hystrix","slug":"Hystrix","permalink":"https://midkuro.gitee.io/categories/Hystrix/"},{"name":"Config","slug":"Config","permalink":"https://midkuro.gitee.io/categories/Config/"},{"name":"Feign","slug":"Feign","permalink":"https://midkuro.gitee.io/categories/Feign/"},{"name":"Eureka","slug":"Eureka","permalink":"https://midkuro.gitee.io/categories/Eureka/"},{"name":"SSO","slug":"SSO","permalink":"https://midkuro.gitee.io/categories/SSO/"},{"name":"Security","slug":"Security","permalink":"https://midkuro.gitee.io/categories/Security/"},{"name":"Cache","slug":"Cache","permalink":"https://midkuro.gitee.io/categories/Cache/"},{"name":"Starter","slug":"Starter","permalink":"https://midkuro.gitee.io/categories/Starter/"},{"name":"Druid","slug":"Druid","permalink":"https://midkuro.gitee.io/categories/Druid/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.gitee.io/categories/Cryptography/"},{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/categories/Redis/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/categories/ActiveMQ/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.gitee.io/categories/Kubernetes/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/categories/Docker/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://midkuro.gitee.io/categories/Nodejs/"},{"name":"Linux","slug":"Linux","permalink":"https://midkuro.gitee.io/categories/Linux/"},{"name":"Systemctl","slug":"Systemctl","permalink":"https://midkuro.gitee.io/categories/Systemctl/"},{"name":"Firewall","slug":"Firewall","permalink":"https://midkuro.gitee.io/categories/Firewall/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://midkuro.gitee.io/categories/Jenkins/"}],"tags":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"https://midkuro.gitee.io/tags/Elasticsearch/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://midkuro.gitee.io/tags/HTTPS/"},{"name":"LVS","slug":"LVS","permalink":"https://midkuro.gitee.io/tags/LVS/"},{"name":"Java","slug":"Java","permalink":"https://midkuro.gitee.io/tags/Java/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://midkuro.gitee.io/tags/Mybatis/"},{"name":"algorithm","slug":"algorithm","permalink":"https://midkuro.gitee.io/tags/algorithm/"},{"name":"Thread","slug":"Thread","permalink":"https://midkuro.gitee.io/tags/Thread/"},{"name":"JVM","slug":"JVM","permalink":"https://midkuro.gitee.io/tags/JVM/"},{"name":"NIO","slug":"NIO","permalink":"https://midkuro.gitee.io/tags/NIO/"},{"name":"Spring","slug":"Spring","permalink":"https://midkuro.gitee.io/tags/Spring/"},{"name":"HashMap","slug":"HashMap","permalink":"https://midkuro.gitee.io/tags/HashMap/"},{"name":"Linux","slug":"Linux","permalink":"https://midkuro.gitee.io/tags/Linux/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://midkuro.gitee.io/tags/SpringMVC/"},{"name":"MYSQL","slug":"MYSQL","permalink":"https://midkuro.gitee.io/tags/MYSQL/"},{"name":"Netty","slug":"Netty","permalink":"https://midkuro.gitee.io/tags/Netty/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://midkuro.gitee.io/tags/RocketMQ/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://midkuro.gitee.io/tags/SpringCloud/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://midkuro.gitee.io/tags/SpringBoot/"},{"name":"Cryptography","slug":"Cryptography","permalink":"https://midkuro.gitee.io/tags/Cryptography/"},{"name":"Redis","slug":"Redis","permalink":"https://midkuro.gitee.io/tags/Redis/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://midkuro.gitee.io/tags/ActiveMQ/"},{"name":"DevOps","slug":"DevOps","permalink":"https://midkuro.gitee.io/tags/DevOps/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://midkuro.gitee.io/tags/Kubernetes/"},{"name":"Docker","slug":"Docker","permalink":"https://midkuro.gitee.io/tags/Docker/"},{"name":"Nginx","slug":"Nginx","permalink":"https://midkuro.gitee.io/tags/Nginx/"}]}